Commit Message,predict
from Cython.Distutils import build_ext,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
"node_desat=None,",0
Extract node color data,0
Extract edge color data,0
Compute or extract layout,0
Add edges,0
Add FLASC features,0
Add raw data features,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
Support branch detection within clusters.,0
Select finite data points,0
Construct tree,0
Allocate to maintain data point indices,0
Find neighbours for non-noise points,0
Check clusterer state,0
Validate parameters,0
Extract state,0
Configure parallelization,0
Detect branches,0
Maintain data indices for non-finite data,0
Combined result,0
Branching result,0
Clusters to branches,0
List points within cluster,0
Extract MST edges within cluster,0
Compute in cluster centrality,0
Construct cluster approximation graph,0
Extract centrality MST and compute single linkage,0
Re-label edges with data ids,0
Return values,0
Allocate output (won't be filled completely),0
Fill (undirected) MST edges with within-cluster-ids,0
Fill neighbors with within-cluster-ids,0
Fill mutual reachabilities,0
Extract unique edges that stay within the cluster,0
Query KDTree/BallTree for neighours within the distance,0
Count number of returned edges per point,0
Create full edge list,0
Create output,0
Reset noise labels to k-cluster,0
Allocate output,0
Compute the labels and probabilities,0
Reorder other parts,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
"If the following line does not raise an error, the test passes",0
"If the following line does not raise an error, the test passes",0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
--- Branch Detection Data,0
There are no fast metrics that are not supported by KDTree or BallTree!,0
"Cosine and arccoss both crash HDBSCAN. They go down the BallTree path, but",0
the implementation does not support them.,0
Distance matrix,0
Sparse matrix,0
--- Detecting Branches,0
Generate single-cluster data,0
"Without persistence, find 6 branches",0
"Mac & Windows give 71, Linux gives 72. Probably different random values.",0
Adding presistence removes some branches,0
--- Branch Detector Functionality,0
A point on a branch (not noise) exact labels change per run,0
A point in a cluster,0
A noise point,0
--- Attribute Output Formats,0
--- Attribute plots,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
from Cython.Distutils import build_ext,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
"node_desat=None,",0
Extract node color data,0
Extract edge color data,0
Compute or extract layout,0
Add edges,0
Add FLASC features,0
Add raw data features,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
Support branch detection within clusters.,0
Select finite data points,0
Construct tree,0
Allocate to maintain data point indices,0
Find neighbours for non-noise points,0
Check clusterer state,0
Validate parameters,0
Extract state,0
Configure parallelization,0
Detect branches,0
Maintain data indices for non-finite data,0
Combined result,0
Branching result,0
Clusters to branches,0
List points within cluster,0
Extract MST edges within cluster,0
Compute in cluster centrality,0
Construct cluster approximation graph,0
Extract centrality MST and compute single linkage,0
Re-label edges with data ids,0
Return values,0
Allocate output (won't be filled completely),0
Fill (undirected) MST edges with within-cluster-ids,0
Fill neighbors with within-cluster-ids,0
Fill mutual reachabilities,0
Extract unique edges that stay within the cluster,0
Query KDTree/BallTree for neighours within the distance,0
Count number of returned edges per point,0
Create full edge list,0
Create output,0
Reset noise labels to k-cluster,0
Allocate output,0
Compute the labels and probabilities,0
Reorder other parts,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
--- Branch Detection Data,0
There are no fast metrics that are not supported by KDTree or BallTree!,0
"Cosine and arccoss both crash HDBSCAN. They go down the BallTree path, but",0
the implementation does not support them.,0
Distance matrix,0
Sparse matrix,0
--- Detecting Branches,0
Generate single-cluster data,0
"Without persistence, find 6 branches",0
"Mac & Windows give 71, Linux gives 72. Probably different random values.",0
Adding presistence removes some branches,0
--- Branch Detector Functionality,0
A point on a branch (not noise) exact labels change per run,0
A point in a cluster,0
A noise point,0
--- Attribute Output Formats,0
--- Attribute plots,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
"node_desat=None,",0
Extract node color data,0
Extract edge color data,0
Compute or extract layout,0
Add edges,0
Add FLASC features,0
Add raw data features,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
Support branch detection within clusters.,0
Select finite data points,0
Construct tree,0
Allocate to maintain data point indices,0
Find neighbours for non-noise points,0
Check clusterer state,0
Validate parameters,0
Extract state,0
Configure parallelization,0
Detect branches,0
Maintain data indices for non-finite data,0
Combined result,0
Branching result,0
Clusters to branches,0
List points within cluster,0
Extract MST edges within cluster,0
Compute in cluster centrality,0
Construct cluster approximation graph,0
Extract centrality MST and compute single linkage,0
Re-label edges with data ids,0
Return values,0
Allocate output (won't be filled completely),0
Fill (undirected) MST edges with within-cluster-ids,0
Fill neighbors with within-cluster-ids,0
Fill mutual reachabilities,0
Extract unique edges that stay within the cluster,0
Query KDTree/BallTree for neighours within the distance,0
Count number of returned edges per point,0
Create full edge list,0
Create output,0
Reset noise labels to k-cluster,0
Allocate output,0
Compute the labels and probabilities,0
Reorder other parts,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
--- Branch Detection Data,0
There are no fast metrics that are not supported by KDTree or BallTree!,0
"Cosine and arccoss both crash HDBSCAN. They go down the BallTree path, but",0
the implementation does not support them.,0
Distance matrix,0
Sparse matrix,0
--- Detecting Branches,0
Generate single-cluster data,0
"Without persistence, find 6 branches",0
"Mac & Windows give 71, Linux gives 72. Probably different random values.",0
Adding presistence removes some branches,0
--- Branch Detector Functionality,0
A point on a branch (not noise) exact labels change per run,0
A point in a cluster,0
A noise point,0
--- Attribute Output Formats,0
--- Attribute plots,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
"node_desat=None,",0
Extract node color data,0
Extract edge color data,0
Compute or extract layout,0
Add edges,0
Add FLASC features,0
Add raw data features,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
Support branch detection within clusters.,0
Select finite data points,0
Construct tree,0
Allocate to maintain data point indices,0
Find neighbours for non-noise points,0
Check clusterer state,0
Validate parameters,0
Extract state,0
Configure parallelization,0
Detect branches,0
Maintain data indices for non-finite data,0
Combined result,0
Branching result,0
Clusters to branches,0
List points within cluster,0
Extract MST edges within cluster,0
Compute in cluster centrality,0
Construct cluster approximation graph,0
Extract centrality MST and compute single linkage,0
Re-label edges with data ids,0
Return values,0
Allocate output (won't be filled completely),0
Fill (undirected) MST edges with within-cluster-ids,0
Fill neighbors with within-cluster-ids,0
Fill mutual reachabilities,0
Extract unique edges that stay within the cluster,0
Query KDTree/BallTree for neighours within the distance,0
Count number of returned edges per point,0
Create full edge list,0
Create output,0
Reset noise labels to k-cluster,0
Allocate output,0
Compute the labels and probabilities,0
Reorder other parts,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
--- Branch Detection Data,0
There are no fast metrics that are not supported by KDTree or BallTree!,0
"Cosine and arccoss both crash HDBSCAN. They go down the BallTree path, but",0
the implementation does not support them.,0
Distance matrix,0
Sparse matrix,0
--- Detecting Branches,0
Generate single-cluster data,0
"Without persistence, find 6 branches",0
"Mac & Windows give 71, Linux gives 72. Probably different random values.",0
Adding presistence removes some branches,0
--- Branch Detector Functionality,0
A point on a branch (not noise) exact labels change per run,0
A point in a cluster,0
A noise point,0
--- Attribute Output Formats,0
--- Attribute plots,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
"node_desat=None,",0
Extract node color data,0
Extract edge color data,0
Compute or extract layout,0
Add edges,0
Add FLASC features,0
Add raw data features,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
Support branch detection within clusters.,0
Select finite data points,0
Construct tree,0
Allocate to maintain data point indices,0
Find neighbours for non-noise points,0
Check clusterer state,0
Validate parameters,0
Extract state,0
Configure parallelization,0
Detect branches,0
Maintain data indices for non-finite data,0
Combined result,0
Branching result,0
Clusters to branches,0
List points within cluster,0
Extract MST edges within cluster,0
Compute in cluster centrality,0
Construct cluster approximation graph,0
Extract centrality MST and compute single linkage,0
Re-label edges with data ids,0
Return values,0
Allocate output (won't be filled completely),0
Fill (undirected) MST edges with within-cluster-ids,0
Fill neighbors with within-cluster-ids,0
Fill mutual reachabilities,0
Extract unique edges that stay within the cluster,0
Query KDTree/BallTree for neighours within the distance,0
Count number of returned edges per point,0
Create full edge list,0
Create output,0
Reset noise labels to k-cluster,0
Allocate output,0
Compute the labels and probabilities,0
Reorder other parts,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
--- Branch Detection Data,0
There are no fast metrics that are not supported by KDTree or BallTree!,0
"Cosine and arccoss both crash HDBSCAN. They go down the BallTree path, but",0
the implementation does not support them.,0
Distance matrix,0
Sparse matrix,0
--- Detecting Branches,0
Generate single-cluster data,0
"Without persistence, find 6 branches",0
"Mac & Windows give 71, Linux gives 72. Probably different random values.",0
Adding presistence removes some branches,0
--- Branch Detector Functionality,0
A point on a branch (not noise) exact labels change per run,0
A point in a cluster,0
A noise point,0
--- Attribute Output Formats,0
--- Attribute plots,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
"node_desat=None,",0
Extract node color data,0
Extract edge color data,0
Compute or extract layout,0
Add edges,0
Add FLASC features,0
Add raw data features,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
Support branch detection within clusters.,0
Select finite data points,0
Construct tree,0
Allocate to maintain data point indices,0
Find neighbours for non-noise points,0
Check clusterer state,0
Validate parameters,0
Extract state,0
Configure parallelization,0
Detect branches,0
Maintain data indices for non-finite data,0
Combined result,0
Branching result,0
Clusters to branches,0
List points within cluster,0
Extract MST edges within cluster,0
Compute in cluster centrality,0
Construct cluster approximation graph,0
Extract centrality MST and compute single linkage,0
Re-label edges with data ids,0
Return values,0
Allocate output (won't be filled completely),0
Fill (undirected) MST edges with within-cluster-ids,0
Fill neighbors with within-cluster-ids,0
Fill mutual reachabilities,0
Extract unique edges that stay within the cluster,0
Query KDTree/BallTree for neighours within the distance,0
Count number of returned edges per point,0
Create full edge list,0
Create output,0
Reset noise labels to k-cluster,0
Allocate output,0
Compute the labels and probabilities,0
Reorder other parts,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
--- Branch Detection Data,0
There are no fast metrics that are not supported by KDTree or BallTree!,0
"Cosine and arccoss both crash HDBSCAN. They go down the BallTree path, but",0
the implementation does not support them.,0
Distance matrix,0
Sparse matrix,0
--- Detecting Branches,0
Generate single-cluster data,0
"Without persistence, find 6 branches",0
"Mac & Windows give 71, Linux gives 72. Probably different random values.",0
Adding presistence removes some branches,0
--- Branch Detector Functionality,0
A point on a branch (not noise) exact labels change per run,0
A point in a cluster,0
A noise point,0
--- Attribute Output Formats,0
--- Attribute plots,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"assert ""Cannot predict"" in str(w[-1].message)",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Non-precomputed matrices may contain non-finite values.,0
Rows with these values,0
Pass only the purely finite indices into hdbscan,0
We will later assign all non-finite points to the background -1 cluster,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
remap indices to align with original data in the case of non-finite entries.,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
Extract flat clustering from HDBSCAN's hierarchy for 7 clusters,0
Use a previously initialized/trained HDBSCAN,0
Handle the trivial case first.,0
Always generate prediction_data to avoid later woes,0
This will later be chosen according to n_clusters,0
Initialize and train clusterer if one was not previously supplied.,0
Always generate prediction data,0
We do not pass cluster_selection_epsilon here.,0
"While this adds unnecessary computation, it makes the code",0
easier to read and debug.,0
"Train on 'X'. Do this even if the supplied clusterer was trained,",0
because we want to make sure it fits 'X'.,0
"Pick an epsilon value right after a split produces n_clusters,",0
and the don't split further for smaller epsilon (larger lambda),0
Or use the specified cluster_selection_epsilon,0
"Extract tree related stuff, in order to re-assign labels",0
Get labels according to the required cluster_selection_epsilon,0
Reflect the related changes in HDBSCAN.,0
PredictionData attached to HDBSCAN should also change.,0
A function re_init is defined in this module to handle this.,0
"From a fitted HDBSCAN model, predict for n_clusters=5",0
Store prediciton data for later use.,0
and use this prediction data to predict on new points,0
Get number of fitted clusters for later use.,0
We'll need the condensed tree later...,0
"If none of the three arguments: prediction_data, n_clusters,",0
"and cluster_selection_epsilon are supplied,",0
then use clusterer's prediciton data directly,0
"If either of n_clusters or cluster_selection_epsilon were supplied,",0
then build prediction data from these by modifying clusterer's,0
Get prediction data from clusterer,0
Modify prediction_data to reflect new n_clusters,0
"First, make a copy of prediction data to avoid modifying source",0
Cluster selection method is hold by condensed_tree.,0
Change from 'eom' to 'leaf' if n_clusters is too large.,0
This change does not affect the tree associated with 'clusterer',0
Re-initialize prediction_data for the specified n_clusters or epsilon,0
============================================================,0
Now we're ready to use prediction_data,0
"The rest of the code is copied from HDBSCAN's approximate_predict,",0
but modified to use prediction_data instead of clusterer's attribute,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering from prediction data,0
Initialize probabilities,0
k-NN for prediciton points to training set,0
Loop over prediction points to compute probabilities,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"Find row in tree where nearest neighbor drops out,",0
so we can get a lambda value for the nearest neighbor,0
"Assign lambda as min(lambda-to-neighbor, neighbor's-lambda-to-tree)",0
"Equivalently, this assigns core distance for prediction point as",0
"max(dist-to-neighbor, neighbor's-dist-to-tree)",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the nearest exemplar persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Merge the two probabilities to produce a single set of probabilities,0
Include probability that the nearest neighbor belongs to a cluster,0
Rename variable so it's easy to understand what's being returned,0
Extract condensed tree for later use,0
Choose flat clustering based on cluster_selection_epsilon or n_clusters.,0
"If neither is specified, use clusterer's cluster_selection_epsilon",0
Use the same prediction_data as clusterer's,0
Compute cluster_selection_epsilon so that a flat clustering,0
produces a specified number of n_clusters,0
"With method 'eom', we may fail to get 'n_clusters' clusters. So,",0
Create another instance of prediction_data that is consistent,0
with the selected value of epsilon.,0
Flat clustering at the chosen epsilon from prediction_data,0
"When no clusters found, return array of 0's",0
Probabilities based on distance to closest exemplar in each cluster:,0
Use new prediction_data that points to exemplars that are specific,0
to the choice of n_clusters,0
Probabilities based on how long the point persists in,0
each cluster (with respect to most persistent exemplar),0
Use new clusters that are defined by the choice of n_clusters.,0
Include probability that the point belongs to a cluster,0
Aggregate the three probabilities to produce membership vectors,0
Re-name variable to clarify what's being returned.,0
"With method 'eom', max clusters are produced for epsilon=0,",0
as computed by,0
Increasing epsilon can only reduce the number of ouput clusters.,0
"To select epsilon, consider all values where clusters are split",0
Subtract the extra e-12 to avoid numerical errors in comparison,0
"Then, we avoid splitting for all epsilon below this.",0
Use an epsilon value that produces the right number of clusters.,0
The condensed tree of HDBSCAN has this information.,0
Extract the lambda levels (=1/distance) from the condensed tree,0
We don't want values that produce a large cluster and,0
just one or two individual points.,0
Keep only those lambda values corresponding to cluster separation;,0
"i.e., with child_sizes > 1",0
"Get the unique values, because when two clusters fall out of one,",0
the entry with lambda is repeated.,0
lambda values are sorted by np.unique.,0
"Now, get epsilon (distance threshold) as 1/lambda",0
"At this epsilon, n_clusters have been split.",0
Stop splits at epsilons smaller than this.,0
"To allow for numerical errors,",0
predData must be a pre-trained PredictionData instance from hdbscan,0
"If n_clusters is specified, compute cluster_selection_epsilon;",0
This is the key modification:,0
Select clusters according to selection method and epsilon.,0
_new_select_clusters is a modification of get_clusters,0
from hdbscan._hdbscan_tree,0
"raw tree, used later to get exemplars and lambda values",0
"Re-do the cluster map: Map cluster numbers in tree (N, N+1, ..)",0
to the cluster labels produced as output,0
Re-compute lambdas and exemplars for selected clusters;,0
max_lambda <=> smallest distance <=> most persistent point(s),0
Map all sub-clusters of selected cluster to the selected cluster's,0
label in output.,0
Map lambdas too...,0
Create set of exemplar points for later use.,0
Novel points are assigned based on cluster of closest exemplar.,0
"For each selected cluster, get all of its leaves,",0
"and leaves of leaves, and so on...",0
Largest lambda => Most persistent points,0
Get the most persistent points,0
Add most persistent points as exemplars,0
Add exemplars for each leaf of each selected cluster.,0
(exclude root),0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
"the point is in the dataset, fix lambda for rounding errors",0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
no prediction data error,0
wrong dimensions error,0
no clusters warning,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
without epsilon we should see many noise points as children of root.,0
for this random seed an epsilon of 0.2 will produce exactly 2 noise,0
points at that cut in single linkage.,0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
"Given negative, zero and positive denominator and positive numerator",0
Make sure safe division is always positive and doesn't raise ZeroDivision error,0
Ignore future warnings thrown by sklearn,0
Create a nice dataset with 6 circular clusters and 2 moons,0
"Given, the base HDBSCAN with method 'eom'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
"Given, the base HDBSCAN with method 'leaf'",0
"When we ask for flat clustering with same n_clusters,",0
"Then, the labels and probabilities should match",0
Method 'eom'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
Method 'leaf'...,0
"Given, a flat clustering for required n_clusters,",0
"When we run the base HDBSCAN using it's epsilon,",0
"Then, the labels and probabilities should match",0
"Given the max number of clusters that can be produced by 'eom',",0
(these are produced for epsilon=0) (??? Needs verification),0
"When we try flat clustering with 'eom' method for more n_clusters,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
"the resulting clusterer switches to using method 'leaf',",0
and the resulting probabilities and labels must match,0
"Given the base HDBSCAN trained on some data,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the clustering should match that due to approximate_predict,",0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat without specifying n_clusters,",0
"Then, the number of clusters produced must match the original n_clusters",0
and all probabilities are <= 1.,0
"Given a flat clustering trained for some n_clusters,",0
"When using approximate_predict_flat with specified n_clusters,",0
"Then, the requested number of clusters must be produced",0
and all probabilities are <= 1.,0
When using approximate_predict_flat with more clusters,0
"than 'eom' can handle,",0
"Then, a warning is raised saying 'eom' can't get this clustering,",0
But the requested number of clusters must still be produced using 'leaf',0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called with new data for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the test set,0
and all probabilities are <= 1.,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When all_points_membership_vectors_flat is called,",0
"Then the number of clusters in memberships matches those of clusterer,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Ignore user warnings in this function,0
"Given a flat clustering trained for n_clusters picked by HDBSCAN,",0
"When all_points_membership_vectors_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
========================================,0
"Given a flat clustering for a specified n_clusters,",0
"When membership_vector_flat is called for some n_clusters,",0
"Then the number of clusters in memberships should be as requested,",0
and the number of points should equal those in the training set,0
and all probabilities are <= 1.,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
this fails if no $DISPLAY specified,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Extract the chosen cluster bounds. If enough duplicate data points exist in the,0
data the lambda value might be infinite. This breaks labeling and highlighting,0
the chosen clusters.,0
Extract the plot range of the y-axis and set default center and height values for ellipses.,0
Extremly dense clusters might result in near infinite lambda values. Setting max_height,0
based on the percentile should alleviate the impact on plotting.,0
Set center and height to default values if necessary,0
Ensure the ellipse is visible,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
Disable for now -- need to refactor to meet newer standards,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Disable for now -- need to refactor to meet newer standards,0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Check for connected component on X,0
Compute sparse mutual reachability graph,0
"if max_dist > 0, max distance to use when the reachability is infinite",0
Check connected component on mutual reachability,0
"If more than one component, it means that even if the distance matrix X",0
"has one component, there exists with less than `min_samples` neighbors",0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
"Unltimately, for each Ci, we only require the",0
"minimum of DSPC(Ci, Cj) over all Cj != Ci.",0
"So let's call this value DSPC_wrt(Ci), i.e.",0
density separation 'with respect to' Ci.,0
If exactly one of the points is noise,0
Set the density sparseness of the cluster,0
to the sparsest value seen so far.,0
Check whether density separations with,0
respect to each of these clusters can,0
be reduced.,0
"In case min_outlier_sep is still np.inf, we assign a new value to it.",0
This only makes sense if num_clusters = 1 since it has turned out,0
that the MR-MST has no edges between a noise point and a core point.,0
DSPC_wrt[Ci] might be infinite if the connected component for Ci is,0
"an ""island"" in the MR-MST. Whereas for other clusters Cj and Ck, the",0
MR-MST might contain an edge with one point in Cj and ther other one,0
"in Ck. Here, we replace the infinite density separation of Ci by",0
another large enough value.,0
,0
TODO: Think of a better yet efficient way to handle this.,1
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
The dependencies are the same as the contents of requirements.txt,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"Treating this case explicitly, instead of letting",0
"sklearn.metrics.pairwise_distances handle it,",0
enables the usage of numpy.inf in the distance,0
matrix to indicate missing distance information.,0
TODO: Check if copying is necessary,1
raise TypeError('Sparse distance matrices not yet supported'),0
Warn if the MST couldn't be constructed around the missing distances,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
"Only non-sparse, precomputed distance matrices are handled here",0
and thereby allowed to contain numpy.inf for missing distances,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
Handle sparse precomputed distance matrices separately,0
"Only non-sparse, precomputed distance matrices are allowed",0
to have numpy.inf values indicating missing distances,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
"for xs, ys in zip(plot_data['line_xs'], plot_data['line_ys']):",0
"axis.plot(xs, ys, color='black', linewidth=1)",0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"Import numpy here, only when headers are needed",0
Add numpy headers to include_dirs,0
Call original build_ext command,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
"Return the only cluster, the root",0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
"When no clusters found, return array of 0's",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
assert_array_almost_equal(,0
"vector,",0
"np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
def test_rsl_unavailable_hierarchy():,0
clusterer = RobustSingleLinkage(),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.cluster_hierarchy_,0
assert len(w) > 0,0
assert tree is None,0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_unavailable_attributes():,0
clusterer = HDBSCAN(gen_min_span_tree=False),0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.condensed_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.single_linkage_tree_,0
assert len(w) > 0,0
assert tree is None,0
with warnings.catch_warnings(record=True) as w:,0
scores = clusterer.outlier_scores_,0
assert len(w) > 0,0
assert scores is None,0
with warnings.catch_warnings(record=True) as w:,0
tree = clusterer.minimum_spanning_tree_,0
assert len(w) > 0,0
assert tree is None,0
def test_hdbscan_min_span_tree_availability():,0
clusterer = HDBSCAN().fit(X),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
D = distance.squareform(distance.pdist(X)),0
D /= np.max(D),0
HDBSCAN(metric='precomputed').fit(D),0
tree = clusterer.minimum_spanning_tree_,0
assert tree is None,0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
def test_hdbscan_membership_vector():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
"vector = membership_vector(clusterer, np.array([[-1.5, -1.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.05705305,  0.05974177,  0.12228153]]))",0
"vector = membership_vector(clusterer, np.array([[1.5, -1.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.09462176,  0.32061556,  0.10112905]]))",0
"vector = membership_vector(clusterer, np.array([[0.0, 0.0]]))",0
"assert_array_almost_equal(vector, np.array([[ 0.03545607,  0.03363318,  0.04643177]]))",0
,0
def test_hdbscan_all_points_membership_vectors():,0
clusterer = HDBSCAN(prediction_data=True).fit(X),0
vects = all_points_membership_vectors(clusterer),0
"assert_array_almost_equal(vects[0], np.array([7.86400992e-002,",0
"2.52734246e-001,",0
8.38299608e-002])),0
"assert_array_almost_equal(vects[-1], np.array([8.09055344e-001,",0
"8.35882503e-002,",0
1.07356406e-001])),0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
"prediction data only applies to the persistent model, so remove",0
it from the keyword args we pass on the the function,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Support various prediction methods for predicting cluster membership,0
of new or unseen points. There are several ways to interpret how,0
"to do this correctly, so we provide several methods for",0
the different use cases that may arise.,0
raw_condensed_tree = condensed_tree.to_numpy(),0
New point departs with the old,0
Find appropriate cluster based on lambda of new point,0
Find appropriate cluster based on lambda of new point,0
We need to find where in the tree the new point would go,0
for the purposes of outlier membership approximation,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
"A little ""fancy"" we select from the flattened array reshape back",0
(Fortran format to get indexing right) and take the product to do an and,0
then convert back to boolean type.,0
Density sparseness is not well defined if there are no,0
internal edges (as per the referenced paper). However,0
MATLAB code from the original authors simply selects the,0
largest of *all* the edges in the case that there are,0
"no internal edges, so we do the same here",0
"If there are any internal edges, then subselect them out",0
If there are no internal edges then we want to take the,0
"max over all the edges that exist in the MST, so we simply",0
do nothing and return all the edges in the MST.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow",0
"subclasses (e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same",0
"shape. Ideally, we'd just do x, y = broadcast_arrays(x, y).",0
"It's in lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
We can't do much with sparse matrices ...,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
We can't do much with sparse matrices ...,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
Need heuristic to decide when to go to boruvka;,0
still debugging for now,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
Probably not applicable now #,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Supporting numpy prior to version 1.7 is a little painful ...,0
Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).,0
"This will cause casting of x later. Also, make sure to allow subclasses",0
"(e.g., for numpy.ma).",0
"Because we're using boolean indexing, x & y must be the same shape.",0
"Ideally, we'd just do x, y = broadcast_arrays(x, y). It's in",0
"lib.stride_tricks, though, so we can't import it here.",0
Avoid subtraction with infinite/nan values...,0
Check for equality of infinite values...,0
Make NaN == NaN,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Ensure we don't try to take log of zero,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
The Cython routines used require contiguous arrays,0
The Cython routines used require contiguous arrays,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
"H, y = shuffle(X, y, random_state=7)",0
import pickle,0
from sklearn.cluster.tests.common import generate_clustered_data,0
"X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)",0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"H, y = shuffle(X, y, random_state=7)",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
"## We now install the package in a virtualenv to build docs, so this is not needed",0
"sys.path.insert(0, os.path.abspath('../'))",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
"'sphinx.ext.napoleon',",0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Try and work around older sklearn api,0
raise TypeError('Sparse distance matrices not yet supported'),0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Compute sparse mutual reachability graph,0
Compute the minimum spanning tree for the sparse graph,0
Convert the graph to scipy cluster array format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicit in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
"metric is the function reference, not the string key.",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
import pickle,0
"number of clusters, ignoring noise if present",0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
,0
"hdbscan documentation build configuration file, created by",0
sphinx-quickstart on Sat May 28 10:34:44 2016.,0
,0
This file is execfile()d with the current directory set to its,0
containing dir.,0
,0
Note that not all possible configuration values are present in this,0
autogenerated file.,0
,0
All configuration values have a default; values that are commented out,0
serve to show the default.,0
"If extensions (or modules to document with autodoc) are in another directory,",0
add these directories to sys.path here. If the directory is relative to the,0
"documentation root, use os.path.abspath to make it absolute, like shown here.",0
-- General configuration ------------------------------------------------,0
"If your documentation needs a minimal Sphinx version, state it here.",0
needs_sphinx = '1.0',0
"Add any Sphinx extension module names here, as strings. They can be",0
extensions coming with Sphinx (named 'sphinx.ext.*') or your custom,0
ones.,0
'sphinx.ext.napoleon',0
'numpy_ext.numpydoc',0
napoleon_google_docstring = False,0
napoleon_numpy_docstring = True,0
"Add any paths that contain templates here, relative to this directory.",0
The suffix(es) of source filenames.,0
You can specify multiple suffix as a list of string:,0
"source_suffix = ['.rst', '.md']",0
The encoding of source files.,0
source_encoding = 'utf-8-sig',0
The master toctree document.,0
General information about the project.,0
"The version info for the project you're documenting, acts as replacement for",0
"|version| and |release|, also used in various other places throughout the",0
built documents.,0
,0
The short X.Y version.,0
"The full version, including alpha/beta/rc tags.",0
The language for content autogenerated by Sphinx. Refer to documentation,0
for a list of supported languages.,0
,0
This is also used if you do content translation via gettext catalogs.,0
"Usually you set ""language"" from the command line for these cases.",0
"There are two options for replacing |today|: either, you set today to some",0
"non-false value, then it is used:",0
today = '',0
"Else, today_fmt is used as the format for a strftime call.",0
"today_fmt = '%B %d, %Y'",0
"List of patterns, relative to source directory, that match files and",0
directories to ignore when looking for source files.,0
The reST default role (used for this markup: `text`) to use for all,0
documents.,0
default_role = None,0
"If true, '()' will be appended to :func: etc. cross-reference text.",0
add_function_parentheses = True,0
"If true, the current module name will be prepended to all description",0
unit titles (such as .. function::).,0
add_module_names = True,0
"If true, sectionauthor and moduleauthor directives will be shown in the",0
output. They are ignored by default.,0
show_authors = False,0
The name of the Pygments (syntax highlighting) style to use.,0
A list of ignored prefixes for module index sorting.,0
modindex_common_prefix = [],0
"If true, keep warnings as ""system message"" paragraphs in the built documents.",0
keep_warnings = False,0
"If true, `todo` and `todoList` produce output, else they produce nothing.",1
-- Options for HTML output ----------------------------------------------,0
The theme to use for HTML and HTML Help pages.  See the documentation for,0
a list of builtin themes.,0
html_theme = 'alabaster',0
Theme options are theme-specific and customize the look and feel of a theme,0
"further.  For a list of options available for each theme, see the",0
documentation.,0
html_theme_options = {},0
"Add any paths that contain custom themes here, relative to this directory.",0
html_theme_path = [],0
"The name for this set of Sphinx documents.  If None, it defaults to",0
"""<project> v<release> documentation"".",0
html_title = None,0
A shorter title for the navigation bar.  Default is the same as html_title.,0
html_short_title = None,0
The name of an image file (relative to this directory) to place at the top,0
of the sidebar.,0
html_logo = None,0
The name of an image file (within the static path) to use as favicon of the,0
docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32,0
pixels large.,0
html_favicon = None,0
"Add any paths that contain custom static files (such as style sheets) here,",0
"relative to this directory. They are copied after the builtin static files,",0
"so a file named ""default.css"" will overwrite the builtin ""default.css"".",0
Add any extra paths that contain custom files (such as robots.txt or,0
".htaccess) here, relative to this directory. These files are copied",0
directly to the root of the documentation.,0
html_extra_path = [],0
"If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",0
using the given strftime format.,0
"html_last_updated_fmt = '%b %d, %Y'",0
"If true, SmartyPants will be used to convert quotes and dashes to",0
typographically correct entities.,0
html_use_smartypants = True,0
"Custom sidebar templates, maps document names to template names.",0
html_sidebars = {},0
"Additional templates that should be rendered to pages, maps page names to",0
template names.,0
html_additional_pages = {},0
"If false, no module index is generated.",0
html_domain_indices = True,0
"If false, no index is generated.",0
html_use_index = True,0
"If true, the index is split into individual pages for each letter.",0
html_split_index = False,0
"If true, links to the reST sources are added to the pages.",0
html_show_sourcelink = True,0
"If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.",0
html_show_sphinx = True,0
"If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.",0
html_show_copyright = True,0
"If true, an OpenSearch description file will be output, and all pages will",0
contain a <link> tag referring to it.  The value of this option must be the,0
base URL from which the finished HTML is served.,0
html_use_opensearch = '',0
"This is the file name suffix for HTML files (e.g. "".xhtml"").",0
html_file_suffix = None,0
Language to be used for generating the HTML full-text search index.,0
Sphinx supports the following languages:,0
"'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'",0
"'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'",0
html_search_language = 'en',0
"A dictionary with options for the search language support, empty by default.",0
Now only 'ja' uses this config value,0
html_search_options = {'type': 'default'},0
The name of a javascript file (relative to the configuration directory) that,0
"implements a search results scorer. If empty, the default will be used.",0
html_search_scorer = 'scorer.js',0
Output file base name for HTML help builder.,0
-- Options for LaTeX output ---------------------------------------------,0
The paper size ('letterpaper' or 'a4paper').,0
"'papersize': 'letterpaper',",0
"The font size ('10pt', '11pt' or '12pt').",0
"'pointsize': '10pt',",0
Additional stuff for the LaTeX preamble.,0
"'preamble': '',",0
Latex figure (float) alignment,0
"'figure_align': 'htbp',",0
Grouping the document tree into LaTeX files. List of tuples,0
"(source start file, target name, title,",0
"author, documentclass [howto, manual, or own class]).",0
The name of an image file (relative to this directory) to place at the top of,0
the title page.,0
latex_logo = None,0
"For ""manual"" documents, if this is true, then toplevel headings are parts,",0
not chapters.,0
latex_use_parts = False,0
"If true, show page references after internal links.",0
latex_show_pagerefs = False,0
"If true, show URL addresses after external links.",0
latex_show_urls = False,0
Documents to append as an appendix to all manuals.,0
latex_appendices = [],0
"If false, no module index is generated.",0
latex_domain_indices = True,0
-- Options for manual page output ---------------------------------------,0
One entry per manual page. List of tuples,0
"(source start file, name, description, authors, manual section).",0
"If true, show URL addresses after external links.",0
man_show_urls = False,0
-- Options for Texinfo output -------------------------------------------,0
Grouping the document tree into Texinfo files. List of tuples,0
"(source start file, target name, title, author,",0
"dir menu entry, description, category)",0
Documents to append as an appendix to all manuals.,0
texinfo_appendices = [],0
"If false, no module index is generated.",0
texinfo_domain_indices = True,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
texinfo_show_urls = 'footnote',0
"If true, do not generate a @detailmenu in the ""Top"" node's menu.",0
texinfo_no_detailmenu = False,0
-- Options for Epub output ----------------------------------------------,0
Bibliographic Dublin Core info.,0
The basename for the epub file. It defaults to the project name.,0
epub_basename = project,0
The HTML theme for the epub output. Since the default themes are not,0
"optimized for small screen space, using the same theme for HTML and epub",0
"output is usually not wise. This defaults to 'epub', a theme designed to save",0
visual space.,0
epub_theme = 'epub',0
The language of the text. It defaults to the language option,0
or 'en' if the language is not set.,0
epub_language = '',0
The scheme of the identifier. Typical schemes are ISBN or URL.,0
epub_scheme = '',0
The unique identifier of the text. This can be a ISBN number,0
or the project homepage.,0
epub_identifier = '',0
A unique identification for the text.,0
epub_uid = '',0
A tuple containing the cover image and cover page html template filenames.,0
epub_cover = (),0
"A sequence of (type, uri, title) tuples for the guide element of content.opf.",0
epub_guide = (),0
HTML files that should be inserted before the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_pre_files = [],0
HTML files that should be inserted after the pages created by sphinx.,0
The format is a list of tuples containing the path and title.,0
epub_post_files = [],0
A list of files that should not be packed into the epub file.,0
The depth of the table of contents in toc.ncx.,0
epub_tocdepth = 3,0
Allow duplicate toc entries.,0
epub_tocdup = True,0
Choose between 'default' and 'includehidden'.,0
epub_tocscope = 'default',0
Fix unsupported image types using the Pillow.,0
epub_fix_images = False,0
Scale large images.,0
epub_max_image_width = 0,0
"How to display URL addresses: 'footnote', 'no', or 'inline'.",0
epub_show_urls = 'inline',0
"If false, no index is generated.",0
epub_use_index = True,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Try and work around older sklearn api,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_vector,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
"metric is the function reference, not the string key.",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Try and work around older sklearn api,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
The Cython routines used require contiguous arrays,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
"metric is the function reference, not the string key.",0
"assert_equal(n_clusters_1, n_clusters)",0
"assert_equal(n_clusters_2, n_clusters)",0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Try and work around older sklearn api,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Try and work around older sklearn api,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Try and work around older sklearn api,0
mst_linkage_core does not generate a full minimal spanning tree,0
If a tree is required then we must build the edges from the information,0
returned by mst_linkage_core (i.e. just the order of points to be merged),0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
TO DO: Deal with p for minkowski appropriately,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Get distance to kth nearest neighbour,0
Mutual reachability distance is implicite in mst_linkage_core_cdist,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Sort edges of the min_spanning_tree by weight,0
Convert edge list into standard hierarchical clustering format,0
Checks input and converts to an nd-array where possible,0
Python 2 and 3 compliant string_type checking,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
TO DO: Need heuristic to decide when to go to boruvka; still debugging for now,0
Inherits from sklearn,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"kdtree_pdist_mutual_reachability,",0
"balltree_pdist_mutual_reachability,",0
"kdtree_mutual_reachability,",0
balltree_mutual_reachability,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
If the cluster was formed prior to the cut and is large enough,0
If the cluster had not been merged before the cut,0
Generate labels for each data point,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"kdtree_pdist_mutual_reachability,",0
"balltree_pdist_mutual_reachability,",0
"kdtree_mutual_reachability,",0
balltree_mutual_reachability,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
If the cluster was formed prior to the cut and is large enough,0
If the cluster had not been merged before the cut,0
Generate labels for each data point,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
"kdtree_pdist_mutual_reachability,",0
"balltree_pdist_mutual_reachability,",0
"kdtree_mutual_reachability,",0
balltree_mutual_reachability,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
If the cluster was formed prior to the cut and is large enough,0
If the cluster had not been merged before the cut,0
Generate labels for each data point,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
Need heuristic to decide when to go to boruvka; still debugging for now,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
If the cluster was formed prior to the cut and is large enough,0
If the cluster had not been merged before the cut,0
Generate labels for each data point,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
Steve Astels <sastels@gmail.com>,0
John Healy <jchealy@gmail.com>,0
,0
License: BSD 3 clause,0
-*- coding: utf-8 -*-,0
Author: Leland McInnes <leland.mcinnes@gmail.com>,0
,0
License: BSD 3 clause,0
We want to get the x and y coordinates for the start of each cluster,0
"Initialize the leaves, since we know where they go, the iterate",0
"through everything from the leaves back, setting coords as we go",0
"We use bars to plot the 'icicles', so we need to generate centers, tops,",0
bottoms and widths for each rectangle. We can go through each cluster,0
and do this for each in turn.,0
Finally we need the horizontal lines that occur at cluster splits.,0
Get a 2D projection; if we have a lot of dimensions use PCA first,0
Use PCA to get down to 32 dimension,0
import pickle,0
"number of clusters, ignoring noise if present",0
"metric is the function reference, not the string key.",0
## Probably not applicable now #########################,0
def test_dbscan_sparse():,0
def test_dbscan_balltree():,0
def test_pickle():,0
def test_dbscan_core_samples_toy():,0
def test_boundaries():,0
Generate datasets. We choose the size big enough to see the scalability,0
"of the algorithms, but not too big to avoid too long running times",0
normalize dataset for easier parameter selection,0
estimate bandwidth for mean shift,0
connectivity matrix for structured Ward,0
make connectivity symmetric,0
create clustering estimators,0
predict cluster memberships,0
plot,0
-*- coding: utf-8 -*-,0
#############################################################################,0
Generate sample data,0
#############################################################################,0
Compute DBSCAN,0
"Number of clusters in labels, ignoring noise if present.",0
#############################################################################,0
Plot result,0
Black removed and is used for noise instead.,0
Black used for noise.,0
Black used for noise.,0
