{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//Use a StringBuffer in lieu of String concatenation -- it is //much more efficient this way.',\n",
       " '// writing directly the Class object would be nicer, except that // serialized a Class object can not be read back by JDK // 1.1.x. We have to resort to this hack instead.',\n",
       " '// Note that we use Class.getDeclaredMethod instead of // Class.getMethod. This assumes that the Level subclass // implements the toLevel(int) method which is a // requirement. Actually, it does not make sense for Level // subclasses NOT to implement this method. Also note that // only Level can be subclassed and not Priority.',\n",
       " '// We could not find resource. Ler us now try with the // classloader that loaded this class.',\n",
       " '// convert to specified encoding - which may be sequence of // 8-bit chars, or multi-byte encodings like UTF-8 or UTF-16. // The receiving end had better be expecting whatever encoding // is used here on the sending end!',\n",
       " '/* this Appender is not supposed to be used for logging of Exceptions */',\n",
       " '// er.. how much do we actually need to copy? // We should not copy more than the actual number of elements.',\n",
       " '// //  TODO: why is this returning ,120 ... , 120 // //assertEquals(\"00:00:00,120 00:00:00,000\", s) ;',\n",
       " '// The synchronization on ht is necessary to prevent JDK 1.2.x from // throwing ConcurrentModificationExceptions at us. This sucks BIG-TIME. // One solution is to write our own hashtable implementation.',\n",
       " '// Note that we use Class.getDeclaredMethod instead of // Class.getMethod. This assumes that the Level subclass // implements the toLevel(int) method which is a // requirement. Actually, it does not make sense for Level // subclasses NOT to implement this method. Also note that // only Level can be subclassed and not Priority.',\n",
       " '// Failing to reset the object output stream every now and // then creates a serious memory leak. // right now we always reset. TODO - set up frequency counter per oos?',\n",
       " \"// catch this, but just don't assign a value // this should not really occur as this method is // the only one that can remove oos's (besides cleanUp).\",\n",
       " '// Print Stacktrace // Quick Hack maybe there is a better/faster way?',\n",
       " '// writing directly the Class object would be nicer, except that // serialized a Class object can not be read back by JDK // 1.1.x. We have to resort to this hack instead.',\n",
       " '// Print Stacktrace // Quick Hack maybe there is a better/faster way?',\n",
       " '// Hack finished.',\n",
       " \"// Endre's hack:\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Self_admitted_technical_debt_identified_and_removed_for_the_Log4j_project.csv', encoding='ISO-8859-1')\n",
    "dev = df[df['has_removed_version'] == 'f']\n",
    "d =dev['comment_text'].values.tolist()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = df['removed_version_author'].unique()\n",
    "len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 312.05207771232824\n",
      "P-value: 1.3791382198127103e-59\n",
      "Degrees of Freedom: 12\n",
      "Expected Frequencies:\n",
      "[[1.21993721e+03 2.80523032e+01 1.90958449e+01 5.91464224e+00]\n",
      " [4.23863494e+03 9.74668791e+01 6.63479357e+01 2.05502456e+01]\n",
      " [1.29947750e+03 2.98813222e+01 2.03409000e+01 6.30027877e+00]\n",
      " [1.51414045e+02 3.48174698e+00 2.37010487e+00 7.34103279e-01]\n",
      " [3.09536307e+02 7.11774857e+00 4.84521439e+00 1.50073012e+00]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a DataFrame with the provided data\n",
    "data = {\n",
    "    'Number of commits': [2000, 5000, 3000, 800, 400],\n",
    "    'Number of technical debt commits': [1164, 4331, 1317, 136, 271],\n",
    "    'Number of commits SATD removed': [472, 3926, 1009, 118, 208],\n",
    "    'Remaining percentage of commits': [692, 405, 308, 18, 64],\n",
    "    'Total developer': [113, 1368, 160, 230, 585],\n",
    "    'Days active': [4228, 6083, 6440, 4932, 8351],\n",
    "    'Number of releases': [35, 98, 11, 54, 7],\n",
    "    'Number of Community smell before SATD removal': [7, 8, 5, 7, 8],\n",
    "    'Number of Community smell after SATD removal': [2, 2, 3, 2, 2],\n",
    "    'Number of SATD introduced developers': [64, 47, 19, 8, 28],\n",
    "    'Number of SATD removal developers': [38, 37, 15, 7, 16]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract the relevant columns for the chi-square test\n",
    "observed_data = df[[\n",
    "                    'Number of technical debt commits',\n",
    "                    'Number of SATD introduced developers',\n",
    "                    'Number of SATD removal developers', \n",
    "                    # 'Number of commits SATD removed',\n",
    "                    'Number of Community smell before SATD removal', \n",
    "                    # 'Number of Community smell after SATD removal'\n",
    "            ]]\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(observed_data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m result \u001b[38;5;241m=\u001b[39m num_to_divide \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate random percentages\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m random_percentages \u001b[38;5;241m=\u001b[39m [random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate values with random percentages\u001b[39;00m\n\u001b[1;32m     13\u001b[0m results_with_random_percentages \u001b[38;5;241m=\u001b[39m [result \u001b[38;5;241m*\u001b[39m (percentage \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m percentage \u001b[38;5;129;01min\u001b[39;00m random_percentages]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Number to divide\n",
    "num_to_divide = 50\n",
    "\n",
    "# Divide by 6\n",
    "result = num_to_divide / 4\n",
    "\n",
    "# Generate random percentages\n",
    "random_percentages = [random.uniform(0, 100) for _ in range(6)]\n",
    "\n",
    "# Calculate values with random percentages\n",
    "results_with_random_percentages = [result * (percentage / 100) for percentage in random_percentages]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Original Result: {result}\")\n",
    "print(\"Results with Random Percentages:\")\n",
    "for i, value in enumerate(results_with_random_percentages, start=1):\n",
    "    print(f\"Scenario {i}: {value:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
