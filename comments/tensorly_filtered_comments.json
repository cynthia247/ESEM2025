{
  "0.9.0": [
    "from slimit import minify",
    "Ignore already minified files",
    "Ignore already minified files",
    "!/usr/bin/env python3",
    "",
    "tensorly documentation build configuration file",
    "",
    "This file is execfile()d with the current directory set to its",
    "containing dir.",
    "",
    "Note that not all possible configuration values are present in this",
    "autogenerated file.",
    "",
    "All configuration values have a default; values that are commented out",
    "serve to show the default.",
    "If extensions (or modules to document with autodoc) are in another directory,",
    "add these directories to sys.path here. If the directory is relative to the",
    "documentation root, use os.path.abspath to make it absolute, like shown here.",
    "sys.path.insert(0, os.path.abspath('sphinx_ext'))",
    "-- General configuration ------------------------------------------------",
    "If your documentation needs a minimal Sphinx version, state it here.",
    "needs_sphinx = '1.0'",
    "Add any Sphinx extension module names here, as strings. They can be",
    "extensions coming with Sphinx (named 'sphinx.ext.*') or your custom",
    "ones.",
    "'sphinx.ext.imgmath',",
    "path to your examples scripts",
    "path where to save gallery generated examples",
    "Add any paths that contain templates here, relative to this directory.",
    "generate autosummary even if no references",
    "The suffix(es) of source filenames.",
    "You can specify multiple suffix as a list of string:",
    "source_suffix = ['.rst', '.md']",
    "The encoding of source files.",
    "source_encoding = 'utf-8-sig'",
    "The master toctree document.",
    "General information about the project.",
    "The version info for the project you're documenting, acts as replacement for",
    "|version| and |release|, also used in various other places throughout the",
    "built documents.",
    "",
    "The short X.Y version.",
    "version = '0.1'",
    "The full version, including alpha/beta/rc tags.",
    "release = ''",
    "The language for content autogenerated by Sphinx. Refer to documentation",
    "for a list of supported languages.",
    "",
    "This is also used if you do content translation via gettext catalogs.",
    "Usually you set \"language\" from the command line for these cases.",
    "There are two options for replacing |today|: either, you set today to some",
    "non-false value, then it is used:",
    "today = ''",
    "Else, today_fmt is used as the format for a strftime call.",
    "today_fmt = '%B %d, %Y'",
    "List of patterns, relative to source directory, that match files and",
    "directories to ignore when looking for source files.",
    "This patterns also effect to html_static_path and html_extra_path",
    "The reST default role (used for this markup: `text`) to use for all",
    "documents.",
    "default_role = None",
    "If true, '()' will be appended to :func: etc. cross-reference text.",
    "If true, the current module name will be prepended to all description",
    "unit titles (such as .. function::).",
    "If true, sectionauthor and moduleauthor directives will be shown in the",
    "output. They are ignored by default.",
    "show_authors = False",
    "The name of the Pygments (syntax highlighting) style to use.",
    "A list of ignored prefixes for module index sorting.",
    "modindex_common_prefix = []",
    "If true, keep warnings as \"system message\" paragraphs in the built documents.",
    "keep_warnings = False",
    "If true, `todo` and `todoList` produce output, else they produce nothing.",
    "-- Options for HTML output ----------------------------------------------",
    "\"<project> v<release> documentation\" by default.",
    "A shorter title for the navigation bar.  Default is the same as html_title.",
    "Add any paths that contain custom static files (such as style sheets) here,",
    "relative to this directory. They are copied after the builtin static files,",
    "so a file named \"default.css\" will overwrite the builtin \"default.css\".",
    "The name of an image file (relative to this directory) to place at the top",
    "of the sidebar.",
    "html_logo_url = '_static/logos/logo_tensorly.png'",
    "-- Options for LaTeX output ---------------------------------------------",
    "Grouping the document tree into LaTeX files. List of tuples",
    "(source start file, target name, title,",
    "author, documentclass [howto, manual, or own class]).",
    "\\setcounter{MaxMatrixCols}{20} corrects an ugly bug if you try to have a matrix of more than 10 elements or so",
    "We want the same for the html version:",
    "The name of an image file (relative to this directory) to place at the top of",
    "the title page.",
    "latex_logo = None",
    "For \"manual\" documents, if this is true, then toplevel headings are parts,",
    "not chapters.",
    "latex_use_parts = False",
    "If true, show page references after internal links.",
    "If true, show URL addresses after external links.",
    "Documents to append as an appendix to all manuals.",
    "latex_appendices = []",
    "Get completely rid of index",
    "If false, no module index is generated.",
    "latex_domain_indices = True",
    "-- Options for manual page output ---------------------------------------",
    "One entry per manual page. List of tuples",
    "(source start file, name, description, authors, manual section).",
    "If true, show URL addresses after external links.",
    "man_show_urls = False",
    "-- Options for Texinfo output -------------------------------------------",
    "Grouping the document tree into Texinfo files. List of tuples",
    "(source start file, target name, title, author,",
    "dir menu entry, description, category)",
    "Documents to append as an appendix to all manuals.",
    "texinfo_appendices = []",
    "If false, no module index is generated.",
    "texinfo_domain_indices = True",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "texinfo_show_urls = 'footnote'",
    "If true, do not generate a @detailmenu in the \"Top\" node's menu.",
    "texinfo_no_detailmenu = False",
    "-- Options for Epub output ----------------------------------------------",
    "Bibliographic Dublin Core info.",
    "The basename for the epub file. It defaults to the project name.",
    "epub_basename = project",
    "The HTML theme for the epub output. Since the default themes are not",
    "optimized for small screen space, using the same theme for HTML and epub",
    "output is usually not wise. This defaults to 'epub', a theme designed to save",
    "visual space.",
    "epub_theme = 'epub'",
    "The language of the text. It defaults to the language option",
    "or 'en' if the language is not set.",
    "epub_language = ''",
    "The scheme of the identifier. Typical schemes are ISBN or URL.",
    "epub_scheme = ''",
    "The unique identifier of the text. This can be a ISBN number",
    "or the project homepage.",
    "epub_identifier = ''",
    "A unique identification for the text.",
    "epub_uid = ''",
    "A tuple containing the cover image and cover page html template filenames.",
    "epub_cover = ()",
    "A sequence of (type, uri, title) tuples for the guide element of content.opf.",
    "epub_guide = ()",
    "HTML files that should be inserted before the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_pre_files = []",
    "HTML files that should be inserted after the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_post_files = []",
    "A list of files that should not be packed into the epub file.",
    "The depth of the table of contents in toc.ncx.",
    "epub_tocdepth = 3",
    "Allow duplicate toc entries.",
    "epub_tocdup = True",
    "Choose between 'default' and 'includehidden'.",
    "epub_tocscope = 'default'",
    "Fix unsupported image types using the Pillow.",
    "epub_fix_images = False",
    "Scale large images.",
    "epub_max_image_width = 0",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "epub_show_urls = 'inline'",
    "If false, no index is generated.",
    "epub_use_index = True",
    "##########################################################################",
    "A tensor is simply a numpy array",
    "##########################################################################",
    "Unfolding a tensor is easy",
    "##########################################################################",
    "Re-folding the tensor is as easy:",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.7, Tensorly includes constrained CP decomposition which penalizes or",
    "constrains factors as chosen by the user. The proposed implementation of constrained CP uses the",
    "Alternating Optimization Alternating Direction Method of Multipliers (AO-ADMM) algorithm from [1] which",
    "solves alternatively convex optimization problem using primal-dual optimization. In constrained CP",
    "decomposition, an auxilliary factor is introduced which is constrained or regularized using an operator called the",
    "proximal operator. The proximal operator may therefore change according to the selected constraint or penalization.",
    "",
    "Tensorly provides several constraints and their corresponding proximal operators, each can apply to one or all factors in the CP decomposition:",
    "",
    "1. Non-negativity",
    "* `non_negative` in signature",
    "* Prevents negative values in CP factors.",
    "2. L1 regularization",
    "* `l1_reg` in signature",
    "* Adds a L1 regularization term on the CP factors to the CP cost function, this promotes sparsity in the CP factors. The user chooses the regularization amount.",
    "3. L2 regularization",
    "* `l2_reg` in signature",
    "* Adds a L2 regularization term on the CP factors to the CP cost function. The user chooses the regularization amount.",
    "4. L2 square regularization",
    "* `l2_square_reg` in signature",
    "* Adds a L2 regularization term on the CP factors to the CP cost function. The user chooses the regularization amount.",
    "5. Unimodality",
    "* `unimodality` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors is unimodal (there is only one local maximum, like a Gaussian).",
    "6. Simplex",
    "* `simplex` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors lives on the simplex or user-defined radius (entries are nonnegative and sum to a user-defined positive parameter columnwise).",
    "7. Normalization",
    "* `normalize` in signature",
    "* Impose that the largest absolute value in the factors elementwise is 1.",
    "8. Normalized sparsity",
    "* `normalized_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the columns of factors are both normalized with the L2 norm, and k-sparse (at most k-nonzeros per column) with k user-defined.",
    "9. Soft sparsity",
    "* `soft_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the columns of factors have L1 norm bounded by a user-defined threshold.",
    "10. Smoothness",
    "* `smoothness` in signature",
    "* This constraint acts columnwise on the factors",
    "* Favor smoothness in factors columns by penalizing the L2 norm of finite differences. The user chooses the regularization amount. The proximal operator in fact solves a banded system.",
    "11. Monotonicity",
    "* `monotonicity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the factors are either always increasing or decreasing (user-specified) columnwise. This is based on isotonic regression.",
    "12. Hard sparsity",
    "* `hard_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors has at most k nonzero entries (k is user-defined).",
    "",
    "While some of these constraints (2, 3, 4, 6, 8, 9, 12) require a scalar",
    "input as its parameter or regularizer, boolean input could be enough",
    "for other constraints (1, 5, 7, 10, 11). Selection of one of these",
    "constraints for all mode (or factors) or using different constraints for different modes are both supported.",
    "tensor generation",
    "#############################################################################",
    "Using one constraint for all modes",
    "--------------------------------------------",
    "Constraints are inputs of the constrained_parafac function, which itself uses the",
    "``tensorly.solver.proximal.validate_constraints`` function in order to process the input",
    "of the user. If a user wants to use the same constraint for all modes, an",
    "input (bool or a scalar value or list of scalar values) should be given to this constraint.",
    "Assume, one wants to use unimodality constraint for all modes. Since it does not require",
    "any scalar input, unimodality can be imposed by writing `True` for `unimodality`:",
    "#############################################################################",
    "This constraint imposes that each column of all the factors in the CP decomposition are unimodal:",
    "#############################################################################",
    "Constraints requiring a scalar input can be used similarly as follows:",
    "#############################################################################",
    "The same regularization coefficient l1_reg is used for all the modes. Here the l1 penalization induces sparsity given that the regularization coefficient is large enough.",
    "#############################################################################",
    "Using one constraint for some modes",
    "--------------------------------------------",
    "As a second option, constraint can be used for only a few selected modes by using",
    "a python dictionary:",
    "#############################################################################",
    "Since only the first and last factors are chosen, entries on the second mode factor could be negative.",
    "#############################################################################",
    "Using a constraint with the different scalar inputs for each mode",
    "---------------------------------------------------------",
    "One may prefer different scalar value for each mode. It is possible by",
    "using a list structure:",
    "#############################################################################",
    "Using different constraints for each mode",
    "--------------------------------------------",
    "To use different constraint for different modes, the dictionary structure",
    "should be preferred:",
    "#############################################################################",
    "In the dictionary, `key` is the selected mode and `value` is a scalar value or",
    "only `True` depending on the selected constraint.",
    "#############################################################################",
    "Thus, first factor will be non-negative, second factor will be regularized",
    "by :math:`0.01` with :math:`l_1` and last factor will be regularized by",
    ":math:`0.01` with :math:`l_2^2`.",
    "#############################################################################",
    "References",
    "----------",
    "",
    "[1] Huang, Kejun, Nicholas D. Sidiropoulos, and Athanasios P. Liavas.",
    "\"A flexible and efficient algorithmic framework for constrained",
    "matrix and tensor factorization.\"",
    "IEEE Transactions on Signal Processing 64.19 (2016): 5052-5065.",
    "`(Online version)",
    "<https://ieeexplore.ieee.org/document/7484753>`_",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor that follows the PARAFAC2 constraints found",
    "in `(Kiers et al 1999)`_.",
    "",
    "This particular tensor,",
    ":math:`\\mathcal{X}\u00a0\\in \\mathbb{R}^{I\\times J \\times K}`, is a shifted",
    "CP tensor, that is, a tensor on the form:",
    "",
    ".. math::",
    "\\mathcal{X}_{ijk} = \\sum_{r=1}^R A_{ir} B_{\\sigma_i(j) r} C_{kr},",
    "",
    "where :math:`\\sigma_i`\u00a0is a cyclic permutation of :math:`J` elements.",
    "Set parameters",
    "Generate random matrices",
    "Normalised factor matrices",
    "Generate the shifted factor matrix",
    "Construct the tensor",
    "Add noise",
    "#############################################################################",
    "Fit a PARAFAC2 tensor",
    "---------------------",
    "To avoid local minima, we initialise and fit 10 models and choose the one",
    "with the lowest error",
    "#############################################################################",
    "A decomposition is a wrapper object for three variables: the *weights*,",
    "the *factor matrices* and the *projection matrices*. The weights are similar",
    "to the output of a CP decomposition. The factor matrices and projection",
    "matrices are somewhat different. For a CP decomposition, we only have the",
    "weights and the factor matrices. However, since the PARAFAC2 factor matrices",
    "for the second mode is given by",
    "",
    ".. math::",
    "B_i = P_i B,",
    "",
    "where :math:`B` is an :math:`R \\times R` matrix and :math:`P_i` is an",
    ":math:`I \\times R` projection matrix, we cannot store the factor matrices",
    "the same as for a CP decomposition.",
    "",
    "Instead, we store the factor matrix along the first mode (:math:`A`), the",
    "\"blueprint\" matrix for the second mode (:math:`B`) and the factor matrix",
    "along the third mode (:math:`C`) in one tuple and the projection matrices,",
    ":math:`P_i`, in a separate tuple.",
    "",
    "If we wish to extract the informative :math:`B_i` factor matrices, then we",
    "use the ``tensorly.parafac2_tensor.apply_projection_matrices`` function on",
    "the PARAFAC2 tensor instance to get another wrapper object for two",
    "variables: *weights* and *factor matrices*. However, now, the second element",
    "of the factor matrices tuple is now a list of factor matrices, one for each",
    "frontal slice of the tensor.",
    "",
    "Likewise, if we wish to construct the tensor or the frontal slices, then we",
    "can use the ``tensorly.parafac2_tensor.parafac2_to_tensor`` function. If the",
    "decomposed dataset consisted of uneven-length frontal slices, then we can",
    "use the ``tensorly.parafac2_tensor.parafac2_to_slices`` function to get a",
    "list of frontal slices.",
    "#############################################################################",
    "Compute performance metrics",
    "---------------------------",
    "To evaluate how well the original structure is recovered, we calculate the tucker congruence coefficient.",
    "#############################################################################",
    "Visualize the components",
    "------------------------",
    "Find the best permutation so that we can plot the estimated components on top of the true components",
    "Create plots of each component vector for each mode",
    "(We just look at one of the B_i matrices)",
    "Plot true and estimated components for mode A",
    "Labels for the different components",
    "Plot true and estimated components for mode C",
    "Plot true components for mode B",
    "Get the signs so that we can flip the B mode factor matrices",
    "Plot estimated components for mode B (after sign correction)",
    "Titles for the different modes",
    "Create a legend for the entire figure",
    "#############################################################################",
    "Inspect the convergence rate",
    "----------------------------",
    "It can be interesting to look at the loss plot to make sure that we have",
    "converged to a stationary point. We skip the first iteration since the",
    "initial loss often dominate the rest of the plot, making it difficult",
    "to check for convergence.",
    "#############################################################################",
    "References",
    "----------",
    "",
    ".. _(Kiers et al 1999):",
    "",
    "Kiers HA, Ten Berge JM, Bro R. *PARAFAC2\u2014Part I.",
    "A direct fitting algorithm for the PARAFAC2 model.*",
    "**Journal of Chemometrics: A Journal of the Chemometrics Society.**",
    "1999 May;13(3\u20104):275-94. `(Online version)",
    "<https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-128X(199905/08)13:3/4%3C275::AID-CEM543%3E3.0.CO;2-B>`_",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, several options are available to compute",
    "non-negative CP (NCP), in particular several",
    "algorithms:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that factors must have only non-negative values after it is",
    "obtained from a non-negative tensor.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random from the sequence of integers from 1 to 24000.",
    "Tensor generation",
    "#############################################################################",
    "Our goal here is to produce an approximation of the tensor generated above",
    "which follows a low-rank CP model, with non-negative coefficients. Before",
    "using these algorithms, we can use Tensorly to produce a good initial guess",
    "for our NCP. In fact, in order to compare both algorithmic options in a",
    "fair way, it is a good idea to use same initialized factors in decomposition",
    "algorithms. We make use of the ``initialize_cp`` function to initialize the",
    "factors of the NCP (setting the ``non_negative`` option to `True`)",
    "and transform these factors (and factors weights) into",
    "an instance of the CPTensor class:",
    "#############################################################################",
    "Non-negative Parafac",
    "-----------------------",
    "From now on, we can use the same ``cp_init`` tensor as the initial tensor when",
    "we use decomposition functions. Now let us first use the algorithm based on",
    "Multiplicative Update, which can be called as follows:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the cp_to_tensor function. The tensor cp_reconstruction_mu is therefore a",
    "low-rank non-negative approximation of the input tensor; looking at the",
    "first few values of both tensors shows that this is indeed",
    "the case but the approximation is quite coarse.",
    "#############################################################################",
    "Non-negative Parafac with HALS",
    "------------------------------",
    "Our second (new) option to compute NCP is the HALS algorithm, which can be",
    "used as follows:",
    "#############################################################################",
    "Again, we can look at the reconstructed tensor entries.",
    "#############################################################################",
    "Non-negative Parafac with Exact HALS",
    "------------------------------------",
    "From only looking at a few entries of the reconstructed tensors, we can",
    "already see a huge gap between HALS and MU outputs.",
    "Additionally, HALS algorithm has an option for exact solution to the non-negative",
    "least squares subproblem rather than the faster, approximate solution.",
    "Note that the overall HALS algorithm will still provide an approximation of",
    "the input data, but will need longer to reach convergence.",
    "Exact subroutine solution option can be used simply choosing exact as True",
    "in the function:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "First comparison option is processing time for each algorithm:",
    "#############################################################################",
    "As it is expected, the exact solution takes much longer than the approximate",
    "solution, while the gain in performance is often void. Therefore we recommend",
    "to avoid this option unless it is specifically required by the application.",
    "Also note that on appearance, both MU and HALS have similar runtimes.",
    "However, a closer look suggest they are indeed behaving quite differently.",
    "Computing the error between the output and the input tensor tells that story better.",
    "In Tensorly, we provide a function to calculate Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both exact and approximate solution. In particular, HALS converged to a",
    "much lower reconstruction error than MU. We can better appreciate the difference",
    "in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases (only",
    "encountered by expert users most likely).",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105. (Link)",
    "<https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, two algorithms are available to compute non-negative",
    "Tucker decomposition:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that core and factors must have only non-negative values after",
    "it is obtained from a non-negative tensor. Tucker decomposition includes core",
    "(:math:`G`) and factors (:math:`A`, :math:`B`, :math:`C`).",
    "",
    ".. math::",
    "T = [| G; A, B , C |],",
    "",
    "We need to solve the following problem for each factor (e.g. factor :math:`A` here):",
    "",
    ".. math::",
    "\\min_{A \\geq 0} ||T_{[1]} - A\\times G_{[1]}(B\\times C)^T||_F^2,",
    "",
    "Here, :math:`G_{[i]}` represents ith mode unfolding of the core. To update",
    "the core, we need the solve following problem:",
    "",
    ".. math::",
    "\\min_{g \\geq 0} ||t -   (A\\times B \\times C)\\times g ||_F^2,",
    "",
    "where :math:`t` and :math:`g` are the vectorized data tensor :math:`T` and core :math:`G`.",
    "#############################################################################",
    "To update the factors, we will use HALS and to update the core, we have two",
    "different algorithms Active Set (AS) and Fast Iterative Shrinkage-Thresholding",
    "Algorithm (FISTA) in Tensorly. While FISTA is an accelerated gradient method for",
    "non-negative or unconstrained problems, AS is the widely used non-negative",
    "least square solution proposed by Lawson and Hanson in 1974. Both algorithms",
    "return non-negative core and FISTA is the default algorithm for HALS Tucker",
    "decomposition in Tensorly.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random tensor from the sequence of integers from",
    "1 to 1000.",
    "tensor generation",
    "#############################################################################",
    "Non-negative Tucker",
    "-----------------------",
    "First, multiplicative update can be implemented as:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the ``tucker_to_tensor`` function. The tensor ``tucker_reconstruction_mu`` is",
    "therefore a low-rank non-negative approximation of the input tensor ``tensor``.",
    "#############################################################################",
    "Non-negative Tucker with HALS and FISTA",
    "---------------------------------------",
    "HALS algorithm with FISTA can be calculated as:",
    "#############################################################################",
    "Non-negative Tucker with HALS and Active Set",
    "--------------------------------------------",
    "As a second option, HALS algorithm with Active Set can be called as follows:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "To compare the various methods, first we may look at each algorithm",
    "processing time:",
    "#############################################################################",
    "All algorithms should run with about the same number of iterations on our",
    "example, so at first glance the MU algorithm is faster (i.e. has lower",
    "per-iteration complexity). A second way to compare methods is to compute",
    "the error between the output and input tensor. In Tensorly, there is a function",
    "to compute Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both FISTA and active set core update options. We can better appreciate",
    "the difference in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases",
    "(only encountered by expert users most likely). Besides, in this experiment",
    "FISTA and active set give very similar results, however active set may last",
    "longer when it is used with higher ranks according to our experience.",
    "Therefore, we recommend to use FISTA with high rank decomposition.",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105.",
    "`(Link) https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>`_",
    "#############################################################################",
    "Function to create synthetic data",
    "---------------------------------",
    "",
    "Here, we create a function that constructs a random tensor from a PARAFAC2",
    "decomposition with noise",
    "#############################################################################",
    "Compressing data with many rows and few columns",
    "-----------------------------------------------",
    "",
    "Here, we set up for a case where we have many rows compared to columns",
    "#############################################################################",
    "Fitting without compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "As a baseline, we see how long time it takes to fit models without compression.",
    "Since PARAFAC2 is very prone to local minima, we fit five models and select the model",
    "with the lowest reconstruction error.",
    "#############################################################################",
    "Fitting with lossless compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Since the tensor slices have many rows compared to columns, we should be able to save",
    "a lot of time by compressing the data. By compressing the matrices, we only need to",
    "fit the PARAFAC2 model to a set of 10 matrices, each of size 15 x 15, not 10_000 x 15.",
    "",
    "The main bottleneck here is the SVD computation at the beginning of the fitting",
    "procedure, but luckily, this is independent of the initialisations, so we only need",
    "to compute this once. Also, if we are performing a grid search for the rank, then",
    "we just need to perform the compression once for the whole grid search as well.",
    "#############################################################################",
    "We see that we saved a lot of time by compressing the data before fitting the model.",
    "#############################################################################",
    "Fitting with lossy compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "We can try to speed the process up even further by accepting a slight discrepancy",
    "between the model obtained from compressed data and a model obtained from uncompressed",
    "data. Specifically, we can truncate the singular values at some threshold, essentially",
    "removing the parts of the data matrices that have a very low \"signal strength\".",
    "#############################################################################",
    "We see that we didn't save much, if any, time in this case (compared to using",
    "lossless compression). This is because the main bottleneck now is the CP-part of",
    "the PARAFAC2 procedure, so reducing the tensor size from 10 x 15 x 15 to 10 x 4 x 15",
    "(which is typically what we would get here) will have a negligible effect.",
    "#############################################################################",
    "Compressing data that is approximately low-rank",
    "-----------------------------------------------",
    "",
    "Here, we simulate data with many rows and columns but an approximately low rank.",
    "#############################################################################",
    "Fitting without compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Again, we start by fitting without compression as a baseline.",
    "#############################################################################",
    "Fitting with lossless compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Next, we fit with lossless compression.",
    "#############################################################################",
    "We see that the lossless compression no effect for this data. This is because the",
    "number ofrows is equal to the number of columns, so we cannot compress the data",
    "losslessly with the SVD.",
    "#############################################################################",
    "Fitting with lossy compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Finally, we fit with lossy SVD compression.",
    "#############################################################################",
    "Here we see a large speedup. This is because the data is approximately low rank so",
    "the compressed tensor slices will have shape R x 2_000, where R is typically below 10",
    "in this example. If your tensor slices are large in both modes, you might want to plot",
    "the singular values of your dataset to see if lossy compression could speed up",
    "PARAFAC2.",
    "Get a high-accuracy decomposition for comparison",
    "Run PARAFAC decomposition without line search and time",
    "Run PARAFAC decomposition with line search and time",
    "Calculate the error of both decompositions",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "This function compares factors of a reference cp tensor with factors of another tensor",
    "(or list of tensor) in order to match component order. Permutation occurs on the columns of factors,",
    "minimizing the cosine distance to reference cp tensor with scipy Linear Sum Assignment method.",
    "The permuted tensor (or list of tensors) and list of permutation for each permuted tensors are returned.",
    "Tensorly CPTensor should be used as an input to permute their factors and weights simultaneously.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor, then we permute its factors manually.",
    "one reference cp tensor",
    "two target cp tensors",
    "#############################################################################",
    "Permute target CPTensors",
    "------------------------",
    "Now, we can use these two manipulated CPTensors as inputs to the permutation function. Here,",
    "cp_tensor_1 will be used as a reference to permute other CPTensors, which are called target CPTensors.",
    "There is no limitation for the number of target CPTensors but there should be only one reference CPTensor.",
    "Results will include permuted CPTensors and permutation for each permuted cp tensor.",
    "It should be noted that, reference CPTensor won't be included among the output CPTensors.",
    "#############################################################################",
    "As it is expected, permutation variable stores two lists which are equal to predefined col_order_1",
    "col_order_2 above.",
    "#############################################################################",
    "We can also observe the evolution of the factor columns order by plotting one column",
    "before and after permuting.",
    "sphinx_gallery_thumbnail_number = 2",
    "#############################################################################",
    "Introduction",
    "------------",
    "PARAFAC (CP) decomposition is extremely useful in dimensionality reduction, allowing us",
    "to develop models that are both representative and compact while retaining crucial patterns",
    "between subjects. Here, we provide an example of how it can be applied to biomedical research.",
    "",
    "Systems serology is a new technology that examines the antibodies from a patient's serum, aiming",
    "to comprehensively profile the interactions between the antibodies and",
    "`Fc receptors <https://en.wikipedia.org/wiki/Fc_receptor>`_ alongside other types of immunological",
    "and demographic data. Here, we will apply CP decomposition to a",
    "`COVID-19 system serology dataset <https://www.sciencedirect.com/science/article/pii/S0092867420314598>`_.",
    "In this dataset, serum antibodies",
    "of 438 samples collected from COVID-19 patients were systematically profiled by their binding behavior",
    "to SARS-CoV-2 (the virus that causes COVID-19) antigens and Fc receptors activities. Samples are",
    "labeled by the status of the patients.",
    "",
    "Details of this analysis as well as more in-depth biological implications can be found in",
    "`this work <https://www.embopress.org/doi/full/10.15252/msb.202110243>`_. It also includes applying",
    "tensor methods to HIV systems serology measurements and using them to predict patient status.",
    "",
    "We first import this dataset of a panel of COVID-19 patients:",
    "#############################################################################",
    "Apply CP decomposition to this dataset with Tensorly",
    "----------------------------------------------------",
    "Now we apply CP decomposition to this dataset.",
    "#############################################################################",
    "To evaluate how well CP decomposition explains the variance in the dataset, we plot the percent",
    "variance reconstructed (R2X) for a range of ranks.",
    "#############################################################################",
    "Inspect the biological insights from CP components",
    "--------------------------------------------------",
    "Eventually, we wish CP decomposition can bring insights to this dataset. For example, in this",
    "case, revealing the underlying trend of COVID-19 serum-level immunity. To do this, we can inspect",
    "how each component looks like on weights.",
    "Ensure that factors are negative on at most one direction.",
    "#############################################################################",
    "From the results, we can see that serum COVID-19 immunity separates into two distinct signals,",
    "represented by two CP components: a clear acute response with IgG3, IgM, and IgA, and a long-term,",
    "IgG1-specific response. Samples from patients with different symptoms can be distinguished from",
    "these two components. This indicates that CP decomposition is a great tool to find these biologically",
    "significant signals.",
    "#############################################################################",
    "References",
    "----------",
    "[1] Tan, Z. C., Murphy, M. C., Alpay, H. S., Taylor, S. D., & Meyer, A. S. (2021). Tensor\u2010structured",
    "decomposition improves systems serology analysis. Molecular systems biology, 17(9), e10243.",
    "`<https://www.embopress.org/doi/full/10.15252/msb.202110243>`_",
    "",
    "[2] Zohar, T., Loos, C., Fischinger, S., Atyeo, C., Wang, C., Slein, M. D., ... & Alter, G. (2020).",
    "Compromised humoral functional evolution tracks with SARS-CoV-2 mortality. Cell, 183(6), 1508-1519.",
    "`<https://www.sciencedirect.com/science/article/pii/S0092867420314598>`_",
    "Rank of the CP decomposition",
    "Rank of the Tucker decomposition",
    "Perform the CP decomposition",
    "Reconstruct the image from the factors",
    "Tucker decomposition",
    "Plotting the original and reconstruction from the decompositions",
    "%%",
    "Here we will load a tensor of experimentally measured cellular responses to",
    "IL-2 stimulation. IL-2 is a naturally occurring immune signaling molecule",
    "which has been engineered by pharmaceutical companies and drug designers",
    "in attempts to act as an effective immunotherapy. In order to make effective IL-2",
    "therapies, pharmaceutical engineer have altered IL-2's signaling activity in order to",
    "increase or decrease its interactions with particular cell types.",
    "",
    "IL-2 signals through the Jak/STAT pathway and transmits a signal into immune cells by",
    "phosphorylating STAT5 (pSTAT5). When phosphorylated, STAT5 will cause various immune",
    "cell types to proliferate, and depending on whether regulatory (regulatory T cells, or Tregs)",
    "or effector cells (helper T cells, natural killer cells, and cytotoxic T cells,",
    "or Thelpers, NKs, and CD8+ cells) respond, IL-2 signaling can result in",
    "immunosuppression or immunostimulation respectively. Thus, when designing a drug",
    "meant to repress the immune system, potentially for the treatment of autoimmune",
    "diseases, IL-2 which primarily enacts a response in Tregs is desirable. Conversely,",
    "when designing a drug that is meant to stimulate the immune system, potentially for",
    "the treatment of cancer, IL-2 which primarily enacts a response in effector cells",
    "is desirable. In order to achieve either signaling bias, IL-2 variants with altered",
    "affinity for it's various receptors (IL2R\u03b1 or IL2R\u03b2) have been designed. Furthermore",
    "IL-2 variants with multiple binding domains have been designed as multivalent",
    "IL-2 may act as a more effective therapeutic. In order to understand how these mutations",
    "and alterations affect which cells respond to an IL-2 mutant, we will perform",
    "non-negative PARAFAC tensor decomposition on our cell response data tensor.",
    "",
    "Here, our data contains the responses of 8 different cell types to 13 different",
    "IL-2 mutants, at 4 different timepoints, at 12 standardized IL-2 concentrations.",
    "Therefore, our tensor will have shape (13 x 4 x 12 x 8), with dimensions",
    "representing IL-2 mutant, stimulation time, dose, and cell type respectively. Each",
    "measured quantity represents the amount of phosphorlyated STAT5 (pSTAT5) in a",
    "given cell population following stimulation with the specified IL-2 mutant.",
    "%%",
    "Now we will run non-negative PARAFAC tensor decomposition to reduce the dimensionality",
    "of our tensor. We will use 3 components, and normalize our resulting tensor to aid in",
    "future comparisons of correlations across components.",
    "",
    "First we must preprocess our tensor to ready it for factorization. Our data has a",
    "few missing values, and so we must first generate a mask to mark where those values",
    "occur.",
    "%%",
    "Now that we've marked where those non-finite values occur, we can regenerate our",
    "tensor without including non-finite values, allowing it to be factorized.",
    "%%",
    "Using this mask, and finite-value only tensor, we can decompose our signaling data into",
    "three components. We will also normalize this tensor, which will allow for easier",
    "comparisons to be made between the meanings, and magnitudes of our resulting components.",
    "%%",
    "Now we will load the names of our cell types and IL-2 mutants, in the order in which",
    "they are present in our original tensor. IL-2 mutant names refer to the specific",
    "mutations made to their amino acid sequence, as well as their valency",
    "format (monovalent or bivalent).",
    "",
    "Finally, we label, plot, and analyze our factored tensor of data.",
    "%%",
    "Here we observe the correlations which both ligands and cell types have with each of",
    "our three components - we can interepret our tensor factorization for looking for",
    "patterns among these correlations.",
    "",
    "For example, we can see that bivalent mutants generally have higher correlations with",
    "component two, as do regulatory T cells. Thus we can infer that bivalent ligands",
    "activate regulatory T cells more than monovalent ligands. We also see that this",
    "relationship is strengthened by the availability of IL2R\u03b1, one subunit of the IL-2 receptor.",
    "",
    "This is just one example of an insight we can make using tensor factorization.",
    "By plotting the correlations which time and dose have with each component, we",
    "could additionally make inferences as to the dynamics and dose dependence of how mutations",
    "affect IL-2 signaling in immune cells.",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Should we allow None weights?",
    "it's already been validated at creation",
    "Skip the target mode",
    "Calculate the sign of the current factor in each component",
    "Update both the current and receiving factor",
    "Check the weight signs",
    "Test for the validity of the operation",
    "norm = T.dot(T.dot(weights, norm), weights)",
    "We sum even if weights is not None",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Check user input for potential errors",
    "Check first and last rank",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi",
    "Import opt-einsum for the contraction path",
    "Import cuQuantum for the actual contraction",
    "return cuquantum.contract(equation, *args, optimize={'path': path})",
    "Note how tt_matrix_to_tensor is implemented in tenalg to allow for more efficient implementations",
    "(e.g. using the einsum backend)",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Test for the validity of the operation",
    "rank is 'same' or float: choose rank so as to preserve a fraction of the original #parameters",
    "sorted to be careful with the order when popping and reinserting to not remove/add at wrong index.",
    "list (mode, shape) that we removed as they will be kept the same, rank[i] =",
    "number of parameters coming from the fixed modes (these don't have a variable size as a fun of fraction_param)",
    "Doesn't contain fixed_modes, those factors are accounted for in fixed_params",
    "it's already been validated at creation",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Border rank of 1, R_0 = R_N = 1",
    "First and last factor of size I_0 R and I_N R",
    "We want the number of params of decomp (=sum of params of factors)",
    "To be equal to c = \\prod_k I_k",
    "We get the non-negative solution",
    "Choose a rank proportional to the size of each mode",
    "The method is similar to the above one for constant_rank == True",
    "We get the non-negative solution",
    "Check user input for potential errors",
    "Initialization",
    "Will raise an error if invalid",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "it's already been validated at creation",
    "Skip first factor matrix since the rank is extracted from it.",
    "allocate variables for weights, and normalized factors",
    "if (not copy) and (weights is None):",
    "warnings.warn('Provided copy=False and weights=None: a new Parafac2Tensor'",
    "'with new weights and factors normalised inplace will be returned.')",
    "weights = T.ones(rank, **T.context(factors[0]))",
    "The if test below was added to enable inplace edits",
    "however, TensorFlow does not support inplace edits",
    "so this is always set to True",
    "backend_context,",
    "backend_manager,",
    "_get_backend_dir, _get_backend_method,",
    "from . import backend as backend_manager",
    "Add Backend functions, dynamically dispatched",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__,",
    "backend_manager.__getattribute__,",
    "full_dir)",
    "# override_module_dispatch(__name__, _get_backend_method, full_dir)",
    "del override_module_dispatch, full_dir#, _get_backend_method",
    "Threshold SVD, keeping only singular values that satisfy s_i >= s_0 * epsilon",
    "where epsilon is the compression threshold",
    "Array broadcasting happens at the last dimension, since Vh is num_svds x n_cols",
    "we need to transpose it, multiply in the singular values and then transpose",
    "it again. This is equivalent to writing diag(s) @ Vh. If we skip the",
    "transposes, we would get Vh @ diag(s), which is wrong.",
    "Authors: Isabell Lehmann <isabell.lehmann94@outlook.de>",
    "License: BSD 3 clause",
    "initialize values",
    "the coupled factor should be initialized with the concatenated dataset",
    "alternating least squares",
    "note that the order of the khatri rao product is reversed since tl.unfold has another order",
    "than assumed in paper",
    "Loop over modes of the tensor",
    "We want to solve for mode 0 last, since the coupled factor matrix is most influential and SVD gave us a good approximation",
    "If we are at the coupled mode, concat the matrix",
    "Getting the TT factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TT factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "A TTM with a single factor is just a matrix...",
    "A list of candidates for each mode",
    "Refine the init",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "If the concatenated matrix would be larger than the cross-product, use the latter",
    "Clip if the mode should be non-negative",
    "If nn_modes is set, we use HALS, otherwise, we use the standard parafac implementation.",
    "Will we be performing a line search iteration?",
    "Start line search if requested.",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "TODO: this is a hack but it seems to do the job for now",
    "TODO: Test this",
    "Make decomposition feasible by taking the absolute value of all factor matrices",
    "If we have to update the mask we already have to build the full tensor",
    "Update the tensor based on the mask",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Will we be performing a line search iteration",
    "Calculate the current unnormalized error if we need it",
    "Start line search if requested.",
    "For each matrix, randomly choose n_samples indices for which to compute the khatri-rao product",
    "Compute corresponding rows of the full khatri-rao product",
    "Compute the Khatri-Rao product for the chosen indices",
    "Keep all the elements of the currently considered mode",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Caglayan Tuna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "ADMM inits",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise the decompositions",
    "Norm of the reconstructions at each iteration",
    "Update the lagrangian multipliers",
    "Evolution of the reconstruction errors",
    "Convergence check",
    "Randomly initialize decomposition cores",
    "Run callback function if provided",
    "Main loop",
    "Compute appropriate transposed unfolding of tensor",
    "Compute design matrix",
    "Solve least squares problem directly",
    "Solve least squares problem via normal equations",
    "Update core",
    "Compute relative error if necessary",
    "Run callback function if provided",
    "Check convergence",
    "Create index orderings for computation of sketched design matrix",
    "Randomly initialize decomposition cores",
    "Compute initial sampling distributions",
    "Run callback function if provided",
    "Main loop",
    "Randomly draw row indices",
    "Combine repeated samples",
    "Compute row rescaling factors (see discussion in Sec 4.1 in paper by",
    "Larsen & Kolda (2022), DOI: 10.1137/21M1441754)",
    "Converting samples_unq[n] to a tl.tensor is necessary for indexing",
    "to work with jax, which doesn't allow indexing with lists; see",
    "https://github.com/google/jax/issues/4564. The dtype needs to be",
    "explicitly set to an int type, otherwise tl.tensor does the",
    "conversion to floating type which causes issues with the pytorch",
    "backend.",
    "Sample core tensors",
    "Construct sketched design matrix",
    "Construct sampled right-hand side",
    "Solve sampled least squares problem directly",
    "Update core",
    "Compute sampling distribution for updated core",
    "Compute relative error if necessary",
    "Run callback function if provided",
    "Check convergence",
    "Change order",
    "Getting the first factor",
    "SVD of unfolding matrix",
    "Get first TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the TR factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "Reorder factors to match input",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "A list of candidates for each mode",
    "Refine the init",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Initialisation",
    "The initial core approximation is needed here for the masking step",
    "SVD init",
    "The factors are orthonormal and therefore do not affect the reconstructed tensor's norm",
    "TO-DO validate rank for partial tucker as well",
    "Initialisation",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local variables",
    "Iterate over one step of NTD",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "UtU",
    "UtM",
    "Call the hals resolution with nnls, optimizing the current mode",
    "updating core",
    "Adding the l1 norm value to the reconstruction error",
    "error computation",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan TUna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "khatri_rao(factors).tl.dot(khatri_rao(factors))",
    "simplifies to multiplications",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local varaibles",
    "Iteratation",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "Call the hals resolution with nnls, optimizing the current mode",
    "check recovery",
    "check low rank recovery",
    "Check for sparsity of the gross error",
    "assert tl.sum(noise_pred > 0.01) == tl.sum(noise > 0.01)",
    "check sparse gross error recovery",
    "###########################",
    "Test with missing values #",
    "###########################",
    "Add some corruption (missing values, replaced by ones)",
    "Decompose the tensor",
    "check recovery",
    "check low rank recovery",
    "check sparse gross error recovery",
    "Check for recovery of the corrupted/missing part",
    "tensorflow has issues with type promotion that would require more code changes",
    "Generate a random complex tensor if requested",
    "Callback to record error",
    "Given all the random seed is set, this should provide the same answer for random initialization",
    "Callback to record error",
    "Check that the error monotonically decreases",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Check that sparse component works",
    "Check that we get roughly the same answer with the full tensor and masking",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Regression test: used wrong variable for convergence checking",
    "Used mttkrp*factor instead of mttkrp*factors[-1], which resulted in",
    "error when mode 2 was not constrained and erroneous convergence checking",
    "when mode 2 was constrained.",
    "test tensor reconstructed properly",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "Test random_state fixes the core and the factor matrices",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "try fixing the core",
    "Random and SVD init should converge to a similar solution",
    "Mask an outlier value, and check that the decomposition ignores it",
    "We won't use the SVD decomposition, but check that it at least runs successfully",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Testing if estimated factors are monotonic",
    "Check if maximum values is 1",
    "Check if factors have l1 norm smaller than threshold",
    "Check if factors are normalized and k-sparse",
    "Check if factors are normalized and k-sparse",
    "Test the max abs difference between the reconstruction and the tensor",
    "Check that the error monotonically decreases",
    "# Check reconstruction of noisy tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "Generate random tensor which has exact tensor ring decomposition",
    "Ensure ValueError is raised for when invalid ls_solve is given",
    "Create callback function for error tracking and run decomposition",
    "Ensure decomposition returns right number of factors",
    "Ensure cores are sized correctly",
    "Compute decomposition relative error and ensure it's small enough",
    "Ensure error decreases monotonically (up to numerical error)",
    "Ensure TensorRingALS class passes arguments correctly to decomposition function",
    "Ensure that the computed decomposition is the same when the same random seed is",
    "used",
    "Generate random tensor which has exact tensor ring decomposition",
    "Create callback function for error tracking and run decomposition",
    "Ensure decomposition returns right number of factors",
    "Ensure cores are sized correctly",
    "Compute decomposition relative error and ensure it's small enough.",
    "Note that sampling-based decomposition of the small tensors used in this test",
    "is somewhat precarious, so the rel_error_tol or number of samples used may have",
    "to be adapted in case of failure for other backends/random seeds.",
    "Ensure TensorRingALS class passes arguments correctly to decomposition function",
    "Ensure that the computed decomposition is the same when the same random seed is",
    "used",
    "The point of this test is to attempt decomposing a sligthly larger tensor than the",
    "test in test_tensor_ring_als_sampled. The tensor in the present function is",
    "approaching a size where we can expect sampling to yield an accurate result even",
    "with meaningful downsampling.",
    "Define tensor properties",
    "Some decomposition properties",
    "Generate random tensor which has exact tensor ring decomposition",
    "Create callback function for error tracking and run decomposition",
    "Get relative error from callback object",
    "Check if computed relative error is less than acceptable tolerance",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Test convergence criterion",
    "Check that the previous iteration didn't meet the criteria",
    "Create dummy variable for the previous iteration",
    "Test with line search where the reconstruction error would worsen if accepted",
    "Assert that the factor matrices, projection and reconstruction error all",
    "are unaffected by the line search",
    "Test with line search where the reconstruction error would improve if accepted",
    "Assert that the factor matrices, projection and reconstruction error all",
    "are changed by the line search",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Fit with only one iteration to check non-negativity",
    "The default random parafac2 tensor has non-negative A and C",
    "we therefore multiply them randomly with -1, 0 or 1 to get both positive and negative components",
    "Test that constraining B leads to a warning",
    "Double the number of matrices so that we switch to the cross-product",
    "These factor matrices should be essentially the same",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Generate a random state for me",
    "random state from integer seed",
    "if it is already a random state, just return it",
    "only takes as seed a random state, an int or None",
    "tests that the columns of each factor matrix are indeed orthogonal",
    "(See issue #40)",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Authors: Taylor Lee Patti <taylorpatti@g.harvard.edu>",
    "Jean Kossaifi",
    "All density matrices are Hermitian, here real. Hermitianize matrix if rounding/transformation",
    "errors have occured.",
    "Check if matrix1 and matrix2 are lists of the same length",
    "Check if all matrices have the same number of columns",
    "Check if any norm is exactly zero to avoid singularity",
    "Authors: Hratch Baghdassarian <hmbaghdassarian@gmail.com>, Erick Armingol <earmingol14@gmail.com>",
    "similarity metrics for tensor decompositions",
    "check input factors shape",
    "check method",
    "vertically stack loading matrices -- shape sum(tensor.shape)xR)",
    "normalize columns to L2 norm - even if ran decomposition with normalize_factors=True",
    "generate the correlation index input",
    "correlation index scoring",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "TODO: write a function to do this..",
    "Adding test from @maximeguillaud issue #487",
    "Overfactoring causes a singular matrix error.",
    "Create no_row-by-no_col matrix of given rank",
    "Compute leverage scores via leverage_score_dist function",
    "Assert that all entries of distribution are non-negative",
    "Assert that the distribution sums to one",
    "Assert that lev_score_dist matches true leverage score distribution",
    "initialize random matrix",
    "Workaround for tensorflow",
    "randomly create intervals to separate matrix into factors list",
    "test column permutation invariance",
    "test scaling invariance",
    "Make sure it's not a tuple but a list",
    "Add two one-dimensional mode to data_tensor",
    "perform TTOI for n_iter iterations",
    "first perform forward update",
    "left_singular_vectors will be a list including estimated left singular spaces at the current iteration",
    "initialize left_residuals (sequential unfolding of data_tensor multiplied by left_singular_vectors sequentially on the left, useful for backward update to obtain right_singular_vectors)",
    "estimate the first left singular spaces",
    "Here, R_tmp is the first sequential unfolding compressed on the right by previous updated right_singular_vectors (if exists)",
    "estimate the 2nd to (d-1)th left singular spaces",
    "compress the (mode+2)th sequential unfolding of data_tensor from the left",
    "R_tmp_l will be useful for backward update",
    "compress the (mode+2)th sequential unfolding of data_tensor from the right (if iteration>0)",
    "forward update is done; output the final residual",
    "perform backward update",
    "initialize right_singular_vectors: right_singular_vectors will be a list of estimated right singular spaces at the current or previous iteration",
    "estimate the 2nd to (d-1)th right singular spaces",
    "compress left_residuals from the right",
    "return final results",
    "Check user input for errors",
    "Make sure iter's not a tuple but a list",
    "Initialize rank",
    "list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.",
    "list row_idx: row indices    (left indices)  for skeleton-decomposition: indicate which rows used in each core.",
    "Initialize indice: random selection of column indices",
    "Initialize the cores of tensor-train",
    "#####################################",
    "left-to-right step",
    "list row_idx: list of (tensor_order-1) of lists of left indices",
    "update row indices",
    "end left-to-right step",
    "##############################################",
    "##############################################",
    "right-to-left step",
    "list col_idx: list (tensor_order-1) of lists of right indices",
    "update col indices",
    "Compute cores",
    "The rank should not be larger than the input tensor's size",
    "Add the last core",
    "end right-to-left step",
    "###############################################",
    "check the error for while-loop",
    "check convergence",
    "Extract fibers according to the row and col indices",
    "Extract the core",
    "shape the core as a 3-tensor_order cube",
    "merge r_k and n_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "Extract fibers",
    "shape the core as a 3-tensor_order cube",
    "merge n_{k-1} and r_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "The index of row of the submatrix",
    "Rest of rows / unselected rows",
    "Find r rows iteratively",
    "Compute the square of norm of each row",
    "If there is only one row of A left, let's just return it.",
    "If a row is 0, we delete it.",
    "Find the row of max norm",
    "Compute the projection of max_row to other rows",
    "projection a to b is computed as: <a,b> / sqrt(|a|*|b|)",
    "make sure normalization vector is of the same shape of projection",
    "Subtract the projection from A_new:  b <- b - a * projection",
    "Delete the selected row",
    "update the row_idx and rest_of_rows",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TEST 4",
    "Random tensor is not really compress-able. Test on a tensor as values of a function",
    "Find TT decomposition of the tensor",
    "!/usr/bin/env python3",
    "Generate tensor true_tensor with low tensor train rank, and its noisy observation data_tensor",
    "run TTOI",
    "Check that the approximation error monotonically decreases",
    "assert (np.all(np.diff(tl.to_numpy(approx_errors)) <= 1e-3))",
    "check that the estimation error of TTOI improves from initialization (TTSVD)",
    "from ...backend import _get_backend_method, _get_backend_dir",
    "from ...backend import backend",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__, backend_manager.__getattribute__, sparse_dir)",
    "override_module_dispatch(__name__, _get_backend_method, sparse_dir)",
    "Make sure the algorithm stays sparse. This will run out of memory on",
    "most machines if the algorithm densifies.",
    "Will blow-up memory if not sparse-safe",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Default on standard SVD",
    "all-zeros matrix, so we should do a quick return.",
    "We can perform a partial SVD",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "use dense form when sparse form will fail",
    "use dense form when sparse form will fail",
    "WARNING: here, V is still the transpose of what it should be",
    "Check correct rank and shapes are returned",
    "One of the factors has the wrong rank",
    "Not the correct amount of weights",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test cp_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test cp_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "If we're taking the gradient of comparison with self it should be 0",
    "Check that we can solve for a direction of descent",
    "Check that modifying copy tensor doesn't change the original tensor",
    "one target cp tensor",
    "two target cp tensors",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not three factor matrices",
    "Not enough projections",
    "Wrong number of weights",
    "The projections aren't orthogonal",
    "Disable tests for inplace edits, since that possibility is removed",
    "to support TensorFlow.",
    "@pytest.mark.parametrize('copy', [True, False])",
    "First slice is compressed",
    "Second slice is not compressed",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create tensor",
    "Compute ground truth TT factors",
    "Check that TT factors re-assemble to the original tensor",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Reconstruct the original tensor",
    "Check that the rank is 10",
    "Rounding = floor",
    "Rounding = ceil",
    "Testing for a tensor-train",
    "Testing for a Tensor-Ring",
    "Testing for a TT-Matrix",
    "Author: Jean Kossaifi",
    "Set in context manager",
    "Sets back to numpy",
    "Reset back to initial backend",
    "Set not in context manager",
    "Improper name doesn't reset backend",
    "Changes only happen locally in this thread",
    "Set the global default backend",
    "Changed toplevel default in all threads",
    "Changes only happen locally in this thread",
    "Set the global default backend",
    "Changed toplevel default in all threads",
    "True reconstruction error (based on numpy SVD)",
    "Reconstruction error with the backend's SVD",
    "Check that the two are similar",
    "Check for orthogonality when relevant",
    "Should fail on non-matrices",
    "Test for singular matrices (some eigenvals will be zero)",
    "Rank at most 5",
    "Test orthonormality when  max_dim > n_eigenvecs > matrix_rank",
    "Test if truncated_svd returns the same result for the same setting",
    "limit as order->oo is the oo-norm",
    "Test that clip can work with single arguments",
    "More extensive test with a larger random tensor",
    "Regression test for bug found with the pytorch backend",
    "1D",
    "2D",
    "3D",
    "random testing against Numpy's output",
    "1-dim x n-dim",
    "n_dim x 1-dim",
    "n-dim x n-dim",
    "test dimensions",
    "test residuals",
    "test least squares solution",
    "assert that the columns of Q are orthonormal",
    "Third order tensor",
    "Example data",
    "Tensorly tensor",
    "Compare against scipy baseline result",
    "Run tensorly logsumexp",
    "Numpy array",
    "No dtype given -> dtype should be inferred from input array",
    "dtype given -> dtype should be overwritten",
    "Check init from numpy array",
    "Check init from python list",
    "Numpy array",
    "No dtype given -> dtype should be inferred from input array",
    "dtype given -> dtype should be overwritten",
    "Check init from numpy array",
    "Check init from python list",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create ground truth TR factors",
    "Create tensor",
    "Check that TR factors re-assemble to the original tensor",
    "Rounding = floor",
    "Rounding = ceil",
    "Integer rank",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not enough factors to match core",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test tucker_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test tucker_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "With fixed modes",
    "Floor",
    "Ceil",
    "Check that modifying copy tensor doesn't change the original tensor",
    "Author: Jean Kossaifi",
    "hard coded example",
    "check dims",
    "chain unfolding and folding",
    "Convert to vector and back to tensor",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "We created here a tensor with 3 samples, each sample being similar to X",
    "Test for raveled tensor",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Test for raveled tensor",
    "Test for raveled_tensor=True",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "we created here a tensor with 3 samples, each sample being similar to X",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Equivalence with unfolding",
    "We're not changing anything:",
    "We're missing some modes of the tensor:",
    "We have a duplicate mode",
    "New function renaming old_fun",
    "Old fun will return fun but issue a deprecation warning",
    "Check if the default function is called when the backend is not \"backend\"",
    "Monkeypatch get_backend and check that the specific function is called when backend is \"backend\"",
    "Test using the deprecated function",
    "Test using the new function instead",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Meraj Hashemizadeh <merajhse@mila.quebec>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "License: BSD 3 clause",
    "columns of U, rows of V",
    "rows of V, columns of U",
    "NNDSVD initialization",
    "The leading singular triplet is non-negative",
    "so it can be used as is for initialization.",
    "extract positive and negative parts of column vectors",
    "and their norms",
    "choose update",
    "After this point we no longer need H",
    "Perform power iterations when spectrum decays slowly",
    "Check that matrix is... a matrix!",
    "transpose matrix to keep the reduced matrix shape minimal",
    "Workaround to avoid needing fill_diagonal",
    "Checking that no mode is constrained twice",
    "Next line finds mutual peak points",
    "Making it work for 1-dimensional tensors as well",
    "Broadcasting is used to divide rows by 1,2,3...",
    "Added -1 to correspond to a Python index",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "backend = getattr(module, )()",
    "Initialise the backend to the default one",
    "Author: Jean Kossaifi",
    "Check that we did not change the original tensor",
    "Check that we did not change the original tensor",
    "1d Tensor",
    "2d Tensor",
    "Monotone increasing",
    "Monotone decreasing",
    "small test",
    "account for floating point errors: np array have a precision of around 2e-15",
    "check np.finfo(np.float64).eps",
    "Check that we did not change the original tensor",
    "Another test",
    "Test with missing values",
    "Version forming explicitely the khatri-rao product",
    "Efficient sparse-safe version",
    "Equivalence with inner product when contracting with self along all modes",
    "Equivalent to the above expression",
    "Equivalence with n-mode-dot",
    "Multi-mode-dot",
    "Wrong number of modes",
    "size mismatch",
    "Test Batched tensor dot",
    "Check for each sample of the batch-size individually",
    "Test for actual tensordot",
    "Author: Jean Kossaifi",
    "resulting matrix must be of shape (prod(n_rows), n_columns)",
    "fail case: all matrices must have same number of columns",
    "all matrices should be of dim 2...",
    "Classic example/test",
    "A = np.hstack((np.eye(3), np.arange(3)[:, None]))",
    "Test with one matrix only: khatri-rao of one matrix = that matrix",
    "Check that negative dims are made positive",
    "Author: Jean Kossaifi",
    "Mathematical test",
    "Another test",
    "Adding a third matrices",
    "Test for the reverse argument",
    "Check that the original list has not been reversed",
    "Check the returned shape",
    "Khatri-rao is a column-wise kronecker product",
    "Khatri-rao product is a column-wise kronecker product",
    "Test while skipping a matrix",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "For one common mode, equivalent to dot product",
    "For no common mode, equivalent to inner product",
    "Inner product of tensors with different shapes is not defined",
    "tensor times matrix",
    "######################",
    "tensor times vector #",
    "######################",
    "Test with a matrix",
    "Test with a third order tensor",
    "Using equivalence with unfolded expression",
    "########################################",
    "Test for errors that should be raised #",
    "########################################",
    "Same test for the vector case",
    "Cannot take mode product of tensor with tensor",
    "Test using the equivalence with unfolded expression",
    "Test skipping a factor",
    "Test contracting with a vector",
    "result should be a scalar",
    "Average pooling each mode",
    "Order should not matter",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Indices of each matrix",
    "Author: Jean Kossaifi",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "However, it is needed to pop dimensions contracted over",
    "print(i, matrix_or_vec.shape, mode)",
    "print(f'skipping {skip}')",
    "We are contracting over the mode-th dimension",
    "mat_symbol = f'{tensor_modes[mode]}{chr(counter)}'",
    "Contracting mode-th mode with a matrix: new dimension",
    "If fully contracting",
    "matrix_or_vec_list = [m for (i, m) in enumerate(matrix_or_vec_list) if ((skip is None) or (skip != i))]",
    "print(equation, tl.shape(tensor), [tl.shape(f) for f in matrix_or_vec_list])",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Testing whether the matrices have the proper size",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "Each core is of shape (rank_left, size_in, size_out, rank_right)",
    "Intertwine the dims",
    "full_shape = in_shape[0], out_shape[0], in_shape[1], ...",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "Create the tensor algebra dispatching backend and register methods",
    "TODO : add batched_modes as in batched_tensor_dot?",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Testing whether the matrices have the proper size",
    "Prepare to reorganize the modes afterwards by moving bactch size back to their place",
    "(while ommiting modes contracted over)",
    "We will reorganize tensor1 to (batch_modes, new_modes1, contraction_modes)",
    "Tensor2 will be (batch_modes, contraction_modes, new_modes2)",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "@staticmethod",
    "def tensor(data, dtype=np.float64, device=None, device_id=None):",
    "if isinstance(data, tf.Tensor) or isinstance(data, tf.Variable):",
    "return tf.cast(data, dtype=dtype)",
    "",
    "out = tf.Variable(data, dtype=dtype)",
    "return out.gpu(device_id) if device == \"gpu\" else out",
    "Determine the dtype and device from the input if not provided",
    "Create the tensor and cast to the determined dtype",
    "If device or device_id is specified, place the tensor on the correct device",
    "Register numpy functions",
    "Register linalg functions",
    "Register tfm functions",
    "Register tnp functions",
    "See https://github.com/tensorly/tensorly/pull/397",
    "and https://github.com/google/jax/issues/3473",
    "return copy.copy(tensor)",
    "handle difference in default axis notation",
    "If source is a tensor, use clone-detach as suggested by PyTorch",
    "Else, use PyTorch's tensor constructor",
    "Set dtype/device/requires_grad if specified",
    "pytorch does not accept `None` for any keyword arguments. additionally,",
    "pytorch doesn't seems to support keyword arguments in the first place",
    "Register the other functions",
    "set default device to cpu",
    "\"place\": tensor.place,",
    "\"stop_gradient\": tensor.stop_gradient,",
    "If source is a tensor, use clone-detach as suggested by Paddle",
    "Else, use Paddle's tensor constructor",
    "set default device to cpu when place is not specified",
    "and  gpu is avaiable",
    "Set dtype/place/stop_gradient if specified",
    "indices is bool mask",
    "NOTE: Assure source Tensor is contiguous",
    "NOTE: Behavior in paddle.linalg.lstsq may be different from numpy.linalg.lstsq",
    "so we add some extra process here to keep the same behavior.",
    "Register the other functions",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "We don't use `functools.wraps` here because some of the dispatched",
    "methods include the backend (`cls`) as a parameter. Instead we manually",
    "copy over the needed information, and filter the signature for `cls`.",
    "If it doesn't have a signature we don't need to remove self",
    "This happens for NumPy (e.g. np.where) where inspect.signature(np.where) errors:",
    "ValueError: no signature found for builtin <built-in function where>",
    "backend = getattr(module, )()",
    "Backend is a string",
    "Initialise the backend to the default one",
    "Swiss",
    "Rectangle",
    "circle: approximate test",
    "Scaling",
    "Safety procedure, if columns aren't allow to be zero",
    "Parameters",
    "To avoid singularity error when initial x exists",
    "Start from zeros if solve is not achieved",
    "update support vector if it is necessary",
    "set x to s",
    "gradient update",
    "Weights processing",
    "Populate None or the input float in a list for all modes",
    "Populate None or the input float in a list for all modes",
    "Convert None to 0",
    "adding ridge penalty unless done by user on non-sparse/ridge factors to avoid degeneracy",
    "case 1: individual values for l1 l2 regularization parameters",
    "nothing particular to process",
    "case 2: add l2 regularization to a mode not regularized with a warning",
    "case 3: format regularizations when not provided as a list",
    "Author: Jean Kossaifi",
    "Author: Jean Kossaifi",
    "Author: Cyrillus Tan, Jackson Chin, Aaron Meyer",
    "License: BSD 3 clause",
    "# PREPROCESSING",
    "Check that both tensors are coupled along the first mode",
    "Check the shape of X and Y; convert vector Y to a matrix",
    "Mean center the data, record info the object",
    "Coefficients of the linear model",
    "# FITTING EACH COMPONENT",
    "Put iteration results back to the parameter variables",
    "Deflation",
    "Check on the shape of Y",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise modes of W",
    "Regress phi on y: we could call a package here, e.g. scikit-learn",
    "Convergence check",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise the weights randomly",
    "Norm of the weight tensor at each iteration",
    "Optimise each factor of W",
    "Convergence check",
    "Parameter of the experiment",
    "Generate random samples",
    "Authors: Jackson L. Chin, Cyrillus Tan, Aaron Meyer",
    "Supporting Functions",
    "Class Structure Tests",
    "Dimension Compatibility Tests",
    "Decomposition Accuracy Tests",
    "Parameter of the experiment",
    "Generate random samples"
  ],
  "0.8.2": [
    "from slimit import minify",
    "Ignore already minified files",
    "Ignore already minified files",
    "!/usr/bin/env python3",
    "-*- coding: utf-8 -*-",
    "",
    "tensorly documentation build configuration file",
    "",
    "This file is execfile()d with the current directory set to its",
    "containing dir.",
    "",
    "Note that not all possible configuration values are present in this",
    "autogenerated file.",
    "",
    "All configuration values have a default; values that are commented out",
    "serve to show the default.",
    "If extensions (or modules to document with autodoc) are in another directory,",
    "add these directories to sys.path here. If the directory is relative to the",
    "documentation root, use os.path.abspath to make it absolute, like shown here.",
    "sys.path.insert(0, os.path.abspath('sphinx_ext'))",
    "-- General configuration ------------------------------------------------",
    "If your documentation needs a minimal Sphinx version, state it here.",
    "needs_sphinx = '1.0'",
    "Add any Sphinx extension module names here, as strings. They can be",
    "extensions coming with Sphinx (named 'sphinx.ext.*') or your custom",
    "ones.",
    "'sphinx.ext.imgmath',",
    "path to your examples scripts",
    "path where to save gallery generated examples",
    "Add any paths that contain templates here, relative to this directory.",
    "generate autosummary even if no references",
    "The suffix(es) of source filenames.",
    "You can specify multiple suffix as a list of string:",
    "source_suffix = ['.rst', '.md']",
    "The encoding of source files.",
    "source_encoding = 'utf-8-sig'",
    "The master toctree document.",
    "General information about the project.",
    "The version info for the project you're documenting, acts as replacement for",
    "|version| and |release|, also used in various other places throughout the",
    "built documents.",
    "",
    "The short X.Y version.",
    "version = '0.1'",
    "The full version, including alpha/beta/rc tags.",
    "release = ''",
    "The language for content autogenerated by Sphinx. Refer to documentation",
    "for a list of supported languages.",
    "",
    "This is also used if you do content translation via gettext catalogs.",
    "Usually you set \"language\" from the command line for these cases.",
    "There are two options for replacing |today|: either, you set today to some",
    "non-false value, then it is used:",
    "today = ''",
    "Else, today_fmt is used as the format for a strftime call.",
    "today_fmt = '%B %d, %Y'",
    "List of patterns, relative to source directory, that match files and",
    "directories to ignore when looking for source files.",
    "This patterns also effect to html_static_path and html_extra_path",
    "The reST default role (used for this markup: `text`) to use for all",
    "documents.",
    "default_role = None",
    "If true, '()' will be appended to :func: etc. cross-reference text.",
    "If true, the current module name will be prepended to all description",
    "unit titles (such as .. function::).",
    "If true, sectionauthor and moduleauthor directives will be shown in the",
    "output. They are ignored by default.",
    "show_authors = False",
    "The name of the Pygments (syntax highlighting) style to use.",
    "A list of ignored prefixes for module index sorting.",
    "modindex_common_prefix = []",
    "If true, keep warnings as \"system message\" paragraphs in the built documents.",
    "keep_warnings = False",
    "If true, `todo` and `todoList` produce output, else they produce nothing.",
    "-- Options for HTML output ----------------------------------------------",
    "\"<project> v<release> documentation\" by default.",
    "A shorter title for the navigation bar.  Default is the same as html_title.",
    "Add any paths that contain custom static files (such as style sheets) here,",
    "relative to this directory. They are copied after the builtin static files,",
    "so a file named \"default.css\" will overwrite the builtin \"default.css\".",
    "The name of an image file (relative to this directory) to place at the top",
    "of the sidebar.",
    "html_logo_url = '_static/logos/logo_tensorly.png'",
    "-- Options for LaTeX output ---------------------------------------------",
    "Grouping the document tree into LaTeX files. List of tuples",
    "(source start file, target name, title,",
    "author, documentclass [howto, manual, or own class]).",
    "\\setcounter{MaxMatrixCols}{20} corrects an ugly bug if you try to have a matrix of more than 10 elements or so",
    "We want the same for the html version:",
    "The name of an image file (relative to this directory) to place at the top of",
    "the title page.",
    "latex_logo = None",
    "For \"manual\" documents, if this is true, then toplevel headings are parts,",
    "not chapters.",
    "latex_use_parts = False",
    "If true, show page references after internal links.",
    "If true, show URL addresses after external links.",
    "Documents to append as an appendix to all manuals.",
    "latex_appendices = []",
    "Get completely rid of index",
    "If false, no module index is generated.",
    "latex_domain_indices = True",
    "-- Options for manual page output ---------------------------------------",
    "One entry per manual page. List of tuples",
    "(source start file, name, description, authors, manual section).",
    "If true, show URL addresses after external links.",
    "man_show_urls = False",
    "-- Options for Texinfo output -------------------------------------------",
    "Grouping the document tree into Texinfo files. List of tuples",
    "(source start file, target name, title, author,",
    "dir menu entry, description, category)",
    "Documents to append as an appendix to all manuals.",
    "texinfo_appendices = []",
    "If false, no module index is generated.",
    "texinfo_domain_indices = True",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "texinfo_show_urls = 'footnote'",
    "If true, do not generate a @detailmenu in the \"Top\" node's menu.",
    "texinfo_no_detailmenu = False",
    "-- Options for Epub output ----------------------------------------------",
    "Bibliographic Dublin Core info.",
    "The basename for the epub file. It defaults to the project name.",
    "epub_basename = project",
    "The HTML theme for the epub output. Since the default themes are not",
    "optimized for small screen space, using the same theme for HTML and epub",
    "output is usually not wise. This defaults to 'epub', a theme designed to save",
    "visual space.",
    "epub_theme = 'epub'",
    "The language of the text. It defaults to the language option",
    "or 'en' if the language is not set.",
    "epub_language = ''",
    "The scheme of the identifier. Typical schemes are ISBN or URL.",
    "epub_scheme = ''",
    "The unique identifier of the text. This can be a ISBN number",
    "or the project homepage.",
    "epub_identifier = ''",
    "A unique identification for the text.",
    "epub_uid = ''",
    "A tuple containing the cover image and cover page html template filenames.",
    "epub_cover = ()",
    "A sequence of (type, uri, title) tuples for the guide element of content.opf.",
    "epub_guide = ()",
    "HTML files that should be inserted before the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_pre_files = []",
    "HTML files that should be inserted after the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_post_files = []",
    "A list of files that should not be packed into the epub file.",
    "The depth of the table of contents in toc.ncx.",
    "epub_tocdepth = 3",
    "Allow duplicate toc entries.",
    "epub_tocdup = True",
    "Choose between 'default' and 'includehidden'.",
    "epub_tocscope = 'default'",
    "Fix unsupported image types using the Pillow.",
    "epub_fix_images = False",
    "Scale large images.",
    "epub_max_image_width = 0",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "epub_show_urls = 'inline'",
    "If false, no index is generated.",
    "epub_use_index = True",
    "-*- coding: utf-8 -*-",
    "Created: Sun May 21 20:38:59 2017",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Created Sun Nov 27 14:03:07 2016",
    "Author: \u00d3scar N\u00e1jera",
    "can't use codecs.open(filename, 'r', 'utf-8') here b/c ast doesn't",
    "seem to work with unicode strings in Python2.7",
    "\"SyntaxError: encoding declaration in Unicode string\"",
    "change from Windows format to UNIX for uniformity",
    "This get the content of the file after the docstring last line",
    "Note: 'maxsplit' argument is not a keyword argument in python2",
    "sphinx_gallery_<name> = <value>",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "Try Python 3 first, otherwise load from Python 2",
    "This is a.b, not e.g. a().b",
    "need to get a in a().b",
    "Join import path to relative path",
    "Find out what the real object is supposed to be.",
    "Ensure shortened object is the same as what we expect.",
    "get the last working module name",
    "name is as written in file (e.g. np.asarray)",
    "full_name includes resolved import path (e.g. numpy.asarray)",
    "module without attribute. This is not useful for",
    "backreferences",
    "get shortened module name",
    "Inside rst files forward slash defines paths",
    "-*- coding: utf-8 -*-",
    "This gets set when the extension is initialized.",
    "colorfunc is a valid kwarg in 1.5, but not older, so we just",
    "apply it ourselves.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "shelve keys need to be str in python 2",
    "value is a list",
    "try to convert elements to int",
    "value is another dictionary",
    "Make sure searchindex uses UTF-8 encoding",
    "parse objects",
    "parse filenames",
    "detect if we are using relative links on a Windows system",
    "download and initialize the search index",
    "In 1.5+ Sphinx seems to have changed from .rst.html to only",
    ".html extension in converted files. But URLs could be",
    "built with < 1.5 or >= 1.5 regardless of what we're currently",
    "building with, so let's just check both :(",
    "test if cobj appears in page",
    "we don't have it cached",
    "cache it for the future",
    "failed to resolve",
    "replace '\\' with '/' so it on the web",
    "for some reason, the relative link goes one directory too high up",
    "Add resolvers for the packages for which we want to show links",
    "patterns for replacement",
    "This could be turned into a generator if necessary, but should be okay",
    "we have a pickle file with the objects to embed links for",
    "generate replacement strings with the links",
    "do the replacement in the html file",
    "ensure greediness",
    "No need to waste time embedding hyperlinks when not running the examples",
    "XXX: also at the time of writing this fixes make html-noplot",
    "for some reason I don't fully understand",
    "XXX: Whitelist of builders for which it makes sense to embed",
    "hyperlinks inside the example html. Note that the link embedding",
    "require searchindex.js to exist for the links to the local doc",
    "and there does not seem to be a good way of knowing which",
    "builders creates a searchindex.js.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "##############################################################################",
    "Notebook shell utility",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "build options",
    "Sphinx hack: sphinx copies generated images to the build directory",
    "each time the docs are made.  If the desired image name already",
    "exists, it appends a digit to prevent overwrites.  The problem is,",
    "the directory is never cleared.  This means that each time you build",
    "the docs, the number of images in the directory grows.",
    "",
    "This question has been asked on the sphinx development list, but there",
    "was no response: https://git.net/ml/sphinx-dev/2011-02/msg00123.html",
    "",
    "The following is a hack that prevents this behavior by clearing the",
    "image build directory from gallery images each time the docs are built.",
    "If sphinx changes their layout between versions, this will not",
    "work (though it should probably not cause a crash).",
    "Tested successfully on Sphinx 1.0.7",
    "this assures I can call the config in other places",
    "Here we don't use an os.walk, but we recurse only twice: flat is",
    "better than nested.",
    "we create an index.rst with all examples",
    ":orphan: to suppress \"not included in TOCTREE\" sphinx warnings",
    "touch file",
    "Under no-plot Examples are not run so nothing to summarize",
    "Sphinx < 1.6 calls it `_extensions`, >= 1.6 is `extensions`.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Don't use unicode_literals here (be explicit with u\"...\" instead) otherwise",
    "tricky errors come up with exec(code_blocks, ...) calls",
    "Try Python 2 first, otherwise load from Python 3",
    "textwrap indent only exists in python 3",
    "make sure that the Agg backend is set before importing any",
    "matplotlib",
    "##############################################################################",
    "##############################################################################",
    "The following strings are used when we have several pictures: we use",
    "an html div tag that our CSS uses to turn the lists into horizontal",
    "lists.",
    "This one could contain unicode",
    "Sphinx only starts numbering from the first non-empty line.",
    "lstrip is just in case docstring has a '\\n\\n' at the beginning",
    "Set the fig_num figure as the current figure as we can't",
    "save a figure that's not the current figure.",
    "make sure the image is not too large",
    "local import to avoid testing dependency on PIL:",
    "resize the image",
    "insert centered",
    "Use optipng to perform lossless compression on the resized image if",
    "software is installed",
    "read specification of the figure to display as thumbnail from main text",
    "create something to replace the thumbnail",
    "Add empty lines to avoid bug in issue #165",
    "sort to have the smallest entries in the beginning",
    "clear at the end of the section",
    "Remove our code from traceback:",
    "Remove one extra level through ast.parse.",
    "Breaks build on first example error",
    "Stores failing file",
    "If example is not suitable to run, skip executing its blocks",
    "Redirect output to stdout and",
    "First cd in the original example dir, so that any file",
    "created by the example get created in this directory",
    "don't use unicode_literals at the top of this file or you get",
    "nasty errors here on Py2.7",
    "Horrible code to 'unload' seaborn, so that it resets",
    "its default when is load",
    "Python does not support unloading of modules",
    "https://bugs.python.org/issue9072",
    "Reset Matplotlib to default",
    "A lot of examples contains 'print(__doc__)' for example in",
    "scikit-learn so that running the example prints some useful",
    "information. Because the docstring has been separated from",
    "the code blocks in sphinx-gallery, __doc__ is actually",
    "__builtin__.__doc__ in the execution context and we do not",
    "want to print it",
    "Examples may contain if __name__ == '__main__' guards",
    "for in example scikit-learn if the example uses multiprocessing",
    "Don't ever support __file__: Issues #166 #212",
    "A simple example has two blocks: one for the",
    "example introduction/explanation and one for the code",
    "We want to run the example without arguments. See",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/252",
    "for more details.",
    "Add some vertical space after output",
    "Writes md5 checksum if example has build correctly",
    "not failed and was initially meant to run(no-plot shall not cache md5sum)",
    "-*- coding: utf-8 -*-",
    "Error + critical both go through warning:",
    "-*- coding: utf-8 -*-",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Need to import gen_rst before matplotlib.pyplot to set backend to 'Agg'",
    "For more details see",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/49",
    "verify correct md5sum",
    "False because is a new file",
    "Write md5sum to file to check is current",
    "read rst file and check if it contains traceback output",
    "create three files in tempdir (only one matches the pattern)",
    "generate rst file",
    "read rst file and check if it contains code output",
    "which plot to show as the thumbnail image",
    "test issue #229",
    "TODO: test that broken thumbnail does appear when needed",
    "TODO: test that examples are not executed twice",
    "TODO: test that examples are executed after a no-plot and produce",
    "the correct image in the thumbnail",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "recovers data from temporary file and caches it in the shelve",
    "tests recovered data matches",
    "test if cached data is available after temporary file has vanished",
    "shelve keys need to be str in python 2, deal with unicode input",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "General information about the project.",
    "no duplicate values allowed The config is present already",
    "General information about the project.",
    "General information about the project.",
    "General information about the project.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Test fails on wrong input",
    "Test missing folder",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "##############################################################################",
    "Notebook shell utility",
    "replace reference numbers so that there are no duplicates",
    "Strip top title",
    "call function to replace reference numbers so that there are no",
    "duplicates",
    "Do not try to inspect classes that don't define `__init__`",
    "Extra mangling domains",
    "------------------------------------------------------------------------------",
    "Docstring-mangling domains",
    "------------------------------------------------------------------------------",
    "go to next non-empty line in old:",
    "line.strip() checks whether the string is all whitespace",
    "------------------------------------------------------------------------------",
    "Registration hook",
    "------------------------------------------------------------------------------",
    "------------------------------------------------------------------------------",
    "plot:: directive",
    "------------------------------------------------------------------------------",
    "no argument given, assume used as a flag",
    "------------------------------------------------------------------------------",
    "Generating output",
    "------------------------------------------------------------------------------",
    "Sphinx depends on either Jinja or Jinja2",
    "determine input",
    "ensure that LaTeX includegraphics doesn't choke in foo.bar.pdf filenames",
    "is it in doctest format?",
    "determine output directory name fragment",
    "build_dir: where to place output files (temporarily)",
    "output_dir: final location in the builder's directory",
    "how to link to files from the RST file",
    "make figures",
    "generate output restructuredtext",
    "copy image files to builder's output directory",
    "copy script (if necessary)",
    "------------------------------------------------------------------------------",
    "Run code and capture figures",
    "------------------------------------------------------------------------------",
    "check if it's valid Python as-is",
    "Change the working directory to the directory of the example, so",
    "it can get at its data files, if any.",
    "Redirect stdout",
    "Reset sys.argv",
    "------------------------------------------------------------------------------",
    "Generating figures",
    "------------------------------------------------------------------------------",
    "-- Parse format list",
    "-- Try to determine if all images already exist",
    "Look for single-figure output files first",
    "Then look for multi-figure output files",
    "assume that if we have one, we have them all",
    "-- We didn't find the files, so build them",
    "Clear between runs",
    "Run code",
    "Collect images",
    "Results",
    "------------------------------------------------------------------------------",
    "Relative pathnames",
    "------------------------------------------------------------------------------",
    "Copied from Python 2.7",
    "Work out how much of the filepath is shared by start and path.",
    "Work out how much of the filepath is shared by start and path.",
    "If several signatures present, take the last one",
    "We could do more tests, but we are not. Arbitrarily.",
    "string conversion routines",
    "try to read signature, backward compat for older Python",
    "########################################################################",
    "object interface.",
    "########################################################################",
    "########################################################################",
    "Unparser private interface.",
    "########################################################################",
    "## format, output, and dispatch methods ################################",
    "########################################################################",
    "compiler.ast unparsing methods.",
    "",
    "There should be one method per concrete grammar type. They are",
    "organized in alphabetical order.",
    "########################################################################",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "fixme: Are From and ImportFrom handled differently?",
    "if t.step:",
    "self._write(\":\")",
    "self._dispatch(t.step)",
    "Empty tuple.",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "Check if parenthesis are needed on left side and then dispatch",
    "Write the appropriate symbol for operator",
    "Check if parenthesis are needed on the right side and then dispatch",
    "if t is 0.1, str(t)->'0.1' while repr(t)->'0.1000000000001'",
    "We prefer str here.",
    "########################################################################",
    "These are the methods from the _ast modules unparse.",
    "",
    "As our needs to handle more advanced code increase, we may want to",
    "modify some of the methods below so that they work for compiler.ast.",
    "########################################################################",
    "# stmt",
    "def _Expr(self, tree):",
    "self._fill()",
    "self._dispatch(tree.value)",
    "",
    "def _Import(self, t):",
    "self._fill(\"import \")",
    "first = True",
    "for a in t.names:",
    "if first:",
    "first = False",
    "else:",
    "self._write(\", \")",
    "self._write(a.name)",
    "if a.asname:",
    "self._write(\" as \"+a.asname)",
    "",
    "#    def _ImportFrom(self, t):",
    "#        self._fill(\"from \")",
    "#        self._write(t.module)",
    "#        self._write(\" import \")",
    "#        for i, a in enumerate(t.names):",
    "#            if i == 0:",
    "#                self._write(\", \")",
    "#            self._write(a.name)",
    "#            if a.asname:",
    "#                self._write(\" as \"+a.asname)",
    "#        # XXX(jpe) what is level for?",
    "#",
    "",
    "def _Break(self, t):",
    "self._fill(\"break\")",
    "",
    "def _Continue(self, t):",
    "self._fill(\"continue\")",
    "",
    "def _Delete(self, t):",
    "self._fill(\"del \")",
    "self._dispatch(t.targets)",
    "",
    "def _Assert(self, t):",
    "self._fill(\"assert \")",
    "self._dispatch(t.test)",
    "if t.msg:",
    "self._write(\", \")",
    "self._dispatch(t.msg)",
    "",
    "def _Exec(self, t):",
    "self._fill(\"exec \")",
    "self._dispatch(t.body)",
    "if t.globals:",
    "self._write(\" in \")",
    "self._dispatch(t.globals)",
    "if t.locals:",
    "self._write(\", \")",
    "self._dispatch(t.locals)",
    "",
    "def _Print(self, t):",
    "self._fill(\"print \")",
    "do_comma = False",
    "if t.dest:",
    "self._write(\">>\")",
    "self._dispatch(t.dest)",
    "do_comma = True",
    "for e in t.values:",
    "if do_comma:self._write(\", \")",
    "else:do_comma=True",
    "self._dispatch(e)",
    "if not t.nl:",
    "self._write(\",\")",
    "",
    "def _Global(self, t):",
    "self._fill(\"global\")",
    "for i, n in enumerate(t.names):",
    "if i != 0:",
    "self._write(\",\")",
    "self._write(\" \" + n)",
    "",
    "def _Yield(self, t):",
    "self._fill(\"yield\")",
    "if t.value:",
    "self._write(\" (\")",
    "self._dispatch(t.value)",
    "self._write(\")\")",
    "",
    "def _Raise(self, t):",
    "self._fill('raise ')",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.inst:",
    "self._write(\", \")",
    "self._dispatch(t.inst)",
    "if t.tback:",
    "self._write(\", \")",
    "self._dispatch(t.tback)",
    "",
    "",
    "def _TryFinally(self, t):",
    "self._fill(\"try\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "self._fill(\"finally\")",
    "self._enter()",
    "self._dispatch(t.finalbody)",
    "self._leave()",
    "",
    "def _excepthandler(self, t):",
    "self._fill(\"except \")",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.name:",
    "self._write(\", \")",
    "self._dispatch(t.name)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _ClassDef(self, t):",
    "self._write(\"\\n\")",
    "self._fill(\"class \"+t.name)",
    "if t.bases:",
    "self._write(\"(\")",
    "for a in t.bases:",
    "self._dispatch(a)",
    "self._write(\", \")",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _FunctionDef(self, t):",
    "self._write(\"\\n\")",
    "for deco in t.decorators:",
    "self._fill(\"@\")",
    "self._dispatch(deco)",
    "self._fill(\"def \"+t.name + \"(\")",
    "self._dispatch(t.args)",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _For(self, t):",
    "self._fill(\"for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "def _While(self, t):",
    "self._fill(\"while \")",
    "self._dispatch(t.test)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "# expr",
    "def _Str(self, tree):",
    "self._write(repr(tree.s))",
    "#",
    "def _Repr(self, t):",
    "self._write(\"`\")",
    "self._dispatch(t.value)",
    "self._write(\"`\")",
    "",
    "def _Num(self, t):",
    "self._write(repr(t.n))",
    "",
    "def _ListComp(self, t):",
    "self._write(\"[\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\"]\")",
    "",
    "def _GeneratorExp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\")\")",
    "",
    "def _comprehension(self, t):",
    "self._write(\" for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "for if_clause in t.ifs:",
    "self._write(\" if \")",
    "self._dispatch(if_clause)",
    "",
    "def _IfExp(self, t):",
    "self._dispatch(t.body)",
    "self._write(\" if \")",
    "self._dispatch(t.test)",
    "if t.orelse:",
    "self._write(\" else \")",
    "self._dispatch(t.orelse)",
    "",
    "unop = {\"Invert\":\"~\", \"Not\": \"not\", \"UAdd\":\"+\", \"USub\":\"-\"}",
    "def _UnaryOp(self, t):",
    "self._write(self.unop[t.op.__class__.__name__])",
    "self._write(\"(\")",
    "self._dispatch(t.operand)",
    "self._write(\")\")",
    "",
    "binop = { \"Add\":\"+\", \"Sub\":\"-\", \"Mult\":\"*\", \"Div\":\"/\", \"Mod\":\"%\",",
    "\"LShift\":\">>\", \"RShift\":\"<<\", \"BitOr\":\"|\", \"BitXor\":\"^\", \"BitAnd\":\"&\",",
    "\"FloorDiv\":\"//\", \"Pow\": \"**\"}",
    "def _BinOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.left)",
    "self._write(\")\" + self.binop[t.op.__class__.__name__] + \"(\")",
    "self._dispatch(t.right)",
    "self._write(\")\")",
    "",
    "boolops = {_ast.And: 'and', _ast.Or: 'or'}",
    "def _BoolOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.values[0])",
    "for v in t.values[1:]:",
    "self._write(\" %s \" % self.boolops[t.op.__class__])",
    "self._dispatch(v)",
    "self._write(\")\")",
    "",
    "def _Attribute(self,t):",
    "self._dispatch(t.value)",
    "self._write(\".\")",
    "self._write(t.attr)",
    "",
    "#    def _Call(self, t):",
    "#        self._dispatch(t.func)",
    "#        self._write(\"(\")",
    "#        comma = False",
    "#        for e in t.args:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        for e in t.keywords:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        if t.starargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"*\")",
    "#            self._dispatch(t.starargs)",
    "#        if t.kwargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"**\")",
    "#            self._dispatch(t.kwargs)",
    "#        self._write(\")\")",
    "",
    "# slice",
    "def _Index(self, t):",
    "self._dispatch(t.value)",
    "",
    "def _ExtSlice(self, t):",
    "for i, d in enumerate(t.dims):",
    "if i != 0:",
    "self._write(': ')",
    "self._dispatch(d)",
    "",
    "# others",
    "def _arguments(self, t):",
    "first = True",
    "nonDef = len(t.args)-len(t.defaults)",
    "for a in t.args[0:nonDef]:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a)",
    "for a,d in zip(t.args[nonDef:], t.defaults):",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a),",
    "self._write(\"=\")",
    "self._dispatch(d)",
    "if t.vararg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"*\"+t.vararg)",
    "if t.kwarg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"**\"+t.kwarg)",
    "",
    "#    def _keyword(self, t):",
    "#        self._write(t.arg)",
    "#        self._write(\"=\")",
    "#        self._dispatch(t.value)",
    "",
    "def _Lambda(self, t):",
    "self._write(\"lambda \")",
    "self._dispatch(t.args)",
    "self._write(\": \")",
    "self._dispatch(t.body)",
    "int : The first line number in the block. 1-indexed.",
    "int : The last line number. Inclusive!",
    "str : The text block including '#' character but not any leading spaces.",
    "Only add if not entirely whitespace.",
    "Start with a dummy.",
    "All of the blocks seen so far.",
    "The index mapping lines of code to their associated comment blocks.",
    "Oops! Trailing comment, not a comment block.",
    "A comment block.",
    "FIXME: gracefully handle errors here or in the caller?",
    "FIXME: handle other kinds of assignments?",
    "string conversion routines",
    "Check if the referenced member can have a docstring or not",
    "Referenced object has a docstring",
    "Latex collects all references to a separate bibliography,",
    "so we need to insert links to it",
    "-*- coding: utf-8 -*-",
    "Convert signode to a specified format",
    "Call user code to resolve the link",
    "no source",
    "only one link per name, please",
    "------------------------------------------------------------------------------",
    "Creating 'phantom' modules from an XML description",
    "------------------------------------------------------------------------------",
    "Sort items so that",
    "- Base classes come before classes inherited from them",
    "- Modules come before their contents",
    "Create phantom items",
    "create parent, if missing",
    "create object",
    "Populate items",
    "-*- coding: utf-8 -*-",
    "##########################################################################",
    "A tensor is simply a numpy array",
    "##########################################################################",
    "Unfolding a tensor is easy",
    "##########################################################################",
    "Re-folding the tensor is as easy:",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.7, Tensorly includes constrained CP decomposition which penalizes or",
    "constrains factors as chosen by the user. The proposed implementation of constrained CP uses the",
    "Alternating Optimization Alternating Direction Method of Multipliers (AO-ADMM) algorithm from [1] which",
    "solves alternatively convex optimization problem using primal-dual optimization. In constrained CP",
    "decomposition, an auxilliary factor is introduced which is constrained or regularized using an operator called the",
    "proximal operator. The proximal operator may therefore change according to the selected constraint or penalization.",
    "",
    "Tensorly provides several constraints and their corresponding proximal operators, each can apply to one or all factors in the CP decomposition:",
    "",
    "1. Non-negativity",
    "* `non_negative` in signature",
    "* Prevents negative values in CP factors.",
    "2. L1 regularization",
    "* `l1_reg` in signature",
    "* Adds a L1 regularization term on the CP factors to the CP cost function, this promotes sparsity in the CP factors. The user chooses the regularization amount.",
    "3. L2 regularization",
    "* `l2_reg` in signature",
    "* Adds a L2 regularization term on the CP factors to the CP cost function. The user chooses the regularization amount.",
    "4. L2 square regularization",
    "* `l2_square_reg` in signature",
    "* Adds a L2 regularization term on the CP factors to the CP cost function. The user chooses the regularization amount.",
    "5. Unimodality",
    "* `unimodality` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors is unimodal (there is only one local maximum, like a Gaussian).",
    "6. Simplex",
    "* `simplex` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors lives on the simplex or user-defined radius (entries are nonnegative and sum to a user-defined positive parameter columnwise).",
    "7. Normalization",
    "* `normalize` in signature",
    "* Impose that the largest absolute value in the factors elementwise is 1.",
    "8. Normalized sparsity",
    "* `normalized_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the columns of factors are both normalized with the L2 norm, and k-sparse (at most k-nonzeros per column) with k user-defined.",
    "9. Soft sparsity",
    "* `soft_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the columns of factors have L1 norm bounded by a user-defined threshold.",
    "10. Smoothness",
    "* `smoothness` in signature",
    "* This constraint acts columnwise on the factors",
    "* Favor smoothness in factors columns by penalizing the L2 norm of finite differences. The user chooses the regularization amount. The proximal operator in fact solves a banded system.",
    "11. Monotonicity",
    "* `monotonicity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the factors are either always increasing or decreasing (user-specified) columnwise. This is based on isotonic regression.",
    "12. Hard sparsity",
    "* `hard_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors has at most k nonzero entries (k is user-defined).",
    "",
    "While some of these constraints (2, 3, 4, 6, 8, 9, 12) require a scalar",
    "input as its parameter or regularizer, boolean input could be enough",
    "for other constraints (1, 5, 7, 10, 11). Selection of one of these",
    "constraints for all mode (or factors) or using different constraints for different modes are both supported.",
    "tensor generation",
    "#############################################################################",
    "Using one constraint for all modes",
    "--------------------------------------------",
    "Constraints are inputs of the constrained_parafac function, which itself uses the",
    "``tensorly.tenalg.proximal.validate_constraints`` function in order to process the input",
    "of the user. If a user wants to use the same constraint for all modes, an",
    "input (bool or a scalar value or list of scalar values) should be given to this constraint.",
    "Assume, one wants to use unimodality constraint for all modes. Since it does not require",
    "any scalar input, unimodality can be imposed by writing `True` for `unimodality`:",
    "#############################################################################",
    "This constraint imposes that each column of all the factors in the CP decomposition are unimodal:",
    "#############################################################################",
    "Constraints requiring a scalar input can be used similarly as follows:",
    "#############################################################################",
    "The same regularization coefficient l1_reg is used for all the modes. Here the l1 penalization induces sparsity given that the regularization coefficient is large enough.",
    "#############################################################################",
    "Using one constraint for some modes",
    "--------------------------------------------",
    "As a second option, constraint can be used for only a few selected modes by using",
    "a python dictionary:",
    "#############################################################################",
    "Since only the first and last factors are chosen, entries on the second mode factor could be negative.",
    "#############################################################################",
    "Using a constraint with the different scalar inputs for each mode",
    "---------------------------------------------------------",
    "One may prefer different scalar value for each mode. It is possible by",
    "using a list structure:",
    "#############################################################################",
    "Using different constraints for each mode",
    "--------------------------------------------",
    "To use different constraint for different modes, the dictionary structure",
    "should be preferred:",
    "#############################################################################",
    "In the dictionary, `key` is the selected mode and `value` is a scalar value or",
    "only `True` depending on the selected constraint.",
    "#############################################################################",
    "Thus, first factor will be non-negative, second factor will be regularized",
    "by :math:`0.01` with :math:`l_1` and last factor will be regularized by",
    ":math:`0.01` with :math:`l_2^2`.",
    "#############################################################################",
    "References",
    "----------",
    "",
    "[1] Huang, Kejun, Nicholas D. Sidiropoulos, and Athanasios P. Liavas.",
    "\"A flexible and efficient algorithmic framework for constrained",
    "matrix and tensor factorization.\"",
    "IEEE Transactions on Signal Processing 64.19 (2016): 5052-5065.",
    "`(Online version)",
    "<https://ieeexplore.ieee.org/document/7484753>`_",
    "-*- coding: utf-8 -*-",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor that follows the PARAFAC2 constraints found",
    "in `(Kiers et al 1999)`_.",
    "",
    "This particular tensor,",
    ":math:`\\mathcal{X}\u00a0\\in \\mathbb{R}^{I\\times J \\times K}`, is a shifted",
    "CP tensor, that is, a tensor on the form:",
    "",
    ".. math::",
    "\\mathcal{X}_{ijk} = \\sum_{r=1}^R A_{ir} B_{\\sigma_i(j) r} C_{kr},",
    "",
    "where :math:`\\sigma_i`\u00a0is a cyclic permutation of :math:`J` elements.",
    "Set parameters",
    "Generate random matrices",
    "Normalised factor matrices",
    "Generate the shifted factor matrix",
    "Construct the tensor",
    "Add noise",
    "#############################################################################",
    "Fit a PARAFAC2 tensor",
    "---------------------",
    "To avoid local minima, we initialise and fit 10 models and choose the one",
    "with the lowest error",
    "#############################################################################",
    "A decomposition is a wrapper object for three variables: the *weights*,",
    "the *factor matrices* and the *projection matrices*. The weights are similar",
    "to the output of a CP decomposition. The factor matrices and projection",
    "matrices are somewhat different. For a CP decomposition, we only have the",
    "weights and the factor matrices. However, since the PARAFAC2 factor matrices",
    "for the second mode is given by",
    "",
    ".. math::",
    "B_i = P_i B,",
    "",
    "where :math:`B` is an :math:`R \\times R` matrix and :math:`P_i` is an",
    ":math:`I \\times R` projection matrix, we cannot store the factor matrices",
    "the same as for a CP decomposition.",
    "",
    "Instead, we store the factor matrix along the first mode (:math:`A`), the",
    "\"blueprint\" matrix for the second mode (:math:`B`) and the factor matrix",
    "along the third mode (:math:`C`) in one tuple and the projection matrices,",
    ":math:`P_i`, in a separate tuple.",
    "",
    "If we wish to extract the informative :math:`B_i` factor matrices, then we",
    "use the ``tensorly.parafac2_tensor.apply_projection_matrices`` function on",
    "the PARAFAC2 tensor instance to get another wrapper object for two",
    "variables: *weights* and *factor matrices*. However, now, the second element",
    "of the factor matrices tuple is now a list of factor matrices, one for each",
    "frontal slice of the tensor.",
    "",
    "Likewise, if we wish to construct the tensor or the frontal slices, then we",
    "can use the ``tensorly.parafac2_tensor.parafac2_to_tensor`` function. If the",
    "decomposed dataset consisted of uneven-length frontal slices, then we can",
    "use the ``tensorly.parafac2_tensor.parafac2_to_slices`` function to get a",
    "list of frontal slices.",
    "#############################################################################",
    "Compute performance metrics",
    "---------------------------",
    "To evaluate how well the original structure is recovered, we calculate the tucker congruence coefficient.",
    "#############################################################################",
    "Visualize the components",
    "------------------------",
    "Find the best permutation so that we can plot the estimated components on top of the true components",
    "Create plots of each component vector for each mode",
    "(We just look at one of the B_i matrices)",
    "Plot true and estimated components for mode A",
    "Labels for the different components",
    "Plot true and estimated components for mode C",
    "Plot true components for mode B",
    "Get the signs so that we can flip the B mode factor matrices",
    "Plot estimated components for mode B (after sign correction)",
    "Titles for the different modes",
    "Create a legend for the entire figure",
    "#############################################################################",
    "Inspect the convergence rate",
    "----------------------------",
    "It can be interesting to look at the loss plot to make sure that we have",
    "converged to a stationary point. We skip the first iteration since the",
    "initial loss often dominate the rest of the plot, making it difficult",
    "to check for convergence.",
    "#############################################################################",
    "References",
    "----------",
    "",
    ".. _(Kiers et al 1999):",
    "",
    "Kiers HA, Ten Berge JM, Bro R. *PARAFAC2\u2014Part I.",
    "A direct fitting algorithm for the PARAFAC2 model.*",
    "**Journal of Chemometrics: A Journal of the Chemometrics Society.**",
    "1999 May;13(3\u20104):275-94. `(Online version)",
    "<https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-128X(199905/08)13:3/4%3C275::AID-CEM543%3E3.0.CO;2-B>`_",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, several options are available to compute",
    "non-negative CP (NCP), in particular several",
    "algorithms:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that factors must have only non-negative values after it is",
    "obtained from a non-negative tensor.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random from the sequence of integers from 1 to 24000.",
    "Tensor generation",
    "#############################################################################",
    "Our goal here is to produce an approximation of the tensor generated above",
    "which follows a low-rank CP model, with non-negative coefficients. Before",
    "using these algorithms, we can use Tensorly to produce a good initial guess",
    "for our NCP. In fact, in order to compare both algorithmic options in a",
    "fair way, it is a good idea to use same initialized factors in decomposition",
    "algorithms. We make use of the ``initialize_cp`` function to initialize the",
    "factors of the NCP (setting the ``non_negative`` option to `True`)",
    "and transform these factors (and factors weights) into",
    "an instance of the CPTensor class:",
    "#############################################################################",
    "Non-negative Parafac",
    "-----------------------",
    "From now on, we can use the same ``cp_init`` tensor as the initial tensor when",
    "we use decomposition functions. Now let us first use the algorithm based on",
    "Multiplicative Update, which can be called as follows:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the cp_to_tensor function. The tensor cp_reconstruction_mu is therefore a",
    "low-rank non-negative approximation of the input tensor; looking at the",
    "first few values of both tensors shows that this is indeed",
    "the case but the approximation is quite coarse.",
    "#############################################################################",
    "Non-negative Parafac with HALS",
    "------------------------------",
    "Our second (new) option to compute NCP is the HALS algorithm, which can be",
    "used as follows:",
    "#############################################################################",
    "Again, we can look at the reconstructed tensor entries.",
    "#############################################################################",
    "Non-negative Parafac with Exact HALS",
    "------------------------------------",
    "From only looking at a few entries of the reconstructed tensors, we can",
    "already see a huge gap between HALS and MU outputs.",
    "Additionally, HALS algorithm has an option for exact solution to the non-negative",
    "least squares subproblem rather than the faster, approximate solution.",
    "Note that the overall HALS algorithm will still provide an approximation of",
    "the input data, but will need longer to reach convergence.",
    "Exact subroutine solution option can be used simply choosing exact as True",
    "in the function:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "First comparison option is processing time for each algorithm:",
    "#############################################################################",
    "As it is expected, the exact solution takes much longer than the approximate",
    "solution, while the gain in performance is often void. Therefore we recommend",
    "to avoid this option unless it is specifically required by the application.",
    "Also note that on appearance, both MU and HALS have similar runtimes.",
    "However, a closer look suggest they are indeed behaving quite differently.",
    "Computing the error between the output and the input tensor tells that story better.",
    "In Tensorly, we provide a function to calculate Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both exact and approximate solution. In particular, HALS converged to a",
    "much lower reconstruction error than MU. We can better appreciate the difference",
    "in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases (only",
    "encountered by expert users most likely).",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105. (Link)",
    "<https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, two algorithms are available to compute non-negative",
    "Tucker decomposition:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that core and factors must have only non-negative values after",
    "it is obtained from a non-negative tensor. Tucker decomposition includes core",
    "(:math:`G`) and factors (:math:`A`, :math:`B`, :math:`C`).",
    "",
    ".. math::",
    "T = [| G; A, B , C |],",
    "",
    "We need to solve the following problem for each factor (e.g. factor :math:`A` here):",
    "",
    ".. math::",
    "\\min_{A \\geq 0} ||T_{[1]} - A\\times G_{[1]}(B\\times C)^T||_F^2,",
    "",
    "Here, :math:`G_{[i]}` represents ith mode unfolding of the core. To update",
    "the core, we need the solve following problem:",
    "",
    ".. math::",
    "\\min_{g \\geq 0} ||t -   (A\\times B \\times C)\\times g ||_F^2,",
    "",
    "where :math:`t` and :math:`g` are the vectorized data tensor :math:`T` and core :math:`G`.",
    "#############################################################################",
    "To update the factors, we will use HALS and to update the core, we have two",
    "different algorithms Active Set (AS) and Fast Iterative Shrinkage-Thresholding",
    "Algorithm (FISTA) in Tensorly. While FISTA is an accelerated gradient method for",
    "non-negative or unconstrained problems, AS is the widely used non-negative",
    "least square solution proposed by Lawson and Hanson in 1974. Both algorithms",
    "return non-negative core and FISTA is the default algorithm for HALS Tucker",
    "decomposition in Tensorly.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random tensor from the sequence of integers from",
    "1 to 1000.",
    "tensor generation",
    "#############################################################################",
    "Non-negative Tucker",
    "-----------------------",
    "First, multiplicative update can be implemented as:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the ``tucker_to_tensor`` function. The tensor ``tucker_reconstruction_mu`` is",
    "therefore a low-rank non-negative approximation of the input tensor ``tensor``.",
    "#############################################################################",
    "Non-negative Tucker with HALS and FISTA",
    "---------------------------------------",
    "HALS algorithm with FISTA can be calculated as:",
    "#############################################################################",
    "Non-negative Tucker with HALS and Active Set",
    "--------------------------------------------",
    "As a second option, HALS algorithm with Active Set can be called as follows:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "To compare the various methods, first we may look at each algorithm",
    "processing time:",
    "#############################################################################",
    "All algorithms should run with about the same number of iterations on our",
    "example, so at first glance the MU algorithm is faster (i.e. has lower",
    "per-iteration complexity). A second way to compare methods is to compute",
    "the error between the output and input tensor. In Tensorly, there is a function",
    "to compute Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both FISTA and active set core update options. We can better appreciate",
    "the difference in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases",
    "(only encountered by expert users most likely). Besides, in this experiment",
    "FISTA and active set give very similar results, however active set may last",
    "longer when it is used with higher ranks according to our experience.",
    "Therefore, we recommend to use FISTA with high rank decomposition.",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105.",
    "`(Link) https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>`_",
    "#############################################################################",
    "Function to create synthetic data",
    "---------------------------------",
    "",
    "Here, we create a function that constructs a random tensor from a PARAFAC2",
    "decomposition with noise",
    "#############################################################################",
    "Compressing data with many rows and few columns",
    "-----------------------------------------------",
    "",
    "Here, we set up for a case where we have many rows compared to columns",
    "#############################################################################",
    "Fitting without compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "As a baseline, we see how long time it takes to fit models without compression.",
    "Since PARAFAC2 is very prone to local minima, we fit five models and select the model",
    "with the lowest reconstruction error.",
    "#############################################################################",
    "Fitting with lossless compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Since the tensor slices have many rows compared to columns, we should be able to save",
    "a lot of time by compressing the data. By compressing the matrices, we only need to",
    "fit the PARAFAC2 model to a set of 10 matrices, each of size 15 x 15, not 10_000 x 15.",
    "",
    "The main bottleneck here is the SVD computation at the beginning of the fitting",
    "procedure, but luckily, this is independent of the initialisations, so we only need",
    "to compute this once. Also, if we are performing a grid search for the rank, then",
    "we just need to perform the compression once for the whole grid search as well.",
    "#############################################################################",
    "We see that we saved a lot of time by compressing the data before fitting the model.",
    "#############################################################################",
    "Fitting with lossy compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "We can try to speed the process up even further by accepting a slight discrepancy",
    "between the model obtained from compressed data and a model obtained from uncompressed",
    "data. Specifically, we can truncate the singular values at some threshold, essentially",
    "removing the parts of the data matrices that have a very low \"signal strength\".",
    "#############################################################################",
    "We see that we didn't save much, if any, time in this case (compared to using",
    "lossless compression). This is because the main bottleneck now is the CP-part of",
    "the PARAFAC2 procedure, so reducing the tensor size from 10 x 15 x 15 to 10 x 4 x 15",
    "(which is typically what we would get here) will have a negligible effect.",
    "#############################################################################",
    "Compressing data that is approximately low-rank",
    "-----------------------------------------------",
    "",
    "Here, we simulate data with many rows and columns but an approximately low rank.",
    "#############################################################################",
    "Fitting without compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Again, we start by fitting without compression as a baseline.",
    "#############################################################################",
    "Fitting with lossless compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Next, we fit with lossless compression.",
    "#############################################################################",
    "We see that the lossless compression no effect for this data. This is because the",
    "number ofrows is equal to the number of columns, so we cannot compress the data",
    "losslessly with the SVD.",
    "#############################################################################",
    "Fitting with lossy compression",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "",
    "Finally, we fit with lossy SVD compression.",
    "#############################################################################",
    "Here we see a large speedup. This is because the data is approximately low rank so",
    "the compressed tensor slices will have shape R x 2_000, where R is typically below 10",
    "in this example. If your tensor slices are large in both modes, you might want to plot",
    "the singular values of your dataset to see if lossy compression could speed up",
    "PARAFAC2.",
    "Get a high-accuracy decomposition for comparison",
    "Run PARAFAC decomposition without line search and time",
    "Run PARAFAC decomposition with line search and time",
    "Calculate the error of both decompositions",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "This function compares factors of a reference cp tensor with factors of another tensor",
    "(or list of tensor) in order to match component order. Permutation occurs on the columns of factors,",
    "minimizing the cosine distance to reference cp tensor with scipy Linear Sum Assignment method.",
    "The permuted tensor (or list of tensors) and list of permutation for each permuted tensors are returned.",
    "Tensorly CPTensor should be used as an input to permute their factors and weights simultaneously.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor, then we permute its factors manually.",
    "one reference cp tensor",
    "two target cp tensors",
    "#############################################################################",
    "Permute target CPTensors",
    "------------------------",
    "Now, we can use these two manipulated CPTensors as inputs to the permutation function. Here,",
    "cp_tensor_1 will be used as a reference to permute other CPTensors, which are called target CPTensors.",
    "There is no limitation for the number of target CPTensors but there should be only one reference CPTensor.",
    "Results will include permuted CPTensors and permutation for each permuted cp tensor.",
    "It should be noted that, reference CPTensor won't be included among the output CPTensors.",
    "#############################################################################",
    "As it is expected, permutation variable stores two lists which are equal to predefined col_order_1",
    "col_order_2 above.",
    "#############################################################################",
    "We can also observe the evolution of the factor columns order by plotting one column",
    "before and after permuting.",
    "sphinx_gallery_thumbnail_number = 2",
    "#############################################################################",
    "Introduction",
    "------------",
    "PARAFAC (CP) decomposition is extremely useful in dimensionality reduction, allowing us",
    "to develop models that are both representative and compact while retaining crucial patterns",
    "between subjects. Here, we provide an example of how it can be applied to biomedical research.",
    "",
    "Systems serology is a new technology that examines the antibodies from a patient's serum, aiming",
    "to comprehensively profile the interactions between the antibodies and",
    "`Fc receptors <https://en.wikipedia.org/wiki/Fc_receptor>`_ alongside other types of immunological",
    "and demographic data. Here, we will apply CP decomposition to a",
    "`COVID-19 system serology dataset <https://www.sciencedirect.com/science/article/pii/S0092867420314598>`_.",
    "In this dataset, serum antibodies",
    "of 438 samples collected from COVID-19 patients were systematically profiled by their binding behavior",
    "to SARS-CoV-2 (the virus that causes COVID-19) antigens and Fc receptors activities. Samples are",
    "labeled by the status of the patients.",
    "",
    "Details of this analysis as well as more in-depth biological implications can be found in",
    "`this work <https://www.embopress.org/doi/full/10.15252/msb.202110243>`_. It also includes applying",
    "tensor methods to HIV systems serology measurements and using them to predict patient status.",
    "",
    "We first import this dataset of a panel of COVID-19 patients:",
    "#############################################################################",
    "Apply CP decomposition to this dataset with Tensorly",
    "----------------------------------------------------",
    "Now we apply CP decomposition to this dataset.",
    "#############################################################################",
    "To evaluate how well CP decomposition explains the variance in the dataset, we plot the percent",
    "variance reconstructed (R2X) for a range of ranks.",
    "#############################################################################",
    "Inspect the biological insights from CP components",
    "--------------------------------------------------",
    "Eventually, we wish CP decomposition can bring insights to this dataset. For example, in this",
    "case, revealing the underlying trend of COVID-19 serum-level immunity. To do this, we can inspect",
    "how each component looks like on weights.",
    "Ensure that factors are negative on at most one direction.",
    "#############################################################################",
    "From the results, we can see that serum COVID-19 immunity separates into two distinct signals,",
    "represented by two CP components: a clear acute response with IgG3, IgM, and IgA, and a long-term,",
    "IgG1-specific response. Samples from patients with different symptoms can be distinguished from",
    "these two components. This indicates that CP decomposition is a great tool to find these biologically",
    "significant signals.",
    "#############################################################################",
    "References",
    "----------",
    "[1] Tan, Z. C., Murphy, M. C., Alpay, H. S., Taylor, S. D., & Meyer, A. S. (2021). Tensor\u2010structured",
    "decomposition improves systems serology analysis. Molecular systems biology, 17(9), e10243.",
    "`<https://www.embopress.org/doi/full/10.15252/msb.202110243>`_",
    "",
    "[2] Zohar, T., Loos, C., Fischinger, S., Atyeo, C., Wang, C., Slein, M. D., ... & Alter, G. (2020).",
    "Compromised humoral functional evolution tracks with SARS-CoV-2 mortality. Cell, 183(6), 1508-1519.",
    "`<https://www.sciencedirect.com/science/article/pii/S0092867420314598>`_",
    "Rank of the CP decomposition",
    "Rank of the Tucker decomposition",
    "Perform the CP decomposition",
    "Reconstruct the image from the factors",
    "Tucker decomposition",
    "Plotting the original and reconstruction from the decompositions",
    "%%",
    "Here we will load a tensor of experimentally measured cellular responses to",
    "IL-2 stimulation. IL-2 is a naturally occurring immune signaling molecule",
    "which has been engineered by pharmaceutical companies and drug designers",
    "in attempts to act as an effective immunotherapy. In order to make effective IL-2",
    "therapies, pharmaceutical engineer have altered IL-2's signaling activity in order to",
    "increase or decrease its interactions with particular cell types.",
    "",
    "IL-2 signals through the Jak/STAT pathway and transmits a signal into immune cells by",
    "phosphorylating STAT5 (pSTAT5). When phosphorylated, STAT5 will cause various immune",
    "cell types to proliferate, and depending on whether regulatory (regulatory T cells, or Tregs)",
    "or effector cells (helper T cells, natural killer cells, and cytotoxic T cells,",
    "or Thelpers, NKs, and CD8+ cells) respond, IL-2 signaling can result in",
    "immunosuppression or immunostimulation respectively. Thus, when designing a drug",
    "meant to repress the immune system, potentially for the treatment of autoimmune",
    "diseases, IL-2 which primarily enacts a response in Tregs is desirable. Conversely,",
    "when designing a drug that is meant to stimulate the immune system, potentially for",
    "the treatment of cancer, IL-2 which primarily enacts a response in effector cells",
    "is desirable. In order to achieve either signaling bias, IL-2 variants with altered",
    "affinity for it's various receptors (IL2R\u03b1 or IL2R\u03b2) have been designed. Furthermore",
    "IL-2 variants with multiple binding domains have been designed as multivalent",
    "IL-2 may act as a more effective therapeutic. In order to understand how these mutations",
    "and alterations affect which cells respond to an IL-2 mutant, we will perform",
    "non-negative PARAFAC tensor decomposition on our cell response data tensor.",
    "",
    "Here, our data contains the responses of 8 different cell types to 13 different",
    "IL-2 mutants, at 4 different timepoints, at 12 standardized IL-2 concentrations.",
    "Therefore, our tensor will have shape (13 x 4 x 12 x 8), with dimensions",
    "representing IL-2 mutant, stimulation time, dose, and cell type respectively. Each",
    "measured quantity represents the amount of phosphorlyated STAT5 (pSTAT5) in a",
    "given cell population following stimulation with the specified IL-2 mutant.",
    "%%",
    "Now we will run non-negative PARAFAC tensor decomposition to reduce the dimensionality",
    "of our tensor. We will use 3 components, and normalize our resulting tensor to aid in",
    "future comparisons of correlations across components.",
    "",
    "First we must preprocess our tensor to ready it for factorization. Our data has a",
    "few missing values, and so we must first generate a mask to mark where those values",
    "occur.",
    "%%",
    "Now that we've marked where those non-finite values occur, we can regenerate our",
    "tensor without including non-finite values, allowing it to be factorized.",
    "%%",
    "Using this mask, and finite-value only tensor, we can decompose our signaling data into",
    "three components. We will also normalize this tensor, which will allow for easier",
    "comparisons to be made between the meanings, and magnitudes of our resulting components.",
    "%%",
    "Now we will load the names of our cell types and IL-2 mutants, in the order in which",
    "they are present in our original tensor. IL-2 mutant names refer to the specific",
    "mutations made to their amino acid sequence, as well as their valency",
    "format (monovalent or bivalent).",
    "",
    "Finally, we label, plot, and analyze our factored tensor of data.",
    "%%",
    "Here we observe the correlations which both ligands and cell types have with each of",
    "our three components - we can interepret our tensor factorization for looking for",
    "patterns among these correlations.",
    "",
    "For example, we can see that bivalent mutants generally have higher correlations with",
    "component two, as do regulatory T cells. Thus we can infer that bivalent ligands",
    "activate regulatory T cells more than monovalent ligands. We also see that this",
    "relationship is strengthened by the availability of IL2R\u03b1, one subunit of the IL-2 receptor.",
    "",
    "This is just one example of an insight we can make using tensor factorization.",
    "By plotting the correlations which time and dose have with each component, we",
    "could additionally make inferences as to the dynamics and dose dependence of how mutations",
    "affect IL-2 signaling in immune cells.",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Should we allow None weights?",
    "it's already been validated at creation",
    "Skip the target mode",
    "Calculate the sign of the current factor in each component",
    "Update both the current and receiving factor",
    "Check the weight signs",
    "Test for the validity of the operation",
    "norm = T.dot(T.dot(weights, norm), weights)",
    "We sum even if weights is not None",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Check user input for potential errors",
    "Check first and last rank",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi",
    "Import opt-einsum for the contraction path",
    "Import cuQuantum for the actual contraction",
    "return cuquantum.contract(equation, *args, optimize={'path': path})",
    "Note how tt_matrix_to_tensor is implemented in tenalg to allow for more efficient implementations",
    "(e.g. using the einsum backend)",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Test for the validity of the operation",
    "rank is 'same' or float: choose rank so as to preserve a fraction of the original #parameters",
    "sorted to be careful with the order when popping and reinserting to not remove/add at wrong index.",
    "list (mode, shape) that we removed as they will be kept the same, rank[i] =",
    "number of parameters coming from the fixed modes (these don't have a variable size as a fun of fraction_param)",
    "Doesn't contain fixed_modes, those factors are accounted for in fixed_params",
    "it's already been validated at creation",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Border rank of 1, R_0 = R_N = 1",
    "First and last factor of size I_0 R and I_N R",
    "We want the number of params of decomp (=sum of params of factors)",
    "To be equal to c = \\prod_k I_k",
    "We get the non-negative solution",
    "Choose a rank proportional to the size of each mode",
    "The method is similar to the above one for constant_rank == True",
    "We get the non-negative solution",
    "Check user input for potential errors",
    "Initialization",
    "Will raise an error if invalid",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "it's already been validated at creation",
    "Skip first factor matrix since the rank is extracted from it.",
    "allocate variables for weights, and normalized factors",
    "if (not copy) and (weights is None):",
    "warnings.warn('Provided copy=False and weights=None: a new Parafac2Tensor'",
    "'with new weights and factors normalised inplace will be returned.')",
    "weights = T.ones(rank, **T.context(factors[0]))",
    "The if test below was added to enable inplace edits",
    "however, TensorFlow does not support inplace edits",
    "so this is always set to True",
    "backend_context,",
    "backend_manager,",
    "_get_backend_dir, _get_backend_method,",
    "from . import backend as backend_manager",
    "Add Backend functions, dynamically dispatched",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__,",
    "backend_manager.__getattribute__,",
    "full_dir)",
    "# override_module_dispatch(__name__, _get_backend_method, full_dir)",
    "del override_module_dispatch, full_dir#, _get_backend_method",
    "Threshold SVD, keeping only singular values that satisfy s_i >= s_0 * epsilon",
    "where epsilon is the compression threshold",
    "Array broadcasting happens at the last dimension, since Vh is num_svds x n_cols",
    "we need to transpose it, multiply in the singular values and then transpose",
    "it again. This is equivalent to writing diag(s) @ Vh. If we skip the",
    "transposes, we would get Vh @ diag(s), which is wrong.",
    "Authors: Isabell Lehmann <isabell.lehmann94@outlook.de>",
    "License: BSD 3 clause",
    "initialize values",
    "the coupled factor should be initialized with the concatenated dataset",
    "alternating least squares",
    "note that the order of the khatri rao product is reversed since tl.unfold has another order",
    "than assumed in paper",
    "Loop over modes of the tensor",
    "We want to solve for mode 0 last, since the coupled factor matrix is most influential and SVD gave us a good approximation",
    "If we are at the coupled mode, concat the matrix",
    "Getting the TT factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TT factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "A TTM with a single factor is just a matrix...",
    "A list of candidates for each mode",
    "Refine the init",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "If the concatenated matrix would be larger than the cross-product, use the latter",
    "Clip if the mode should be non-negative",
    "If nn_modes is set, we use HALS, otherwise, we use the standard parafac implementation.",
    "Will we be performing a line search iteration?",
    "Start line search if requested.",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "TODO: this is a hack but it seems to do the job for now",
    "TODO: Test this",
    "Make decomposition feasible by taking the absolute value of all factor matrices",
    "If we have to update the mask we already have to build the full tensor",
    "Update the tensor based on the mask",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Will we be performing a line search iteration",
    "Calculate the current unnormalized error if we need it",
    "Start line search if requested.",
    "For each matrix, randomly choose n_samples indices for which to compute the khatri-rao product",
    "Compute corresponding rows of the full khatri-rao product",
    "Compute the Khatri-Rao product for the chosen indices",
    "Keep all the elements of the currently considered mode",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Caglayan Tuna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "ADMM inits",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise the decompositions",
    "Norm of the reconstructions at each iteration",
    "Update the lagrangian multipliers",
    "Evolution of the reconstruction errors",
    "Convergence check",
    "Randomly initialize decomposition cores",
    "Run callback function if provided",
    "Main loop",
    "Compute appropriate transposed unfolding of tensor",
    "Compute design matrix",
    "Solve least squares problem directly",
    "Solve least squares problem via normal equations",
    "Update core",
    "Compute relative error if necessary",
    "Run callback function if provided",
    "Check convergence",
    "Create index orderings for computation of sketched design matrix",
    "Randomly initialize decomposition cores",
    "Compute initial sampling distributions",
    "Run callback function if provided",
    "Main loop",
    "Randomly draw row indices",
    "Combine repeated samples",
    "Compute row rescaling factors (see discussion in Sec 4.1 in paper by",
    "Larsen & Kolda (2022), DOI: 10.1137/21M1441754)",
    "Converting samples_unq[n] to a tl.tensor is necessary for indexing",
    "to work with jax, which doesn't allow indexing with lists; see",
    "https://github.com/google/jax/issues/4564. The dtype needs to be",
    "explicitly set to an int type, otherwise tl.tensor does the",
    "conversion to floating type which causes issues with the pytorch",
    "backend.",
    "Sample core tensors",
    "Construct sketched design matrix",
    "Construct sampled right-hand side",
    "Solve sampled least squares problem directly",
    "Update core",
    "Compute sampling distribution for updated core",
    "Compute relative error if necessary",
    "Run callback function if provided",
    "Check convergence",
    "Change order",
    "Getting the first factor",
    "SVD of unfolding matrix",
    "Get first TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the TR factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "Reorder factors to match input",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "A list of candidates for each mode",
    "Refine the init",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Initialisation",
    "The initial core approximation is needed here for the masking step",
    "SVD init",
    "The factors are orthonormal and therefore do not affect the reconstructed tensor's norm",
    "TO-DO validate rank for partial tucker as well",
    "Initialisation",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local variables",
    "Iterate over one step of NTD",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "UtU",
    "UtM",
    "Call the hals resolution with nnls, optimizing the current mode",
    "updating core",
    "Adding the l1 norm value to the reconstruction error",
    "error computation",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan TUna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "khatri_rao(factors).tl.dot(khatri_rao(factors))",
    "simplifies to multiplications",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local varaibles",
    "Iteratation",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "Call the hals resolution with nnls, optimizing the current mode",
    "check recovery",
    "check low rank recovery",
    "Check for sparsity of the gross error",
    "assert tl.sum(noise_pred > 0.01) == tl.sum(noise > 0.01)",
    "check sparse gross error recovery",
    "###########################",
    "Test with missing values #",
    "###########################",
    "Add some corruption (missing values, replaced by ones)",
    "Decompose the tensor",
    "check recovery",
    "check low rank recovery",
    "check sparse gross error recovery",
    "Check for recovery of the corrupted/missing part",
    "tensorflow has issues with type promotion that would require more code changes",
    "Generate a random complex tensor if requested",
    "Callback to record error",
    "Given all the random seed is set, this should provide the same answer for random initialization",
    "Callback to record error",
    "Check that the error monotonically decreases",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Check that sparse component works",
    "Check that we get roughly the same answer with the full tensor and masking",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Regression test: used wrong variable for convergence checking",
    "Used mttkrp*factor instead of mttkrp*factors[-1], which resulted in",
    "error when mode 2 was not constrained and erroneous convergence checking",
    "when mode 2 was constrained.",
    "test tensor reconstructed properly",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "Test random_state fixes the core and the factor matrices",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "try fixing the core",
    "Random and SVD init should converge to a similar solution",
    "Mask an outlier value, and check that the decomposition ignores it",
    "We won't use the SVD decomposition, but check that it at least runs successfully",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Testing if estimated factors are monotonic",
    "Check if maximum values is 1",
    "Check if factors have l1 norm smaller than threshold",
    "Check if factors are normalized and k-sparse",
    "Check if factors are normalized and k-sparse",
    "Test the max abs difference between the reconstruction and the tensor",
    "Check that the error monotonically decreases",
    "# Check reconstruction of noisy tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "Generate random tensor which has exact tensor ring decomposition",
    "Ensure ValueError is raised for when invalid ls_solve is given",
    "Create callback function for error tracking and run decomposition",
    "Ensure decomposition returns right number of factors",
    "Ensure cores are sized correctly",
    "Compute decomposition relative error and ensure it's small enough",
    "Ensure error decreases monotonically (up to numerical error)",
    "Ensure TensorRingALS class passes arguments correctly to decomposition function",
    "Ensure that the computed decomposition is the same when the same random seed is",
    "used",
    "Generate random tensor which has exact tensor ring decomposition",
    "Create callback function for error tracking and run decomposition",
    "Ensure decomposition returns right number of factors",
    "Ensure cores are sized correctly",
    "Compute decomposition relative error and ensure it's small enough.",
    "Note that sampling-based decomposition of the small tensors used in this test",
    "is somewhat precarious, so the rel_error_tol or number of samples used may have",
    "to be adapted in case of failure for other backends/random seeds.",
    "Ensure TensorRingALS class passes arguments correctly to decomposition function",
    "Ensure that the computed decomposition is the same when the same random seed is",
    "used",
    "The point of this test is to attempt decomposing a sligthly larger tensor than the",
    "test in test_tensor_ring_als_sampled. The tensor in the present function is",
    "approaching a size where we can expect sampling to yield an accurate result even",
    "with meaningful downsampling.",
    "Define tensor properties",
    "Some decomposition properties",
    "Generate random tensor which has exact tensor ring decomposition",
    "Create callback function for error tracking and run decomposition",
    "Get relative error from callback object",
    "Check if computed relative error is less than acceptable tolerance",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Test convergence criterion",
    "Create dummy variable for the previous iteration",
    "Test with line search where the reconstruction error would worsen if accepted",
    "Assert that the factor matrices, projection and reconstruction error all",
    "are unaffected by the line search",
    "Test with line search where the reconstruction error would improve if accepted",
    "Assert that the factor matrices, projection and reconstruction error all",
    "are changed by the line search",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Fit with only one iteration to check non-negativity",
    "The default random parafac2 tensor has non-negative A and C",
    "we therefore multiply them randomly with -1, 0 or 1 to get both positive and negative components",
    "Test that constraining B leads to a warning",
    "Double the number of matrices so that we switch to the cross-product",
    "These factor matrices should be essentially the same",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Generate a random state for me",
    "random state from integer seed",
    "if it is already a random state, just return it",
    "only takes as seed a random state, an int or None",
    "tests that the columns of each factor matrix are indeed orthogonal",
    "(See issue #40)",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Authors: Taylor Lee Patti <taylorpatti@g.harvard.edu>",
    "Jean Kossaifi",
    "All density matrices are Hermitian, here real. Hermitianize matrix if rounding/transformation",
    "errors have occured.",
    "Check if matrix1 and matrix2 are lists of the same length",
    "Check if all matrices have the same number of columns",
    "Check if any norm is exactly zero to avoid singularity",
    "Authors: Hratch Baghdassarian <hmbaghdassarian@gmail.com>, Erick Armingol <earmingol14@gmail.com>",
    "similarity metrics for tensor decompositions",
    "check input factors shape",
    "check method",
    "vertically stack loading matrices -- shape sum(tensor.shape)xR)",
    "normalize columns to L2 norm - even if ran decomposition with normalize_factors=True",
    "generate the correlation index input",
    "correlation index scoring",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "TODO: write a function to do this..",
    "Adding test from @maximeguillaud issue #487",
    "Overfactoring causes a singular matrix error.",
    "Create no_row-by-no_col matrix of given rank",
    "Compute leverage scores via leverage_score_dist function",
    "Assert that all entries of distribution are non-negative",
    "Assert that the distribution sums to one",
    "Assert that lev_score_dist matches true leverage score distribution",
    "initialize random matrix",
    "Workaround for tensorflow",
    "randomly create intervals to separate matrix into factors list",
    "test column permutation invariance",
    "test scaling invariance",
    "Make sure it's not a tuple but a list",
    "Add two one-dimensional mode to data_tensor",
    "perform TTOI for n_iter iterations",
    "first perform forward update",
    "left_singular_vectors will be a list including estimated left singular spaces at the current iteration",
    "initialize left_residuals (sequential unfolding of data_tensor multiplied by left_singular_vectors sequentially on the left, useful for backward update to obtain right_singular_vectors)",
    "estimate the first left singular spaces",
    "Here, R_tmp is the first sequential unfolding compressed on the right by previous updated right_singular_vectors (if exists)",
    "estimate the 2nd to (d-1)th left singular spaces",
    "compress the (mode+2)th sequential unfolding of data_tensor from the left",
    "R_tmp_l will be useful for backward update",
    "compress the (mode+2)th sequential unfolding of data_tensor from the right (if iteration>0)",
    "forward update is done; output the final residual",
    "perform backward update",
    "initialize right_singular_vectors: right_singular_vectors will be a list of estimated right singular spaces at the current or previous iteration",
    "estimate the 2nd to (d-1)th right singular spaces",
    "compress left_residuals from the right",
    "return final results",
    "Check user input for errors",
    "Make sure iter's not a tuple but a list",
    "Initialize rank",
    "list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.",
    "list row_idx: row indices    (left indices)  for skeleton-decomposition: indicate which rows used in each core.",
    "Initialize indice: random selection of column indices",
    "Initialize the cores of tensor-train",
    "#####################################",
    "left-to-right step",
    "list row_idx: list of (tensor_order-1) of lists of left indices",
    "update row indices",
    "end left-to-right step",
    "##############################################",
    "##############################################",
    "right-to-left step",
    "list col_idx: list (tensor_order-1) of lists of right indices",
    "update col indices",
    "Compute cores",
    "The rank should not be larger than the input tensor's size",
    "Add the last core",
    "end right-to-left step",
    "###############################################",
    "check the error for while-loop",
    "check convergence",
    "Extract fibers according to the row and col indices",
    "Extract the core",
    "shape the core as a 3-tensor_order cube",
    "merge r_k and n_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "Extract fibers",
    "shape the core as a 3-tensor_order cube",
    "merge n_{k-1} and r_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "The index of row of the submatrix",
    "Rest of rows / unselected rows",
    "Find r rows iteratively",
    "Compute the square of norm of each row",
    "If there is only one row of A left, let's just return it.",
    "If a row is 0, we delete it.",
    "Find the row of max norm",
    "Compute the projection of max_row to other rows",
    "projection a to b is computed as: <a,b> / sqrt(|a|*|b|)",
    "make sure normalization vector is of the same shape of projection",
    "Subtract the projection from A_new:  b <- b - a * projection",
    "Delete the selected row",
    "update the row_idx and rest_of_rows",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TEST 4",
    "Random tensor is not really compress-able. Test on a tensor as values of a function",
    "Find TT decomposition of the tensor",
    "!/usr/bin/env python3",
    "-*- coding: utf-8 -*-",
    "Generate tensor true_tensor with low tensor train rank, and its noisy observation data_tensor",
    "run TTOI",
    "Check that the approximation error monotonically decreases",
    "assert (np.all(np.diff(tl.to_numpy(approx_errors)) <= 1e-3))",
    "check that the estimation error of TTOI improves from initialization (TTSVD)",
    "from ...backend import _get_backend_method, _get_backend_dir",
    "from ...backend import backend",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__, backend_manager.__getattribute__, sparse_dir)",
    "override_module_dispatch(__name__, _get_backend_method, sparse_dir)",
    "Make sure the algorithm stays sparse. This will run out of memory on",
    "most machines if the algorithm densifies.",
    "Will blow-up memory if not sparse-safe",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Default on standard SVD",
    "all-zeros matrix, so we should do a quick return.",
    "We can perform a partial SVD",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "use dense form when sparse form will fail",
    "use dense form when sparse form will fail",
    "WARNING: here, V is still the transpose of what it should be",
    "Check correct rank and shapes are returned",
    "One of the factors has the wrong rank",
    "Not the correct amount of weights",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test cp_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test cp_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "If we're taking the gradient of comparison with self it should be 0",
    "Check that we can solve for a direction of descent",
    "Check that modifying copy tensor doesn't change the original tensor",
    "one target cp tensor",
    "two target cp tensors",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not three factor matrices",
    "Not enough projections",
    "Wrong number of weights",
    "The projections aren't orthogonal",
    "Disable tests for inplace edits, since that possibility is removed",
    "to support TensorFlow.",
    "@pytest.mark.parametrize('copy', [True, False])",
    "First slice is compressed",
    "Second slice is not compressed",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create tensor",
    "Compute ground truth TT factors",
    "Check that TT factors re-assemble to the original tensor",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Reconstruct the original tensor",
    "Check that the rank is 10",
    "Rounding = floor",
    "Rounding = ceil",
    "Testing for a tensor-train",
    "Testing for a Tensor-Ring",
    "Testing for a TT-Matrix",
    "Author: Jean Kossaifi",
    "Set in context manager",
    "Sets back to numpy",
    "Reset back to initial backend",
    "Set not in context manager",
    "Improper name doesn't reset backend",
    "Changes only happen locally in this thread",
    "Set the global default backend",
    "Changed toplevel default in all threads",
    "True reconstruction error (based on numpy SVD)",
    "Reconstruction error with the backend's SVD",
    "Check that the two are similar",
    "Check for orthogonality when relevant",
    "Should fail on non-matrices",
    "Test for singular matrices (some eigenvals will be zero)",
    "Rank at most 5",
    "Test orthonormality when  max_dim > n_eigenvecs > matrix_rank",
    "Test if truncated_svd returns the same result for the same setting",
    "limit as order->oo is the oo-norm",
    "Test that clip can work with single arguments",
    "More extensive test with a larger random tensor",
    "Regression test for bug found with the pytorch backend",
    "1D",
    "2D",
    "3D",
    "random testing against Numpy's output",
    "1-dim x n-dim",
    "n_dim x 1-dim",
    "n-dim x n-dim",
    "test dimensions",
    "test residuals",
    "test least squares solution",
    "assert that the columns of Q are orthonormal",
    "Third order tensor",
    "Example data",
    "Tensorly tensor",
    "Compare against scipy baseline result",
    "Run tensorly logsumexp",
    "Numpy array",
    "No dtype given -> dtype should be inferred from input array",
    "dtype given -> dtype should be overwritten",
    "Check init from numpy array",
    "Check init from python list",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create ground truth TR factors",
    "Create tensor",
    "Check that TR factors re-assemble to the original tensor",
    "Rounding = floor",
    "Rounding = ceil",
    "Integer rank",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not enough factors to match core",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test tucker_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test tucker_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "With fixed modes",
    "Floor",
    "Ceil",
    "Check that modifying copy tensor doesn't change the original tensor",
    "Author: Jean Kossaifi",
    "hard coded example",
    "check dims",
    "chain unfolding and folding",
    "Convert to vector and back to tensor",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "We created here a tensor with 3 samples, each sample being similar to X",
    "Test for raveled tensor",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Test for raveled tensor",
    "Test for raveled_tensor=True",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "we created here a tensor with 3 samples, each sample being similar to X",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Equivalence with unfolding",
    "We're not changing anything:",
    "We're missing some modes of the tensor:",
    "We have a duplicate mode",
    "New function renaming old_fun",
    "Old fun will return fun but issue a deprecation warning",
    "Check if the default function is called when the backend is not \"backend\"",
    "Monkeypatch get_backend and check that the specific function is called when backend is \"backend\"",
    "Test using the deprecated function",
    "Test using the new function instead",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Meraj Hashemizadeh <merajhse@mila.quebec>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "License: BSD 3 clause",
    "columns of U, rows of V",
    "rows of V, columns of U",
    "NNDSVD initialization",
    "The leading singular triplet is non-negative",
    "so it can be used as is for initialization.",
    "extract positive and negative parts of column vectors",
    "and their norms",
    "choose update",
    "After this point we no longer need H",
    "Perform power iterations when spectrum decays slowly",
    "Check that matrix is... a matrix!",
    "transpose matrix to keep the reduced matrix shape minimal",
    "Workaround to avoid needing fill_diagonal",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan Tuna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Next line finds mutual peak points",
    "Making it work for 1-dimensional tensors as well",
    "Broadcasting is used to divide rows by 1,2,3...",
    "Added -1 to correspond to a Python index",
    "Scaling",
    "Modifying the function for sparsification",
    "Safety procedure, if columns aren't allow to be zero",
    "Parameters",
    "To avoid singularity error when initial x exists",
    "Start from zeros if solve is not achieved",
    "Update support vector with passive solution",
    "update support vector if it is necessary",
    "Update support vector with passive solution",
    "Break if finished updating",
    "set x to s",
    "gradient update",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "backend = getattr(module, )()",
    "Initialise the backend to the default one",
    "Author: Jean Kossaifi",
    "Check that we did not change the original tensor",
    "Check that we did not change the original tensor",
    "1d Tensor",
    "2d Tensor",
    "Monotone increasing",
    "Monotone decreasing",
    "small test",
    "account for floating point errors: np array have a precision of around 2e-15",
    "check np.finfo(np.float64).eps",
    "Check that we did not change the original tensor",
    "Another test",
    "Test with missing values",
    "Version forming explicitely the khatri-rao product",
    "Efficient sparse-safe version",
    "Equivalence with inner product when contracting with self along all modes",
    "Equivalent to the above expression",
    "Equivalence with n-mode-dot",
    "Multi-mode-dot",
    "Wrong number of modes",
    "size mismatch",
    "Test Batched tensor dot",
    "Check for each sample of the batch-size individually",
    "Test for actual tensordot",
    "Author: Jean Kossaifi",
    "resulting matrix must be of shape (prod(n_rows), n_columns)",
    "fail case: all matrices must have same number of columns",
    "all matrices should be of dim 2...",
    "Classic example/test",
    "A = np.hstack((np.eye(3), np.arange(3)[:, None]))",
    "Test with one matrix only: khatri-rao of one matrix = that matrix",
    "Check that negative dims are made positive",
    "Author: Jean Kossaifi",
    "Mathematical test",
    "Another test",
    "Adding a third matrices",
    "Test for the reverse argument",
    "Check that the original list has not been reversed",
    "Check the returned shape",
    "Khatri-rao is a column-wise kronecker product",
    "Khatri-rao product is a column-wise kronecker product",
    "Test while skipping a matrix",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "For one common mode, equivalent to dot product",
    "For no common mode, equivalent to inner product",
    "Inner product of tensors with different shapes is not defined",
    "tensor times matrix",
    "######################",
    "tensor times vector #",
    "######################",
    "Test with a matrix",
    "Test with a third order tensor",
    "Using equivalence with unfolded expression",
    "########################################",
    "Test for errors that should be raised #",
    "########################################",
    "Same test for the vector case",
    "Cannot take mode product of tensor with tensor",
    "Test using the equivalence with unfolded expression",
    "Test skipping a factor",
    "Test contracting with a vector",
    "result should be a scalar",
    "Average pooling each mode",
    "Order should not matter",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Indices of each matrix",
    "Author: Jean Kossaifi",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "However, it is needed to pop dimensions contracted over",
    "print(i, matrix_or_vec.shape, mode)",
    "print(f'skipping {skip}')",
    "We are contracting over the mode-th dimension",
    "mat_symbol = f'{tensor_modes[mode]}{chr(counter)}'",
    "Contracting mode-th mode with a matrix: new dimension",
    "If fully contracting",
    "matrix_or_vec_list = [m for (i, m) in enumerate(matrix_or_vec_list) if ((skip is None) or (skip != i))]",
    "print(equation, tl.shape(tensor), [tl.shape(f) for f in matrix_or_vec_list])",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Testing whether the matrices have the proper size",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "Each core is of shape (rank_left, size_in, size_out, rank_right)",
    "Intertwine the dims",
    "full_shape = in_shape[0], out_shape[0], in_shape[1], ...",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "Create the tensor algebra dispatching backend and register methods",
    "TODO : add batched_modes as in batched_tensor_dot?",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Testing whether the matrices have the proper size",
    "Prepare to reorganize the modes afterwards by moving bactch size back to their place",
    "(while ommiting modes contracted over)",
    "We will reorganize tensor1 to (batch_modes, new_modes1, contraction_modes)",
    "Tensor2 will be (batch_modes, contraction_modes, new_modes2)",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "@staticmethod",
    "def tensor(data, dtype=np.float64, device=None, device_id=None):",
    "if isinstance(data, tf.Tensor) or isinstance(data, tf.Variable):",
    "return tf.cast(data, dtype=dtype)",
    "",
    "out = tf.Variable(data, dtype=dtype)",
    "return out.gpu(device_id) if device == \"gpu\" else out",
    "Determine the dtype and device from the input if not provided",
    "Create the tensor and cast to the determined dtype",
    "If device or device_id is specified, place the tensor on the correct device",
    "Register numpy functions",
    "Register linalg functions",
    "Register tfm functions",
    "Register tnp functions",
    "See https://github.com/tensorly/tensorly/pull/397",
    "and https://github.com/google/jax/issues/3473",
    "return copy.copy(tensor)",
    "handle difference in default axis notation",
    "If source is a tensor, use clone-detach as suggested by PyTorch",
    "Else, use PyTorch's tensor constructor",
    "Set dtype/device/requires_grad if specified",
    "pytorch does not accept `None` for any keyword arguments. additionally,",
    "pytorch doesn't seems to support keyword arguments in the first place",
    "Register the other functions",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "We don't use `functools.wraps` here because some of the dispatched",
    "methods include the backend (`cls`) as a parameter. Instead we manually",
    "copy over the needed information, and filter the signature for `cls`.",
    "If it doesn't have a signature we don't need to remove self",
    "This happens for NumPy (e.g. np.where) where inspect.signature(np.where) errors:",
    "ValueError: no signature found for builtin <built-in function where>",
    "backend = getattr(module, )()",
    "Backend is a string",
    "Initialise the backend to the default one",
    "Swiss",
    "Rectangle",
    "circle: approximate test",
    "Author: Cyrillus Tan, Jackson Chin, Aaron Meyer",
    "License: BSD 3 clause",
    "# PREPROCESSING",
    "Check that both tensors are coupled along the first mode",
    "Check the shape of X and Y; convert vector Y to a matrix",
    "Mean center the data, record info the object",
    "Coefficients of the linear model",
    "# FITTING EACH COMPONENT",
    "Put iteration results back to the parameter variables",
    "Deflation",
    "Check on the shape of Y",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise modes of W",
    "Regress phi on y: we could call a package here, e.g. scikit-learn",
    "Convergence check",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise each factor of W",
    "Convergence check",
    "Parameter of the experiment",
    "Generate random samples",
    "Authors: Jackson L. Chin, Cyrillus Tan, Aaron Meyer",
    "Supporting Functions",
    "Class Structure Tests",
    "Dimension Compatibility Tests",
    "Decomposition Accuracy Tests",
    "Parameter of the experiment",
    "Generate random samples"
  ],
  "0.8.0": [
    "from slimit import minify",
    "Ignore already minified files",
    "Ignore already minified files",
    "!/usr/bin/env python3",
    "-*- coding: utf-8 -*-",
    "",
    "tensorly documentation build configuration file",
    "",
    "This file is execfile()d with the current directory set to its",
    "containing dir.",
    "",
    "Note that not all possible configuration values are present in this",
    "autogenerated file.",
    "",
    "All configuration values have a default; values that are commented out",
    "serve to show the default.",
    "If extensions (or modules to document with autodoc) are in another directory,",
    "add these directories to sys.path here. If the directory is relative to the",
    "documentation root, use os.path.abspath to make it absolute, like shown here.",
    "sys.path.insert(0, os.path.abspath('sphinx_ext'))",
    "-- General configuration ------------------------------------------------",
    "If your documentation needs a minimal Sphinx version, state it here.",
    "needs_sphinx = '1.0'",
    "Add any Sphinx extension module names here, as strings. They can be",
    "extensions coming with Sphinx (named 'sphinx.ext.*') or your custom",
    "ones.",
    "'sphinx.ext.imgmath',",
    "path to your examples scripts",
    "path where to save gallery generated examples",
    "Add any paths that contain templates here, relative to this directory.",
    "generate autosummary even if no references",
    "The suffix(es) of source filenames.",
    "You can specify multiple suffix as a list of string:",
    "source_suffix = ['.rst', '.md']",
    "The encoding of source files.",
    "source_encoding = 'utf-8-sig'",
    "The master toctree document.",
    "General information about the project.",
    "The version info for the project you're documenting, acts as replacement for",
    "|version| and |release|, also used in various other places throughout the",
    "built documents.",
    "",
    "The short X.Y version.",
    "version = '0.1'",
    "The full version, including alpha/beta/rc tags.",
    "release = ''",
    "The language for content autogenerated by Sphinx. Refer to documentation",
    "for a list of supported languages.",
    "",
    "This is also used if you do content translation via gettext catalogs.",
    "Usually you set \"language\" from the command line for these cases.",
    "There are two options for replacing |today|: either, you set today to some",
    "non-false value, then it is used:",
    "today = ''",
    "Else, today_fmt is used as the format for a strftime call.",
    "today_fmt = '%B %d, %Y'",
    "List of patterns, relative to source directory, that match files and",
    "directories to ignore when looking for source files.",
    "This patterns also effect to html_static_path and html_extra_path",
    "The reST default role (used for this markup: `text`) to use for all",
    "documents.",
    "default_role = None",
    "If true, '()' will be appended to :func: etc. cross-reference text.",
    "If true, the current module name will be prepended to all description",
    "unit titles (such as .. function::).",
    "If true, sectionauthor and moduleauthor directives will be shown in the",
    "output. They are ignored by default.",
    "show_authors = False",
    "The name of the Pygments (syntax highlighting) style to use.",
    "A list of ignored prefixes for module index sorting.",
    "modindex_common_prefix = []",
    "If true, keep warnings as \"system message\" paragraphs in the built documents.",
    "keep_warnings = False",
    "If true, `todo` and `todoList` produce output, else they produce nothing.",
    "-- Options for HTML output ----------------------------------------------",
    "\"<project> v<release> documentation\" by default.",
    "A shorter title for the navigation bar.  Default is the same as html_title.",
    "Add any paths that contain custom static files (such as style sheets) here,",
    "relative to this directory. They are copied after the builtin static files,",
    "so a file named \"default.css\" will overwrite the builtin \"default.css\".",
    "The name of an image file (relative to this directory) to place at the top",
    "of the sidebar.",
    "html_logo_url = '_static/logos/logo_tensorly.png'",
    "-- Options for LaTeX output ---------------------------------------------",
    "Grouping the document tree into LaTeX files. List of tuples",
    "(source start file, target name, title,",
    "author, documentclass [howto, manual, or own class]).",
    "\\setcounter{MaxMatrixCols}{20} corrects an ugly bug if you try to have a matrix of more than 10 elements or so",
    "We want the same for the html version:",
    "The name of an image file (relative to this directory) to place at the top of",
    "the title page.",
    "latex_logo = None",
    "For \"manual\" documents, if this is true, then toplevel headings are parts,",
    "not chapters.",
    "latex_use_parts = False",
    "If true, show page references after internal links.",
    "If true, show URL addresses after external links.",
    "Documents to append as an appendix to all manuals.",
    "latex_appendices = []",
    "Get completely rid of index",
    "If false, no module index is generated.",
    "latex_domain_indices = True",
    "-- Options for manual page output ---------------------------------------",
    "One entry per manual page. List of tuples",
    "(source start file, name, description, authors, manual section).",
    "If true, show URL addresses after external links.",
    "man_show_urls = False",
    "-- Options for Texinfo output -------------------------------------------",
    "Grouping the document tree into Texinfo files. List of tuples",
    "(source start file, target name, title, author,",
    "dir menu entry, description, category)",
    "Documents to append as an appendix to all manuals.",
    "texinfo_appendices = []",
    "If false, no module index is generated.",
    "texinfo_domain_indices = True",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "texinfo_show_urls = 'footnote'",
    "If true, do not generate a @detailmenu in the \"Top\" node's menu.",
    "texinfo_no_detailmenu = False",
    "-- Options for Epub output ----------------------------------------------",
    "Bibliographic Dublin Core info.",
    "The basename for the epub file. It defaults to the project name.",
    "epub_basename = project",
    "The HTML theme for the epub output. Since the default themes are not",
    "optimized for small screen space, using the same theme for HTML and epub",
    "output is usually not wise. This defaults to 'epub', a theme designed to save",
    "visual space.",
    "epub_theme = 'epub'",
    "The language of the text. It defaults to the language option",
    "or 'en' if the language is not set.",
    "epub_language = ''",
    "The scheme of the identifier. Typical schemes are ISBN or URL.",
    "epub_scheme = ''",
    "The unique identifier of the text. This can be a ISBN number",
    "or the project homepage.",
    "epub_identifier = ''",
    "A unique identification for the text.",
    "epub_uid = ''",
    "A tuple containing the cover image and cover page html template filenames.",
    "epub_cover = ()",
    "A sequence of (type, uri, title) tuples for the guide element of content.opf.",
    "epub_guide = ()",
    "HTML files that should be inserted before the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_pre_files = []",
    "HTML files that should be inserted after the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_post_files = []",
    "A list of files that should not be packed into the epub file.",
    "The depth of the table of contents in toc.ncx.",
    "epub_tocdepth = 3",
    "Allow duplicate toc entries.",
    "epub_tocdup = True",
    "Choose between 'default' and 'includehidden'.",
    "epub_tocscope = 'default'",
    "Fix unsupported image types using the Pillow.",
    "epub_fix_images = False",
    "Scale large images.",
    "epub_max_image_width = 0",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "epub_show_urls = 'inline'",
    "If false, no index is generated.",
    "epub_use_index = True",
    "-*- coding: utf-8 -*-",
    "Created: Sun May 21 20:38:59 2017",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Created Sun Nov 27 14:03:07 2016",
    "Author: \u00d3scar N\u00e1jera",
    "can't use codecs.open(filename, 'r', 'utf-8') here b/c ast doesn't",
    "seem to work with unicode strings in Python2.7",
    "\"SyntaxError: encoding declaration in Unicode string\"",
    "change from Windows format to UNIX for uniformity",
    "This get the content of the file after the docstring last line",
    "Note: 'maxsplit' argument is not a keyword argument in python2",
    "sphinx_gallery_<name> = <value>",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "Try Python 3 first, otherwise load from Python 2",
    "This is a.b, not e.g. a().b",
    "need to get a in a().b",
    "Join import path to relative path",
    "Find out what the real object is supposed to be.",
    "Ensure shortened object is the same as what we expect.",
    "get the last working module name",
    "name is as written in file (e.g. np.asarray)",
    "full_name includes resolved import path (e.g. numpy.asarray)",
    "module without attribute. This is not useful for",
    "backreferences",
    "get shortened module name",
    "Inside rst files forward slash defines paths",
    "-*- coding: utf-8 -*-",
    "This gets set when the extension is initialized.",
    "colorfunc is a valid kwarg in 1.5, but not older, so we just",
    "apply it ourselves.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "shelve keys need to be str in python 2",
    "value is a list",
    "try to convert elements to int",
    "value is another dictionary",
    "Make sure searchindex uses UTF-8 encoding",
    "parse objects",
    "parse filenames",
    "detect if we are using relative links on a Windows system",
    "download and initialize the search index",
    "In 1.5+ Sphinx seems to have changed from .rst.html to only",
    ".html extension in converted files. But URLs could be",
    "built with < 1.5 or >= 1.5 regardless of what we're currently",
    "building with, so let's just check both :(",
    "test if cobj appears in page",
    "we don't have it cached",
    "cache it for the future",
    "failed to resolve",
    "replace '\\' with '/' so it on the web",
    "for some reason, the relative link goes one directory too high up",
    "Add resolvers for the packages for which we want to show links",
    "patterns for replacement",
    "This could be turned into a generator if necessary, but should be okay",
    "we have a pickle file with the objects to embed links for",
    "generate replacement strings with the links",
    "do the replacement in the html file",
    "ensure greediness",
    "No need to waste time embedding hyperlinks when not running the examples",
    "XXX: also at the time of writing this fixes make html-noplot",
    "for some reason I don't fully understand",
    "XXX: Whitelist of builders for which it makes sense to embed",
    "hyperlinks inside the example html. Note that the link embedding",
    "require searchindex.js to exist for the links to the local doc",
    "and there does not seem to be a good way of knowing which",
    "builders creates a searchindex.js.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "##############################################################################",
    "Notebook shell utility",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "build options",
    "Sphinx hack: sphinx copies generated images to the build directory",
    "each time the docs are made.  If the desired image name already",
    "exists, it appends a digit to prevent overwrites.  The problem is,",
    "the directory is never cleared.  This means that each time you build",
    "the docs, the number of images in the directory grows.",
    "",
    "This question has been asked on the sphinx development list, but there",
    "was no response: https://git.net/ml/sphinx-dev/2011-02/msg00123.html",
    "",
    "The following is a hack that prevents this behavior by clearing the",
    "image build directory from gallery images each time the docs are built.",
    "If sphinx changes their layout between versions, this will not",
    "work (though it should probably not cause a crash).",
    "Tested successfully on Sphinx 1.0.7",
    "this assures I can call the config in other places",
    "Here we don't use an os.walk, but we recurse only twice: flat is",
    "better than nested.",
    "we create an index.rst with all examples",
    ":orphan: to suppress \"not included in TOCTREE\" sphinx warnings",
    "touch file",
    "Under no-plot Examples are not run so nothing to summarize",
    "Sphinx < 1.6 calls it `_extensions`, >= 1.6 is `extensions`.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Don't use unicode_literals here (be explicit with u\"...\" instead) otherwise",
    "tricky errors come up with exec(code_blocks, ...) calls",
    "Try Python 2 first, otherwise load from Python 3",
    "textwrap indent only exists in python 3",
    "make sure that the Agg backend is set before importing any",
    "matplotlib",
    "##############################################################################",
    "##############################################################################",
    "The following strings are used when we have several pictures: we use",
    "an html div tag that our CSS uses to turn the lists into horizontal",
    "lists.",
    "This one could contain unicode",
    "Sphinx only starts numbering from the first non-empty line.",
    "lstrip is just in case docstring has a '\\n\\n' at the beginning",
    "Set the fig_num figure as the current figure as we can't",
    "save a figure that's not the current figure.",
    "make sure the image is not too large",
    "local import to avoid testing dependency on PIL:",
    "resize the image",
    "insert centered",
    "Use optipng to perform lossless compression on the resized image if",
    "software is installed",
    "read specification of the figure to display as thumbnail from main text",
    "create something to replace the thumbnail",
    "Add empty lines to avoid bug in issue #165",
    "sort to have the smallest entries in the beginning",
    "clear at the end of the section",
    "Remove our code from traceback:",
    "Remove one extra level through ast.parse.",
    "Breaks build on first example error",
    "Stores failing file",
    "If example is not suitable to run, skip executing its blocks",
    "Redirect output to stdout and",
    "First cd in the original example dir, so that any file",
    "created by the example get created in this directory",
    "don't use unicode_literals at the top of this file or you get",
    "nasty errors here on Py2.7",
    "Horrible code to 'unload' seaborn, so that it resets",
    "its default when is load",
    "Python does not support unloading of modules",
    "https://bugs.python.org/issue9072",
    "Reset Matplotlib to default",
    "A lot of examples contains 'print(__doc__)' for example in",
    "scikit-learn so that running the example prints some useful",
    "information. Because the docstring has been separated from",
    "the code blocks in sphinx-gallery, __doc__ is actually",
    "__builtin__.__doc__ in the execution context and we do not",
    "want to print it",
    "Examples may contain if __name__ == '__main__' guards",
    "for in example scikit-learn if the example uses multiprocessing",
    "Don't ever support __file__: Issues #166 #212",
    "A simple example has two blocks: one for the",
    "example introduction/explanation and one for the code",
    "We want to run the example without arguments. See",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/252",
    "for more details.",
    "Add some vertical space after output",
    "Writes md5 checksum if example has build correctly",
    "not failed and was initially meant to run(no-plot shall not cache md5sum)",
    "-*- coding: utf-8 -*-",
    "Error + critical both go through warning:",
    "-*- coding: utf-8 -*-",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Need to import gen_rst before matplotlib.pyplot to set backend to 'Agg'",
    "For more details see",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/49",
    "verify correct md5sum",
    "False because is a new file",
    "Write md5sum to file to check is current",
    "read rst file and check if it contains traceback output",
    "create three files in tempdir (only one matches the pattern)",
    "generate rst file",
    "read rst file and check if it contains code output",
    "which plot to show as the thumbnail image",
    "test issue #229",
    "TODO: test that broken thumbnail does appear when needed",
    "TODO: test that examples are not executed twice",
    "TODO: test that examples are executed after a no-plot and produce",
    "the correct image in the thumbnail",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "recovers data from temporary file and caches it in the shelve",
    "tests recovered data matches",
    "test if cached data is available after temporary file has vanished",
    "shelve keys need to be str in python 2, deal with unicode input",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "General information about the project.",
    "no duplicate values allowed The config is present already",
    "General information about the project.",
    "General information about the project.",
    "General information about the project.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Test fails on wrong input",
    "Test missing folder",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "##############################################################################",
    "Notebook shell utility",
    "replace reference numbers so that there are no duplicates",
    "Strip top title",
    "call function to replace reference numbers so that there are no",
    "duplicates",
    "Do not try to inspect classes that don't define `__init__`",
    "Extra mangling domains",
    "------------------------------------------------------------------------------",
    "Docstring-mangling domains",
    "------------------------------------------------------------------------------",
    "go to next non-empty line in old:",
    "line.strip() checks whether the string is all whitespace",
    "------------------------------------------------------------------------------",
    "Registration hook",
    "------------------------------------------------------------------------------",
    "------------------------------------------------------------------------------",
    "plot:: directive",
    "------------------------------------------------------------------------------",
    "no argument given, assume used as a flag",
    "------------------------------------------------------------------------------",
    "Generating output",
    "------------------------------------------------------------------------------",
    "Sphinx depends on either Jinja or Jinja2",
    "determine input",
    "ensure that LaTeX includegraphics doesn't choke in foo.bar.pdf filenames",
    "is it in doctest format?",
    "determine output directory name fragment",
    "build_dir: where to place output files (temporarily)",
    "output_dir: final location in the builder's directory",
    "how to link to files from the RST file",
    "make figures",
    "generate output restructuredtext",
    "copy image files to builder's output directory",
    "copy script (if necessary)",
    "------------------------------------------------------------------------------",
    "Run code and capture figures",
    "------------------------------------------------------------------------------",
    "check if it's valid Python as-is",
    "Change the working directory to the directory of the example, so",
    "it can get at its data files, if any.",
    "Redirect stdout",
    "Reset sys.argv",
    "------------------------------------------------------------------------------",
    "Generating figures",
    "------------------------------------------------------------------------------",
    "-- Parse format list",
    "-- Try to determine if all images already exist",
    "Look for single-figure output files first",
    "Then look for multi-figure output files",
    "assume that if we have one, we have them all",
    "-- We didn't find the files, so build them",
    "Clear between runs",
    "Run code",
    "Collect images",
    "Results",
    "------------------------------------------------------------------------------",
    "Relative pathnames",
    "------------------------------------------------------------------------------",
    "Copied from Python 2.7",
    "Work out how much of the filepath is shared by start and path.",
    "Work out how much of the filepath is shared by start and path.",
    "If several signatures present, take the last one",
    "We could do more tests, but we are not. Arbitrarily.",
    "string conversion routines",
    "try to read signature, backward compat for older Python",
    "########################################################################",
    "object interface.",
    "########################################################################",
    "########################################################################",
    "Unparser private interface.",
    "########################################################################",
    "## format, output, and dispatch methods ################################",
    "########################################################################",
    "compiler.ast unparsing methods.",
    "",
    "There should be one method per concrete grammar type. They are",
    "organized in alphabetical order.",
    "########################################################################",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "fixme: Are From and ImportFrom handled differently?",
    "if t.step:",
    "self._write(\":\")",
    "self._dispatch(t.step)",
    "Empty tuple.",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "Check if parenthesis are needed on left side and then dispatch",
    "Write the appropriate symbol for operator",
    "Check if parenthesis are needed on the right side and then dispatch",
    "if t is 0.1, str(t)->'0.1' while repr(t)->'0.1000000000001'",
    "We prefer str here.",
    "########################################################################",
    "These are the methods from the _ast modules unparse.",
    "",
    "As our needs to handle more advanced code increase, we may want to",
    "modify some of the methods below so that they work for compiler.ast.",
    "########################################################################",
    "# stmt",
    "def _Expr(self, tree):",
    "self._fill()",
    "self._dispatch(tree.value)",
    "",
    "def _Import(self, t):",
    "self._fill(\"import \")",
    "first = True",
    "for a in t.names:",
    "if first:",
    "first = False",
    "else:",
    "self._write(\", \")",
    "self._write(a.name)",
    "if a.asname:",
    "self._write(\" as \"+a.asname)",
    "",
    "#    def _ImportFrom(self, t):",
    "#        self._fill(\"from \")",
    "#        self._write(t.module)",
    "#        self._write(\" import \")",
    "#        for i, a in enumerate(t.names):",
    "#            if i == 0:",
    "#                self._write(\", \")",
    "#            self._write(a.name)",
    "#            if a.asname:",
    "#                self._write(\" as \"+a.asname)",
    "#        # XXX(jpe) what is level for?",
    "#",
    "",
    "def _Break(self, t):",
    "self._fill(\"break\")",
    "",
    "def _Continue(self, t):",
    "self._fill(\"continue\")",
    "",
    "def _Delete(self, t):",
    "self._fill(\"del \")",
    "self._dispatch(t.targets)",
    "",
    "def _Assert(self, t):",
    "self._fill(\"assert \")",
    "self._dispatch(t.test)",
    "if t.msg:",
    "self._write(\", \")",
    "self._dispatch(t.msg)",
    "",
    "def _Exec(self, t):",
    "self._fill(\"exec \")",
    "self._dispatch(t.body)",
    "if t.globals:",
    "self._write(\" in \")",
    "self._dispatch(t.globals)",
    "if t.locals:",
    "self._write(\", \")",
    "self._dispatch(t.locals)",
    "",
    "def _Print(self, t):",
    "self._fill(\"print \")",
    "do_comma = False",
    "if t.dest:",
    "self._write(\">>\")",
    "self._dispatch(t.dest)",
    "do_comma = True",
    "for e in t.values:",
    "if do_comma:self._write(\", \")",
    "else:do_comma=True",
    "self._dispatch(e)",
    "if not t.nl:",
    "self._write(\",\")",
    "",
    "def _Global(self, t):",
    "self._fill(\"global\")",
    "for i, n in enumerate(t.names):",
    "if i != 0:",
    "self._write(\",\")",
    "self._write(\" \" + n)",
    "",
    "def _Yield(self, t):",
    "self._fill(\"yield\")",
    "if t.value:",
    "self._write(\" (\")",
    "self._dispatch(t.value)",
    "self._write(\")\")",
    "",
    "def _Raise(self, t):",
    "self._fill('raise ')",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.inst:",
    "self._write(\", \")",
    "self._dispatch(t.inst)",
    "if t.tback:",
    "self._write(\", \")",
    "self._dispatch(t.tback)",
    "",
    "",
    "def _TryFinally(self, t):",
    "self._fill(\"try\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "self._fill(\"finally\")",
    "self._enter()",
    "self._dispatch(t.finalbody)",
    "self._leave()",
    "",
    "def _excepthandler(self, t):",
    "self._fill(\"except \")",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.name:",
    "self._write(\", \")",
    "self._dispatch(t.name)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _ClassDef(self, t):",
    "self._write(\"\\n\")",
    "self._fill(\"class \"+t.name)",
    "if t.bases:",
    "self._write(\"(\")",
    "for a in t.bases:",
    "self._dispatch(a)",
    "self._write(\", \")",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _FunctionDef(self, t):",
    "self._write(\"\\n\")",
    "for deco in t.decorators:",
    "self._fill(\"@\")",
    "self._dispatch(deco)",
    "self._fill(\"def \"+t.name + \"(\")",
    "self._dispatch(t.args)",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _For(self, t):",
    "self._fill(\"for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "def _While(self, t):",
    "self._fill(\"while \")",
    "self._dispatch(t.test)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "# expr",
    "def _Str(self, tree):",
    "self._write(repr(tree.s))",
    "#",
    "def _Repr(self, t):",
    "self._write(\"`\")",
    "self._dispatch(t.value)",
    "self._write(\"`\")",
    "",
    "def _Num(self, t):",
    "self._write(repr(t.n))",
    "",
    "def _ListComp(self, t):",
    "self._write(\"[\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\"]\")",
    "",
    "def _GeneratorExp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\")\")",
    "",
    "def _comprehension(self, t):",
    "self._write(\" for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "for if_clause in t.ifs:",
    "self._write(\" if \")",
    "self._dispatch(if_clause)",
    "",
    "def _IfExp(self, t):",
    "self._dispatch(t.body)",
    "self._write(\" if \")",
    "self._dispatch(t.test)",
    "if t.orelse:",
    "self._write(\" else \")",
    "self._dispatch(t.orelse)",
    "",
    "unop = {\"Invert\":\"~\", \"Not\": \"not\", \"UAdd\":\"+\", \"USub\":\"-\"}",
    "def _UnaryOp(self, t):",
    "self._write(self.unop[t.op.__class__.__name__])",
    "self._write(\"(\")",
    "self._dispatch(t.operand)",
    "self._write(\")\")",
    "",
    "binop = { \"Add\":\"+\", \"Sub\":\"-\", \"Mult\":\"*\", \"Div\":\"/\", \"Mod\":\"%\",",
    "\"LShift\":\">>\", \"RShift\":\"<<\", \"BitOr\":\"|\", \"BitXor\":\"^\", \"BitAnd\":\"&\",",
    "\"FloorDiv\":\"//\", \"Pow\": \"**\"}",
    "def _BinOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.left)",
    "self._write(\")\" + self.binop[t.op.__class__.__name__] + \"(\")",
    "self._dispatch(t.right)",
    "self._write(\")\")",
    "",
    "boolops = {_ast.And: 'and', _ast.Or: 'or'}",
    "def _BoolOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.values[0])",
    "for v in t.values[1:]:",
    "self._write(\" %s \" % self.boolops[t.op.__class__])",
    "self._dispatch(v)",
    "self._write(\")\")",
    "",
    "def _Attribute(self,t):",
    "self._dispatch(t.value)",
    "self._write(\".\")",
    "self._write(t.attr)",
    "",
    "#    def _Call(self, t):",
    "#        self._dispatch(t.func)",
    "#        self._write(\"(\")",
    "#        comma = False",
    "#        for e in t.args:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        for e in t.keywords:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        if t.starargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"*\")",
    "#            self._dispatch(t.starargs)",
    "#        if t.kwargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"**\")",
    "#            self._dispatch(t.kwargs)",
    "#        self._write(\")\")",
    "",
    "# slice",
    "def _Index(self, t):",
    "self._dispatch(t.value)",
    "",
    "def _ExtSlice(self, t):",
    "for i, d in enumerate(t.dims):",
    "if i != 0:",
    "self._write(': ')",
    "self._dispatch(d)",
    "",
    "# others",
    "def _arguments(self, t):",
    "first = True",
    "nonDef = len(t.args)-len(t.defaults)",
    "for a in t.args[0:nonDef]:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a)",
    "for a,d in zip(t.args[nonDef:], t.defaults):",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a),",
    "self._write(\"=\")",
    "self._dispatch(d)",
    "if t.vararg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"*\"+t.vararg)",
    "if t.kwarg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"**\"+t.kwarg)",
    "",
    "#    def _keyword(self, t):",
    "#        self._write(t.arg)",
    "#        self._write(\"=\")",
    "#        self._dispatch(t.value)",
    "",
    "def _Lambda(self, t):",
    "self._write(\"lambda \")",
    "self._dispatch(t.args)",
    "self._write(\": \")",
    "self._dispatch(t.body)",
    "int : The first line number in the block. 1-indexed.",
    "int : The last line number. Inclusive!",
    "str : The text block including '#' character but not any leading spaces.",
    "Only add if not entirely whitespace.",
    "Start with a dummy.",
    "All of the blocks seen so far.",
    "The index mapping lines of code to their associated comment blocks.",
    "Oops! Trailing comment, not a comment block.",
    "A comment block.",
    "FIXME: gracefully handle errors here or in the caller?",
    "FIXME: handle other kinds of assignments?",
    "string conversion routines",
    "Check if the referenced member can have a docstring or not",
    "Referenced object has a docstring",
    "Latex collects all references to a separate bibliography,",
    "so we need to insert links to it",
    "-*- coding: utf-8 -*-",
    "Convert signode to a specified format",
    "Call user code to resolve the link",
    "no source",
    "only one link per name, please",
    "------------------------------------------------------------------------------",
    "Creating 'phantom' modules from an XML description",
    "------------------------------------------------------------------------------",
    "Sort items so that",
    "- Base classes come before classes inherited from them",
    "- Modules come before their contents",
    "Create phantom items",
    "create parent, if missing",
    "create object",
    "Populate items",
    "-*- coding: utf-8 -*-",
    "##########################################################################",
    "A tensor is simply a numpy array",
    "##########################################################################",
    "Unfolding a tensor is easy",
    "##########################################################################",
    "Re-folding the tensor is as easy:",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.7, Tensorly includes constrained CP decomposition which penalizes or",
    "constrains factors as chosen by the user. The proposed implementation of constrained CP uses the",
    "Alternating Optimization Alternating Direction Method of Multipliers (AO-ADMM) algorithm from [1] which",
    "solves alternatively convex optimization problem using primal-dual optimization. In constrained CP",
    "decomposition, an auxilliary factor is introduced which is constrained or regularized using an operator called the",
    "proximal operator. The proximal operator may therefore change according to the selected constraint or penalization.",
    "",
    "Tensorly provides several constraints and their corresponding proximal operators, each can apply to one or all factors in the CP decomposition:",
    "",
    "1. Non-negativity",
    "* `non_negative` in signature",
    "* Prevents negative values in CP factors.",
    "2. L1 regularization",
    "* `l1_reg` in signature",
    "* Adds a L1 regularization term on the CP factors to the CP cost function, this promotes sparsity in the CP factors. The user chooses the regularization amount.",
    "3. L2 regularization",
    "* `l2_reg` in signature",
    "* Adds a L2 regularization term on the CP factors to the CP cost function. The user chooses the regularization amount.",
    "4. L2 square regularization",
    "* `l2_square_reg` in signature",
    "* Adds a L2 regularization term on the CP factors to the CP cost function. The user chooses the regularization amount.",
    "5. Unimodality",
    "* `unimodality` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors is unimodal (there is only one local maximum, like a Gaussian).",
    "6. Simplex",
    "* `simplex` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors lives on the simplex or user-defined radius (entries are nonnegative and sum to a user-defined positive parameter columnwise).",
    "7. Normalization",
    "* `normalize` in signature",
    "* Impose that the largest absolute value in the factors elementwise is 1.",
    "8. Normalized sparsity",
    "* `normalized_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the columns of factors are both normalized with the L2 norm, and k-sparse (at most k-nonzeros per column) with k user-defined.",
    "9. Soft sparsity",
    "* `soft_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the columns of factors have L1 norm bounded by a user-defined threshold.",
    "10. Smoothness",
    "* `smoothness` in signature",
    "* This constraint acts columnwise on the factors",
    "* Favor smoothness in factors columns by penalizing the L2 norm of finite differences. The user chooses the regularization amount. The proximal operator in fact solves a banded system.",
    "11. Monotonicity",
    "* `monotonicity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that the factors are either always increasing or decreasing (user-specified) columnwise. This is based on isotonic regression.",
    "12. Hard sparsity",
    "* `hard_sparsity` in signature",
    "* This constraint acts columnwise on the factors",
    "* Impose that each column of the factors has at most k nonzero entries (k is user-defined).",
    "",
    "While some of these constraints (2, 3, 4, 6, 8, 9, 12) require a scalar",
    "input as its parameter or regularizer, boolean input could be enough",
    "for other constraints (1, 5, 7, 10, 11). Selection of one of these",
    "constraints for all mode (or factors) or using different constraints for different modes are both supported.",
    "tensor generation",
    "#############################################################################",
    "Using one constraint for all modes",
    "--------------------------------------------",
    "Constraints are inputs of the constrained_parafac function, which itself uses the",
    "``tensorly.tenalg.proximal.validate_constraints`` function in order to process the input",
    "of the user. If a user wants to use the same constraint for all modes, an",
    "input (bool or a scalar value or list of scalar values) should be given to this constraint.",
    "Assume, one wants to use unimodality constraint for all modes. Since it does not require",
    "any scalar input, unimodality can be imposed by writing `True` for `unimodality`:",
    "#############################################################################",
    "This constraint imposes that each column of all the factors in the CP decomposition are unimodal:",
    "#############################################################################",
    "Constraints requiring a scalar input can be used similarly as follows:",
    "#############################################################################",
    "The same regularization coefficient l1_reg is used for all the modes. Here the l1 penalization induces sparsity given that the regularization coefficient is large enough.",
    "#############################################################################",
    "Using one constraint for some modes",
    "--------------------------------------------",
    "As a second option, constraint can be used for only a few selected modes by using",
    "a python dictionary:",
    "#############################################################################",
    "Since only the first and last factors are chosen, entries on the second mode factor could be negative.",
    "#############################################################################",
    "Using a constraint with the different scalar inputs for each mode",
    "---------------------------------------------------------",
    "One may prefer different scalar value for each mode. It is possible by",
    "using a list structure:",
    "#############################################################################",
    "Using different constraints for each mode",
    "--------------------------------------------",
    "To use different constraint for different modes, the dictionary structure",
    "should be preferred:",
    "#############################################################################",
    "In the dictionary, `key` is the selected mode and `value` is a scalar value or",
    "only `True` depending on the selected constraint.",
    "#############################################################################",
    "Thus, first factor will be non-negative, second factor will be regularized",
    "by :math:`0.01` with :math:`l_1` and last factor will be regularized by",
    ":math:`0.01` with :math:`l_2^2`.",
    "#############################################################################",
    "References",
    "----------",
    "",
    "[1] Huang, Kejun, Nicholas D. Sidiropoulos, and Athanasios P. Liavas.",
    "\"A flexible and efficient algorithmic framework for constrained",
    "matrix and tensor factorization.\"",
    "IEEE Transactions on Signal Processing 64.19 (2016): 5052-5065.",
    "`(Online version)",
    "<https://ieeexplore.ieee.org/document/7484753>`_",
    "-*- coding: utf-8 -*-",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor that follows the PARAFAC2 constraints found",
    "inx `(Kiers et al 1999)`_.",
    "",
    "This particular tensor,",
    ":math:`\\mathcal{X}\u00a0\\in \\mathbb{R}^{I\\times J \\times K}`, is a shifted",
    "CP tensor, that is, a tensor on the form:",
    "",
    ".. math::",
    "\\mathcal{X}_{ijk} = \\sum_{r=1}^R A_{ir} B_{\\sigma_i(j) r} C_{kr},",
    "",
    "where :math:`\\sigma_i`\u00a0is a cyclic permutation of :math:`J` elements.",
    "Set parameters",
    "Generate random matrices",
    "Normalised factor matrices",
    "Generate the shifted factor matrix",
    "Construct the tensor",
    "Add noise",
    "#############################################################################",
    "Fit a PARAFAC2 tensor",
    "---------------------",
    "To avoid local minima, we initialise and fit 10 models and choose the one",
    "with the lowest error",
    "#############################################################################",
    "A decomposition is a wrapper object for three variables: the *weights*,",
    "the *factor matrices* and the *projection matrices*. The weights are similar",
    "to the output of a CP decomposition. The factor matrices and projection",
    "matrices are somewhat different. For a CP decomposition, we only have the",
    "weights and the factor matrices. However, since the PARAFAC2 factor matrices",
    "for the second mode is given by",
    "",
    ".. math::",
    "B_i = P_i B,",
    "",
    "where :math:`B` is an :math:`R \\times R` matrix and :math:`P_i` is an",
    ":math:`I \\times R` projection matrix, we cannot store the factor matrices",
    "the same as for a CP decomposition.",
    "",
    "Instead, we store the factor matrix along the first mode (:math:`A`), the",
    "\"blueprint\" matrix for the second mode (:math:`B`) and the factor matrix",
    "along the third mode (:math:`C`) in one tuple and the projection matrices,",
    ":math:`P_i`, in a separate tuple.",
    "",
    "If we wish to extract the informative :math:`B_i` factor matrices, then we",
    "use the ``tensorly.parafac2_tensor.apply_projection_matrices`` function on",
    "the PARAFAC2 tensor instance to get another wrapper object for two",
    "variables: *weights* and *factor matrices*. However, now, the second element",
    "of the factor matrices tuple is now a list of factor matrices, one for each",
    "frontal slice of the tensor.",
    "",
    "Likewise, if we wish to construct the tensor or the frontal slices, then we",
    "can use the ``tensorly.parafac2_tensor.parafac2_to_tensor`` function. If the",
    "decomposed dataset consisted of uneven-length frontal slices, then we can",
    "use the ``tensorly.parafac2_tensor.parafac2_to_slices`` function to get a",
    "list of frontal slices.",
    "#############################################################################",
    "Compute performance metrics",
    "---------------------------",
    "To evaluate how well the original structure is recovered, we calculate the tucker congruence coefficient.",
    "#############################################################################",
    "Visualize the components",
    "------------------------",
    "Find the best permutation so that we can plot the estimated components on top of the true components",
    "Create plots of each component vector for each mode",
    "(We just look at one of the B_i matrices)",
    "Plot true and estimated components for mode A",
    "Labels for the different components",
    "Plot true and estimated components for mode C",
    "Plot true components for mode B",
    "Get the signs so that we can flip the B mode factor matrices",
    "Plot estimated components for mode B (after sign correction)",
    "Titles for the different modes",
    "Create a legend for the entire figure",
    "#############################################################################",
    "Inspect the convergence rate",
    "----------------------------",
    "It can be interesting to look at the loss plot to make sure that we have",
    "converged to a stationary point. We skip the first iteration since the",
    "initial loss often dominate the rest of the plot, making it difficult",
    "to check for convergence.",
    "#############################################################################",
    "References",
    "----------",
    "",
    ".. _(Kiers et al 1999):",
    "",
    "Kiers HA, Ten Berge JM, Bro R. *PARAFAC2\u2014Part I.",
    "A direct fitting algorithm for the PARAFAC2 model.*",
    "**Journal of Chemometrics: A Journal of the Chemometrics Society.**",
    "1999 May;13(3\u20104):275-94. `(Online version)",
    "<https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-128X(199905/08)13:3/4%3C275::AID-CEM543%3E3.0.CO;2-B>`_",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, several options are available to compute",
    "non-negative CP (NCP), in particular several",
    "algorithms:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that factors must have only non-negative values after it is",
    "obtained from a non-negative tensor.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random from the sequence of integers from 1 to 24000.",
    "Tensor generation",
    "#############################################################################",
    "Our goal here is to produce an approximation of the tensor generated above",
    "which follows a low-rank CP model, with non-negative coefficients. Before",
    "using these algorithms, we can use Tensorly to produce a good initial guess",
    "for our NCP. In fact, in order to compare both algorithmic options in a",
    "fair way, it is a good idea to use same initialized factors in decomposition",
    "algorithms. We make use of the ``initialize_cp`` function to initialize the",
    "factors of the NCP (setting the ``non_negative`` option to `True`)",
    "and transform these factors (and factors weights) into",
    "an instance of the CPTensor class:",
    "#############################################################################",
    "Non-negative Parafac",
    "-----------------------",
    "From now on, we can use the same ``cp_init`` tensor as the initial tensor when",
    "we use decomposition functions. Now let us first use the algorithm based on",
    "Multiplicative Update, which can be called as follows:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the cp_to_tensor function. The tensor cp_reconstruction_mu is therefore a",
    "low-rank non-negative approximation of the input tensor; looking at the",
    "first few values of both tensors shows that this is indeed",
    "the case but the approximation is quite coarse.",
    "#############################################################################",
    "Non-negative Parafac with HALS",
    "------------------------------",
    "Our second (new) option to compute NCP is the HALS algorithm, which can be",
    "used as follows:",
    "#############################################################################",
    "Again, we can look at the reconstructed tensor entries.",
    "#############################################################################",
    "Non-negative Parafac with Exact HALS",
    "------------------------------------",
    "From only looking at a few entries of the reconstructed tensors, we can",
    "already see a huge gap between HALS and MU outputs.",
    "Additionally, HALS algorithm has an option for exact solution to the non-negative",
    "least squares subproblem rather than the faster, approximate solution.",
    "Note that the overall HALS algorithm will still provide an approximation of",
    "the input data, but will need longer to reach convergence.",
    "Exact subroutine solution option can be used simply choosing exact as True",
    "in the function:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "First comparison option is processing time for each algorithm:",
    "#############################################################################",
    "As it is expected, the exact solution takes much longer than the approximate",
    "solution, while the gain in performance is often void. Therefore we recommend",
    "to avoid this option unless it is specifically required by the application.",
    "Also note that on appearance, both MU and HALS have similar runtimes.",
    "However, a closer look suggest they are indeed behaving quite differently.",
    "Computing the error between the output and the input tensor tells that story better.",
    "In Tensorly, we provide a function to calculate Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both exact and approximate solution. In particular, HALS converged to a",
    "much lower reconstruction error than MU. We can better appreciate the difference",
    "in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases (only",
    "encountered by expert users most likely).",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105. (Link)",
    "<https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, two algorithms are available to compute non-negative",
    "Tucker decomposition:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that core and factors must have only non-negative values after",
    "it is obtained from a non-negative tensor. Tucker decomposition includes core",
    "(:math:`G`) and factors (:math:`A`, :math:`B`, :math:`C`).",
    "",
    ".. math::",
    "T = [| G; A, B , C |],",
    "",
    "We need to solve the following problem for each factor (e.g. factor :math:`A` here):",
    "",
    ".. math::",
    "\\min_{A \\geq 0} ||T_{[1]} - A\\times G_{[1]}(B\\times C)^T||_F^2,",
    "",
    "Here, :math:`G_{[i]}` represents ith mode unfolding of the core. To update",
    "the core, we need the solve following problem:",
    "",
    ".. math::",
    "\\min_{g \\geq 0} ||t -   (A\\times B \\times C)\\times g ||_F^2,",
    "",
    "where :math:`t` and :math:`g` are the vectorized data tensor :math:`T` and core :math:`G`.",
    "#############################################################################",
    "To update the factors, we will use HALS and to update the core, we have two",
    "different algorithms Active Set (AS) and Fast Iterative Shrinkage-Thresholding",
    "Algorithm (FISTA) in Tensorly. While FISTA is an accelerated gradient method for",
    "non-negative or unconstrained problems, AS is the widely used non-negative",
    "least square solution proposed by Lawson and Hanson in 1974. Both algorithms",
    "return non-negative core and FISTA is the default algorithm for HALS Tucker",
    "decomposition in Tensorly.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random tensor from the sequence of integers from",
    "1 to 1000.",
    "tensor generation",
    "#############################################################################",
    "Non-negative Tucker",
    "-----------------------",
    "First, multiplicative update can be implemented as:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the ``tucker_to_tensor`` function. The tensor ``tucker_reconstruction_mu`` is",
    "therefore a low-rank non-negative approximation of the input tensor ``tensor``.",
    "#############################################################################",
    "Non-negative Tucker with HALS and FISTA",
    "---------------------------------------",
    "HALS algorithm with FISTA can be calculated as:",
    "#############################################################################",
    "Non-negative Tucker with HALS and Active Set",
    "--------------------------------------------",
    "As a second option, HALS algorithm with Active Set can be called as follows:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "To compare the various methods, first we may look at each algorithm",
    "processing time:",
    "#############################################################################",
    "All algorithms should run with about the same number of iterations on our",
    "example, so at first glance the MU algorithm is faster (i.e. has lower",
    "per-iteration complexity). A second way to compare methods is to compute",
    "the error between the output and input tensor. In Tensorly, there is a function",
    "to compute Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both FISTA and active set core update options. We can better appreciate",
    "the difference in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases",
    "(only encountered by expert users most likely). Besides, in this experiment",
    "FISTA and active set give very similar results, however active set may last",
    "longer when it is used with higher ranks according to our experience.",
    "Therefore, we recommend to use FISTA with high rank decomposition.",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105.",
    "`(Link) https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>`_",
    "Get a high-accuracy decomposition for comparison",
    "Run PARAFAC decomposition without line search and time",
    "Run PARAFAC decomposition with line search and time",
    "Calculate the error of both decompositions",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "This function compares factors of a reference cp tensor with factors of another tensor",
    "(or list of tensor) in order to match component order. Permutation occurs on the columns of factors,",
    "minimizing the cosine distance to reference cp tensor with scipy Linear Sum Assignment method.",
    "The permuted tensor (or list of tensors) and list of permutation for each permuted tensors are returned.",
    "Tensorly CPTensor should be used as an input to permute their factors and weights simultaneously.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor, then we permute its factors manually.",
    "one reference cp tensor",
    "two target cp tensors",
    "#############################################################################",
    "Permute target CPTensors",
    "------------------------",
    "Now, we can use these two manipulated CPTensors as inputs to the permutation function. Here,",
    "cp_tensor_1 will be used as a reference to permute other CPTensors, which are called target CPTensors.",
    "There is no limitation for the number of target CPTensors but there should be only one reference CPTensor.",
    "Results will include permuted CPTensors and permutation for each permuted cp tensor.",
    "It should be noted that, reference CPTensor won't be included among the output CPTensors.",
    "#############################################################################",
    "As it is expected, permutation variable stores two lists which are equal to predefined col_order_1",
    "col_order_2 above.",
    "#############################################################################",
    "We can also observe the evolution of the factor columns order by plotting one column",
    "before and after permuting.",
    "sphinx_gallery_thumbnail_number = 2",
    "#############################################################################",
    "Introduction",
    "------------",
    "PARAFAC (CP) decomposition is extremely useful in dimensionality reduction, allowing us",
    "to develop models that are both representative and compact while retaining crucial patterns",
    "between subjects. Here, we provide an example of how it can be applied to biomedical research.",
    "",
    "Systems serology is a new technology that examines the antibodies from a patient's serum, aiming",
    "to comprehensively profile the interactions between the antibodies and",
    "`Fc receptors <https://en.wikipedia.org/wiki/Fc_receptor>`_ alongside other types of immunological",
    "and demographic data. Here, we will apply CP decomposition to a",
    "`COVID-19 system serology dataset <https://www.sciencedirect.com/science/article/pii/S0092867420314598>`_.",
    "In this dataset, serum antibodies",
    "of 438 samples collected from COVID-19 patients were systematically profiled by their binding behavior",
    "to SARS-CoV-2 (the virus that causes COVID-19) antigens and Fc receptors activities. Samples are",
    "labeled by the status of the patients.",
    "",
    "Details of this analysis as well as more in-depth biological implications can be found in",
    "`this work <https://www.embopress.org/doi/full/10.15252/msb.202110243>`_. It also includes applying",
    "tensor methods to HIV systems serology measurements and using them to predict patient status.",
    "",
    "We first import this dataset of a panel of COVID-19 patients:",
    "#############################################################################",
    "Apply CP decomposition to this dataset with Tensorly",
    "----------------------------------------------------",
    "Now we apply CP decomposition to this dataset.",
    "#############################################################################",
    "To evaluate how well CP decomposition explains the variance in the dataset, we plot the percent",
    "variance reconstructed (R2X) for a range of ranks.",
    "#############################################################################",
    "Inspect the biological insights from CP components",
    "--------------------------------------------------",
    "Eventually, we wish CP decomposition can bring insights to this dataset. For example, in this",
    "case, revealing the underlying trend of COVID-19 serum-level immunity. To do this, we can inspect",
    "how each component looks like on weights.",
    "Ensure that factors are negative on at most one direction.",
    "#############################################################################",
    "From the results, we can see that serum COVID-19 immunity separates into two distinct signals,",
    "represented by two CP components: a clear acute response with IgG3, IgM, and IgA, and a long-term,",
    "IgG1-specific response. Samples from patients with different symptoms can be distinguished from",
    "these two components. This indicates that CP decomposition is a great tool to find these biologically",
    "significant signals.",
    "#############################################################################",
    "References",
    "----------",
    "[1] Tan, Z. C., Murphy, M. C., Alpay, H. S., Taylor, S. D., & Meyer, A. S. (2021). Tensor\u2010structured",
    "decomposition improves systems serology analysis. Molecular systems biology, 17(9), e10243.",
    "`<https://www.embopress.org/doi/full/10.15252/msb.202110243>`_",
    "",
    "[2] Zohar, T., Loos, C., Fischinger, S., Atyeo, C., Wang, C., Slein, M. D., ... & Alter, G. (2020).",
    "Compromised humoral functional evolution tracks with SARS-CoV-2 mortality. Cell, 183(6), 1508-1519.",
    "`<https://www.sciencedirect.com/science/article/pii/S0092867420314598>`_",
    "Rank of the CP decomposition",
    "Rank of the Tucker decomposition",
    "Perform the CP decomposition",
    "Reconstruct the image from the factors",
    "Tucker decomposition",
    "Plotting the original and reconstruction from the decompositions",
    "%%",
    "Here we will load a tensor of experimentally measured cellular responses to",
    "IL-2 stimulation. IL-2 is a naturally occurring immune signaling molecule",
    "which has been engineered by pharmaceutical companies and drug designers",
    "in attempts to act as an effective immunotherapy. In order to make effective IL-2",
    "therapies, pharmaceutical engineer have altered IL-2's signaling activity in order to",
    "increase or decrease its interactions with particular cell types.",
    "",
    "IL-2 signals through the Jak/STAT pathway and transmits a signal into immune cells by",
    "phosphorylating STAT5 (pSTAT5). When phosphorylated, STAT5 will cause various immune",
    "cell types to proliferate, and depending on whether regulatory (regulatory T cells, or Tregs)",
    "or effector cells (helper T cells, natural killer cells, and cytotoxic T cells,",
    "or Thelpers, NKs, and CD8+ cells) respond, IL-2 signaling can result in",
    "immunosuppression or immunostimulation respectively. Thus, when designing a drug",
    "meant to repress the immune system, potentially for the treatment of autoimmune",
    "diseases, IL-2 which primarily enacts a response in Tregs is desirable. Conversely,",
    "when designing a drug that is meant to stimulate the immune system, potentially for",
    "the treatment of cancer, IL-2 which primarily enacts a response in effector cells",
    "is desirable. In order to achieve either signaling bias, IL-2 variants with altered",
    "affinity for it's various receptors (IL2R\u03b1 or IL2R\u03b2) have been designed. Furthermore",
    "IL-2 variants with multiple binding domains have been designed as multivalent",
    "IL-2 may act as a more effective therapeutic. In order to understand how these mutations",
    "and alterations affect which cells respond to an IL-2 mutant, we will perform",
    "non-negative PARAFAC tensor decomposition on our cell response data tensor.",
    "",
    "Here, our data contains the responses of 8 different cell types to 13 different",
    "IL-2 mutants, at 4 different timepoints, at 12 standardized IL-2 concentrations.",
    "Therefore, our tensor will have shape (13 x 4 x 12 x 8), with dimensions",
    "representing IL-2 mutant, stimulation time, dose, and cell type respectively. Each",
    "measured quantity represents the amount of phosphorlyated STAT5 (pSTAT5) in a",
    "given cell population following stimulation with the specified IL-2 mutant.",
    "%%",
    "Now we will run non-negative PARAFAC tensor decomposition to reduce the dimensionality",
    "of our tensor. We will use 3 components, and normalize our resulting tensor to aid in",
    "future comparisons of correlations across components.",
    "",
    "First we must preprocess our tensor to ready it for factorization. Our data has a",
    "few missing values, and so we must first generate a mask to mark where those values",
    "occur.",
    "%%",
    "Now that we've marked where those non-finite values occur, we can regenerate our",
    "tensor without including non-finite values, allowing it to be factorized.",
    "%%",
    "Using this mask, and finite-value only tensor, we can decompose our signaling data into",
    "three components. We will also normalize this tensor, which will allow for easier",
    "comparisons to be made between the meanings, and magnitudes of our resulting components.",
    "%%",
    "Now we will load the names of our cell types and IL-2 mutants, in the order in which",
    "they are present in our original tensor. IL-2 mutant names refer to the specific",
    "mutations made to their amino acid sequence, as well as their valency",
    "format (monovalent or bivalent).",
    "",
    "Finally, we label, plot, and analyze our factored tensor of data.",
    "%%",
    "Here we observe the correlations which both ligands and cell types have with each of",
    "our three components - we can interepret our tensor factorization for looking for",
    "patterns among these correlations.",
    "",
    "For example, we can see that bivalent mutants generally have higher correlations with",
    "component two, as do regulatory T cells. Thus we can infer that bivalent ligands",
    "activate regulatory T cells more than monovalent ligands. We also see that this",
    "relationship is strengthened by the availability of IL2R\u03b1, one subunit of the IL-2 receptor.",
    "",
    "This is just one example of an insight we can make using tensor factorization.",
    "By plotting the correlations which time and dose have with each component, we",
    "could additionally make inferences as to the dynamics and dose dependence of how mutations",
    "affect IL-2 signaling in immune cells.",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Should we allow None weights?",
    "it's already been validated at creation",
    "Skip the target mode",
    "Calculate the sign of the current factor in each component",
    "Update both the current and receiving factor",
    "Check the weight signs",
    "Test for the validity of the operation",
    "norm = T.dot(T.dot(weights, norm), weights)",
    "We sum even if weigths is not None",
    "as e.g. MXNet would return a 1D tensor, not a 0D tensor",
    "Deprecated classes and functions",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Check user input for potential errors",
    "Check first and last rank",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi",
    "Import opt-einsum for the contraction path",
    "Import cuQuantum for the actual contraction",
    "return cuquantum.contract(equation, *args, optimize={'path': path})",
    "Note how tt_matrix_to_tensor is implemented in tenalg to allow for more efficient implementations",
    "(e.g. using the einsum backend)",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Test for the validity of the operation",
    "rank is 'same' or float: choose rank so as to preserve a fraction of the original #parameters",
    "sorted to be careful with the order when popping and reinserting to not remove/add at wrong index.",
    "list (mode, shape) that we removed as they will be kept the same, rank[i] =",
    "number of parameters coming from the fixed modes (these don't have a variable size as a fun of fraction_param)",
    "Doesn't contain fixed_modes, those factors are accounted for in fixed_params",
    "it's already been validated at creation",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Border rank of 1, R_0 = R_N = 1",
    "First and last factor of size I_0 R and I_N R",
    "We want the number of params of decomp (=sum of params of factors)",
    "To be equal to c = \\prod_k I_k",
    "We get the non-negative solution",
    "Choose a rank proportional to the size of each mode",
    "The method is similar to the above one for constant_rank == True",
    "We get the non-negative solution",
    "Check user input for potential errors",
    "Initialization",
    "Will raise an error if invalid",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "it's already been validated at creation",
    "Skip first factor matrix since the rank is extracted from it.",
    "allocate variables for weights, and normalized factors",
    "if (not copy) and (weights is None):",
    "warnings.warn('Provided copy=False and weights=None: a new Parafac2Tensor'",
    "'with new weights and factors normalised inplace will be returned.')",
    "weights = T.ones(rank, **T.context(factors[0]))",
    "The if test below was added to enable inplace edits",
    "however, TensorFlow does not support inplace edits",
    "so this is always set to True",
    "backend_context,",
    "backend_manager,",
    "_get_backend_dir, _get_backend_method,",
    "from . import backend as backend_manager",
    "Deprecated",
    "Add Backend functions, dynamically dispatched",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__,",
    "backend_manager.__getattribute__,",
    "full_dir)",
    "# override_module_dispatch(__name__, _get_backend_method, full_dir)",
    "del override_module_dispatch, full_dir#, _get_backend_method",
    "Authors: Isabell Lehmann <isabell.lehmann94@outlook.de>",
    "License: BSD 3 clause",
    "initialize values",
    "the coupled factor should be initialized with the concatenated dataset",
    "alternating least squares",
    "note that the order of the khatri rao product is reversed since tl.unfold has another order",
    "than assumed in paper",
    "Loop over modes of the tensor",
    "We want to solve for mode 0 last, since the coupled factor matrix is most influential and SVD gave us a good approximation",
    "If we are at the coupled mode, concat the matrix",
    "Getting the TT factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TT factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "A TTM with a single factor is just a matrix...",
    "Change order",
    "Getting the first factor",
    "SVD of unfolding matrix",
    "Get first TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the TR factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "Reorder factors to match input",
    "A list of candidates for each mode",
    "Refine the init",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "If nn_modes is set, we use HALS, otherwise, we use the standard parafac implementation.",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "TODO: this is a hack but it seems to do the job for now",
    "TODO: Test this",
    "Make decomposition feasible by taking the absolute value of all factor matrices",
    "If we have to update the mask we already have to build the full tensor",
    "Update the tensor based on the mask",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Will we be performing a line search iteration",
    "Calculate the current unnormalized error if we need it",
    "Start line search if requested.",
    "For each matrix, randomly choose n_samples indices for which to compute the khatri-rao product",
    "Compute corresponding rows of the full khatri-rao product",
    "Compute the Khatri-Rao product for the chosen indices",
    "Keep all the elements of the currently considered mode",
    "MXNet will not be happy if this is a list instead of a tuple",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Caglayan Tuna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "ADMM inits",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Fix to address surprising MXNet.numpy behavior (Issue #19891)",
    "Initialise the decompositions",
    "Norm of the reconstructions at each iteration",
    "Update the lagrangian multipliers",
    "Evolution of the reconstruction errors",
    "Convergence check",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "A list of candidates for each mode",
    "Refine the init",
    "Deprecated",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Initialisation",
    "The initial core approximation is needed here for the masking step",
    "SVD init",
    "The factors are orthonormal and therefore do not affect the reconstructed tensor's norm",
    "TO-DO validate rank for partial tucker as well",
    "Initialisation",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local variables",
    "Iterate over one step of NTD",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "UtU",
    "UtM",
    "Call the hals resolution with nnls, optimizing the current mode",
    "updating core",
    "Adding the l1 norm value to the reconstruction error",
    "error computation",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan TUna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "khatri_rao(factors).tl.dot(khatri_rao(factors))",
    "simplifies to multiplications",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local varaibles",
    "Iteratation",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "Call the hals resolution with nnls, optimizing the current mode",
    "check recovery",
    "check low rank recovery",
    "Check for sparsity of the gross error",
    "assert tl.sum(noise_pred > 0.01) == tl.sum(noise > 0.01)",
    "check sparse gross error recovery",
    "###########################",
    "Test with missing values #",
    "###########################",
    "Add some corruption (missing values, replaced by ones)",
    "Decompose the tensor",
    "check recovery",
    "check low rank recovery",
    "check sparse gross error recovery",
    "Check for recovery of the corrupted/missing part",
    "mxnet does not support complex numbers. tensorflow has issues with type promotion that would require more code changes",
    "Generate a random complex tensor if requested",
    "Callback to record error",
    "Given all the random seed is set, this should provide the same answer for random initialization",
    "Callback to record error",
    "Check that the error monotonically decreases",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Check that sparse component works",
    "Check that we get roughly the same answer with the full tensor and masking",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test normalization",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test normalization",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Regression test: used wrong variable for convergence checking",
    "Used mttkrp*factor instead of mttkrp*factors[-1], which resulted in",
    "error when mode 2 was not constrained and erroneous convergence checking",
    "when mode 2 was constrained.",
    "test tensor reconstructed properly",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "Test random_state fixes the core and the factor matrices",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "try fixing the core",
    "Random and SVD init should converge to a similar solution",
    "Mask an outlier value, and check that the decomposition ignores it",
    "We won't use the SVD decomposition, but check that it at least runs successfully",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "try fixing the mode",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Testing if estimated factors are monotonic",
    "Check if maximum values is 1",
    "Check if factors have l1 norm smaller than threshold",
    "Check if factors are normalized and k-sparse",
    "Check if factors are normalized and k-sparse",
    "Test the max abs difference between the reconstruction and the tensor",
    "Check that the error monotonically decreases",
    "# Check reconstruction of noisy tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Test convergence criterion",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Fit with only one iteration to check non-negativity",
    "The default random parafac2 tensor has non-negative A and C",
    "we therefore multiply them randomly with -1, 0 or 1 to get both positive and negative components",
    "Test that constraining B leads to a warning",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TODO: Remove once MXNet supports transpose for > 6th order tensors",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Deprecated",
    "Generate a random state for me",
    "random state from integer seed",
    "if it is already a random state, just return it",
    "only takes as seed a random state, an int or None",
    "tests that the columns of each factor matrix are indeed orthogonal",
    "(See issue #40)",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Authors: Taylor Lee Patti <taylorpatti@g.harvard.edu>",
    "Jean Kossaifi",
    "All density matrices are Hermitian, here real. Hermitianize matrix if rounding/transformation",
    "errors have occured.",
    "Authors: Hratch Baghdassarian <hmbaghdassarian@gmail.com>, Erick Armingol <earmingol14@gmail.com>",
    "similarity metrics for tensor decompositions",
    "check input factors shape",
    "check method",
    "vertically stack loading matrices -- shape sum(tensor.shape)xR)",
    "normalize columns to L2 norm - even if ran decomposition with normalize_factors=True",
    "generate the correlation index input",
    "correlation index scoring",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "TODO: write a function to do this..",
    "initialize random matrix",
    "Workaround for tensorflow",
    "randomly create intervals to separate matrix into factors list",
    "test column permutation invariance",
    "test scaling invariance",
    "Make sure it's not a tuple but a list",
    "Add two one-dimensional mode to data_tensor",
    "perform TTOI for n_iter iterations",
    "first perform forward update",
    "left_singular_vectors will be a list including estimated left singular spaces at the current iteration",
    "initialize left_residuals (sequential unfolding of data_tensor multiplied by left_singular_vectors sequentially on the left, useful for backward update to obtain right_singular_vectors)",
    "estimate the first left singular spaces",
    "Here, R_tmp is the first sequential unfolding compressed on the right by previous updated right_singular_vectors (if exists)",
    "estimate the 2nd to (d-1)th left singular spaces",
    "compress the (mode+2)th sequential unfolding of data_tensor from the left",
    "R_tmp_l will be useful for backward update",
    "compress the (mode+2)th sequential unfolding of data_tensor from the right (if iteration>0)",
    "forward update is done; output the final residual",
    "perform backward update",
    "initialize right_singular_vectors: right_singular_vectors will be a list of estimated right singular spaces at the current or previous iteration",
    "estimate the 2nd to (d-1)th right singular spaces",
    "compress left_residuals from the right",
    "return final results",
    "Check user input for errors",
    "Make sure iter's not a tuple but a list",
    "Initialize rank",
    "list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.",
    "list row_idx: row indices    (left indices)  for skeleton-decomposition: indicate which rows used in each core.",
    "Initialize indice: random selection of column indices",
    "Initialize the cores of tensor-train",
    "#####################################",
    "left-to-right step",
    "list row_idx: list of (tensor_order-1) of lists of left indices",
    "update row indices",
    "end left-to-right step",
    "##############################################",
    "##############################################",
    "right-to-left step",
    "list col_idx: list (tensor_order-1) of lists of right indices",
    "update col indices",
    "Compute cores",
    "The rank should not be larger than the input tensor's size",
    "Add the last core",
    "end right-to-left step",
    "###############################################",
    "check the error for while-loop",
    "check convergence",
    "Extract fibers according to the row and col indices",
    "Extract the core",
    "shape the core as a 3-tensor_order cube",
    "merge r_k and n_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "Extract fibers",
    "shape the core as a 3-tensor_order cube",
    "merge n_{k-1} and r_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "The index of row of the submatrix",
    "Rest of rows / unselected rows",
    "Find r rows iteratively",
    "Compute the square of norm of each row",
    "If there is only one row of A left, let's just return it. MxNet is not robust about this case.",
    "If a row is 0, we delete it.",
    "Find the row of max norm",
    "Compute the projection of max_row to other rows",
    "projection a to b is computed as: <a,b> / sqrt(|a|*|b|)",
    "make sure normalization vector is of the same shape of projection (causing bugs for MxNet)",
    "Subtract the projection from A_new:  b <- b - a * projection",
    "Delete the selected row",
    "update the row_idx and rest_of_rows",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TEST 4",
    "Random tensor is not really compress-able. Test on a tensor as values of a function",
    "Find TT decomposition of the tensor",
    "!/usr/bin/env python3",
    "-*- coding: utf-8 -*-",
    "Generate tensor true_tensor with low tensor train rank, and its noisy observation data_tensor",
    "run TTOI",
    "Check that the approximation error monotonically decreases",
    "assert (np.all(np.diff(tl.to_numpy(approx_errors)) <= 1e-3))",
    "check that the estimation error of TTOI improves from initialization (TTSVD)",
    "from ...backend import _get_backend_method, _get_backend_dir",
    "from ...backend import backend",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__, backend_manager.__getattribute__, sparse_dir)",
    "override_module_dispatch(__name__, _get_backend_method, sparse_dir)",
    "Deprecated",
    "Make sure the algorithm stays sparse. This will run out of memory on",
    "most machines if the algorithm densifies.",
    "Will blow-up memory if not sparse-safe",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Default on standard SVD",
    "all-zeros matrix, so we should do a quick return.",
    "We can perform a partial SVD",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "use dense form when sparse form will fail",
    "use dense form when sparse form will fail",
    "WARNING: here, V is still the transpose of what it should be",
    "Check correct rank and shapes are returned",
    "One of the factors has the wrong rank",
    "Not the correct amount of weights",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test cp_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test cp_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "If we're taking the gradient of comparison with self it should be 0",
    "Check that we can solve for a direction of descent",
    "Check that modifying copy tensor doesn't change the original tensor",
    "one target cp tensor",
    "two target cp tensors",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not three factor matrices",
    "Not enough projections",
    "Wrong number of weights",
    "The projections aren't orthogonal",
    "Disable tests for inplace edits, since that possibility is removed",
    "to support TensorFlow.",
    "@pytest.mark.parametrize('copy', [True, False])",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create tensor",
    "Compute ground truth TT factors",
    "Check that TT factors re-assemble to the original tensor",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Reconstruct the original tensor",
    "Check that the rank is 10",
    "Rounding = floor",
    "Rounding = ceil",
    "Testing for a tensor-train",
    "Testing for a Tensor-Ring",
    "Testing for a TT-Matrix",
    "TODO: Remove once MXNet supports transpose for > 6th order tensors",
    "Author: Jean Kossaifi",
    "Set in context manager",
    "Sets back to numpy",
    "Reset back to initial backend",
    "Set not in context manager",
    "Improper name doesn't reset backend",
    "Changes only happen locally in this thread",
    "Set the global default backend",
    "Changed toplevel default in all threads",
    "True reconstruction error (based on numpy SVD)",
    "Reconstruction error with the backend's SVD",
    "Check that the two are similar",
    "Check for orthogonality when relevant",
    "Should fail on non-matrices",
    "Test for singular matrices (some eigenvals will be zero)",
    "Rank at most 5",
    "Test orthonormality when  max_dim > n_eigenvecs > matrix_rank",
    "Test if truncated_svd returns the same result for the same setting",
    "limit as order->oo is the oo-norm",
    "Test that clip can work with single arguments",
    "More extensive test with a larger random tensor",
    "Regression test for bug found with the pytorch backend",
    "1D",
    "2D",
    "3D",
    "random testing against Numpy's output",
    "1-dim x n-dim",
    "n_dim x 1-dim",
    "n-dim x n-dim",
    "test dimensions",
    "test residuals",
    "test least squares solution",
    "assert that the columns of Q are orthonormal",
    "Third order tensor",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create ground truth TR factors",
    "Create tensor",
    "TODO: add trace to backend instead of this",
    "Check that TR factors re-assemble to the original tensor",
    "Rounding = floor",
    "Rounding = ceil",
    "Integer rank",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not enough factors to match core",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test tucker_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test tucker_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "With fixed modes",
    "Floor",
    "Ceil",
    "Check that modifying copy tensor doesn't change the original tensor",
    "Author: Jean Kossaifi",
    "hard coded example",
    "check dims",
    "chain unfolding and folding",
    "Convert to vector and back to tensor",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "We created here a tensor with 3 samples, each sample being similar to X",
    "Test for raveled tensor",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Test for raveled tensor",
    "Test for raveled_tensor=True",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "we created here a tensor with 3 samples, each sample being similar to X",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Equivalence with unfolding",
    "We're not changing anything:",
    "We're missing some modes of the tensor:",
    "We have a duplicate mode",
    "New function renaming old_fun",
    "Old fun will return fun but issue a deprecation warning",
    "Check if the default function is called when the backend is not \"backend\"",
    "Monkeypatch get_backend and check that the specific function is called when backend is \"backend\"",
    "Test using the deprecated function",
    "Test using the new function instead",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Meraj Hashemizadeh <merajhse@mila.quebec>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "License: BSD 3 clause",
    "columns of U, rows of V",
    "rows of V, columns of U",
    "NNDSVD initialization",
    "The leading singular triplet is non-negative",
    "so it can be used as is for initialization.",
    "extract positive and negative parts of column vectors",
    "and their norms",
    "choose update",
    "After this point we no longer need H",
    "Perform power iterations when spectrum decays slowly",
    "Check that matrix is... a matrix!",
    "transpose matrix to keep the reduced matrix shape minimal",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan Tuna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Next line finds mutual peak points",
    "Making it work for 1-dimensional tensors as well",
    "Broadcasting is used to divide rows by 1,2,3...",
    "Added -1 to correspond to a Python index",
    "Scaling",
    "Safety procedure, if columns aren't allow to be zero",
    "Parameters",
    "To avoid singularity error when initial x exists",
    "Start from zeros if solve is not achieved",
    "update support vector if it is necessary",
    "set x to s",
    "gradient update",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "backend = getattr(module, )()",
    "Initialise the backend to the default one",
    "Author: Jean Kossaifi",
    "Check that we did not change the original tensor",
    "Check that we did not change the original tensor",
    "1d Tensor",
    "2d Tensor",
    "Monotone increasing",
    "Monotone decreasing",
    "small test",
    "account for floating point errors: np array have a precision of around 2e-15",
    "check np.finfo(np.float64).eps",
    "Check that we did not change the original tensor",
    "Another test",
    "Test with missing values",
    "Version forming explicitely the khatri-rao product",
    "Efficient sparse-safe version",
    "Equivalence with inner product when contracting with self along all modes",
    "Equivalent to the above expression",
    "Equivalence with n-mode-dot",
    "Multi-mode-dot",
    "Wrong number of modes",
    "size mismatch",
    "Test Batched tensor dot",
    "Check for each sample of the batch-size individually",
    "Test for actual tensordot",
    "Author: Jean Kossaifi",
    "resulting matrix must be of shape (prod(n_rows), n_columns)",
    "fail case: all matrices must have same number of columns",
    "all matrices should be of dim 2...",
    "Classic example/test",
    "A = np.hstack((np.eye(3), np.arange(3)[:, None]))",
    "Test with one matrix only: khatri-rao of one matrix = that matrix",
    "Check that negative dims are made positive",
    "Author: Jean Kossaifi",
    "Mathematical test",
    "Another test",
    "Adding a third matrices",
    "Test for the reverse argument",
    "Check that the original list has not been reversed",
    "Check the returned shape",
    "Khatri-rao is a column-wise kronecker product",
    "Khatri-rao product is a column-wise kronecker product",
    "Test while skipping a matrix",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "For one common mode, equivalent to dot product",
    "For no common mode, equivalent to inner product",
    "Inner product of tensors with different shapes is not defined",
    "tensor times matrix",
    "######################",
    "tensor times vector #",
    "######################",
    "Test with a matrix",
    "Test with a third order tensor",
    "Using equivalence with unfolded expression",
    "########################################",
    "Test for errors that should be raised #",
    "########################################",
    "Same test for the vector case",
    "Cannot take mode product of tensor with tensor",
    "Test using the equivalence with unfolded expression",
    "Test skipping a factor",
    "Test contracting with a vector",
    "result should be a scalar",
    "Average pooling each mode",
    "Order should not matter",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Indices of each matrix",
    "Author: Jean Kossaifi",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "However, it is needed to pop dimensions contracted over",
    "print(i, matrix_or_vec.shape, mode)",
    "print(f'skipping {skip}')",
    "We are contracting over the mode-th dimension",
    "mat_symbol = f'{tensor_modes[mode]}{chr(counter)}'",
    "Contracting mode-th mode with a matrix: new dimension",
    "If fully contracting",
    "matrix_or_vec_list = [m for (i, m) in enumerate(matrix_or_vec_list) if ((skip is None) or (skip != i))]",
    "print(equation, tl.shape(tensor), [tl.shape(f) for f in matrix_or_vec_list])",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "Each core is of shape (rank_left, size_in, size_out, rank_right)",
    "Intertwine the dims",
    "full_shape = in_shape[0], out_shape[0], in_shape[1], ...",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Ideally this should be (), i.e. order-0 tensors",
    "MXNet currently doesn't support this though..",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "Create the tensor algebra dispatching backend and register methods",
    "TODO : add batched_modes as in batched_tensor_dot?",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Prepare to reorganize the modes afterwards by moving bactch size back to their place",
    "(while ommiting modes contracted over)",
    "We will reorganize tensor1 to (batch_modes, new_modes1, contraction_modes)",
    "Tensor2 will be (batch_modes, contraction_modes, new_modes2)",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "Register numpy functions",
    "Register linalg functions",
    "Register tfm functions",
    "Register tnp functions",
    "See https://github.com/tensorly/tensorly/pull/397",
    "and https://github.com/google/jax/issues/3473",
    "return copy.copy(tensor)",
    "handle difference in default axis notation",
    "pytorch does not accept `None` for any keyword arguments. additionally,",
    "pytorch doesn't seems to support keyword arguments in the first place",
    "Currently, gesv doesn't support vectors for matrix2",
    "So we instead solve a least square problem...",
    "Currently, solve doesn't support vectors for matrix2",
    "Register the other functions",
    "PyTorch 1.8.0 has a much better NumPy interface but somoe haven't updated yet",
    "Old version, will be removed in the future",
    "New PyTorch NumPy interface",
    "MXNet doesn't provide an option for full_matrices=True",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "We don't use `functools.wraps` here because some of the dispatched",
    "methods include the backend (`cls`) as a parameter. Instead we manually",
    "copy over the needed information, and filter the signature for `cls`.",
    "If it doesn't have a signature we don't need to remove self",
    "This happens for NumPy (e.g. np.where) where inspect.signature(np.where) errors:",
    "ValueError: no signature found for builtin <built-in function where>",
    "backend = getattr(module, )()",
    "Backend is a string",
    "Initialise the backend to the default one",
    "Swiss",
    "Rectangle",
    "circle: approximate test",
    "Author: Cyrillus Tan, Jackson Chin, Aaron Meyer",
    "License: BSD 3 clause",
    "# PREPROCESSING",
    "Check that both tensors are coupled along the first mode",
    "Check the shape of X and Y; convert vector Y to a matrix",
    "Mean center the data, record info the object",
    "# FITTING EACH COMPONENT",
    "Put iteration results back to the parameter variables",
    "Deflation",
    "Check on the shape of Y",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise modes of W",
    "Regress phi on y: we could call a package here, e.g. scikit-learn",
    "Convergence check",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise each factor of W",
    "Convergence check",
    "Parameter of the experiment",
    "Generate random samples",
    "Authors: Jackson L. Chin, Cyrillus Tan, Aaron Meyer",
    "Supporting Functions",
    "Class Structure Tests",
    "Dimension Compatibility Tests",
    "Decomposition Accuracy Tests",
    "Parameter of the experiment",
    "Generate random samples"
  ],
  "0.7.0": [
    "Ignore already minified files",
    "Ignore already minified files",
    "!/usr/bin/env python3",
    "-*- coding: utf-8 -*-",
    "",
    "tensorly documentation build configuration file",
    "",
    "This file is execfile()d with the current directory set to its",
    "containing dir.",
    "",
    "Note that not all possible configuration values are present in this",
    "autogenerated file.",
    "",
    "All configuration values have a default; values that are commented out",
    "serve to show the default.",
    "If extensions (or modules to document with autodoc) are in another directory,",
    "add these directories to sys.path here. If the directory is relative to the",
    "documentation root, use os.path.abspath to make it absolute, like shown here.",
    "sys.path.insert(0, os.path.abspath('sphinx_ext'))",
    "-- General configuration ------------------------------------------------",
    "If your documentation needs a minimal Sphinx version, state it here.",
    "needs_sphinx = '1.0'",
    "Add any Sphinx extension module names here, as strings. They can be",
    "extensions coming with Sphinx (named 'sphinx.ext.*') or your custom",
    "ones.",
    "'sphinx.ext.imgmath',",
    "path to your examples scripts",
    "path where to save gallery generated examples",
    "Add any paths that contain templates here, relative to this directory.",
    "generate autosummary even if no references",
    "The suffix(es) of source filenames.",
    "You can specify multiple suffix as a list of string:",
    "source_suffix = ['.rst', '.md']",
    "The encoding of source files.",
    "source_encoding = 'utf-8-sig'",
    "The master toctree document.",
    "General information about the project.",
    "The version info for the project you're documenting, acts as replacement for",
    "|version| and |release|, also used in various other places throughout the",
    "built documents.",
    "",
    "The short X.Y version.",
    "version = '0.1'",
    "The full version, including alpha/beta/rc tags.",
    "release = ''",
    "The language for content autogenerated by Sphinx. Refer to documentation",
    "for a list of supported languages.",
    "",
    "This is also used if you do content translation via gettext catalogs.",
    "Usually you set \"language\" from the command line for these cases.",
    "There are two options for replacing |today|: either, you set today to some",
    "non-false value, then it is used:",
    "today = ''",
    "Else, today_fmt is used as the format for a strftime call.",
    "today_fmt = '%B %d, %Y'",
    "List of patterns, relative to source directory, that match files and",
    "directories to ignore when looking for source files.",
    "This patterns also effect to html_static_path and html_extra_path",
    "The reST default role (used for this markup: `text`) to use for all",
    "documents.",
    "default_role = None",
    "If true, '()' will be appended to :func: etc. cross-reference text.",
    "If true, the current module name will be prepended to all description",
    "unit titles (such as .. function::).",
    "If true, sectionauthor and moduleauthor directives will be shown in the",
    "output. They are ignored by default.",
    "show_authors = False",
    "The name of the Pygments (syntax highlighting) style to use.",
    "A list of ignored prefixes for module index sorting.",
    "modindex_common_prefix = []",
    "If true, keep warnings as \"system message\" paragraphs in the built documents.",
    "keep_warnings = False",
    "If true, `todo` and `todoList` produce output, else they produce nothing.",
    "-- Options for HTML output ----------------------------------------------",
    "The theme to use for HTML and HTML Help pages.  See the documentation for",
    "a list of builtin themes.",
    "Add any paths that contain custom themes here, relative to this directory.",
    "html_theme_path = ['themes']",
    "Theme options are theme-specific and customize the look and feel of a theme",
    "further.  For a list of options available for each theme, see the",
    "documentation.",
    "The name for this set of Sphinx documents.",
    "\"<project> v<release> documentation\" by default.",
    "A shorter title for the navigation bar.  Default is the same as html_title.",
    "The name of an image file (relative to this directory) to place at the top",
    "of the sidebar.",
    "The name of an image file (relative to this directory) to use as a favicon of",
    "the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32",
    "pixels large.",
    "html_favicon = None",
    "Add any paths that contain custom static files (such as style sheets) here,",
    "relative to this directory. They are copied after the builtin static files,",
    "so a file named \"default.css\" will overwrite the builtin \"default.css\".",
    "html_additional_pages = {",
    "}",
    "Add any extra paths that contain custom files (such as robots.txt or",
    ".htaccess) here, relative to this directory. These files are copied",
    "directly to the root of the documentation.",
    "html_extra_path = []",
    "If not None, a 'Last updated on:' timestamp is inserted at every page",
    "bottom, using the given strftime format.",
    "The empty string is equivalent to '%b %d, %Y'.",
    "html_last_updated_fmt = None",
    "If true, SmartyPants will be used to convert quotes and dashes to",
    "typographically correct entities.",
    "html_use_smartypants = True",
    "Custom sidebar templates, maps document names to template names.",
    "html_sidebars = {}",
    "Additional templates that should be rendered to pages, maps page names to",
    "template names.",
    "html_additional_pages = {}",
    "If false, no module index is generated.",
    "If false, no index is generated.",
    "If true, the index is split into individual pages for each letter.",
    "html_split_index = False",
    "If true, links to the reST sources are added to the pages.",
    "If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.",
    "If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.",
    "html_show_copyright = True",
    "If true, an OpenSearch description file will be output, and all pages will",
    "contain a <link> tag referring to it.  The value of this option must be the",
    "base URL from which the finished HTML is served.",
    "html_use_opensearch = ''",
    "This is the file name suffix for HTML files (e.g. \".xhtml\").",
    "html_file_suffix = None",
    "Language to be used for generating the HTML full-text search index.",
    "Sphinx supports the following languages:",
    "'da', 'de', 'en', 'es', 'fi', 'fr', 'h', 'it', 'ja'",
    "'nl', 'no', 'pt', 'ro', 'r', 'sv', 'tr', 'zh'",
    "html_search_language = 'en'",
    "A dictionary with options for the search language support, empty by default.",
    "'ja' uses this config value.",
    "'zh' user can custom change `jieba` dictionary path.",
    "html_search_options = {'type': 'default'}",
    "The name of a javascript file (relative to the configuration directory) that",
    "implements a search results scorer. If empty, the default will be used.",
    "html_search_scorer = 'scorer.js'",
    "Output file base name for HTML help builder.",
    "-- Options for LaTeX output ---------------------------------------------",
    "Grouping the document tree into LaTeX files. List of tuples",
    "(source start file, target name, title,",
    "author, documentclass [howto, manual, or own class]).",
    "\\setcounter{MaxMatrixCols}{20} corrects an ugly bug if you try to have a matrix of more than 10 elements or so",
    "We want the same for the html version:",
    "The name of an image file (relative to this directory) to place at the top of",
    "the title page.",
    "latex_logo = None",
    "For \"manual\" documents, if this is true, then toplevel headings are parts,",
    "not chapters.",
    "latex_use_parts = False",
    "If true, show page references after internal links.",
    "If true, show URL addresses after external links.",
    "Documents to append as an appendix to all manuals.",
    "latex_appendices = []",
    "Get completely rid of index",
    "If false, no module index is generated.",
    "latex_domain_indices = True",
    "-- Options for manual page output ---------------------------------------",
    "One entry per manual page. List of tuples",
    "(source start file, name, description, authors, manual section).",
    "If true, show URL addresses after external links.",
    "man_show_urls = False",
    "-- Options for Texinfo output -------------------------------------------",
    "Grouping the document tree into Texinfo files. List of tuples",
    "(source start file, target name, title, author,",
    "dir menu entry, description, category)",
    "Documents to append as an appendix to all manuals.",
    "texinfo_appendices = []",
    "If false, no module index is generated.",
    "texinfo_domain_indices = True",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "texinfo_show_urls = 'footnote'",
    "If true, do not generate a @detailmenu in the \"Top\" node's menu.",
    "texinfo_no_detailmenu = False",
    "-- Options for Epub output ----------------------------------------------",
    "Bibliographic Dublin Core info.",
    "The basename for the epub file. It defaults to the project name.",
    "epub_basename = project",
    "The HTML theme for the epub output. Since the default themes are not",
    "optimized for small screen space, using the same theme for HTML and epub",
    "output is usually not wise. This defaults to 'epub', a theme designed to save",
    "visual space.",
    "epub_theme = 'epub'",
    "The language of the text. It defaults to the language option",
    "or 'en' if the language is not set.",
    "epub_language = ''",
    "The scheme of the identifier. Typical schemes are ISBN or URL.",
    "epub_scheme = ''",
    "The unique identifier of the text. This can be a ISBN number",
    "or the project homepage.",
    "epub_identifier = ''",
    "A unique identification for the text.",
    "epub_uid = ''",
    "A tuple containing the cover image and cover page html template filenames.",
    "epub_cover = ()",
    "A sequence of (type, uri, title) tuples for the guide element of content.opf.",
    "epub_guide = ()",
    "HTML files that should be inserted before the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_pre_files = []",
    "HTML files that should be inserted after the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_post_files = []",
    "A list of files that should not be packed into the epub file.",
    "The depth of the table of contents in toc.ncx.",
    "epub_tocdepth = 3",
    "Allow duplicate toc entries.",
    "epub_tocdup = True",
    "Choose between 'default' and 'includehidden'.",
    "epub_tocscope = 'default'",
    "Fix unsupported image types using the Pillow.",
    "epub_fix_images = False",
    "Scale large images.",
    "epub_max_image_width = 0",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "epub_show_urls = 'inline'",
    "If false, no index is generated.",
    "epub_use_index = True",
    "-*- coding: utf-8 -*-",
    "Created: Sun May 21 20:38:59 2017",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Created Sun Nov 27 14:03:07 2016",
    "Author: \u00d3scar N\u00e1jera",
    "can't use codecs.open(filename, 'r', 'utf-8') here b/c ast doesn't",
    "seem to work with unicode strings in Python2.7",
    "\"SyntaxError: encoding declaration in Unicode string\"",
    "change from Windows format to UNIX for uniformity",
    "This get the content of the file after the docstring last line",
    "Note: 'maxsplit' argument is not a keyword argument in python2",
    "sphinx_gallery_<name> = <value>",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "Try Python 3 first, otherwise load from Python 2",
    "This is a.b, not e.g. a().b",
    "need to get a in a().b",
    "Join import path to relative path",
    "Find out what the real object is supposed to be.",
    "Ensure shortened object is the same as what we expect.",
    "get the last working module name",
    "name is as written in file (e.g. np.asarray)",
    "full_name includes resolved import path (e.g. numpy.asarray)",
    "module without attribute. This is not useful for",
    "backreferences",
    "get shortened module name",
    "Inside rst files forward slash defines paths",
    "-*- coding: utf-8 -*-",
    "This gets set when the extension is initialized.",
    "colorfunc is a valid kwarg in 1.5, but not older, so we just",
    "apply it ourselves.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "shelve keys need to be str in python 2",
    "value is a list",
    "try to convert elements to int",
    "value is another dictionary",
    "Make sure searchindex uses UTF-8 encoding",
    "parse objects",
    "parse filenames",
    "detect if we are using relative links on a Windows system",
    "download and initialize the search index",
    "In 1.5+ Sphinx seems to have changed from .rst.html to only",
    ".html extension in converted files. But URLs could be",
    "built with < 1.5 or >= 1.5 regardless of what we're currently",
    "building with, so let's just check both :(",
    "test if cobj appears in page",
    "we don't have it cached",
    "cache it for the future",
    "failed to resolve",
    "replace '\\' with '/' so it on the web",
    "for some reason, the relative link goes one directory too high up",
    "Add resolvers for the packages for which we want to show links",
    "patterns for replacement",
    "This could be turned into a generator if necessary, but should be okay",
    "we have a pickle file with the objects to embed links for",
    "generate replacement strings with the links",
    "do the replacement in the html file",
    "ensure greediness",
    "No need to waste time embedding hyperlinks when not running the examples",
    "XXX: also at the time of writing this fixes make html-noplot",
    "for some reason I don't fully understand",
    "XXX: Whitelist of builders for which it makes sense to embed",
    "hyperlinks inside the example html. Note that the link embedding",
    "require searchindex.js to exist for the links to the local doc",
    "and there does not seem to be a good way of knowing which",
    "builders creates a searchindex.js.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "##############################################################################",
    "Notebook shell utility",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "build options",
    "Sphinx hack: sphinx copies generated images to the build directory",
    "each time the docs are made.  If the desired image name already",
    "exists, it appends a digit to prevent overwrites.  The problem is,",
    "the directory is never cleared.  This means that each time you build",
    "the docs, the number of images in the directory grows.",
    "",
    "This question has been asked on the sphinx development list, but there",
    "was no response: https://git.net/ml/sphinx-dev/2011-02/msg00123.html",
    "",
    "The following is a hack that prevents this behavior by clearing the",
    "image build directory from gallery images each time the docs are built.",
    "If sphinx changes their layout between versions, this will not",
    "work (though it should probably not cause a crash).",
    "Tested successfully on Sphinx 1.0.7",
    "this assures I can call the config in other places",
    "Here we don't use an os.walk, but we recurse only twice: flat is",
    "better than nested.",
    "we create an index.rst with all examples",
    ":orphan: to suppress \"not included in TOCTREE\" sphinx warnings",
    "touch file",
    "Under no-plot Examples are not run so nothing to summarize",
    "Sphinx < 1.6 calls it `_extensions`, >= 1.6 is `extensions`.",
    "HACK: Stop nosetests running setup() above",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Don't use unicode_literals here (be explicit with u\"...\" instead) otherwise",
    "tricky errors come up with exec(code_blocks, ...) calls",
    "Try Python 2 first, otherwise load from Python 3",
    "textwrap indent only exists in python 3",
    "make sure that the Agg backend is set before importing any",
    "matplotlib",
    "##############################################################################",
    "##############################################################################",
    "The following strings are used when we have several pictures: we use",
    "an html div tag that our CSS uses to turn the lists into horizontal",
    "lists.",
    "This one could contain unicode",
    "Sphinx only starts numbering from the first non-empty line.",
    "lstrip is just in case docstring has a '\\n\\n' at the beginning",
    "Set the fig_num figure as the current figure as we can't",
    "save a figure that's not the current figure.",
    "make sure the image is not too large",
    "local import to avoid testing dependency on PIL:",
    "resize the image",
    "insert centered",
    "Use optipng to perform lossless compression on the resized image if",
    "software is installed",
    "read specification of the figure to display as thumbnail from main text",
    "create something to replace the thumbnail",
    "Add empty lines to avoid bug in issue #165",
    "sort to have the smallest entries in the beginning",
    "clear at the end of the section",
    "Remove our code from traceback:",
    "Remove one extra level through ast.parse.",
    "Breaks build on first example error",
    "Stores failing file",
    "If example is not suitable to run, skip executing its blocks",
    "Redirect output to stdout and",
    "First cd in the original example dir, so that any file",
    "created by the example get created in this directory",
    "don't use unicode_literals at the top of this file or you get",
    "nasty errors here on Py2.7",
    "Horrible code to 'unload' seaborn, so that it resets",
    "its default when is load",
    "Python does not support unloading of modules",
    "https://bugs.python.org/issue9072",
    "Reset Matplotlib to default",
    "A lot of examples contains 'print(__doc__)' for example in",
    "scikit-learn so that running the example prints some useful",
    "information. Because the docstring has been separated from",
    "the code blocks in sphinx-gallery, __doc__ is actually",
    "__builtin__.__doc__ in the execution context and we do not",
    "want to print it",
    "Examples may contain if __name__ == '__main__' guards",
    "for in example scikit-learn if the example uses multiprocessing",
    "Don't ever support __file__: Issues #166 #212",
    "A simple example has two blocks: one for the",
    "example introduction/explanation and one for the code",
    "We want to run the example without arguments. See",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/252",
    "for more details.",
    "Add some vertical space after output",
    "Writes md5 checksum if example has build correctly",
    "not failed and was initially meant to run(no-plot shall not cache md5sum)",
    "-*- coding: utf-8 -*-",
    "Error + critical both go through warning:",
    "-*- coding: utf-8 -*-",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Need to import gen_rst before matplotlib.pyplot to set backend to 'Agg'",
    "For more details see",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/49",
    "verify correct md5sum",
    "False because is a new file",
    "Write md5sum to file to check is current",
    "read rst file and check if it contains traceback output",
    "create three files in tempdir (only one matches the pattern)",
    "generate rst file",
    "read rst file and check if it contains code output",
    "which plot to show as the thumbnail image",
    "test issue #229",
    "TODO: test that broken thumbnail does appear when needed",
    "TODO: test that examples are not executed twice",
    "TODO: test that examples are executed after a no-plot and produce",
    "the correct image in the thumbnail",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "recovers data from temporary file and caches it in the shelve",
    "tests recovered data matches",
    "test if cached data is available after temporary file has vanished",
    "shelve keys need to be str in python 2, deal with unicode input",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "General information about the project.",
    "no duplicate values allowed The config is present already",
    "General information about the project.",
    "General information about the project.",
    "General information about the project.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Test fails on wrong input",
    "Test missing folder",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "##############################################################################",
    "Notebook shell utility",
    "replace reference numbers so that there are no duplicates",
    "Strip top title",
    "call function to replace reference numbers so that there are no",
    "duplicates",
    "Do not try to inspect classes that don't define `__init__`",
    "Extra mangling domains",
    "------------------------------------------------------------------------------",
    "Docstring-mangling domains",
    "------------------------------------------------------------------------------",
    "go to next non-empty line in old:",
    "line.strip() checks whether the string is all whitespace",
    "------------------------------------------------------------------------------",
    "Registration hook",
    "------------------------------------------------------------------------------",
    "------------------------------------------------------------------------------",
    "plot:: directive",
    "------------------------------------------------------------------------------",
    "no argument given, assume used as a flag",
    "------------------------------------------------------------------------------",
    "Generating output",
    "------------------------------------------------------------------------------",
    "Sphinx depends on either Jinja or Jinja2",
    "determine input",
    "ensure that LaTeX includegraphics doesn't choke in foo.bar.pdf filenames",
    "is it in doctest format?",
    "determine output directory name fragment",
    "build_dir: where to place output files (temporarily)",
    "output_dir: final location in the builder's directory",
    "how to link to files from the RST file",
    "make figures",
    "generate output restructuredtext",
    "copy image files to builder's output directory",
    "copy script (if necessary)",
    "------------------------------------------------------------------------------",
    "Run code and capture figures",
    "------------------------------------------------------------------------------",
    "check if it's valid Python as-is",
    "Change the working directory to the directory of the example, so",
    "it can get at its data files, if any.",
    "Redirect stdout",
    "Reset sys.argv",
    "------------------------------------------------------------------------------",
    "Generating figures",
    "------------------------------------------------------------------------------",
    "-- Parse format list",
    "-- Try to determine if all images already exist",
    "Look for single-figure output files first",
    "Then look for multi-figure output files",
    "assume that if we have one, we have them all",
    "-- We didn't find the files, so build them",
    "Clear between runs",
    "Run code",
    "Collect images",
    "Results",
    "------------------------------------------------------------------------------",
    "Relative pathnames",
    "------------------------------------------------------------------------------",
    "Copied from Python 2.7",
    "Work out how much of the filepath is shared by start and path.",
    "Work out how much of the filepath is shared by start and path.",
    "If several signatures present, take the last one",
    "We could do more tests, but we are not. Arbitrarily.",
    "string conversion routines",
    "try to read signature, backward compat for older Python",
    "########################################################################",
    "object interface.",
    "########################################################################",
    "########################################################################",
    "Unparser private interface.",
    "########################################################################",
    "## format, output, and dispatch methods ################################",
    "########################################################################",
    "compiler.ast unparsing methods.",
    "",
    "There should be one method per concrete grammar type. They are",
    "organized in alphabetical order.",
    "########################################################################",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "fixme: Are From and ImportFrom handled differently?",
    "if t.step:",
    "self._write(\":\")",
    "self._dispatch(t.step)",
    "Empty tuple.",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "Check if parenthesis are needed on left side and then dispatch",
    "Write the appropriate symbol for operator",
    "Check if parenthesis are needed on the right side and then dispatch",
    "if t is 0.1, str(t)->'0.1' while repr(t)->'0.1000000000001'",
    "We prefer str here.",
    "########################################################################",
    "These are the methods from the _ast modules unparse.",
    "",
    "As our needs to handle more advanced code increase, we may want to",
    "modify some of the methods below so that they work for compiler.ast.",
    "########################################################################",
    "# stmt",
    "def _Expr(self, tree):",
    "self._fill()",
    "self._dispatch(tree.value)",
    "",
    "def _Import(self, t):",
    "self._fill(\"import \")",
    "first = True",
    "for a in t.names:",
    "if first:",
    "first = False",
    "else:",
    "self._write(\", \")",
    "self._write(a.name)",
    "if a.asname:",
    "self._write(\" as \"+a.asname)",
    "",
    "#    def _ImportFrom(self, t):",
    "#        self._fill(\"from \")",
    "#        self._write(t.module)",
    "#        self._write(\" import \")",
    "#        for i, a in enumerate(t.names):",
    "#            if i == 0:",
    "#                self._write(\", \")",
    "#            self._write(a.name)",
    "#            if a.asname:",
    "#                self._write(\" as \"+a.asname)",
    "#        # XXX(jpe) what is level for?",
    "#",
    "",
    "def _Break(self, t):",
    "self._fill(\"break\")",
    "",
    "def _Continue(self, t):",
    "self._fill(\"continue\")",
    "",
    "def _Delete(self, t):",
    "self._fill(\"del \")",
    "self._dispatch(t.targets)",
    "",
    "def _Assert(self, t):",
    "self._fill(\"assert \")",
    "self._dispatch(t.test)",
    "if t.msg:",
    "self._write(\", \")",
    "self._dispatch(t.msg)",
    "",
    "def _Exec(self, t):",
    "self._fill(\"exec \")",
    "self._dispatch(t.body)",
    "if t.globals:",
    "self._write(\" in \")",
    "self._dispatch(t.globals)",
    "if t.locals:",
    "self._write(\", \")",
    "self._dispatch(t.locals)",
    "",
    "def _Print(self, t):",
    "self._fill(\"print \")",
    "do_comma = False",
    "if t.dest:",
    "self._write(\">>\")",
    "self._dispatch(t.dest)",
    "do_comma = True",
    "for e in t.values:",
    "if do_comma:self._write(\", \")",
    "else:do_comma=True",
    "self._dispatch(e)",
    "if not t.nl:",
    "self._write(\",\")",
    "",
    "def _Global(self, t):",
    "self._fill(\"global\")",
    "for i, n in enumerate(t.names):",
    "if i != 0:",
    "self._write(\",\")",
    "self._write(\" \" + n)",
    "",
    "def _Yield(self, t):",
    "self._fill(\"yield\")",
    "if t.value:",
    "self._write(\" (\")",
    "self._dispatch(t.value)",
    "self._write(\")\")",
    "",
    "def _Raise(self, t):",
    "self._fill('raise ')",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.inst:",
    "self._write(\", \")",
    "self._dispatch(t.inst)",
    "if t.tback:",
    "self._write(\", \")",
    "self._dispatch(t.tback)",
    "",
    "",
    "def _TryFinally(self, t):",
    "self._fill(\"try\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "self._fill(\"finally\")",
    "self._enter()",
    "self._dispatch(t.finalbody)",
    "self._leave()",
    "",
    "def _excepthandler(self, t):",
    "self._fill(\"except \")",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.name:",
    "self._write(\", \")",
    "self._dispatch(t.name)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _ClassDef(self, t):",
    "self._write(\"\\n\")",
    "self._fill(\"class \"+t.name)",
    "if t.bases:",
    "self._write(\"(\")",
    "for a in t.bases:",
    "self._dispatch(a)",
    "self._write(\", \")",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _FunctionDef(self, t):",
    "self._write(\"\\n\")",
    "for deco in t.decorators:",
    "self._fill(\"@\")",
    "self._dispatch(deco)",
    "self._fill(\"def \"+t.name + \"(\")",
    "self._dispatch(t.args)",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _For(self, t):",
    "self._fill(\"for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "def _While(self, t):",
    "self._fill(\"while \")",
    "self._dispatch(t.test)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "# expr",
    "def _Str(self, tree):",
    "self._write(repr(tree.s))",
    "#",
    "def _Repr(self, t):",
    "self._write(\"`\")",
    "self._dispatch(t.value)",
    "self._write(\"`\")",
    "",
    "def _Num(self, t):",
    "self._write(repr(t.n))",
    "",
    "def _ListComp(self, t):",
    "self._write(\"[\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\"]\")",
    "",
    "def _GeneratorExp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\")\")",
    "",
    "def _comprehension(self, t):",
    "self._write(\" for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "for if_clause in t.ifs:",
    "self._write(\" if \")",
    "self._dispatch(if_clause)",
    "",
    "def _IfExp(self, t):",
    "self._dispatch(t.body)",
    "self._write(\" if \")",
    "self._dispatch(t.test)",
    "if t.orelse:",
    "self._write(\" else \")",
    "self._dispatch(t.orelse)",
    "",
    "unop = {\"Invert\":\"~\", \"Not\": \"not\", \"UAdd\":\"+\", \"USub\":\"-\"}",
    "def _UnaryOp(self, t):",
    "self._write(self.unop[t.op.__class__.__name__])",
    "self._write(\"(\")",
    "self._dispatch(t.operand)",
    "self._write(\")\")",
    "",
    "binop = { \"Add\":\"+\", \"Sub\":\"-\", \"Mult\":\"*\", \"Div\":\"/\", \"Mod\":\"%\",",
    "\"LShift\":\">>\", \"RShift\":\"<<\", \"BitOr\":\"|\", \"BitXor\":\"^\", \"BitAnd\":\"&\",",
    "\"FloorDiv\":\"//\", \"Pow\": \"**\"}",
    "def _BinOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.left)",
    "self._write(\")\" + self.binop[t.op.__class__.__name__] + \"(\")",
    "self._dispatch(t.right)",
    "self._write(\")\")",
    "",
    "boolops = {_ast.And: 'and', _ast.Or: 'or'}",
    "def _BoolOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.values[0])",
    "for v in t.values[1:]:",
    "self._write(\" %s \" % self.boolops[t.op.__class__])",
    "self._dispatch(v)",
    "self._write(\")\")",
    "",
    "def _Attribute(self,t):",
    "self._dispatch(t.value)",
    "self._write(\".\")",
    "self._write(t.attr)",
    "",
    "#    def _Call(self, t):",
    "#        self._dispatch(t.func)",
    "#        self._write(\"(\")",
    "#        comma = False",
    "#        for e in t.args:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        for e in t.keywords:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        if t.starargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"*\")",
    "#            self._dispatch(t.starargs)",
    "#        if t.kwargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"**\")",
    "#            self._dispatch(t.kwargs)",
    "#        self._write(\")\")",
    "",
    "# slice",
    "def _Index(self, t):",
    "self._dispatch(t.value)",
    "",
    "def _ExtSlice(self, t):",
    "for i, d in enumerate(t.dims):",
    "if i != 0:",
    "self._write(': ')",
    "self._dispatch(d)",
    "",
    "# others",
    "def _arguments(self, t):",
    "first = True",
    "nonDef = len(t.args)-len(t.defaults)",
    "for a in t.args[0:nonDef]:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a)",
    "for a,d in zip(t.args[nonDef:], t.defaults):",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a),",
    "self._write(\"=\")",
    "self._dispatch(d)",
    "if t.vararg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"*\"+t.vararg)",
    "if t.kwarg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"**\"+t.kwarg)",
    "",
    "#    def _keyword(self, t):",
    "#        self._write(t.arg)",
    "#        self._write(\"=\")",
    "#        self._dispatch(t.value)",
    "",
    "def _Lambda(self, t):",
    "self._write(\"lambda \")",
    "self._dispatch(t.args)",
    "self._write(\": \")",
    "self._dispatch(t.body)",
    "int : The first line number in the block. 1-indexed.",
    "int : The last line number. Inclusive!",
    "str : The text block including '#' character but not any leading spaces.",
    "Only add if not entirely whitespace.",
    "Start with a dummy.",
    "All of the blocks seen so far.",
    "The index mapping lines of code to their associated comment blocks.",
    "Oops! Trailing comment, not a comment block.",
    "A comment block.",
    "FIXME: gracefully handle errors here or in the caller?",
    "FIXME: handle other kinds of assignments?",
    "string conversion routines",
    "Check if the referenced member can have a docstring or not",
    "Referenced object has a docstring",
    "Latex collects all references to a separate bibliography,",
    "so we need to insert links to it",
    "-*- coding: utf-8 -*-",
    "Convert signode to a specified format",
    "Call user code to resolve the link",
    "no source",
    "only one link per name, please",
    "------------------------------------------------------------------------------",
    "Creating 'phantom' modules from an XML description",
    "------------------------------------------------------------------------------",
    "Sort items so that",
    "- Base classes come before classes inherited from them",
    "- Modules come before their contents",
    "Create phantom items",
    "create parent, if missing",
    "create object",
    "Populate items",
    "-*- coding: utf-8 -*-",
    "##########################################################################",
    "A tensor is simply a numpy array",
    "##########################################################################",
    "Unfolding a tensor is easy",
    "##########################################################################",
    "Re-folding the tensor is as easy:",
    "-*- coding: utf-8 -*-",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor that follows the PARAFAC2 constraints found",
    "inx `(Kiers et al 1999)`_.",
    "",
    "This particular tensor,",
    ":math:`\\mathcal{X}\u00a0\\in \\mathbb{R}^{I\\times J \\times K}`, is a shifted",
    "CP tensor, that is, a tensor on the form:",
    "",
    ".. math::",
    "\\mathcal{X}_{ijk} = \\sum_{r=1}^R A_{ir} B_{\\sigma_i(j) r} C_{kr},",
    "",
    "where :math:`\\sigma_i`\u00a0is a cyclic permutation of :math:`J` elements.",
    "Set parameters",
    "Generate random matrices",
    "Normalised factor matrices",
    "Generate the shifted factor matrix",
    "Construct the tensor",
    "Add noise",
    "#############################################################################",
    "Fit a PARAFAC2 tensor",
    "---------------------",
    "To avoid local minima, we initialise and fit 10 models and choose the one",
    "with the lowest error",
    "#############################################################################",
    "A decomposition is a wrapper object for three variables: the *weights*,",
    "the *factor matrices* and the *projection matrices*. The weights are similar",
    "to the output of a CP decomposition. The factor matrices and projection",
    "matrices are somewhat different. For a CP decomposition, we only have the",
    "weights and the factor matrices. However, since the PARAFAC2 factor matrices",
    "for the second mode is given by",
    "",
    ".. math::",
    "B_i = P_i B,",
    "",
    "where :math:`B` is an :math:`R \\times R` matrix and :math:`P_i` is an",
    ":math:`I \\times R` projection matrix, we cannot store the factor matrices",
    "the same as for a CP decomposition.",
    "",
    "Instead, we store the factor matrix along the first mode (:math:`A`), the",
    "\"blueprint\" matrix for the second mode (:math:`B`) and the factor matrix",
    "along the third mode (:math:`C`) in one tuple and the projection matrices,",
    ":math:`P_i`, in a separate tuple.",
    "",
    "If we wish to extract the informative :math:`B_i` factor matrices, then we",
    "use the ``tensorly.parafac2_tensor.apply_projection_matrices`` function on",
    "the PARAFAC2 tensor instance to get another wrapper object for two",
    "variables: *weights* and *factor matrices*. However, now, the second element",
    "of the factor matrices tuple is now a list of factor matrices, one for each",
    "frontal slice of the tensor.",
    "",
    "Likewise, if we wish to construct the tensor or the frontal slices, then we",
    "can use the ``tensorly.parafac2_tensor.parafac2_to_tensor`` function. If the",
    "decomposed dataset consisted of uneven-length frontal slices, then we can",
    "use the ``tensorly.parafac2_tensor.parafac2_to_slices`` function to get a",
    "list of frontal slices.",
    "#############################################################################",
    "Compute performance metrics",
    "---------------------------",
    "To evaluate how well the original structure is recovered, we calculate the tucker congruence coefficient.",
    "#############################################################################",
    "Visualize the components",
    "------------------------",
    "Find the best permutation so that we can plot the estimated components on top of the true components",
    "Create plots of each component vector for each mode",
    "(We just look at one of the B_i matrices)",
    "Plot true and estimated components for mode A",
    "Labels for the different components",
    "Plot true and estimated components for mode C",
    "Plot true components for mode B",
    "Get the signs so that we can flip the B mode factor matrices",
    "Plot estimated components for mode B (after sign correction)",
    "Titles for the different modes",
    "Create a legend for the entire figure",
    "#############################################################################",
    "Inspect the convergence rate",
    "----------------------------",
    "It can be interesting to look at the loss plot to make sure that we have",
    "converged to a stationary point. We skip the first iteration since the",
    "initial loss often dominate the rest of the plot, making it difficult",
    "to check for convergence.",
    "#############################################################################",
    "References",
    "----------",
    "",
    ".. _(Kiers et al 1999):",
    "",
    "Kiers HA, Ten Berge JM, Bro R. *PARAFAC2\u2014Part I.",
    "A direct fitting algorithm for the PARAFAC2 model.*",
    "**Journal of Chemometrics: A Journal of the Chemometrics Society.**",
    "1999 May;13(3\u20104):275-94. `(Online version)",
    "<https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-128X(199905/08)13:3/4%3C275::AID-CEM543%3E3.0.CO;2-B>`_",
    "Rank of the CP decomposition",
    "Rank of the Tucker decomposition",
    "Perform the CP decomposition",
    "Reconstruct the image from the factors",
    "Tucker decomposition",
    "Plotting the original and reconstruction from the decompositions",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, several options are available to compute",
    "non-negative CP (NCP), in particular several",
    "algorithms:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that factors must have only non-negative values after it is",
    "obtained from a non-negative tensor.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random from the sequence of integers from 1 to 24000.",
    "Tensor generation",
    "#############################################################################",
    "Our goal here is to produce an approximation of the tensor generated above",
    "which follows a low-rank CP model, with non-negative coefficients. Before",
    "using these algorithms, we can use Tensorly to produce a good initial guess",
    "for our NCP. In fact, in order to compare both algorithmic options in a",
    "fair way, it is a good idea to use same initialized factors in decomposition",
    "algorithms. We make use of the ``initialize_cp`` function to initialize the",
    "factors of the NCP, and transform these factors (and factors weights) into",
    "an instance of the CPTensor class:",
    "#############################################################################",
    "Non-negative Parafac",
    "-----------------------",
    "From now on, we can use the same ``cp_init`` tensor as the initial tensor when",
    "we use decomposition functions. Now let us first use the algorithm based on",
    "Multiplicative Update, which can be called as follows:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the cp_to_tensor function. The tensor cp_reconstruction_mu is therefore a",
    "low-rank non-negative approximation of the input tensor; looking at the",
    "first few values of both tensors shows that this is indeed",
    "the case but the approximation is quite coarse.",
    "#############################################################################",
    "Non-negative Parafac with HALS",
    "------------------------------",
    "Our second (new) option to compute NCP is the HALS algorithm, which can be",
    "used as follows:",
    "#############################################################################",
    "Again, we can look at the reconstructed tensor entries.",
    "#############################################################################",
    "Non-negative Parafac with Exact HALS",
    "------------------------------------",
    "From only looking at a few entries of the reconstructed tensors, we can",
    "already see a huge gap between HALS and MU outputs.",
    "Additionally, HALS algorithm has an option for exact solution to the non-negative",
    "least squares subproblem rather than the faster, approximate solution.",
    "Note that the overall HALS algorithm will still provide an approximation of",
    "the input data, but will need longer to reach convergence.",
    "Exact subroutine solution option can be used simply choosing exact as True",
    "in the function:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "First comparison option is processing time for each algorithm:",
    "#############################################################################",
    "As it is expected, the exact solution takes much longer than the approximate",
    "solution, while the gain in performance is often void. Therefore we recommend",
    "to avoid this option unless it is specifically required by the application.",
    "Also note that on appearance, both MU and HALS have similar runtimes.",
    "However, a closer look suggest they are indeed behaving quite differently.",
    "Computing the error between the output and the input tensor tells that story better.",
    "In Tensorly, we provide a function to calculate Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both exact and approximate solution. In particular, HALS converged to a",
    "much lower reconstruction error than MU. We can better appreciate the difference",
    "in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases (only",
    "encountered by expert users most likely).",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105. (Link)",
    "<https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>",
    "#############################################################################",
    "Introduction",
    "-----------------------",
    "Since version 0.6 in Tensorly, two algorithms are available to compute non-negative",
    "Tucker decomposition:",
    "",
    "1. Multiplicative updates (MU) (already in Tensorly < 0.6)",
    "2. Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)",
    "",
    "Non-negativity is an important constraint to handle for tensor decompositions.",
    "One could expect that core and factors must have only non-negative values after",
    "it is obtained from a non-negative tensor. Tucker decomposition includes core",
    "(:math:`G`) and factors (:math:`A`, :math:`B`, :math:`C`).",
    "",
    ".. math::",
    "T = [| G; A, B , C |],",
    "",
    "We need to solve the following problem for each factor (e.g. factor :math:`A` here):",
    "",
    ".. math::",
    "\\min_{A \\geq 0} ||T_{[1]} - A\\times G_{[1]}(B\\times C)^T||_F^2,",
    "",
    "Here, :math:`G_{[i]}` represents ith mode unfolding of the core. To update",
    "the core, we need the solve following problem:",
    "",
    ".. math::",
    "\\min_{g \\geq 0} ||t -   (A\\times B \\times C)\\times g ||_F^2,",
    "",
    "where :math:`t` and :math:`g` are the vectorized data tensor :math:`T` and core :math:`G`.",
    "#############################################################################",
    "To update the factors, we will use HALS and to update the core, we have two",
    "different algorithms Active Set (AS) and Fast Iterative Shrinkage-Thresholding",
    "Algorithm (FISTA) in Tensorly. While FISTA is an accelerated gradient method for",
    "non-negative or unconstrained problems, AS is the widely used non-negative",
    "least square solution proposed by Lawson and Hanson in 1974. Both algorithms",
    "return non-negative core and FISTA is the default algorithm for HALS Tucker",
    "decomposition in Tensorly.",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "There are several ways to create a tensor with non-negative entries in Tensorly.",
    "Here we chose to generate a random tensor from the sequence of integers from",
    "1 to 1000.",
    "tensor generation",
    "#############################################################################",
    "Non-negative Tucker",
    "-----------------------",
    "First, multiplicative update can be implemented as:",
    "#############################################################################",
    "Here, we also compute the output tensor from the decomposed factors by using",
    "the ``tucker_to_tensor`` function. The tensor ``tucker_reconstruction_mu`` is",
    "therefore a low-rank non-negative approximation of the input tensor ``tensor``.",
    "#############################################################################",
    "Non-negative Tucker with HALS and FISTA",
    "---------------------------------------",
    "HALS algorithm with FISTA can be calculated as:",
    "#############################################################################",
    "Non-negative Tucker with HALS and Active Set",
    "--------------------------------------------",
    "As a second option, HALS algorithm with Active Set can be called as follows:",
    "#############################################################################",
    "Comparison",
    "-----------------------",
    "To compare the various methods, first we may look at each algorithm",
    "processing time:",
    "#############################################################################",
    "All algorithms should run with about the same number of iterations on our",
    "example, so at first glance the MU algorithm is faster (i.e. has lower",
    "per-iteration complexity). A second way to compare methods is to compute",
    "the error between the output and input tensor. In Tensorly, there is a function",
    "to compute Root Mean Square Error (RMSE):",
    "#############################################################################",
    "According to the RMSE results, HALS is better than the multiplicative update",
    "with both FISTA and active set core update options. We can better appreciate",
    "the difference in convergence speed on the following error per iteration plot:",
    "#############################################################################",
    "In conclusion, on this quick test, it appears that the HALS algorithm gives",
    "much better results than the MU original Tensorly methods. Our recommendation",
    "is to use HALS as a default, and only resort to MU in specific cases",
    "(only encountered by expert users most likely). Besides, in this experiment",
    "FISTA and active set give very similar results, however active set may last",
    "longer when it is used with higher ranks according to our experience.",
    "Therefore, we recommend to use FISTA with high rank decomposition.",
    "#############################################################################",
    "References",
    "----------",
    "",
    "Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and",
    "hierarchical ALS algorithms for nonnegative matrix factorization.",
    "Neural computation, 24(4), 1085-1105. (Link)",
    "<https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and>",
    "Get a high-accuracy decomposition for comparison",
    "Run PARAFAC decomposition without line search and time",
    "Run PARAFAC decomposition with line search and time",
    "Calculate the error of both decompositions",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Should we allow None weights?",
    "it's already been validated at creation",
    "if len(factors) < 2:",
    "raise ValueError('A CP tensor should be composed of at least two factors.'",
    "'However, {} factor was given.'.format(len(factors)))",
    "Skip the target mode",
    "Calculate the sign of the current factor in each component",
    "Update both the current and receiving factor",
    "Check the weight signs",
    "Test for the validity of the operation",
    "norm = T.dot(T.dot(weights, norm), weights)",
    "We sum even if weigths is not None",
    "as e.g. MXNet would return a 1D tensor, not a 0D tensor",
    "Deprecated classes and functions",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Check user input for potential errors",
    "Check first and last rank",
    "Will raise an error if invalid",
    "Note how tt_matrix_to_tensor is implemented in tenalg to allow for more efficient implementations",
    "(e.g. using the einsum backend)",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Test for the validity of the operation",
    "rank is 'same' or float: choose rank so as to preserve a fraction of the original #parameters",
    "sorted to be careful with the order when popping and reinserting to not remove/add at wrong index.",
    "list (mode, shape) that we removed as they will be kept the same, rank[i] =",
    "number of parameters coming from the fixed modes (these don't have a variable size as a fun of fraction_param)",
    "Doesn't contain fixed_modes, those factors are accounted for in fixed_params",
    "it's already been validated at creation",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Border rank of 1, R_0 = R_N = 1",
    "First and last factor of size I_0 R and I_N R",
    "We want the number of params of decomp (=sum of params of factors)",
    "To be equal to c = \\prod_k I_k",
    "We get the non-negative solution",
    "Choose a rank proportional to the size of each mode",
    "The method is similar to the above one for constant_rank == True",
    "We get the non-negative solution",
    "Check user input for potential errors",
    "Initialization",
    "Will raise an error if invalid",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "it's already been validated at creation",
    "Skip first factor matrix since the rank is extracted from it.",
    "allocate variables for weights, and normalized factors",
    "if (not copy) and (weights is None):",
    "warnings.warn('Provided copy=False and weights=None: a new Parafac2Tensor'",
    "'with new weights and factors normalised inplace will be returned.')",
    "weights = T.ones(rank, **T.context(factors[0]))",
    "The if test below was added to enable inplace edits",
    "however, TensorFlow does not support inplace edits",
    "so this is always set to True",
    "backend_context,",
    "backend_manager,",
    "_get_backend_dir, _get_backend_method,",
    "from . import backend as backend_manager",
    "Deprecated",
    "Add Backend functions, dynamically dispatched",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__,",
    "backend_manager.__getattribute__,",
    "full_dir)",
    "# override_module_dispatch(__name__, _get_backend_method, full_dir)",
    "del override_module_dispatch, full_dir#, _get_backend_method",
    "Authors: Isabell Lehmann <isabell.lehmann94@outlook.de>",
    "License: BSD 3 clause",
    "initialize values",
    "alternating least squares",
    "note that the order of the khatri rao product is reversed since tl.unfold has another order",
    "than assumed in paper",
    "Loop over modes of the tensor",
    "If we are at the coupled mode, concat the matrix",
    "Getting the TT factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TT factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "A TTM with a single factor is just a matrix...",
    "Change order",
    "Getting the first factor",
    "SVD of unfolding matrix",
    "Get first TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the TR factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TR factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "Reorder factors to match input",
    "A list of candidates for each mode",
    "Refine the init",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "If nn_modes is set, we use HALS, otherwise, we use the standard parafac implementation.",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "TODO: this is a hack but it seems to do the job for now",
    "TODO: Test this",
    "If we have to update the mask we already have to build the full tensor",
    "Update the tensor based on the mask",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Will we be performing a line search iteration",
    "Calculate the current unnormalized error if we need it",
    "Start line search if requested.",
    "For each matrix, randomly choose n_samples indices for which to compute the khatri-rao product",
    "Compute corresponding rows of the full khatri-rao product",
    "Compute the Khatri-Rao product for the chosen indices",
    "Keep all the elements of the currently considered mode",
    "MXNet will not be happy if this is a list insteaf of a tuple",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Caglayan Tuna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "ADMM inits",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Fix to address surprising MXNet.numpy behavior (Issue #19891)",
    "Initialise the decompositions",
    "Norm of the reconstructions at each iteration",
    "Update the lagrangian multipliers",
    "Evolution of the reconstruction errors",
    "Convergence check",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "A list of candidates for each mode",
    "Refine the init",
    "Deprecated",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Initialisation",
    "The initial core approximation is needed here for the masking step",
    "SVD init",
    "The initial core approximation is needed here for the masking step",
    "len(rank) == len(modes) but we still want a core dimension for the modes not optimized",
    "The factors are orthonormal and therefore do not affect the reconstructed tensor's norm",
    "TO-DO validate rank for partial tucker as well",
    "Initialisation",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local variables",
    "Iterate over one step of NTD",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "UtU",
    "UtM",
    "Call the hals resolution with nnls, optimizing the current mode",
    "updating core",
    "Adding the l1 norm value to the reconstruction error",
    "error computation",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan TUna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "NNDSVD initialization",
    "The leading singular triplet is non-negative",
    "so it can be used as is for initialization.",
    "extract positive and negative parts of column vectors",
    "and their norms",
    "choose update",
    "After this point we no longer need H",
    "Apply nnsvd to make non-negative",
    "TODO: this is a hack but it seems to do the job for now",
    "If the initialisation is a precomputed decomposition, we double check its validity and return it",
    "TODO: Test this",
    "Make decomposition feasible by taking the absolute value of all factor matrices",
    "khatri_rao(factors).tl.dot(khatri_rao(factors))",
    "simplifies to multiplications",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local varaibles",
    "Iteratation",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "Take into account init weights",
    "Call the hals resolution with nnls, optimizing the current mode",
    "check recovery",
    "check low rank recovery",
    "Check for sparsity of the gross error",
    "assert tl.sum(noise_pred > 0.01) == tl.sum(noise > 0.01)",
    "check sparse gross error recovery",
    "###########################",
    "Test with missing values #",
    "###########################",
    "Add some corruption (missing values, replaced by ones)",
    "Decompose the tensor",
    "check recovery",
    "check low rank recovery",
    "check sparse gross error recovery",
    "Check for recovery of the corrupted/missing part",
    "Check that the error monotonically decreases",
    "TODO: This doesn't always pass with these other options",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Check that sparse component works",
    "Check that we get roughly the same answer with the full tensor and masking",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Regression test: used wrong variable for convergence checking",
    "Used mttkrp*factor instead of mttkrp*factors[-1], which resulted in",
    "error when mode 2 was not constrained and erroneous convergence checking",
    "when mode 2 was constrained.",
    "test tensor reconstructed properly",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "Test random_state fixes the core and the factor matrices",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "try fixing the core",
    "Random and SVD init should converge to a similar solution",
    "Mask an outlier value, and check that the decomposition ignores it",
    "We won't use the SVD decomposition, but check that it at least runs successfully",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the max abs difference between the reconstruction and the tensor",
    "Testing if estimated factors are monotonic",
    "Check if maximum values is 1",
    "Check if factors have l1 norm smaller than threshold",
    "Check if factors are normalized and k-sparse",
    "Check if factors are normalized and k-sparse",
    "Test the max abs difference between the reconstruction and the tensor",
    "Check that the error monotonically decreases",
    "# Check reconstruction of noisy tensor",
    "TODO: These error checks do not always pass, possibly due to poor SVD initialization.",
    "assert_(error < tol_norm_2,",
    "'norm 2 of reconstruction higher than tol')",
    "Test the max abs difference between the reconstruction and the tensor",
    "assert_(",
    "tl.max(tl.abs(tensor_true - tensor_pred)) + tl.max(",
    "tl.abs(matrix_true - matrix_pred)) < tol_max_abs,",
    "'abs norm of reconstruction error higher than tol')",
    "Test the max abs difference between the reconstruction and the tensor",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "Create tensor with random elements",
    "Compute TR decomposition",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Test convergence criterion",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "Fit with only one iteration to check non-negativity",
    "The default random parafac2 tensor has non-negative A and C",
    "we therefore multiply them randomly with -1, 0 or 1 to get both positive and negative components",
    "Test that constraining B leads to a warning",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TODO: Remove once MXNet supports transpose for > 6th order tensors",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Deprecated",
    "Generate a random state for me",
    "random state from integer seed",
    "if it is already a random state, just return it",
    "only takes as seed a random state, an int or None",
    "tests that the columns of each factor matrix are indeed orthogonal",
    "(See issue #40)",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Authors: Taylor Lee Patti <taylorpatti@g.harvard.edu>",
    "Jean Kossaifi",
    "All density matrices are Hermitian, here real. Hermitianize matrix if rounding/transformation",
    "errors have occured.",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "TODO: write a function to do this..",
    "Check user input for errors",
    "Make sure iter's not a tuple but a list",
    "Initialize rank",
    "list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.",
    "list row_idx: row indices    (left indices)  for skeleton-decomposition: indicate which rows used in each core.",
    "Initialize indice: random selection of column indices",
    "Initialize the cores of tensor-train",
    "#####################################",
    "left-to-right step",
    "list row_idx: list of (tensor_order-1) of lists of left indices",
    "update row indices",
    "end left-to-right step",
    "##############################################",
    "##############################################",
    "right-to-left step",
    "list col_idx: list (tensor_order-1) of lists of right indices",
    "update col indices",
    "Compute cores",
    "The rank should not be larger than the input tensor's size",
    "Add the last core",
    "end right-to-left step",
    "###############################################",
    "check the error for while-loop",
    "check convergence",
    "Extract fibers according to the row and col indices",
    "Extract the core",
    "shape the core as a 3-tensor_order cube",
    "merge r_k and n_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "Extract fibers",
    "shape the core as a 3-tensor_order cube",
    "merge n_{k-1} and r_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "The index of row of the submatrix",
    "Rest of rows / unselected rows",
    "Find r rows iteratively",
    "Compute the square of norm of each row",
    "If there is only one row of A left, let's just return it. MxNet is not robust about this case.",
    "If a row is 0, we delete it.",
    "Find the row of max norm",
    "Compute the projection of max_row to other rows",
    "projection a to b is computed as: <a,b> / sqrt(|a|*|b|)",
    "make sure normalization vector is of the same shape of projection (causing bugs for MxNet)",
    "Subtract the projection from A_new:  b <- b - a * projection",
    "Delete the selected row",
    "update the row_idx and rest_of_rows",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TEST 4",
    "Random tensor is not really compress-able. Test on a tensor as values of a function",
    "Find TT decomposition of the tensor",
    "from ...backend import _get_backend_method, _get_backend_dir",
    "from ...backend import backend",
    "return _get_backend_dir() + static_items",
    "override_module_dispatch(__name__, backend_manager.__getattribute__, sparse_dir)",
    "override_module_dispatch(__name__, _get_backend_method, sparse_dir)",
    "Deprecated",
    "Make sure the algorithm stays sparse. This will run out of memory on",
    "most machines if the algorithm densifies.",
    "Will blow-up memory if not sparse-safe",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Default on standard SVD",
    "all-zeros matrix, so we should do a quick return.",
    "We can perform a partial SVD",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "use dense form when sparse form will fail",
    "use dense form when sparse form will fail",
    "WARNING: here, V is still the transpose of what it should be",
    "Check correct rank and shapes are returned",
    "One of the factors has the wrong rank",
    "Not the correct amount of weights",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test cp_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test cp_mode_dot with vec",
    "Version forming explicitely the khatri-rao product",
    "Efficient sparse-safe version",
    "Rounding = floor",
    "Rounding = ceil",
    "If we're taking the gradient of comparison with self it should be 0",
    "Check that we can solve for a direction of descent",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not three factor matrices",
    "Not enough projections",
    "Wrong number of weights",
    "The projections aren't orthogonal",
    "Disable tests for inplace edits, since that possibility is removed",
    "to support TensorFlow.",
    "@pytest.mark.parametrize('copy', [True, False])",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create tensor",
    "Compute ground truth TT factors",
    "Check that TT factors re-assemble to the original tensor",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Reconstruct the original tensor",
    "Check that the rank is 10",
    "Rounding = floor",
    "Rounding = ceil",
    "TODO: Remove once MXNet supports transpose for > 6th order tensors",
    "Author: Jean Kossaifi",
    "Set in context manager",
    "Sets back to numpy",
    "Reset back to initial backend",
    "Set not in context manager",
    "Improper name doesn't reset backend",
    "Changes only happen locally in this thread",
    "Set the global default backend",
    "Changed toplevel default in all threads",
    "True reconstruction error (based on numpy SVD)",
    "Reconstruction error with the backend's SVD",
    "Check that the two are similar",
    "Check for orthogonality when relevant",
    "Should fail on non-matrices",
    "Test for singular matrices (some eigenvals will be zero)",
    "Rank at most 5",
    "Test orthonormality when  max_dim > n_eigenvecs > matrix_rank",
    "Test if partial_svd returns the same result for the same setting",
    "limit as order->oo is the oo-norm",
    "1D",
    "2D",
    "3D",
    "random testing against Numpy's output",
    "1-dim x n-dim",
    "n_dim x 1-dim",
    "n-dim x n-dim",
    "test dimensions",
    "test residuals",
    "test least squares solution",
    "assert that the columns of Q are orthonormal",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create ground truth TR factors",
    "Create tensor",
    "TODO: add trace to backend instead of this",
    "Check that TR factors re-assemble to the original tensor",
    "Rounding = floor",
    "Rounding = ceil",
    "Integer rank",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not enough factors to match core",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test tucker_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test tucker_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "With fixed modes",
    "Floor",
    "Ceil",
    "Author: Jean Kossaifi",
    "hard coded example",
    "check dims",
    "chain unfolding and folding",
    "Convert to vector and back to tensor",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "We created here a tensor with 3 samples, each sample being similar to X",
    "Test for raveled tensor",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Test for raveled tensor",
    "Test for raveled_tensor=True",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "we created here a tensor with 3 samples, each sample being similar to X",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "New function renaming old_fun",
    "Old fun will return fun but issue a deprecation warning",
    "Test using the deprecated function",
    "Test using the new function instead",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan Tuna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Next line finds mutual peak points",
    "Scaling",
    "Safety procedure, if columns aren't allow to be zero",
    "Parameters",
    "To avoid singularity error when initial x exists",
    "Start from zeros if solve is not achieved",
    "update support vector if it is necessary",
    "set x to s",
    "gradient update",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "backend = getattr(module, )()",
    "Initialise the backend to the default one",
    "Author: Jean Kossaifi",
    "Check that we did not change the original tensor",
    "Check that we did not change the original tensor",
    "Monotone increasing",
    "Monotone decreasing",
    "small test",
    "account for floating point errors: np array have a precision of around 2e-15",
    "check np.finfo(np.float64).eps",
    "Check that we did not change the original tensor",
    "Another test",
    "Test with missing values",
    "Equivalence with inner product when contracting with self along all modes",
    "Equivalent to the above expression",
    "Equivalence with n-mode-dot",
    "Multi-mode-dot",
    "Wrong number of modes",
    "size mismatch",
    "Test Batched tensor dot",
    "Check for each sample of the batch-size individually",
    "Test for actual tensordot",
    "Author: Jean Kossaifi",
    "resulting matrix must be of shape (prod(n_rows), n_columns)",
    "fail case: all matrices must have same number of columns",
    "all matrices should be of dim 2...",
    "Classic example/test",
    "A = np.hstack((np.eye(3), np.arange(3)[:, None]))",
    "Test with one matrix only: khatri-rao of one matrix = that matrix",
    "Check that negative dims are made positive",
    "Author: Jean Kossaifi",
    "Mathematical test",
    "Another test",
    "Adding a third matrices",
    "Test for the reverse argument",
    "Check that the original list has not been reversed",
    "Check the returned shape",
    "Khatri-rao is a column-wise kronecker product",
    "Khatri-rao product is a column-wise kronecker product",
    "Test while skipping a matrix",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "For one common mode, equivalent to dot product",
    "For no common mode, equivalent to inner product",
    "Inner product of tensors with different shapes is not defined",
    "tensor times matrix",
    "######################",
    "tensor times vector #",
    "######################",
    "Test with a matrix",
    "Test with a third order tensor",
    "Using equivalence with unfolded expression",
    "########################################",
    "Test for errors that should be raised #",
    "########################################",
    "Same test for the vector case",
    "Cannot take mode product of tensor with tensor",
    "Test using the equivalence with unfolded expression",
    "Test skipping a factor",
    "Test contracting with a vector",
    "result should be a scalar",
    "Average pooling each mode",
    "Order should not matter",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Indices of each matrix",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "However, it is needed to pop dimensions contracted over",
    "print(i, matrix_or_vec.shape, mode)",
    "print(f'skipping {skip}')",
    "We are contracting over the mode-th dimension",
    "mat_symbol = f'{tensor_modes[mode]}{chr(counter)}'",
    "Contracting mode-th mode with a matrix: new dimension",
    "If fully contracting",
    "matrix_or_vec_list = [m for (i, m) in enumerate(matrix_or_vec_list) if ((skip is None) or (skip != i))]",
    "print(equation, tl.shape(tensor), [tl.shape(f) for f in matrix_or_vec_list])",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Each core is of shape (rank_left, size_in, size_out, rank_right)",
    "Intertwine the dims",
    "full_shape = in_shape[0], out_shape[0], in_shape[1], ...",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Ideally this should be (), i.e. order-0 tensors",
    "MXNet currently doesn't support this though..",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "TODO : add batched_modes as in batched_tensor_dot?",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Prepare to reorganize the modes afterwards by moving bactch size back to their place",
    "(while ommiting modes contracted over)",
    "We will reorganize tensor1 to (batch_modes, new_modes1, contraction_modes)",
    "Tensor2 will be (batch_modes, contraction_modes, new_modes2)",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "source_fun, target_fun",
    "handle difference in default axis notation",
    "columns of U, rows of V",
    "rows of V, columns of U",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Just perform trucated SVD",
    "If n_eigenvecs == min_dim, we don't want full_matrices=True, it's super slow",
    "We can perform a partial SVD",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "WARNING: here, V is still the transpose of what it should be",
    "Check that matrix is... a matrix!",
    "Check that matrix is... a matrix!",
    "Check that matrix is... a matrix!",
    "transpose matrix to keep the reduced matrix shape minimal",
    "Perform power iterations when spectrum decays slowly",
    "pytorch does not accept `None` for any keyword arguments. additionally,",
    "pytorch doesn't seems to support keyword arguments in the first place",
    "Currently, gesv doesn't support vectors for matrix2",
    "So we instead solve a least square problem...",
    "Currently, solve doesn't support vectors for matrix2",
    "Register the other functions",
    "PyTorch 1.8.0 has a much better NumPy interface but somoe haven't updated yet",
    "Old version, will be removed in the future",
    "New PyTorch NumPy interface",
    "MXNet doesn't provide an option for full_matrices=True",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "Define class methods and attributes that dynamically dispatch to the backend",
    "We don't use `functools.wraps` here because some of the dispatched",
    "methods include the backend (`cls`) as a parameter. Instead we manually",
    "copy over the needed information, and filter the signature for `cls`.",
    "If it doesn't have a signature we don't need to remove self",
    "This happens for NumPy (e.g. np.where) where inspect.signature(np.where) errors:",
    "ValueError: no signature found for builtin <built-in function where>",
    "backend = getattr(module, )()",
    "Backend is a string",
    "Initialise the backend to the default one",
    "Swiss",
    "Rectangle",
    "circle: approximate test",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise modes of W",
    "Regress phi on y: we could call a package here, e.g. scikit-learn",
    "Convergence check",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise each factor of W",
    "Convergence check",
    "Parameter of the experiment",
    "Generate random samples",
    "Parameter of the experiment",
    "Generate random samples"
  ],
  "0.6.0": [
    "Ignore already minified files",
    "Ignore already minified files",
    "!/usr/bin/env python3",
    "-*- coding: utf-8 -*-",
    "",
    "tensorly documentation build configuration file",
    "",
    "This file is execfile()d with the current directory set to its",
    "containing dir.",
    "",
    "Note that not all possible configuration values are present in this",
    "autogenerated file.",
    "",
    "All configuration values have a default; values that are commented out",
    "serve to show the default.",
    "If extensions (or modules to document with autodoc) are in another directory,",
    "add these directories to sys.path here. If the directory is relative to the",
    "documentation root, use os.path.abspath to make it absolute, like shown here.",
    "sys.path.insert(0, os.path.abspath('sphinx_ext'))",
    "-- General configuration ------------------------------------------------",
    "If your documentation needs a minimal Sphinx version, state it here.",
    "needs_sphinx = '1.0'",
    "Add any Sphinx extension module names here, as strings. They can be",
    "extensions coming with Sphinx (named 'sphinx.ext.*') or your custom",
    "ones.",
    "'sphinx.ext.imgmath',",
    "path to your examples scripts",
    "path where to save gallery generated examples",
    "Add any paths that contain templates here, relative to this directory.",
    "generate autosummary even if no references",
    "The suffix(es) of source filenames.",
    "You can specify multiple suffix as a list of string:",
    "source_suffix = ['.rst', '.md']",
    "The encoding of source files.",
    "source_encoding = 'utf-8-sig'",
    "The master toctree document.",
    "General information about the project.",
    "The version info for the project you're documenting, acts as replacement for",
    "|version| and |release|, also used in various other places throughout the",
    "built documents.",
    "",
    "The short X.Y version.",
    "version = '0.1'",
    "The full version, including alpha/beta/rc tags.",
    "release = ''",
    "The language for content autogenerated by Sphinx. Refer to documentation",
    "for a list of supported languages.",
    "",
    "This is also used if you do content translation via gettext catalogs.",
    "Usually you set \"language\" from the command line for these cases.",
    "There are two options for replacing |today|: either, you set today to some",
    "non-false value, then it is used:",
    "today = ''",
    "Else, today_fmt is used as the format for a strftime call.",
    "today_fmt = '%B %d, %Y'",
    "List of patterns, relative to source directory, that match files and",
    "directories to ignore when looking for source files.",
    "This patterns also effect to html_static_path and html_extra_path",
    "The reST default role (used for this markup: `text`) to use for all",
    "documents.",
    "default_role = None",
    "If true, '()' will be appended to :func: etc. cross-reference text.",
    "If true, the current module name will be prepended to all description",
    "unit titles (such as .. function::).",
    "If true, sectionauthor and moduleauthor directives will be shown in the",
    "output. They are ignored by default.",
    "show_authors = False",
    "The name of the Pygments (syntax highlighting) style to use.",
    "A list of ignored prefixes for module index sorting.",
    "modindex_common_prefix = []",
    "If true, keep warnings as \"system message\" paragraphs in the built documents.",
    "keep_warnings = False",
    "If true, `todo` and `todoList` produce output, else they produce nothing.",
    "-- Options for HTML output ----------------------------------------------",
    "The theme to use for HTML and HTML Help pages.  See the documentation for",
    "a list of builtin themes.",
    "Add any paths that contain custom themes here, relative to this directory.",
    "html_theme_path = ['themes']",
    "Theme options are theme-specific and customize the look and feel of a theme",
    "further.  For a list of options available for each theme, see the",
    "documentation.",
    "The name for this set of Sphinx documents.",
    "\"<project> v<release> documentation\" by default.",
    "A shorter title for the navigation bar.  Default is the same as html_title.",
    "The name of an image file (relative to this directory) to place at the top",
    "of the sidebar.",
    "The name of an image file (relative to this directory) to use as a favicon of",
    "the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32",
    "pixels large.",
    "html_favicon = None",
    "Add any paths that contain custom static files (such as style sheets) here,",
    "relative to this directory. They are copied after the builtin static files,",
    "so a file named \"default.css\" will overwrite the builtin \"default.css\".",
    "html_additional_pages = {",
    "}",
    "Add any extra paths that contain custom files (such as robots.txt or",
    ".htaccess) here, relative to this directory. These files are copied",
    "directly to the root of the documentation.",
    "html_extra_path = []",
    "If not None, a 'Last updated on:' timestamp is inserted at every page",
    "bottom, using the given strftime format.",
    "The empty string is equivalent to '%b %d, %Y'.",
    "html_last_updated_fmt = None",
    "If true, SmartyPants will be used to convert quotes and dashes to",
    "typographically correct entities.",
    "html_use_smartypants = True",
    "Custom sidebar templates, maps document names to template names.",
    "html_sidebars = {}",
    "Additional templates that should be rendered to pages, maps page names to",
    "template names.",
    "html_additional_pages = {}",
    "If false, no module index is generated.",
    "If false, no index is generated.",
    "If true, the index is split into individual pages for each letter.",
    "html_split_index = False",
    "If true, links to the reST sources are added to the pages.",
    "If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.",
    "If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.",
    "html_show_copyright = True",
    "If true, an OpenSearch description file will be output, and all pages will",
    "contain a <link> tag referring to it.  The value of this option must be the",
    "base URL from which the finished HTML is served.",
    "html_use_opensearch = ''",
    "This is the file name suffix for HTML files (e.g. \".xhtml\").",
    "html_file_suffix = None",
    "Language to be used for generating the HTML full-text search index.",
    "Sphinx supports the following languages:",
    "'da', 'de', 'en', 'es', 'fi', 'fr', 'h', 'it', 'ja'",
    "'nl', 'no', 'pt', 'ro', 'r', 'sv', 'tr', 'zh'",
    "html_search_language = 'en'",
    "A dictionary with options for the search language support, empty by default.",
    "'ja' uses this config value.",
    "'zh' user can custom change `jieba` dictionary path.",
    "html_search_options = {'type': 'default'}",
    "The name of a javascript file (relative to the configuration directory) that",
    "implements a search results scorer. If empty, the default will be used.",
    "html_search_scorer = 'scorer.js'",
    "Output file base name for HTML help builder.",
    "-- Options for LaTeX output ---------------------------------------------",
    "Grouping the document tree into LaTeX files. List of tuples",
    "(source start file, target name, title,",
    "author, documentclass [howto, manual, or own class]).",
    "\\setcounter{MaxMatrixCols}{20} corrects an ugly bug if you try to have a matrix of more than 10 elements or so",
    "We want the same for the html version:",
    "The name of an image file (relative to this directory) to place at the top of",
    "the title page.",
    "latex_logo = None",
    "For \"manual\" documents, if this is true, then toplevel headings are parts,",
    "not chapters.",
    "latex_use_parts = False",
    "If true, show page references after internal links.",
    "If true, show URL addresses after external links.",
    "Documents to append as an appendix to all manuals.",
    "latex_appendices = []",
    "Get completely rid of index",
    "If false, no module index is generated.",
    "latex_domain_indices = True",
    "-- Options for manual page output ---------------------------------------",
    "One entry per manual page. List of tuples",
    "(source start file, name, description, authors, manual section).",
    "If true, show URL addresses after external links.",
    "man_show_urls = False",
    "-- Options for Texinfo output -------------------------------------------",
    "Grouping the document tree into Texinfo files. List of tuples",
    "(source start file, target name, title, author,",
    "dir menu entry, description, category)",
    "Documents to append as an appendix to all manuals.",
    "texinfo_appendices = []",
    "If false, no module index is generated.",
    "texinfo_domain_indices = True",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "texinfo_show_urls = 'footnote'",
    "If true, do not generate a @detailmenu in the \"Top\" node's menu.",
    "texinfo_no_detailmenu = False",
    "-- Options for Epub output ----------------------------------------------",
    "Bibliographic Dublin Core info.",
    "The basename for the epub file. It defaults to the project name.",
    "epub_basename = project",
    "The HTML theme for the epub output. Since the default themes are not",
    "optimized for small screen space, using the same theme for HTML and epub",
    "output is usually not wise. This defaults to 'epub', a theme designed to save",
    "visual space.",
    "epub_theme = 'epub'",
    "The language of the text. It defaults to the language option",
    "or 'en' if the language is not set.",
    "epub_language = ''",
    "The scheme of the identifier. Typical schemes are ISBN or URL.",
    "epub_scheme = ''",
    "The unique identifier of the text. This can be a ISBN number",
    "or the project homepage.",
    "epub_identifier = ''",
    "A unique identification for the text.",
    "epub_uid = ''",
    "A tuple containing the cover image and cover page html template filenames.",
    "epub_cover = ()",
    "A sequence of (type, uri, title) tuples for the guide element of content.opf.",
    "epub_guide = ()",
    "HTML files that should be inserted before the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_pre_files = []",
    "HTML files that should be inserted after the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_post_files = []",
    "A list of files that should not be packed into the epub file.",
    "The depth of the table of contents in toc.ncx.",
    "epub_tocdepth = 3",
    "Allow duplicate toc entries.",
    "epub_tocdup = True",
    "Choose between 'default' and 'includehidden'.",
    "epub_tocscope = 'default'",
    "Fix unsupported image types using the Pillow.",
    "epub_fix_images = False",
    "Scale large images.",
    "epub_max_image_width = 0",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "epub_show_urls = 'inline'",
    "If false, no index is generated.",
    "epub_use_index = True",
    "-*- coding: utf-8 -*-",
    "Created: Sun May 21 20:38:59 2017",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Created Sun Nov 27 14:03:07 2016",
    "Author: \u00d3scar N\u00e1jera",
    "can't use codecs.open(filename, 'r', 'utf-8') here b/c ast doesn't",
    "seem to work with unicode strings in Python2.7",
    "\"SyntaxError: encoding declaration in Unicode string\"",
    "change from Windows format to UNIX for uniformity",
    "This get the content of the file after the docstring last line",
    "Note: 'maxsplit' argument is not a keyword argument in python2",
    "sphinx_gallery_<name> = <value>",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "Try Python 3 first, otherwise load from Python 2",
    "This is a.b, not e.g. a().b",
    "need to get a in a().b",
    "Join import path to relative path",
    "Find out what the real object is supposed to be.",
    "Ensure shortened object is the same as what we expect.",
    "get the last working module name",
    "name is as written in file (e.g. np.asarray)",
    "full_name includes resolved import path (e.g. numpy.asarray)",
    "module without attribute. This is not useful for",
    "backreferences",
    "get shortened module name",
    "Inside rst files forward slash defines paths",
    "-*- coding: utf-8 -*-",
    "This gets set when the extension is initialized.",
    "colorfunc is a valid kwarg in 1.5, but not older, so we just",
    "apply it ourselves.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "shelve keys need to be str in python 2",
    "value is a list",
    "try to convert elements to int",
    "value is another dictionary",
    "Make sure searchindex uses UTF-8 encoding",
    "parse objects",
    "parse filenames",
    "detect if we are using relative links on a Windows system",
    "download and initialize the search index",
    "In 1.5+ Sphinx seems to have changed from .rst.html to only",
    ".html extension in converted files. But URLs could be",
    "built with < 1.5 or >= 1.5 regardless of what we're currently",
    "building with, so let's just check both :(",
    "test if cobj appears in page",
    "we don't have it cached",
    "cache it for the future",
    "failed to resolve",
    "replace '\\' with '/' so it on the web",
    "for some reason, the relative link goes one directory too high up",
    "Add resolvers for the packages for which we want to show links",
    "patterns for replacement",
    "This could be turned into a generator if necessary, but should be okay",
    "we have a pickle file with the objects to embed links for",
    "generate replacement strings with the links",
    "do the replacement in the html file",
    "ensure greediness",
    "No need to waste time embedding hyperlinks when not running the examples",
    "XXX: also at the time of writing this fixes make html-noplot",
    "for some reason I don't fully understand",
    "XXX: Whitelist of builders for which it makes sense to embed",
    "hyperlinks inside the example html. Note that the link embedding",
    "require searchindex.js to exist for the links to the local doc",
    "and there does not seem to be a good way of knowing which",
    "builders creates a searchindex.js.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "##############################################################################",
    "Notebook shell utility",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "build options",
    "Sphinx hack: sphinx copies generated images to the build directory",
    "each time the docs are made.  If the desired image name already",
    "exists, it appends a digit to prevent overwrites.  The problem is,",
    "the directory is never cleared.  This means that each time you build",
    "the docs, the number of images in the directory grows.",
    "",
    "This question has been asked on the sphinx development list, but there",
    "was no response: https://git.net/ml/sphinx-dev/2011-02/msg00123.html",
    "",
    "The following is a hack that prevents this behavior by clearing the",
    "image build directory from gallery images each time the docs are built.",
    "If sphinx changes their layout between versions, this will not",
    "work (though it should probably not cause a crash).",
    "Tested successfully on Sphinx 1.0.7",
    "this assures I can call the config in other places",
    "Here we don't use an os.walk, but we recurse only twice: flat is",
    "better than nested.",
    "we create an index.rst with all examples",
    ":orphan: to suppress \"not included in TOCTREE\" sphinx warnings",
    "touch file",
    "Under no-plot Examples are not run so nothing to summarize",
    "Sphinx < 1.6 calls it `_extensions`, >= 1.6 is `extensions`.",
    "HACK: Stop nosetests running setup() above",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Don't use unicode_literals here (be explicit with u\"...\" instead) otherwise",
    "tricky errors come up with exec(code_blocks, ...) calls",
    "Try Python 2 first, otherwise load from Python 3",
    "textwrap indent only exists in python 3",
    "make sure that the Agg backend is set before importing any",
    "matplotlib",
    "##############################################################################",
    "##############################################################################",
    "The following strings are used when we have several pictures: we use",
    "an html div tag that our CSS uses to turn the lists into horizontal",
    "lists.",
    "This one could contain unicode",
    "Sphinx only starts numbering from the first non-empty line.",
    "lstrip is just in case docstring has a '\\n\\n' at the beginning",
    "Set the fig_num figure as the current figure as we can't",
    "save a figure that's not the current figure.",
    "make sure the image is not too large",
    "local import to avoid testing dependency on PIL:",
    "resize the image",
    "insert centered",
    "Use optipng to perform lossless compression on the resized image if",
    "software is installed",
    "read specification of the figure to display as thumbnail from main text",
    "create something to replace the thumbnail",
    "Add empty lines to avoid bug in issue #165",
    "sort to have the smallest entries in the beginning",
    "clear at the end of the section",
    "Remove our code from traceback:",
    "Remove one extra level through ast.parse.",
    "Breaks build on first example error",
    "Stores failing file",
    "If example is not suitable to run, skip executing its blocks",
    "Redirect output to stdout and",
    "First cd in the original example dir, so that any file",
    "created by the example get created in this directory",
    "don't use unicode_literals at the top of this file or you get",
    "nasty errors here on Py2.7",
    "Horrible code to 'unload' seaborn, so that it resets",
    "its default when is load",
    "Python does not support unloading of modules",
    "https://bugs.python.org/issue9072",
    "Reset Matplotlib to default",
    "A lot of examples contains 'print(__doc__)' for example in",
    "scikit-learn so that running the example prints some useful",
    "information. Because the docstring has been separated from",
    "the code blocks in sphinx-gallery, __doc__ is actually",
    "__builtin__.__doc__ in the execution context and we do not",
    "want to print it",
    "Examples may contain if __name__ == '__main__' guards",
    "for in example scikit-learn if the example uses multiprocessing",
    "Don't ever support __file__: Issues #166 #212",
    "A simple example has two blocks: one for the",
    "example introduction/explanation and one for the code",
    "We want to run the example without arguments. See",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/252",
    "for more details.",
    "Add some vertical space after output",
    "Writes md5 checksum if example has build correctly",
    "not failed and was initially meant to run(no-plot shall not cache md5sum)",
    "-*- coding: utf-8 -*-",
    "Error + critical both go through warning:",
    "-*- coding: utf-8 -*-",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Need to import gen_rst before matplotlib.pyplot to set backend to 'Agg'",
    "For more details see",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/49",
    "verify correct md5sum",
    "False because is a new file",
    "Write md5sum to file to check is current",
    "read rst file and check if it contains traceback output",
    "create three files in tempdir (only one matches the pattern)",
    "generate rst file",
    "read rst file and check if it contains code output",
    "which plot to show as the thumbnail image",
    "test issue #229",
    "TODO: test that broken thumbnail does appear when needed",
    "TODO: test that examples are not executed twice",
    "TODO: test that examples are executed after a no-plot and produce",
    "the correct image in the thumbnail",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "recovers data from temporary file and caches it in the shelve",
    "tests recovered data matches",
    "test if cached data is available after temporary file has vanished",
    "shelve keys need to be str in python 2, deal with unicode input",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "General information about the project.",
    "no duplicate values allowed The config is present already",
    "General information about the project.",
    "General information about the project.",
    "General information about the project.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Test fails on wrong input",
    "Test missing folder",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "##############################################################################",
    "Notebook shell utility",
    "replace reference numbers so that there are no duplicates",
    "Strip top title",
    "call function to replace reference numbers so that there are no",
    "duplicates",
    "Do not try to inspect classes that don't define `__init__`",
    "Extra mangling domains",
    "------------------------------------------------------------------------------",
    "Docstring-mangling domains",
    "------------------------------------------------------------------------------",
    "go to next non-empty line in old:",
    "line.strip() checks whether the string is all whitespace",
    "------------------------------------------------------------------------------",
    "Registration hook",
    "------------------------------------------------------------------------------",
    "------------------------------------------------------------------------------",
    "plot:: directive",
    "------------------------------------------------------------------------------",
    "no argument given, assume used as a flag",
    "------------------------------------------------------------------------------",
    "Generating output",
    "------------------------------------------------------------------------------",
    "Sphinx depends on either Jinja or Jinja2",
    "determine input",
    "ensure that LaTeX includegraphics doesn't choke in foo.bar.pdf filenames",
    "is it in doctest format?",
    "determine output directory name fragment",
    "build_dir: where to place output files (temporarily)",
    "output_dir: final location in the builder's directory",
    "how to link to files from the RST file",
    "make figures",
    "generate output restructuredtext",
    "copy image files to builder's output directory",
    "copy script (if necessary)",
    "------------------------------------------------------------------------------",
    "Run code and capture figures",
    "------------------------------------------------------------------------------",
    "check if it's valid Python as-is",
    "Change the working directory to the directory of the example, so",
    "it can get at its data files, if any.",
    "Redirect stdout",
    "Reset sys.argv",
    "------------------------------------------------------------------------------",
    "Generating figures",
    "------------------------------------------------------------------------------",
    "-- Parse format list",
    "-- Try to determine if all images already exist",
    "Look for single-figure output files first",
    "Then look for multi-figure output files",
    "assume that if we have one, we have them all",
    "-- We didn't find the files, so build them",
    "Clear between runs",
    "Run code",
    "Collect images",
    "Results",
    "------------------------------------------------------------------------------",
    "Relative pathnames",
    "------------------------------------------------------------------------------",
    "Copied from Python 2.7",
    "Work out how much of the filepath is shared by start and path.",
    "Work out how much of the filepath is shared by start and path.",
    "If several signatures present, take the last one",
    "We could do more tests, but we are not. Arbitrarily.",
    "string conversion routines",
    "try to read signature, backward compat for older Python",
    "########################################################################",
    "object interface.",
    "########################################################################",
    "########################################################################",
    "Unparser private interface.",
    "########################################################################",
    "## format, output, and dispatch methods ################################",
    "########################################################################",
    "compiler.ast unparsing methods.",
    "",
    "There should be one method per concrete grammar type. They are",
    "organized in alphabetical order.",
    "########################################################################",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "fixme: Are From and ImportFrom handled differently?",
    "if t.step:",
    "self._write(\":\")",
    "self._dispatch(t.step)",
    "Empty tuple.",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "Check if parenthesis are needed on left side and then dispatch",
    "Write the appropriate symbol for operator",
    "Check if parenthesis are needed on the right side and then dispatch",
    "if t is 0.1, str(t)->'0.1' while repr(t)->'0.1000000000001'",
    "We prefer str here.",
    "########################################################################",
    "These are the methods from the _ast modules unparse.",
    "",
    "As our needs to handle more advanced code increase, we may want to",
    "modify some of the methods below so that they work for compiler.ast.",
    "########################################################################",
    "# stmt",
    "def _Expr(self, tree):",
    "self._fill()",
    "self._dispatch(tree.value)",
    "",
    "def _Import(self, t):",
    "self._fill(\"import \")",
    "first = True",
    "for a in t.names:",
    "if first:",
    "first = False",
    "else:",
    "self._write(\", \")",
    "self._write(a.name)",
    "if a.asname:",
    "self._write(\" as \"+a.asname)",
    "",
    "#    def _ImportFrom(self, t):",
    "#        self._fill(\"from \")",
    "#        self._write(t.module)",
    "#        self._write(\" import \")",
    "#        for i, a in enumerate(t.names):",
    "#            if i == 0:",
    "#                self._write(\", \")",
    "#            self._write(a.name)",
    "#            if a.asname:",
    "#                self._write(\" as \"+a.asname)",
    "#        # XXX(jpe) what is level for?",
    "#",
    "",
    "def _Break(self, t):",
    "self._fill(\"break\")",
    "",
    "def _Continue(self, t):",
    "self._fill(\"continue\")",
    "",
    "def _Delete(self, t):",
    "self._fill(\"del \")",
    "self._dispatch(t.targets)",
    "",
    "def _Assert(self, t):",
    "self._fill(\"assert \")",
    "self._dispatch(t.test)",
    "if t.msg:",
    "self._write(\", \")",
    "self._dispatch(t.msg)",
    "",
    "def _Exec(self, t):",
    "self._fill(\"exec \")",
    "self._dispatch(t.body)",
    "if t.globals:",
    "self._write(\" in \")",
    "self._dispatch(t.globals)",
    "if t.locals:",
    "self._write(\", \")",
    "self._dispatch(t.locals)",
    "",
    "def _Print(self, t):",
    "self._fill(\"print \")",
    "do_comma = False",
    "if t.dest:",
    "self._write(\">>\")",
    "self._dispatch(t.dest)",
    "do_comma = True",
    "for e in t.values:",
    "if do_comma:self._write(\", \")",
    "else:do_comma=True",
    "self._dispatch(e)",
    "if not t.nl:",
    "self._write(\",\")",
    "",
    "def _Global(self, t):",
    "self._fill(\"global\")",
    "for i, n in enumerate(t.names):",
    "if i != 0:",
    "self._write(\",\")",
    "self._write(\" \" + n)",
    "",
    "def _Yield(self, t):",
    "self._fill(\"yield\")",
    "if t.value:",
    "self._write(\" (\")",
    "self._dispatch(t.value)",
    "self._write(\")\")",
    "",
    "def _Raise(self, t):",
    "self._fill('raise ')",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.inst:",
    "self._write(\", \")",
    "self._dispatch(t.inst)",
    "if t.tback:",
    "self._write(\", \")",
    "self._dispatch(t.tback)",
    "",
    "",
    "def _TryFinally(self, t):",
    "self._fill(\"try\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "self._fill(\"finally\")",
    "self._enter()",
    "self._dispatch(t.finalbody)",
    "self._leave()",
    "",
    "def _excepthandler(self, t):",
    "self._fill(\"except \")",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.name:",
    "self._write(\", \")",
    "self._dispatch(t.name)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _ClassDef(self, t):",
    "self._write(\"\\n\")",
    "self._fill(\"class \"+t.name)",
    "if t.bases:",
    "self._write(\"(\")",
    "for a in t.bases:",
    "self._dispatch(a)",
    "self._write(\", \")",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _FunctionDef(self, t):",
    "self._write(\"\\n\")",
    "for deco in t.decorators:",
    "self._fill(\"@\")",
    "self._dispatch(deco)",
    "self._fill(\"def \"+t.name + \"(\")",
    "self._dispatch(t.args)",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _For(self, t):",
    "self._fill(\"for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "def _While(self, t):",
    "self._fill(\"while \")",
    "self._dispatch(t.test)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "# expr",
    "def _Str(self, tree):",
    "self._write(repr(tree.s))",
    "#",
    "def _Repr(self, t):",
    "self._write(\"`\")",
    "self._dispatch(t.value)",
    "self._write(\"`\")",
    "",
    "def _Num(self, t):",
    "self._write(repr(t.n))",
    "",
    "def _ListComp(self, t):",
    "self._write(\"[\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\"]\")",
    "",
    "def _GeneratorExp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\")\")",
    "",
    "def _comprehension(self, t):",
    "self._write(\" for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "for if_clause in t.ifs:",
    "self._write(\" if \")",
    "self._dispatch(if_clause)",
    "",
    "def _IfExp(self, t):",
    "self._dispatch(t.body)",
    "self._write(\" if \")",
    "self._dispatch(t.test)",
    "if t.orelse:",
    "self._write(\" else \")",
    "self._dispatch(t.orelse)",
    "",
    "unop = {\"Invert\":\"~\", \"Not\": \"not\", \"UAdd\":\"+\", \"USub\":\"-\"}",
    "def _UnaryOp(self, t):",
    "self._write(self.unop[t.op.__class__.__name__])",
    "self._write(\"(\")",
    "self._dispatch(t.operand)",
    "self._write(\")\")",
    "",
    "binop = { \"Add\":\"+\", \"Sub\":\"-\", \"Mult\":\"*\", \"Div\":\"/\", \"Mod\":\"%\",",
    "\"LShift\":\">>\", \"RShift\":\"<<\", \"BitOr\":\"|\", \"BitXor\":\"^\", \"BitAnd\":\"&\",",
    "\"FloorDiv\":\"//\", \"Pow\": \"**\"}",
    "def _BinOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.left)",
    "self._write(\")\" + self.binop[t.op.__class__.__name__] + \"(\")",
    "self._dispatch(t.right)",
    "self._write(\")\")",
    "",
    "boolops = {_ast.And: 'and', _ast.Or: 'or'}",
    "def _BoolOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.values[0])",
    "for v in t.values[1:]:",
    "self._write(\" %s \" % self.boolops[t.op.__class__])",
    "self._dispatch(v)",
    "self._write(\")\")",
    "",
    "def _Attribute(self,t):",
    "self._dispatch(t.value)",
    "self._write(\".\")",
    "self._write(t.attr)",
    "",
    "#    def _Call(self, t):",
    "#        self._dispatch(t.func)",
    "#        self._write(\"(\")",
    "#        comma = False",
    "#        for e in t.args:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        for e in t.keywords:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        if t.starargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"*\")",
    "#            self._dispatch(t.starargs)",
    "#        if t.kwargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"**\")",
    "#            self._dispatch(t.kwargs)",
    "#        self._write(\")\")",
    "",
    "# slice",
    "def _Index(self, t):",
    "self._dispatch(t.value)",
    "",
    "def _ExtSlice(self, t):",
    "for i, d in enumerate(t.dims):",
    "if i != 0:",
    "self._write(': ')",
    "self._dispatch(d)",
    "",
    "# others",
    "def _arguments(self, t):",
    "first = True",
    "nonDef = len(t.args)-len(t.defaults)",
    "for a in t.args[0:nonDef]:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a)",
    "for a,d in zip(t.args[nonDef:], t.defaults):",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a),",
    "self._write(\"=\")",
    "self._dispatch(d)",
    "if t.vararg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"*\"+t.vararg)",
    "if t.kwarg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"**\"+t.kwarg)",
    "",
    "#    def _keyword(self, t):",
    "#        self._write(t.arg)",
    "#        self._write(\"=\")",
    "#        self._dispatch(t.value)",
    "",
    "def _Lambda(self, t):",
    "self._write(\"lambda \")",
    "self._dispatch(t.args)",
    "self._write(\": \")",
    "self._dispatch(t.body)",
    "int : The first line number in the block. 1-indexed.",
    "int : The last line number. Inclusive!",
    "str : The text block including '#' character but not any leading spaces.",
    "Only add if not entirely whitespace.",
    "Start with a dummy.",
    "All of the blocks seen so far.",
    "The index mapping lines of code to their associated comment blocks.",
    "Oops! Trailing comment, not a comment block.",
    "A comment block.",
    "FIXME: gracefully handle errors here or in the caller?",
    "FIXME: handle other kinds of assignments?",
    "string conversion routines",
    "Check if the referenced member can have a docstring or not",
    "Referenced object has a docstring",
    "Latex collects all references to a separate bibliography,",
    "so we need to insert links to it",
    "-*- coding: utf-8 -*-",
    "Convert signode to a specified format",
    "Call user code to resolve the link",
    "no source",
    "only one link per name, please",
    "------------------------------------------------------------------------------",
    "Creating 'phantom' modules from an XML description",
    "------------------------------------------------------------------------------",
    "Sort items so that",
    "- Base classes come before classes inherited from them",
    "- Modules come before their contents",
    "Create phantom items",
    "create parent, if missing",
    "create object",
    "Populate items",
    "-*- coding: utf-8 -*-",
    "##########################################################################",
    "A tensor is simply a numpy array",
    "##########################################################################",
    "Unfolding a tensor is easy",
    "##########################################################################",
    "Re-folding the tensor is as easy:",
    "-*- coding: utf-8 -*-",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor that follows the PARAFAC2 constraints found",
    "inx `(Kiers et al 1999)`_.",
    "",
    "This particular tensor,",
    ":math:`\\mathcal{X}\u00a0\\in \\mathbb{R}^{I\\times J \\times K}`, is a shifted",
    "CP tensor, that is, a tensor on the form:",
    "",
    ".. math::",
    "\\mathcal{X}_{ijk} = \\sum_{r=1}^R A_{ir} B_{\\sigma_i(j) r} C_{kr},",
    "",
    "where :math:`\\sigma_i`\u00a0is a cyclic permutation of :math:`J` elements.",
    "Set parameters",
    "Generate random matrices",
    "Normalised factor matrices",
    "Generate the shifted factor matrix",
    "Construct the tensor",
    "Add noise",
    "#############################################################################",
    "Fit a PARAFAC2 tensor",
    "---------------------",
    "To avoid local minima, we initialise and fit 10 models and choose the one",
    "with the lowest error",
    "#############################################################################",
    "A decomposition is a wrapper object for three variables: the *weights*,",
    "the *factor matrices* and the *projection matrices*. The weights are similar",
    "to the output of a CP decomposition. The factor matrices and projection",
    "matrices are somewhat different. For a CP decomposition, we only have the",
    "weights and the factor matrices. However, since the PARAFAC2 factor matrices",
    "for the second mode is given by",
    "",
    ".. math::",
    "B_i = P_i B,",
    "",
    "where :math:`B` is an :math:`R \\times R` matrix and :math:`P_i` is an",
    ":math:`I \\times R` projection matrix, we cannot store the factor matrices",
    "the same as for a CP decomposition.",
    "",
    "Instead, we store the factor matrix along the first mode (:math:`A`), the",
    "\"blueprint\" matrix for the second mode (:math:`B`) and the factor matrix",
    "along the third mode (:math:`C`) in one tuple and the projection matrices,",
    ":math:`P_i`, in a separate tuple.",
    "",
    "If we wish to extract the informative :math:`B_i` factor matrices, then we",
    "use the ``tensorly.parafac2_tensor.apply_projection_matrices`` function on",
    "the PARAFAC2 tensor instance to get another wrapper object for two",
    "variables: *weights* and *factor matrices*. However, now, the second element",
    "of the factor matrices tuple is now a list of factor matrices, one for each",
    "frontal slice of the tensor.",
    "",
    "Likewise, if we wish to construct the tensor or the frontal slices, then we",
    "can use the ``tensorly.parafac2_tensor.parafac2_to_tensor`` function. If the",
    "decomposed dataset consisted of uneven-length frontal slices, then we can",
    "use the ``tensorly.parafac2_tensor.parafac2_to_slices`` function to get a",
    "list of frontal slices.",
    "#############################################################################",
    "Compute performance metrics",
    "---------------------------",
    "To evaluate how well the original structure is recovered, we calculate the tucker congruence coefficient.",
    "#############################################################################",
    "Visualize the components",
    "------------------------",
    "Find the best permutation so that we can plot the estimated components on top of the true components",
    "Create plots of each component vector for each mode",
    "(We just look at one of the B_i matrices)",
    "Plot true and estimated components for mode A",
    "Labels for the different components",
    "Plot true and estimated components for mode C",
    "Plot true components for mode B",
    "Get the signs so that we can flip the B mode factor matrices",
    "Plot estimated components for mode B (after sign correction)",
    "Titles for the different modes",
    "Create a legend for the entire figure",
    "#############################################################################",
    "Inspect the convergence rate",
    "----------------------------",
    "It can be interesting to look at the loss plot to make sure that we have",
    "converged to a stationary point. We skip the first iteration since the",
    "initial loss often dominate the rest of the plot, making it difficult",
    "to check for convergence.",
    "#############################################################################",
    "References",
    "----------",
    "",
    ".. _(Kiers et al 1999):",
    "",
    "Kiers HA, Ten Berge JM, Bro R. *PARAFAC2\u2014Part I.",
    "A direct fitting algorithm for the PARAFAC2 model.*",
    "**Journal of Chemometrics: A Journal of the Chemometrics Society.**",
    "1999 May;13(3\u20104):275-94. `(Online version)",
    "<https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-128X(199905/08)13:3/4%3C275::AID-CEM543%3E3.0.CO;2-B>`_",
    "Rank of the CP decomposition",
    "Rank of the Tucker decomposition",
    "Perform the CP decomposition",
    "Reconstruct the image from the factors",
    "Tucker decomposition",
    "Plotting the original and reconstruction from the decompositions",
    "Get a high-accuracy decomposition for comparison",
    "Run PARAFAC decomposition without line search and time",
    "Run PARAFAC decomposition with line search and time",
    "Calculate the error of both decompositions",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Should we allow None weights?",
    "it's already been validated at creation",
    "if len(factors) < 2:",
    "raise ValueError('A CP tensor should be composed of at least two factors.'",
    "'However, {} factor was given.'.format(len(factors)))",
    "Skip the target mode",
    "Calculate the sign of the current factor in each component",
    "Update both the current and receiving factor",
    "Check the weight signs",
    "Test for the validity of the operation",
    "norm = T.dot(T.dot(weights, norm), weights)",
    "We sum even if weigths is not None",
    "as e.g. MXNet would return a 1D tensor, not a 0D tensor",
    "Deprecated classes and functions",
    "Note how tt_matrix_to_tensor is implemented in tenalg to allow for more efficient implementations",
    "(e.g. using the einsum backend)",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Test for the validity of the operation",
    "rank is 'same' or float: choose rank so as to preserve a fraction of the original #parameters",
    "sorted to be careful with the order when popping and reinserting to not remove/add at wrong index.",
    "list (mode, shape) that we removed as they will be kept the same, rank[i] =",
    "number of parameters coming from the fixed modes (these don't have a variable size as a fun of fraction_param)",
    "Doesn't contain fixed_modes, those factors are accounted for in fixed_params",
    "it's already been validated at creation",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Border rank of 1, R_0 = R_N = 1",
    "First and last factor of size I_0 R and I_N R",
    "We want the number of params of decomp (=sum of params of factors)",
    "To be equal to c = \\prod_k I_k",
    "We get the non-negative solution",
    "Choose a rank proportional to the size of each mode",
    "The method is similar to the above one for constant_rank == True",
    "We get the non-negative solution",
    "Check user input for potential errors",
    "Initialization",
    "Will raise an error if invalid",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "it's already been validated at creation",
    "Skip first factor matrix since the rank is extracted from it.",
    "allocate variables for weights, and normalized factors",
    "if (not copy) and (weights is None):",
    "warnings.warn('Provided copy=False and weights=None: a new Parafac2Tensor'",
    "'with new weights and factors normalised inplace will be returned.')",
    "weights = T.ones(rank, **T.context(factors[0]))",
    "The if test below was added to enable inplace edits",
    "however, TensorFlow does not support inplace edits",
    "so this is always set to True",
    "Deprecated",
    "Add Backend functions, dynamically dispatched",
    "Getting the TT factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TT factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "A TTM with a single factor is just a matrix...",
    "A list of candidates for each mode",
    "Refine the init",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "License: BSD 3 clause",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "TODO: this is a hack but it seems to do the job for now",
    "TODO: Test this",
    "If we have to update the mask we already have to build the full tensor",
    "Update the tensor based on the mask",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Will we be performing a line search iteration",
    "Calculate the current unnormalized error if we need it",
    "Start line search if requested.",
    "For each matrix, randomly choose n_samples indices for which to compute the khatri-rao product",
    "Compute corresponding rows of the full khatri-rao product",
    "Compute the Khatri-Rao product for the chosen indices",
    "Keep all the elements of the currently considered mode",
    "MXNet will not be happy if this is a list insteaf of a tuple",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Fix to address surprising MXNet.numpy behavior (Issue #19891)",
    "Initialise the decompositions",
    "Norm of the reconstructions at each iteration",
    "Update the lagrangian multipliers",
    "Evolution of the reconstruction errors",
    "Convergence check",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "A list of candidates for each mode",
    "Refine the init",
    "Deprecated",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "SVD init",
    "The initial core approximation is needed here for the masking step",
    "len(rank) == len(modes) but we still want a core dimension for the modes not optimized",
    "The factors are orthonormal and therefore do not affect the reconstructed tensor's norm",
    "TO-DO validate rank for partial tucker as well",
    "Initialisation",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "Aaron Meyer <tensorly@ameyer.me>",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan TUna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "NNDSVD initialization",
    "The leading singular triplet is non-negative",
    "so it can be used as is for initialization.",
    "extract positive and negative parts of column vectors",
    "and their norms",
    "choose update",
    "After this point we no longer need H",
    "Apply nnsvd to make non-negative",
    "TODO: this is a hack but it seems to do the job for now",
    "TODO: Test this",
    "khatri_rao(factors).tl.dot(khatri_rao(factors))",
    "simplifies to multiplications",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Avoiding errors",
    "Generating the mode update sequence",
    "initialisation - declare local varaibles",
    "Iteratation",
    "One pass of least squares on each updated mode",
    "Computing Hadamard of cross-products",
    "Take into account init weights",
    "Call the hals resolution with nnls, optimizing the current mode",
    "check recovery",
    "check low rank recovery",
    "Check for sparsity of the gross error",
    "assert tl.sum(noise_pred > 0.01) == tl.sum(noise > 0.01)",
    "check sparse gross error recovery",
    "###########################",
    "Test with missing values #",
    "###########################",
    "Add some corruption (missing values, replaced by ones)",
    "Decompose the tensor",
    "check recovery",
    "check low rank recovery",
    "check sparse gross error recovery",
    "Check for recovery of the corrupted/missing part",
    "Check that the error monotonically decreases",
    "TODO: This doesn't always pass with these other options",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Check that sparse component works",
    "Check that we get roughly the same answer with the full tensor and masking",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "test tensor reconstructed properly",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "Test random_state fixes the core and the factor matrices",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "try fixing the core",
    "Random and SVD init should converge to a similar solution",
    "Mask an outlier value, and check that the decomposition ignores it",
    "We won't use the SVD decomposition, but check that it at least runs successfully",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Test the max abs difference between the reconstruction and the tensor",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Deprecated",
    "Generate a random state for me",
    "random state from integer seed",
    "if it is already a random state, just return it",
    "only takes as seed a random state, an int or None",
    "tests that the columns of each factor matrix are indeed orthogonal",
    "(See issue #40)",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Author: Taylor Lee Patti <taylorpatti@g.harvard.edu>",
    "All density matrices are Hermitian, here real. Hermitianize matrix if rounding/transformation",
    "errors have occured.",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "TODO: write a function to do this..",
    "Check user input for errors",
    "Make sure iter's not a tuple but a list",
    "Initialize rank",
    "list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.",
    "list row_idx: row indices    (left indices)  for skeleton-decomposition: indicate which rows used in each core.",
    "Initialize indice: random selection of column indices",
    "Initialize the cores of tensor-train",
    "#####################################",
    "left-to-right step",
    "list row_idx: list of (tensor_order-1) of lists of left indices",
    "update row indices",
    "end left-to-right step",
    "##############################################",
    "##############################################",
    "right-to-left step",
    "list col_idx: list (tensor_order-1) of lists of right indices",
    "update col indices",
    "Compute cores",
    "The rank should not be larger than the input tensor's size",
    "Add the last core",
    "end right-to-left step",
    "###############################################",
    "check the error for while-loop",
    "check convergence",
    "Extract fibers according to the row and col indices",
    "Extract the core",
    "shape the core as a 3-tensor_order cube",
    "merge r_k and n_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "Extract fibers",
    "shape the core as a 3-tensor_order cube",
    "merge n_{k-1} and r_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "The index of row of the submatrix",
    "Rest of rows / unselected rows",
    "Find r rows iteratively",
    "Compute the square of norm of each row",
    "If there is only one row of A left, let's just return it. MxNet is not robust about this case.",
    "If a row is 0, we delete it.",
    "Find the row of max norm",
    "Compute the projection of max_row to other rows",
    "projection a to b is computed as: <a,b> / sqrt(|a|*|b|)",
    "make sure normalization vector is of the same shape of projection (causing bugs for MxNet)",
    "Subtract the projection from A_new:  b <- b - a * projection",
    "Delete the selected row",
    "update the row_idx and rest_of_rows",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TEST 4",
    "Random tensor is not really compress-able. Test on a tensor as values of a function",
    "Find TT decomposition of the tensor",
    "Deprecated",
    "Make sure the algorithm stays sparse. This will run out of memory on",
    "most machines if the algorithm densifies.",
    "Will blow-up memory if not sparse-safe",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Default on standard SVD",
    "all-zeros matrix, so we should do a quick return.",
    "We can perform a partial SVD",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "use dense form when sparse form will fail",
    "use dense form when sparse form will fail",
    "WARNING: here, V is still the transpose of what it should be",
    "Check correct rank and shapes are returned",
    "One of the factors has the wrong rank",
    "Not the correct amount of weights",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test cp_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test cp_mode_dot with vec",
    "Version forming explicitely the khatri-rao product",
    "Efficient sparse-safe version",
    "Rounding = floor",
    "Rounding = ceil",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not three factor matrices",
    "Not enough projections",
    "Wrong number of weights",
    "The projections aren't orthogonal",
    "Disable tests for inplace edits, since that possibility is removed",
    "to support TensorFlow.",
    "@pytest.mark.parametrize('copy', [True, False])",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Create tensor",
    "Compute ground truth TT factors",
    "Check that TT factors re-assemble to the original tensor",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Reconstruct the original tensor",
    "Check that the rank is 10",
    "Rounding = floor",
    "Rounding = ceil",
    "Author: Jean Kossaifi",
    "Set in context manager",
    "Sets back to numpy",
    "Reset back to initial backend",
    "Set not in context manager",
    "Improper name doesn't reset backend",
    "Changes only happen locally in this thread",
    "Set the global default backend",
    "Changed toplevel default in all threads",
    "True reconstruction error (based on numpy SVD)",
    "Reconstruction error with the backend's SVD",
    "Check that the two are similar",
    "Check for orthogonality when relevant",
    "Should fail on non-matrices",
    "Test for singular matrices (some eigenvals will be zero)",
    "Rank at most 5",
    "Test if partial_svd returns the same result for the same setting",
    "limit as order->oo is the oo-norm",
    "1D",
    "2D",
    "3D",
    "random testing against Numpy's output",
    "assert that the columns of Q are orthonormal",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not enough factors to match core",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test tucker_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test tucker_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "With fixed modes",
    "Floor",
    "Ceil",
    "Author: Jean Kossaifi",
    "hard coded example",
    "check dims",
    "chain unfolding and folding",
    "Convert to vector and back to tensor",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "We created here a tensor with 3 samples, each sample being similar to X",
    "Test for raveled tensor",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Test for raveled tensor",
    "Test for raveled_tensor=True",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "we created here a tensor with 3 samples, each sample being similar to X",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "New function renaming old_fun",
    "Old fun will return fun but issue a deprecation warning",
    "Test using the deprecated function",
    "Test using the new function instead",
    "Author: Jean Kossaifi",
    "Jeremy Cohen <jeremy.cohen@irisa.fr>",
    "Axel Marmoret <axel.marmoret@inria.fr>",
    "Caglayan TUna <caglayantun@gmail.com>",
    "License: BSD 3 clause",
    "Scaling",
    "Safety procedure, if columns aren't allow to be zero",
    "print('hello')",
    "Equivalence with inner product when contracting with self along all modes",
    "Equivalence with n-mode-dot",
    "Multi-mode-dot",
    "Wrong number of modes",
    "size mismatch",
    "Author: Jean Kossaifi",
    "small test",
    "account for floating point errors: np array have a precision of around 2e-15",
    "check np.finfo(np.float64).eps",
    "Check that we did not change the original tensor",
    "Another test",
    "Test with missing values",
    "Author: Jean Kossaifi",
    "resulting matrix must be of shape (prod(n_rows), n_columns)",
    "fail case: all matrices must have same number of columns",
    "all matrices should be of dim 2...",
    "Classic example/test",
    "A = np.hstack((np.eye(3), np.arange(3)[:, None]))",
    "Test with one matrix only: khatri-rao of one matrix = that matrix",
    "Author: Jean Kossaifi",
    "Mathematical test",
    "Another test",
    "Adding a third matrices",
    "Test for the reverse argument",
    "Check that the original list has not been reversed",
    "Check the returned shape",
    "Khatri-rao is a column-wise kronecker product",
    "Khatri-rao product is a column-wise kronecker product",
    "Test while skipping a matrix",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "For one common mode, equivalent to dot product",
    "For no common mode, equivalent to inner product",
    "Inner product of tensors with different shapes is not defined",
    "tensor times matrix",
    "######################",
    "tensor times vector #",
    "######################",
    "Test with a matrix",
    "Test with a third order tensor",
    "Using equivalence with unfolded expression",
    "########################################",
    "Test for errors that should be raised #",
    "########################################",
    "Same test for the vector case",
    "Cannot take mode product of tensor with tensor",
    "Test using the equivalence with unfolded expression",
    "Test skipping a factor",
    "Test contracting with a vector",
    "result should be a scalar",
    "Average pooling each mode",
    "Order should not matter",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Indices of each matrix",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "However, it is needed to pop dimensions contracted over",
    "print(i, matrix_or_vec.shape, mode)",
    "print(f'skipping {skip}')",
    "We are contracting over the mode-th dimension",
    "mat_symbol = f'{tensor_modes[mode]}{chr(counter)}'",
    "Contracting mode-th mode with a matrix: new dimension",
    "If fully contracting",
    "matrix_or_vec_list = [m for (i, m) in enumerate(matrix_or_vec_list) if ((skip is None) or (skip != i))]",
    "print(equation, tl.shape(tensor), [tl.shape(f) for f in matrix_or_vec_list])",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Each core is of shape (rank_left, size_in, size_out, rank_right)",
    "Intertwine the dims",
    "full_shape = in_shape[0], out_shape[0], in_shape[1], ...",
    "factor = factor.squeeze(0)",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Ideally this should be (), i.e. order-0 tensors",
    "MXNet currently doesn't support this though..",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "source_fun, target_fun",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Just perform trucated SVD",
    "If n_eigenvecs == min_dim, we don't want full_matrices=True, it's super slow",
    "We can perform a partial SVD",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "WARNING: here, V is still the transpose of what it should be",
    "Check that matrix is... a matrix!",
    "Check that matrix is... a matrix!",
    "Check that matrix is... a matrix!",
    "transpose matrix to keep the reduced matrix shape minimal",
    "Perform power iterations when spectrum decays slowly",
    "pytorch does not accept `None` for any keyword arguments. additionally,",
    "pytorch doesn't seems to support keyword arguments in the first place",
    "Currently, gesv doesn't support vectors for matrix2",
    "So we instead solve a least square problem...",
    "Currently, solve doesn't support vectors for matrix2",
    "Register the other functions",
    "PyTorch 1.8.0 has a much better NumPy interface but somoe haven't updated yet",
    "Old version, will be removed in the future",
    "New PyTorch NumPy interface",
    "MXNet doesn't provide an option for full_matrices=True",
    "Backend is a string",
    "Set the backend",
    "We don't use `functools.wraps` here because some of the dispatched",
    "methods include the backend (`self`) as a parameter. Instead we manually",
    "copy over the needed information, and filter the signature for `self`.",
    "Generic methods, exposed as part of the public API",
    "Initialise the backend to the default one",
    "dispatch non-callables (e.g. dtypes, index)",
    "Swiss",
    "Rectangle",
    "circle: approximate test",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise modes of W",
    "Regress phi on y: we could call a package here, e.g. scikit-learn",
    "Convergence check",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise each factor of W",
    "Convergence check",
    "Parameter of the experiment",
    "Generate random samples",
    "Parameter of the experiment",
    "Generate random samples"
  ],
  "0.5.1": [
    "Ignore already minified files",
    "Ignore already minified files",
    "!/usr/bin/env python3",
    "-*- coding: utf-8 -*-",
    "",
    "tensorly documentation build configuration file",
    "",
    "This file is execfile()d with the current directory set to its",
    "containing dir.",
    "",
    "Note that not all possible configuration values are present in this",
    "autogenerated file.",
    "",
    "All configuration values have a default; values that are commented out",
    "serve to show the default.",
    "If extensions (or modules to document with autodoc) are in another directory,",
    "add these directories to sys.path here. If the directory is relative to the",
    "documentation root, use os.path.abspath to make it absolute, like shown here.",
    "sys.path.insert(0, os.path.abspath('sphinx_ext'))",
    "-- General configuration ------------------------------------------------",
    "If your documentation needs a minimal Sphinx version, state it here.",
    "needs_sphinx = '1.0'",
    "Add any Sphinx extension module names here, as strings. They can be",
    "extensions coming with Sphinx (named 'sphinx.ext.*') or your custom",
    "ones.",
    "path to your examples scripts",
    "path where to save gallery generated examples",
    "Add any paths that contain templates here, relative to this directory.",
    "generate autosummary even if no references",
    "The suffix(es) of source filenames.",
    "You can specify multiple suffix as a list of string:",
    "source_suffix = ['.rst', '.md']",
    "The encoding of source files.",
    "source_encoding = 'utf-8-sig'",
    "The master toctree document.",
    "General information about the project.",
    "The version info for the project you're documenting, acts as replacement for",
    "|version| and |release|, also used in various other places throughout the",
    "built documents.",
    "",
    "The short X.Y version.",
    "version = '0.1'",
    "The full version, including alpha/beta/rc tags.",
    "release = ''",
    "The language for content autogenerated by Sphinx. Refer to documentation",
    "for a list of supported languages.",
    "",
    "This is also used if you do content translation via gettext catalogs.",
    "Usually you set \"language\" from the command line for these cases.",
    "There are two options for replacing |today|: either, you set today to some",
    "non-false value, then it is used:",
    "today = ''",
    "Else, today_fmt is used as the format for a strftime call.",
    "today_fmt = '%B %d, %Y'",
    "List of patterns, relative to source directory, that match files and",
    "directories to ignore when looking for source files.",
    "This patterns also effect to html_static_path and html_extra_path",
    "The reST default role (used for this markup: `text`) to use for all",
    "documents.",
    "default_role = None",
    "If true, '()' will be appended to :func: etc. cross-reference text.",
    "If true, the current module name will be prepended to all description",
    "unit titles (such as .. function::).",
    "If true, sectionauthor and moduleauthor directives will be shown in the",
    "output. They are ignored by default.",
    "show_authors = False",
    "The name of the Pygments (syntax highlighting) style to use.",
    "A list of ignored prefixes for module index sorting.",
    "modindex_common_prefix = []",
    "If true, keep warnings as \"system message\" paragraphs in the built documents.",
    "keep_warnings = False",
    "If true, `todo` and `todoList` produce output, else they produce nothing.",
    "-- Options for HTML output ----------------------------------------------",
    "The theme to use for HTML and HTML Help pages.  See the documentation for",
    "a list of builtin themes.",
    "Add any paths that contain custom themes here, relative to this directory.",
    "Theme options are theme-specific and customize the look and feel of a theme",
    "further.  For a list of options available for each theme, see the",
    "documentation.",
    "The name for this set of Sphinx documents.",
    "\"<project> v<release> documentation\" by default.",
    "A shorter title for the navigation bar.  Default is the same as html_title.",
    "The name of an image file (relative to this directory) to place at the top",
    "of the sidebar.",
    "The name of an image file (relative to this directory) to use as a favicon of",
    "the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32",
    "pixels large.",
    "html_favicon = None",
    "Add any paths that contain custom static files (such as style sheets) here,",
    "relative to this directory. They are copied after the builtin static files,",
    "so a file named \"default.css\" will overwrite the builtin \"default.css\".",
    "html_additional_pages = {",
    "}",
    "Add any extra paths that contain custom files (such as robots.txt or",
    ".htaccess) here, relative to this directory. These files are copied",
    "directly to the root of the documentation.",
    "html_extra_path = []",
    "If not None, a 'Last updated on:' timestamp is inserted at every page",
    "bottom, using the given strftime format.",
    "The empty string is equivalent to '%b %d, %Y'.",
    "html_last_updated_fmt = None",
    "If true, SmartyPants will be used to convert quotes and dashes to",
    "typographically correct entities.",
    "html_use_smartypants = True",
    "Custom sidebar templates, maps document names to template names.",
    "html_sidebars = {}",
    "Additional templates that should be rendered to pages, maps page names to",
    "template names.",
    "html_additional_pages = {}",
    "If false, no module index is generated.",
    "If false, no index is generated.",
    "If true, the index is split into individual pages for each letter.",
    "html_split_index = False",
    "If true, links to the reST sources are added to the pages.",
    "If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.",
    "If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.",
    "html_show_copyright = True",
    "If true, an OpenSearch description file will be output, and all pages will",
    "contain a <link> tag referring to it.  The value of this option must be the",
    "base URL from which the finished HTML is served.",
    "html_use_opensearch = ''",
    "This is the file name suffix for HTML files (e.g. \".xhtml\").",
    "html_file_suffix = None",
    "Language to be used for generating the HTML full-text search index.",
    "Sphinx supports the following languages:",
    "'da', 'de', 'en', 'es', 'fi', 'fr', 'h', 'it', 'ja'",
    "'nl', 'no', 'pt', 'ro', 'r', 'sv', 'tr', 'zh'",
    "html_search_language = 'en'",
    "A dictionary with options for the search language support, empty by default.",
    "'ja' uses this config value.",
    "'zh' user can custom change `jieba` dictionary path.",
    "html_search_options = {'type': 'default'}",
    "The name of a javascript file (relative to the configuration directory) that",
    "implements a search results scorer. If empty, the default will be used.",
    "html_search_scorer = 'scorer.js'",
    "Output file base name for HTML help builder.",
    "-- Options for LaTeX output ---------------------------------------------",
    "Grouping the document tree into LaTeX files. List of tuples",
    "(source start file, target name, title,",
    "author, documentclass [howto, manual, or own class]).",
    "\\setcounter{MaxMatrixCols}{20} corrects an ugly bug if you try to have a matrix of more than 10 elements or so",
    "We want the same for the html version:",
    "The name of an image file (relative to this directory) to place at the top of",
    "the title page.",
    "latex_logo = None",
    "For \"manual\" documents, if this is true, then toplevel headings are parts,",
    "not chapters.",
    "latex_use_parts = False",
    "If true, show page references after internal links.",
    "If true, show URL addresses after external links.",
    "Documents to append as an appendix to all manuals.",
    "latex_appendices = []",
    "Get completely rid of index",
    "If false, no module index is generated.",
    "latex_domain_indices = True",
    "-- Options for manual page output ---------------------------------------",
    "One entry per manual page. List of tuples",
    "(source start file, name, description, authors, manual section).",
    "If true, show URL addresses after external links.",
    "man_show_urls = False",
    "-- Options for Texinfo output -------------------------------------------",
    "Grouping the document tree into Texinfo files. List of tuples",
    "(source start file, target name, title, author,",
    "dir menu entry, description, category)",
    "Documents to append as an appendix to all manuals.",
    "texinfo_appendices = []",
    "If false, no module index is generated.",
    "texinfo_domain_indices = True",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "texinfo_show_urls = 'footnote'",
    "If true, do not generate a @detailmenu in the \"Top\" node's menu.",
    "texinfo_no_detailmenu = False",
    "-- Options for Epub output ----------------------------------------------",
    "Bibliographic Dublin Core info.",
    "The basename for the epub file. It defaults to the project name.",
    "epub_basename = project",
    "The HTML theme for the epub output. Since the default themes are not",
    "optimized for small screen space, using the same theme for HTML and epub",
    "output is usually not wise. This defaults to 'epub', a theme designed to save",
    "visual space.",
    "epub_theme = 'epub'",
    "The language of the text. It defaults to the language option",
    "or 'en' if the language is not set.",
    "epub_language = ''",
    "The scheme of the identifier. Typical schemes are ISBN or URL.",
    "epub_scheme = ''",
    "The unique identifier of the text. This can be a ISBN number",
    "or the project homepage.",
    "epub_identifier = ''",
    "A unique identification for the text.",
    "epub_uid = ''",
    "A tuple containing the cover image and cover page html template filenames.",
    "epub_cover = ()",
    "A sequence of (type, uri, title) tuples for the guide element of content.opf.",
    "epub_guide = ()",
    "HTML files that should be inserted before the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_pre_files = []",
    "HTML files that should be inserted after the pages created by sphinx.",
    "The format is a list of tuples containing the path and title.",
    "epub_post_files = []",
    "A list of files that should not be packed into the epub file.",
    "The depth of the table of contents in toc.ncx.",
    "epub_tocdepth = 3",
    "Allow duplicate toc entries.",
    "epub_tocdup = True",
    "Choose between 'default' and 'includehidden'.",
    "epub_tocscope = 'default'",
    "Fix unsupported image types using the Pillow.",
    "epub_fix_images = False",
    "Scale large images.",
    "epub_max_image_width = 0",
    "How to display URL addresses: 'footnote', 'no', or 'inline'.",
    "epub_show_urls = 'inline'",
    "If false, no index is generated.",
    "epub_use_index = True",
    "Top bar burger",
    "SIDEBAR",
    "Fix sidebar on scroll",
    "if(timer) { window.clearTimeout(timer); }",
    "make current position active on the sidebar",
    "toggle show",
    "var attribute = this.parentNode.querySelector(\"ul\").classList.toggle('show');",
    "highlight new position",
    "Add listeners to all elements",
    "Second level list",
    "Remove the doc at the beginning of the name of the functions",
    "-*- coding: utf-8 -*-",
    "Created: Sun May 21 20:38:59 2017",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Created Sun Nov 27 14:03:07 2016",
    "Author: \u00d3scar N\u00e1jera",
    "can't use codecs.open(filename, 'r', 'utf-8') here b/c ast doesn't",
    "seem to work with unicode strings in Python2.7",
    "\"SyntaxError: encoding declaration in Unicode string\"",
    "change from Windows format to UNIX for uniformity",
    "This get the content of the file after the docstring last line",
    "Note: 'maxsplit' argument is not a keyword argument in python2",
    "sphinx_gallery_<name> = <value>",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "Try Python 3 first, otherwise load from Python 2",
    "This is a.b, not e.g. a().b",
    "need to get a in a().b",
    "Join import path to relative path",
    "Find out what the real object is supposed to be.",
    "Ensure shortened object is the same as what we expect.",
    "get the last working module name",
    "name is as written in file (e.g. np.asarray)",
    "full_name includes resolved import path (e.g. numpy.asarray)",
    "module without attribute. This is not useful for",
    "backreferences",
    "get shortened module name",
    "Inside rst files forward slash defines paths",
    "-*- coding: utf-8 -*-",
    "This gets set when the extension is initialized.",
    "colorfunc is a valid kwarg in 1.5, but not older, so we just",
    "apply it ourselves.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Try Python 2 first, otherwise load from Python 3",
    "shelve keys need to be str in python 2",
    "value is a list",
    "try to convert elements to int",
    "value is another dictionary",
    "Make sure searchindex uses UTF-8 encoding",
    "parse objects",
    "parse filenames",
    "detect if we are using relative links on a Windows system",
    "download and initialize the search index",
    "In 1.5+ Sphinx seems to have changed from .rst.html to only",
    ".html extension in converted files. But URLs could be",
    "built with < 1.5 or >= 1.5 regardless of what we're currently",
    "building with, so let's just check both :(",
    "test if cobj appears in page",
    "we don't have it cached",
    "cache it for the future",
    "failed to resolve",
    "replace '\\' with '/' so it on the web",
    "for some reason, the relative link goes one directory too high up",
    "Add resolvers for the packages for which we want to show links",
    "patterns for replacement",
    "This could be turned into a generator if necessary, but should be okay",
    "we have a pickle file with the objects to embed links for",
    "generate replacement strings with the links",
    "do the replacement in the html file",
    "ensure greediness",
    "No need to waste time embedding hyperlinks when not running the examples",
    "XXX: also at the time of writing this fixes make html-noplot",
    "for some reason I don't fully understand",
    "XXX: Whitelist of builders for which it makes sense to embed",
    "hyperlinks inside the example html. Note that the link embedding",
    "require searchindex.js to exist for the links to the local doc",
    "and there does not seem to be a good way of knowing which",
    "builders creates a searchindex.js.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "##############################################################################",
    "Notebook shell utility",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "build options",
    "Sphinx hack: sphinx copies generated images to the build directory",
    "each time the docs are made.  If the desired image name already",
    "exists, it appends a digit to prevent overwrites.  The problem is,",
    "the directory is never cleared.  This means that each time you build",
    "the docs, the number of images in the directory grows.",
    "",
    "This question has been asked on the sphinx development list, but there",
    "was no response: https://git.net/ml/sphinx-dev/2011-02/msg00123.html",
    "",
    "The following is a hack that prevents this behavior by clearing the",
    "image build directory from gallery images each time the docs are built.",
    "If sphinx changes their layout between versions, this will not",
    "work (though it should probably not cause a crash).",
    "Tested successfully on Sphinx 1.0.7",
    "this assures I can call the config in other places",
    "Here we don't use an os.walk, but we recurse only twice: flat is",
    "better than nested.",
    "we create an index.rst with all examples",
    ":orphan: to suppress \"not included in TOCTREE\" sphinx warnings",
    "touch file",
    "Under no-plot Examples are not run so nothing to summarize",
    "Sphinx < 1.6 calls it `_extensions`, >= 1.6 is `extensions`.",
    "HACK: Stop nosetests running setup() above",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Don't use unicode_literals here (be explicit with u\"...\" instead) otherwise",
    "tricky errors come up with exec(code_blocks, ...) calls",
    "Try Python 2 first, otherwise load from Python 3",
    "textwrap indent only exists in python 3",
    "make sure that the Agg backend is set before importing any",
    "matplotlib",
    "##############################################################################",
    "##############################################################################",
    "The following strings are used when we have several pictures: we use",
    "an html div tag that our CSS uses to turn the lists into horizontal",
    "lists.",
    "This one could contain unicode",
    "Sphinx only starts numbering from the first non-empty line.",
    "lstrip is just in case docstring has a '\\n\\n' at the beginning",
    "Set the fig_num figure as the current figure as we can't",
    "save a figure that's not the current figure.",
    "make sure the image is not too large",
    "local import to avoid testing dependency on PIL:",
    "resize the image",
    "insert centered",
    "Use optipng to perform lossless compression on the resized image if",
    "software is installed",
    "read specification of the figure to display as thumbnail from main text",
    "create something to replace the thumbnail",
    "Add empty lines to avoid bug in issue #165",
    "sort to have the smallest entries in the beginning",
    "clear at the end of the section",
    "Remove our code from traceback:",
    "Remove one extra level through ast.parse.",
    "Breaks build on first example error",
    "Stores failing file",
    "If example is not suitable to run, skip executing its blocks",
    "Redirect output to stdout and",
    "First cd in the original example dir, so that any file",
    "created by the example get created in this directory",
    "don't use unicode_literals at the top of this file or you get",
    "nasty errors here on Py2.7",
    "Horrible code to 'unload' seaborn, so that it resets",
    "its default when is load",
    "Python does not support unloading of modules",
    "https://bugs.python.org/issue9072",
    "Reset Matplotlib to default",
    "A lot of examples contains 'print(__doc__)' for example in",
    "scikit-learn so that running the example prints some useful",
    "information. Because the docstring has been separated from",
    "the code blocks in sphinx-gallery, __doc__ is actually",
    "__builtin__.__doc__ in the execution context and we do not",
    "want to print it",
    "Examples may contain if __name__ == '__main__' guards",
    "for in example scikit-learn if the example uses multiprocessing",
    "Don't ever support __file__: Issues #166 #212",
    "A simple example has two blocks: one for the",
    "example introduction/explanation and one for the code",
    "We want to run the example without arguments. See",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/252",
    "for more details.",
    "Add some vertical space after output",
    "Writes md5 checksum if example has build correctly",
    "not failed and was initially meant to run(no-plot shall not cache md5sum)",
    "-*- coding: utf-8 -*-",
    "Error + critical both go through warning:",
    "-*- coding: utf-8 -*-",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Need to import gen_rst before matplotlib.pyplot to set backend to 'Agg'",
    "For more details see",
    "https://github.com/sphinx-gallery/sphinx-gallery/pull/49",
    "verify correct md5sum",
    "False because is a new file",
    "Write md5sum to file to check is current",
    "read rst file and check if it contains traceback output",
    "create three files in tempdir (only one matches the pattern)",
    "generate rst file",
    "read rst file and check if it contains code output",
    "which plot to show as the thumbnail image",
    "test issue #229",
    "TODO: test that broken thumbnail does appear when needed",
    "TODO: test that examples are not executed twice",
    "TODO: test that examples are executed after a no-plot and produce",
    "the correct image in the thumbnail",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "recovers data from temporary file and caches it in the shelve",
    "tests recovered data matches",
    "test if cached data is available after temporary file has vanished",
    "shelve keys need to be str in python 2, deal with unicode input",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "General information about the project.",
    "no duplicate values allowed The config is present already",
    "General information about the project.",
    "General information about the project.",
    "General information about the project.",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Test fails on wrong input",
    "Test missing folder",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "-*- coding: utf-8 -*-",
    "Author: \u00d3scar N\u00e1jera",
    "License: 3-clause BSD",
    "Python2",
    "##############################################################################",
    "Notebook shell utility",
    "replace reference numbers so that there are no duplicates",
    "Strip top title",
    "call function to replace reference numbers so that there are no",
    "duplicates",
    "Do not try to inspect classes that don't define `__init__`",
    "Extra mangling domains",
    "------------------------------------------------------------------------------",
    "Docstring-mangling domains",
    "------------------------------------------------------------------------------",
    "go to next non-empty line in old:",
    "line.strip() checks whether the string is all whitespace",
    "------------------------------------------------------------------------------",
    "Registration hook",
    "------------------------------------------------------------------------------",
    "------------------------------------------------------------------------------",
    "plot:: directive",
    "------------------------------------------------------------------------------",
    "no argument given, assume used as a flag",
    "------------------------------------------------------------------------------",
    "Generating output",
    "------------------------------------------------------------------------------",
    "Sphinx depends on either Jinja or Jinja2",
    "determine input",
    "ensure that LaTeX includegraphics doesn't choke in foo.bar.pdf filenames",
    "is it in doctest format?",
    "determine output directory name fragment",
    "build_dir: where to place output files (temporarily)",
    "output_dir: final location in the builder's directory",
    "how to link to files from the RST file",
    "make figures",
    "generate output restructuredtext",
    "copy image files to builder's output directory",
    "copy script (if necessary)",
    "------------------------------------------------------------------------------",
    "Run code and capture figures",
    "------------------------------------------------------------------------------",
    "check if it's valid Python as-is",
    "Change the working directory to the directory of the example, so",
    "it can get at its data files, if any.",
    "Redirect stdout",
    "Reset sys.argv",
    "------------------------------------------------------------------------------",
    "Generating figures",
    "------------------------------------------------------------------------------",
    "-- Parse format list",
    "-- Try to determine if all images already exist",
    "Look for single-figure output files first",
    "Then look for multi-figure output files",
    "assume that if we have one, we have them all",
    "-- We didn't find the files, so build them",
    "Clear between runs",
    "Run code",
    "Collect images",
    "Results",
    "------------------------------------------------------------------------------",
    "Relative pathnames",
    "------------------------------------------------------------------------------",
    "Copied from Python 2.7",
    "Work out how much of the filepath is shared by start and path.",
    "Work out how much of the filepath is shared by start and path.",
    "If several signatures present, take the last one",
    "We could do more tests, but we are not. Arbitrarily.",
    "string conversion routines",
    "try to read signature, backward compat for older Python",
    "########################################################################",
    "object interface.",
    "########################################################################",
    "########################################################################",
    "Unparser private interface.",
    "########################################################################",
    "## format, output, and dispatch methods ################################",
    "########################################################################",
    "compiler.ast unparsing methods.",
    "",
    "There should be one method per concrete grammar type. They are",
    "organized in alphabetical order.",
    "########################################################################",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "fixme: Are From and ImportFrom handled differently?",
    "if t.step:",
    "self._write(\":\")",
    "self._dispatch(t.step)",
    "Empty tuple.",
    "_write each elements, separated by a comma.",
    "Handle the last one without writing comma",
    "Check if parenthesis are needed on left side and then dispatch",
    "Write the appropriate symbol for operator",
    "Check if parenthesis are needed on the right side and then dispatch",
    "if t is 0.1, str(t)->'0.1' while repr(t)->'0.1000000000001'",
    "We prefer str here.",
    "########################################################################",
    "These are the methods from the _ast modules unparse.",
    "",
    "As our needs to handle more advanced code increase, we may want to",
    "modify some of the methods below so that they work for compiler.ast.",
    "########################################################################",
    "# stmt",
    "def _Expr(self, tree):",
    "self._fill()",
    "self._dispatch(tree.value)",
    "",
    "def _Import(self, t):",
    "self._fill(\"import \")",
    "first = True",
    "for a in t.names:",
    "if first:",
    "first = False",
    "else:",
    "self._write(\", \")",
    "self._write(a.name)",
    "if a.asname:",
    "self._write(\" as \"+a.asname)",
    "",
    "#    def _ImportFrom(self, t):",
    "#        self._fill(\"from \")",
    "#        self._write(t.module)",
    "#        self._write(\" import \")",
    "#        for i, a in enumerate(t.names):",
    "#            if i == 0:",
    "#                self._write(\", \")",
    "#            self._write(a.name)",
    "#            if a.asname:",
    "#                self._write(\" as \"+a.asname)",
    "#        # XXX(jpe) what is level for?",
    "#",
    "",
    "def _Break(self, t):",
    "self._fill(\"break\")",
    "",
    "def _Continue(self, t):",
    "self._fill(\"continue\")",
    "",
    "def _Delete(self, t):",
    "self._fill(\"del \")",
    "self._dispatch(t.targets)",
    "",
    "def _Assert(self, t):",
    "self._fill(\"assert \")",
    "self._dispatch(t.test)",
    "if t.msg:",
    "self._write(\", \")",
    "self._dispatch(t.msg)",
    "",
    "def _Exec(self, t):",
    "self._fill(\"exec \")",
    "self._dispatch(t.body)",
    "if t.globals:",
    "self._write(\" in \")",
    "self._dispatch(t.globals)",
    "if t.locals:",
    "self._write(\", \")",
    "self._dispatch(t.locals)",
    "",
    "def _Print(self, t):",
    "self._fill(\"print \")",
    "do_comma = False",
    "if t.dest:",
    "self._write(\">>\")",
    "self._dispatch(t.dest)",
    "do_comma = True",
    "for e in t.values:",
    "if do_comma:self._write(\", \")",
    "else:do_comma=True",
    "self._dispatch(e)",
    "if not t.nl:",
    "self._write(\",\")",
    "",
    "def _Global(self, t):",
    "self._fill(\"global\")",
    "for i, n in enumerate(t.names):",
    "if i != 0:",
    "self._write(\",\")",
    "self._write(\" \" + n)",
    "",
    "def _Yield(self, t):",
    "self._fill(\"yield\")",
    "if t.value:",
    "self._write(\" (\")",
    "self._dispatch(t.value)",
    "self._write(\")\")",
    "",
    "def _Raise(self, t):",
    "self._fill('raise ')",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.inst:",
    "self._write(\", \")",
    "self._dispatch(t.inst)",
    "if t.tback:",
    "self._write(\", \")",
    "self._dispatch(t.tback)",
    "",
    "",
    "def _TryFinally(self, t):",
    "self._fill(\"try\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "self._fill(\"finally\")",
    "self._enter()",
    "self._dispatch(t.finalbody)",
    "self._leave()",
    "",
    "def _excepthandler(self, t):",
    "self._fill(\"except \")",
    "if t.type:",
    "self._dispatch(t.type)",
    "if t.name:",
    "self._write(\", \")",
    "self._dispatch(t.name)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _ClassDef(self, t):",
    "self._write(\"\\n\")",
    "self._fill(\"class \"+t.name)",
    "if t.bases:",
    "self._write(\"(\")",
    "for a in t.bases:",
    "self._dispatch(a)",
    "self._write(\", \")",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _FunctionDef(self, t):",
    "self._write(\"\\n\")",
    "for deco in t.decorators:",
    "self._fill(\"@\")",
    "self._dispatch(deco)",
    "self._fill(\"def \"+t.name + \"(\")",
    "self._dispatch(t.args)",
    "self._write(\")\")",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "",
    "def _For(self, t):",
    "self._fill(\"for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "def _While(self, t):",
    "self._fill(\"while \")",
    "self._dispatch(t.test)",
    "self._enter()",
    "self._dispatch(t.body)",
    "self._leave()",
    "if t.orelse:",
    "self._fill(\"else\")",
    "self._enter()",
    "self._dispatch(t.orelse)",
    "self._leave",
    "",
    "# expr",
    "def _Str(self, tree):",
    "self._write(repr(tree.s))",
    "#",
    "def _Repr(self, t):",
    "self._write(\"`\")",
    "self._dispatch(t.value)",
    "self._write(\"`\")",
    "",
    "def _Num(self, t):",
    "self._write(repr(t.n))",
    "",
    "def _ListComp(self, t):",
    "self._write(\"[\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\"]\")",
    "",
    "def _GeneratorExp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.elt)",
    "for gen in t.generators:",
    "self._dispatch(gen)",
    "self._write(\")\")",
    "",
    "def _comprehension(self, t):",
    "self._write(\" for \")",
    "self._dispatch(t.target)",
    "self._write(\" in \")",
    "self._dispatch(t.iter)",
    "for if_clause in t.ifs:",
    "self._write(\" if \")",
    "self._dispatch(if_clause)",
    "",
    "def _IfExp(self, t):",
    "self._dispatch(t.body)",
    "self._write(\" if \")",
    "self._dispatch(t.test)",
    "if t.orelse:",
    "self._write(\" else \")",
    "self._dispatch(t.orelse)",
    "",
    "unop = {\"Invert\":\"~\", \"Not\": \"not\", \"UAdd\":\"+\", \"USub\":\"-\"}",
    "def _UnaryOp(self, t):",
    "self._write(self.unop[t.op.__class__.__name__])",
    "self._write(\"(\")",
    "self._dispatch(t.operand)",
    "self._write(\")\")",
    "",
    "binop = { \"Add\":\"+\", \"Sub\":\"-\", \"Mult\":\"*\", \"Div\":\"/\", \"Mod\":\"%\",",
    "\"LShift\":\">>\", \"RShift\":\"<<\", \"BitOr\":\"|\", \"BitXor\":\"^\", \"BitAnd\":\"&\",",
    "\"FloorDiv\":\"//\", \"Pow\": \"**\"}",
    "def _BinOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.left)",
    "self._write(\")\" + self.binop[t.op.__class__.__name__] + \"(\")",
    "self._dispatch(t.right)",
    "self._write(\")\")",
    "",
    "boolops = {_ast.And: 'and', _ast.Or: 'or'}",
    "def _BoolOp(self, t):",
    "self._write(\"(\")",
    "self._dispatch(t.values[0])",
    "for v in t.values[1:]:",
    "self._write(\" %s \" % self.boolops[t.op.__class__])",
    "self._dispatch(v)",
    "self._write(\")\")",
    "",
    "def _Attribute(self,t):",
    "self._dispatch(t.value)",
    "self._write(\".\")",
    "self._write(t.attr)",
    "",
    "#    def _Call(self, t):",
    "#        self._dispatch(t.func)",
    "#        self._write(\"(\")",
    "#        comma = False",
    "#        for e in t.args:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        for e in t.keywords:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._dispatch(e)",
    "#        if t.starargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"*\")",
    "#            self._dispatch(t.starargs)",
    "#        if t.kwargs:",
    "#            if comma: self._write(\", \")",
    "#            else: comma = True",
    "#            self._write(\"**\")",
    "#            self._dispatch(t.kwargs)",
    "#        self._write(\")\")",
    "",
    "# slice",
    "def _Index(self, t):",
    "self._dispatch(t.value)",
    "",
    "def _ExtSlice(self, t):",
    "for i, d in enumerate(t.dims):",
    "if i != 0:",
    "self._write(': ')",
    "self._dispatch(d)",
    "",
    "# others",
    "def _arguments(self, t):",
    "first = True",
    "nonDef = len(t.args)-len(t.defaults)",
    "for a in t.args[0:nonDef]:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a)",
    "for a,d in zip(t.args[nonDef:], t.defaults):",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._dispatch(a),",
    "self._write(\"=\")",
    "self._dispatch(d)",
    "if t.vararg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"*\"+t.vararg)",
    "if t.kwarg:",
    "if first:first = False",
    "else: self._write(\", \")",
    "self._write(\"**\"+t.kwarg)",
    "",
    "#    def _keyword(self, t):",
    "#        self._write(t.arg)",
    "#        self._write(\"=\")",
    "#        self._dispatch(t.value)",
    "",
    "def _Lambda(self, t):",
    "self._write(\"lambda \")",
    "self._dispatch(t.args)",
    "self._write(\": \")",
    "self._dispatch(t.body)",
    "int : The first line number in the block. 1-indexed.",
    "int : The last line number. Inclusive!",
    "str : The text block including '#' character but not any leading spaces.",
    "Only add if not entirely whitespace.",
    "Start with a dummy.",
    "All of the blocks seen so far.",
    "The index mapping lines of code to their associated comment blocks.",
    "Oops! Trailing comment, not a comment block.",
    "A comment block.",
    "FIXME: gracefully handle errors here or in the caller?",
    "FIXME: handle other kinds of assignments?",
    "string conversion routines",
    "Check if the referenced member can have a docstring or not",
    "Referenced object has a docstring",
    "Latex collects all references to a separate bibliography,",
    "so we need to insert links to it",
    "-*- coding: utf-8 -*-",
    "Convert signode to a specified format",
    "Call user code to resolve the link",
    "no source",
    "only one link per name, please",
    "------------------------------------------------------------------------------",
    "Creating 'phantom' modules from an XML description",
    "------------------------------------------------------------------------------",
    "Sort items so that",
    "- Base classes come before classes inherited from them",
    "- Modules come before their contents",
    "Create phantom items",
    "create parent, if missing",
    "create object",
    "Populate items",
    "-*- coding: utf-8 -*-",
    "##########################################################################",
    "A tensor is simply a numpy array",
    "##########################################################################",
    "Unfolding a tensor is easy",
    "##########################################################################",
    "Re-folding the tensor is as easy:",
    "-*- coding: utf-8 -*-",
    "#############################################################################",
    "Create synthetic tensor",
    "-----------------------",
    "Here, we create a random tensor that follows the PARAFAC2 constraints found",
    "inx `(Kiers et al 1999)`_.",
    "",
    "This particular tensor,",
    ":math:`\\mathcal{X}\u00a0\\in \\mathbb{R}^{I\\times J \\times K}`, is a shifted",
    "CP tensor, that is, a tensor on the form:",
    "",
    ".. math::",
    "\\mathcal{X}_{ijk} = \\sum_{r=1}^R A_{ir} B_{\\sigma_i(j) r} C_{kr},",
    "",
    "where :math:`\\sigma_i`\u00a0is a cyclic permutation of :math:`J` elements.",
    "Set parameters",
    "Generate random matrices",
    "Normalised factor matrices",
    "Generate the shifted factor matrix",
    "Construct the tensor",
    "Add noise",
    "#############################################################################",
    "Fit a PARAFAC2 tensor",
    "---------------------",
    "To avoid local minima, we initialise and fit 10 models and choose the one",
    "with the lowest error",
    "#############################################################################",
    "A decomposition is a wrapper object for three variables: the *weights*,",
    "the *factor matrices* and the *projection matrices*. The weights are similar",
    "to the output of a CP decomposition. The factor matrices and projection",
    "matrices are somewhat different. For a CP decomposition, we only have the",
    "weights and the factor matrices. However, since the PARAFAC2 factor matrices",
    "for the second mode is given by",
    "",
    ".. math::",
    "B_i = P_i B,",
    "",
    "where :math:`B` is an :math:`R \\times R` matrix and :math:`P_i` is an",
    ":math:`I \\times R` projection matrix, we cannot store the factor matrices",
    "the same as for a CP decomposition.",
    "",
    "Instead, we store the factor matrix along the first mode (:math:`A`), the",
    "\"blueprint\" matrix for the second mode (:math:`B`) and the factor matrix",
    "along the third mode (:math:`C`) in one tuple and the projection matrices,",
    ":math:`P_i`, in a separate tuple.",
    "",
    "If we wish to extract the informative :math:`B_i` factor matrices, then we",
    "use the ``tensorly.parafac2_tensor.apply_projection_matrices`` function on",
    "the PARAFAC2 tensor instance to get another wrapper object for two",
    "variables: *weights* and *factor matrices*. However, now, the second element",
    "of the factor matrices tuple is now a list of factor matrices, one for each",
    "frontal slice of the tensor.",
    "",
    "Likewise, if we wish to construct the tensor or the frontal slices, then we",
    "can use the ``tensorly.parafac2_tensor.parafac2_to_tensor`` function. If the",
    "decomposed dataset consisted of uneven-length frontal slices, then we can",
    "use the ``tensorly.parafac2_tensor.parafac2_to_slices`` function to get a",
    "list of frontal slices.",
    "#############################################################################",
    "Compute performance metrics",
    "---------------------------",
    "To evaluate how well the original structure is recovered, we calculate the tucker congruence coefficient.",
    "#############################################################################",
    "Visualize the components",
    "------------------------",
    "Find the best permutation so that we can plot the estimated components on top of the true components",
    "Create plots of each component vector for each mode",
    "(We just look at one of the B_i matrices)",
    "Plot true and estimated components for mode A",
    "Labels for the different components",
    "Plot true and estimated components for mode C",
    "Plot true components for mode B",
    "Get the signs so that we can flip the B mode factor matrices",
    "Plot estimated components for mode B (after sign correction)",
    "Titles for the different modes",
    "Create a legend for the entire figure",
    "#############################################################################",
    "Inspect the convergence rate",
    "----------------------------",
    "It can be interesting to look at the loss plot to make sure that we have",
    "converged to a stationary point. We skip the first iteration since the",
    "initial loss often dominate the rest of the plot, making it difficult",
    "to check for convergence.",
    "#############################################################################",
    "References",
    "----------",
    "",
    ".. _(Kiers et al 1999):",
    "",
    "Kiers HA, Ten Berge JM, Bro R. *PARAFAC2\u2014Part I.",
    "A direct fitting algorithm for the PARAFAC2 model.*",
    "**Journal of Chemometrics: A Journal of the Chemometrics Society.**",
    "1999 May;13(3\u20104):275-94. `(Online version)",
    "<https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-128X(199905/08)13:3/4%3C275::AID-CEM543%3E3.0.CO;2-B>`_",
    "Rank of the CP decomposition",
    "Rank of the Tucker decomposition",
    "Perform the CP decomposition",
    "Reconstruct the image from the factors",
    "Tucker decomposition",
    "Plotting the original and reconstruction from the decompositions",
    "Get a high-accuracy decomposition for comparison",
    "Run PARAFAC decomposition without line search and time",
    "Run PARAFAC decomposition with line search and time",
    "Calculate the error of both decompositions",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Parameter of the experiment",
    "shape of the images",
    "ranks to test",
    "Generate random samples",
    "Parameters of the plot, deduced from the data",
    "Plot the three images",
    "Generate the original image",
    "Generate the labels",
    "Plot the original weights",
    "Create a tensor Regressor estimator",
    "Fit the estimator to the data",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Should we allow None weights?",
    "it's already been validated at creation",
    "Test for the validity of the operation",
    "norm = T.dot(T.dot(weights, norm), weights)",
    "We sum even if weigths is not None",
    "as e.g. MXNet would return a 1D tensor, not a 0D tensor",
    "Deprecated classes and functions",
    "Note how tt_matrix_to_tensor is implemented in tenalg to allow for more efficient implementations",
    "(e.g. using the einsum backend)",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Will raise an error if invalid",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "Test for the validity of the operation",
    "rank is 'same' or float: choose rank so as to preserve a fraction of the original #parameters",
    "sorted to be careful with the order when popping and reinserting to not remove/add at wrong index.",
    "list (mode, shape) that we removed as they will be kept the same, rank[i] =",
    "number of parameters coming from the fixed modes (these don't have a variable size as a fun of fraction_param)",
    "Doesn't contain fixed_modes, those factors are accounted for in fixed_params",
    "Check that factors are third order tensors",
    "Consecutive factors should have matching ranks",
    "Check for boundary conditions",
    "Add last rank (boundary condition)",
    "Choose the *same* rank for each mode",
    "R_k I_k R_{k+1} = R^2 I_k",
    "Border rank of 1, R_0 = R_N = 1",
    "First and last factor of size I_0 R and I_N R",
    "We want the number of params of decomp (=sum of params of factors)",
    "To be equal to c = \\prod_k I_k",
    "We get the non-negative solution",
    "Choose a rank proportional to the size of each mode",
    "The method is similar to the above one for constant_rank == True",
    "We get the non-negative solution",
    "Check user input for potential errors",
    "Initialization",
    "Will raise an error if invalid",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "it's already been validated at creation",
    "Skip first factor matrix since the rank is extracted from it.",
    "allocate variables for weights, and normalized factors",
    "if (not copy) and (weights is None):",
    "warnings.warn('Provided copy=False and weights=None: a new Parafac2Tensor'",
    "'with new weights and factors normalised inplace will be returned.')",
    "weights = T.ones(rank, **T.context(factors[0]))",
    "The if test below was added to enable inplace edits",
    "however, TensorFlow does not support inplace edits",
    "so this is always set to True",
    "Deprecated",
    "Add Backend functions, dynamically dispatched",
    "Getting the TT factors up to n_dim - 1",
    "Reshape the unfolding matrix of the remaining factors",
    "SVD of unfolding matrix",
    "Get kth TT factor",
    "Get new unfolding matrix for the remaining factors",
    "Getting the last factor",
    "A list of candidates for each mode",
    "Refine the init",
    "Authors: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "Chris Swierczewski <csw@amazon.com>",
    "Sam Schneider <samjohnschneider@gmail.com>",
    "Aaron Meurer <asmeurer@gmail.com>",
    "License: BSD 3 clause",
    "factors = [tl.tensor(rng.random_sample((tensor.shape[i], rank)), **tl.context(tensor)) for i in range(tl.ndim(tensor))]",
    "kt = CPTensor((None, factors))",
    "Put SVD initialization on the same scaling as the tensor in case normalize_factors=False",
    "TODO: this is a hack but it seems to do the job for now",
    "factor = tl.tensor(np.zeros((U.shape[0], rank)), **tl.context(tensor))",
    "factor[:, tensor.shape[mode]:] = tl.tensor(rng.random_sample((U.shape[0], rank - tl.shape(tensor)[mode])), **tl.context(tensor))",
    "factor[:, :tensor.shape[mode]] = U",
    "TODO: Test this",
    "If we have to update the mask we already have to build the full tensor",
    "Update the tensor based on the mask",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "Take into account init weights",
    "Will we be performing a line search iteration",
    "Calculate the current unnormalized error if we need it",
    "Start line search if requested.",
    "khatri_rao(factors).tl.dot(khatri_rao(factors))",
    "simplifies to multiplications",
    "||tensor - rec||^2 = ||tensor||^2 + ||rec||^2 - 2*<tensor, rec>",
    "mttkrp and factor for the last mode. This is equivalent to the",
    "inner product <tensor, factorization>",
    "For each matrix, randomly choose n_samples indices for which to compute the khatri-rao product",
    "Compute corresponding rows of the full khatri-rao product",
    "Compute the Khatri-Rao product for the chosen indices",
    "Keep all the elements of the currently considered mode",
    "MXNet will not be happy if this is a list insteaf of a tuple",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise the decompositions",
    "Norm of the reconstructions at each iteration",
    "Update the lagrangian multipliers",
    "Evolution of the reconstruction errors",
    "Convergence check",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "A list of candidates for each mode",
    "Refine the init",
    "Authors: Marie Roald",
    "Yngve Mardal Moe",
    "Deprecated",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "SVD init",
    "The initial core approximation is needed here for the masking step",
    "The factors are orthonormal and therefore do not affect the reconstructed tensor's norm",
    "TO-DO validate rank for partial tucker as well",
    "Initialisation",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "def transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors, transpose=True)",
    "def inverse_transform(self, tensor):",
    "_, factors = self.decomposition_",
    "return tlg.multi_mode_dot(tensor, factors)",
    "check recovery",
    "check low rank recovery",
    "Check for sparsity of the gross error",
    "assert tl.sum(noise_pred > 0.01) == tl.sum(noise > 0.01)",
    "check sparse gross error recovery",
    "###########################",
    "Test with missing values #",
    "###########################",
    "Add some corruption (missing values, replaced by ones)",
    "Decompose the tensor",
    "check recovery",
    "check low rank recovery",
    "check sparse gross error recovery",
    "Check for recovery of the corrupted/missing part",
    "Check that the error monotonically decreases",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "Should also converge with orthogonolise = True",
    "Test with rank-1 decomposition",
    "Check that we get roughly the same answer with the full tensor and masking",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test fixing mode 0 or 1 with given init",
    "Check if modified after 2 iterations",
    "test tensor reconstructed properly",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "Test random_state fixes the core and the factor matrices",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test the shape of the core and factors",
    "try fixing the core",
    "Random and SVD init should converge to a similar solution",
    "Mask an outlier value, and check that the decomposition ignores it",
    "We won't use the SVD decomposition, but check that it at least runs successfully",
    "Make sure all components are positive",
    "Test the max abs difference between the reconstruction and the tensor",
    "Test for a single rank passed",
    "(should be used for all modes)",
    "Test the max abs difference between the reconstruction and the tensor",
    "It is difficult to correctly identify B[i, :, r] if A[i, r] is small.",
    "This is sensible, since then B[i, :, r] contributes little to the total value of X.",
    "To test the PARAFAC2 decomposition in the precence of roundoff errors, we therefore add",
    "0.01 to the A factor matrix.",
    "Test factor correlation",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "Make sure it's not a tuple but a list",
    "Initialization",
    "Deprecated",
    "Generate a random state for me",
    "random state from integer seed",
    "if it is already a random state, just return it",
    "only takes as seed a random state, an int or None",
    "tests that the columns of each factor matrix are indeed orthogonal",
    "(See issue #40)",
    "Missing a rank",
    "Not respecting the boundary rank conditions",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "TODO: write a function to do this..",
    "Check user input for errors",
    "Make sure iter's not a tuple but a list",
    "Initialize rank",
    "list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.",
    "list row_idx: row indices    (left indices)  for skeleton-decomposition: indicate which rows used in each core.",
    "Initialize indice: random selection of column indices",
    "Initialize the cores of tensor-train",
    "#####################################",
    "left-to-right step",
    "list row_idx: list of (tensor_order-1) of lists of left indices",
    "update row indices",
    "end left-to-right step",
    "##############################################",
    "##############################################",
    "right-to-left step",
    "list col_idx: list (tensor_order-1) of lists of right indices",
    "update col indices",
    "Compute cores",
    "The rank should not be larger than the input tensor's size",
    "Add the last core",
    "end right-to-left step",
    "###############################################",
    "check the error for while-loop",
    "check convergence",
    "Extract fibers according to the row and col indices",
    "Extract the core",
    "shape the core as a 3-tensor_order cube",
    "merge r_k and n_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "Extract fibers",
    "shape the core as a 3-tensor_order cube",
    "merge n_{k-1} and r_k, get a matrix",
    "Compute QR decomposition",
    "Maxvol",
    "Retrive indices in folded tensor",
    "The index of row of the submatrix",
    "Rest of rows / unselected rows",
    "Find r rows iteratively",
    "Compute the square of norm of each row",
    "If there is only one row of A left, let's just return it. MxNet is not robust about this case.",
    "If a row is 0, we delete it.",
    "Find the row of max norm",
    "Compute the projection of max_row to other rows",
    "projection a to b is computed as: <a,b> / sqrt(|a|*|b|)",
    "make sure normalization vector is of the same shape of projection (causing bugs for MxNet)",
    "Subtract the projection from A_new:  b <- b - a * projection",
    "Delete the selected row",
    "update the row_idx and rest_of_rows",
    "# Test 1",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Check that the ranks are correct and that the second mode of each factor",
    "has the correct number of elements",
    "# Test 2",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "# Test 3",
    "TEST 4",
    "Random tensor is not really compress-able. Test on a tensor as values of a function",
    "Find TT decomposition of the tensor",
    "Deprecated",
    "Make sure the algorithm stays sparse. This will run out of memory on",
    "most machines if the algorithm densifies.",
    "Will blow-up memory if not sparse-safe",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Default on standard SVD",
    "all-zeros matrix, so we should do a quick return.",
    "We can perform a partial SVD",
    "construct np.random.RandomState for sampling a starting vector",
    "if random_state is not specified, do not initialize a starting vector",
    "initilize with [-1, 1] as in ARPACK",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "use dense form when sparse form will fail",
    "use dense form when sparse form will fail",
    "WARNING: here, V is still the transpose of what it should be",
    "moveaxis is temporarily uses the default implementation to fix issue #131",
    "Using the builting function raises a TypeError:",
    "no implementation found for 'numpy.shape' on types",
    "that implement __array_function__: [<class 'sparse._coo.core.COO'>]",
    "This is fixed on sparse master",
    "Check correct rank and shapes are returned",
    "One of the factors has the wrong rank",
    "Not the correct amount of weights",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test cp_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test cp_mode_dot with vec",
    "Version forming explicitely the khatri-rao product",
    "Efficient sparse-safe version",
    "Rounding = floor",
    "Rounding = ceil",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not three factor matrices",
    "Not enough projections",
    "Wrong number of weights",
    "The projections aren't orthogonal",
    "Disable tests for inplace edits, since that possibility is removed",
    "to support TensorFlow.",
    "@pytest.mark.parametrize('copy', [True, False])",
    "Check that the correct shape/rank are returned",
    "One of the factors has the wrong ndim",
    "Consecutive factors ranks don't match",
    "Boundary conditions not respected",
    "Not enough factors",
    "Create tensor",
    "Compute ground truth TT factors",
    "Check that TT factors re-assemble to the original tensor",
    "Create tensor with random elements",
    "Find TT decomposition of the tensor",
    "Reconstruct the original tensor",
    "Check that the rank is 10",
    "Rounding = floor",
    "Rounding = ceil",
    "Author: Jean Kossaifi",
    "Set in context manager",
    "Sets back to numpy",
    "Reset back to initial backend",
    "Set not in context manager",
    "Improper name doesn't reset backend",
    "Changes only happen locally in this thread",
    "Set the global default backend",
    "Changed toplevel default in all threads",
    "hard coded example",
    "check dims",
    "chain unfolding and folding",
    "Convert to vector and back to tensor",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "We created here a tensor with 3 samples, each sample being similar to X",
    "Test for raveled tensor",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "Test for raveled tensor",
    "Test for raveled_tensor=True",
    "##################################",
    "Samples are the first dimension #",
    "##################################",
    "we created here a tensor with 3 samples, each sample being similar to X",
    "#################################",
    "Samples are the last dimension #",
    "#################################",
    "True reconstruction error (based on numpy SVD)",
    "Reconstruction error with the backend's SVD",
    "Check that the two are similar",
    "Check for orthogonality when relevant",
    "Should fail on non-matrices",
    "Test for singular matrices (some eigenvals will be zero)",
    "Rank at most 5",
    "Test if partial_svd returns the same result for the same setting",
    "limit as order->oo is the oo-norm",
    "1D",
    "2D",
    "3D",
    "random testing against Numpy's output",
    "assert that the columns of Q are orthonormal",
    "Check shape and rank returned",
    "One of the factors has the wrong rank",
    "Not enough factors to match core",
    "Not enough factors",
    "matrix for mode 1",
    "vec for mode 2",
    "Test tucker_mode_dot with matrix",
    "Note that if copy=True is not respected, factors will be changes",
    "And the next test will fail",
    "Check that the data was indeed copied",
    "Test tucker_mode_dot with vec",
    "Rounding = floor",
    "Rounding = ceil",
    "With fixed modes",
    "Floor",
    "Ceil",
    "New function renaming old_fun",
    "Old fun will return fun but issue a deprecation warning",
    "Test using the deprecated function",
    "Test using the new function instead",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "print('hello')",
    "Equivalence with inner product when contracting with self along all modes",
    "Equivalence with n-mode-dot",
    "Multi-mode-dot",
    "Wrong number of modes",
    "size mismatch",
    "Author: Jean Kossaifi",
    "small test",
    "account for floating point errors: np array have a precision of around 2e-15",
    "check np.finfo(np.float64).eps",
    "Check that we did not change the original tensor",
    "Another test",
    "Test with missing values",
    "Author: Jean Kossaifi",
    "resulting matrix must be of shape (prod(n_rows), n_columns)",
    "fail case: all matrices must have same number of columns",
    "all matrices should be of dim 2...",
    "Classic example/test",
    "A = np.hstack((np.eye(3), np.arange(3)[:, None]))",
    "Test with one matrix only: khatri-rao of one matrix = that matrix",
    "Author: Jean Kossaifi",
    "Mathematical test",
    "Another test",
    "Adding a third matrices",
    "Test for the reverse argument",
    "Check that the original list has not been reversed",
    "Check the returned shape",
    "Khatri-rao is a column-wise kronecker product",
    "Khatri-rao product is a column-wise kronecker product",
    "Test while skipping a matrix",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "For one common mode, equivalent to dot product",
    "For no common mode, equivalent to inner product",
    "Inner product of tensors with different shapes is not defined",
    "tensor times matrix",
    "######################",
    "tensor times vector #",
    "######################",
    "Test with a matrix",
    "Test with a third order tensor",
    "Using equivalence with unfolded expression",
    "########################################",
    "Test for errors that should be raised #",
    "########################################",
    "Same test for the vector case",
    "Cannot take mode product of tensor with tensor",
    "Test using the equivalence with unfolded expression",
    "Test skipping a factor",
    "Test contracting with a vector",
    "result should be a scalar",
    "MXNet doesn't support order-0 tensors..",
    "FIX ME - this shouldn't have to happen...",
    "Average pooling each mode",
    "Order should not matter",
    "MXNet doesn't support order-0 tensors..",
    "FIX ME - this shouldn't have to happen...",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Indices of each matrix",
    "Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>",
    "License: BSD 3 clause",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "However, it is needed to pop dimensions contracted over",
    "print(i, matrix_or_vec.shape, mode)",
    "print(f'skipping {skip}')",
    "We are contracting over the mode-th dimension",
    "Contracting mode-th mode with a matrix: new dimension",
    "If fully contracting",
    "print(equation, tl.shape(tensor), [tl.shape(f) for f in matrix_or_vec_list])",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Each core is of shape (rank_left, size_in, size_out, rank_right)",
    "Intertwine the dims",
    "full_shape = in_shape[0], out_shape[0], in_shape[1], ...",
    "factor = factor.squeeze(0)",
    "the mode along which to fold might decrease if we take product with a vector",
    "Test for the validity of the operation",
    "Ideally this should be (), i.e. order-0 tensors",
    "MXNet currently doesn't support this though..",
    "Order of mode dots doesn't matter for different modes",
    "Sorting by mode shouldn't change order for equal modes",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:",
    "Khatri-rao of only one matrix: just return that matrix",
    "Optional part, testing whether the matrices have the proper size",
    "Note: we do NOT use .reverse() which would reverse matrices even outside this function",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Traditional inner product",
    "Inner product along `n_modes` common modes",
    "handle difference in default axis notation",
    "source_fun, target_fun",
    "(tf.linalg.solve, 'solve'),",
    "handle difference in default axis notation",
    "Check that matrix is... a matrix!",
    "Choose what to do depending on the params",
    "Default on standard SVD",
    "We can perform a partial SVD",
    "construct np.random.RandomState for sampling a starting vector",
    "if random_state is not specified, do not initialize a starting vector",
    "initilize with [-1, 1] as in ARPACK",
    "initilize with [-1, 1] as in ARPACK",
    "First choose whether to use X * X.T or X.T *X",
    "WARNING: here, V is still the transpose of what it should be",
    "Currently, gesv doesn't support vectors for matrix2",
    "So we instead solve a least square problem...",
    "Currently, solve doesn't support vectors for matrix2",
    "pytorch does not accept `None` for any keyword arguments. additionally,",
    "pytorch doesn't seems to support keyword arguments in the first place",
    "Check that matrix is... a matrix!",
    "we compute decomposition on the largest of the two to keep more eigenvecs",
    "handle difference in default axis notation",
    "NOTE - should be replaced with geqrf when available",
    "Ugly fix for stacking zero-order tensors that are of shape (1, ) in MXNet",
    "Check that matrix is... a matrix!",
    "we compute decomposition on the largest of the two to keep more eigenvecs",
    "Backend is a string",
    "Set the backend",
    "We don't use `functools.wraps` here because some of the dispatched",
    "methods include the backend (`self`) as a parameter. Instead we manually",
    "copy over the needed information, and filter the signature for `self`.",
    "Generic methods, exposed as part of the public API",
    "index = dispatch(Backend.index)",
    "Initialise the backend to the default one",
    "handle difference in default axis notation",
    "Swiss",
    "Rectangle",
    "circle: approximate test",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise modes of W",
    "Regress phi on y: we could call a package here, e.g. scikit-learn",
    "Convergence check",
    "Author: Jean Kossaifi",
    "License: BSD 3 clause",
    "Initialise randomly the weights",
    "Norm of the weight tensor at each iteration",
    "Optimise each factor of W",
    "Convergence check",
    "Parameter of the experiment",
    "Generate random samples",
    "Parameter of the experiment",
    "Generate random samples"
  ]
}