Version,Commit Message,SATD
v0.6.10,TODO: begin_delete can delete on server but fail,1
v0.6.10,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.10,TODO: include support for Azure passwordless credentials:,1
v0.6.10,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.10,TODO: Consider separation of concerns for each field.,1
v0.6.10,TODO: Needs further discussion at design-level.,1
v0.6.10,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.10,TODO: Harden these tests later to check content from data method.,1
v0.6.10,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.10,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.10,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.10,NOTE: We know this environment is going to use Dash.,1
v0.6.10,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.10,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.10,TODO PK add a test for Regression with interactions,1
v0.6.10,TODO PK add a test with a real regression dataset,1
v0.6.10,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.10,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.10,TODO: expand this test to use the other feature types available,1
v0.6.10,TODO: whittle these down to the minimum,1
v0.6.10,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.10,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.10,TODO: write this test,1
v0.6.10,TODO: write this test,1
v0.6.10,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.10,TODO: stop this call from writing to stdout or stderr,1
v0.6.10,NOTE: Not implemented yet,1
v0.6.10,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.10,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.10,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.10,TODO: Remove this if threshold lines are never used.,1
v0.6.10,TODO: Clean this up after validation.,1
v0.6.10,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.10,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.10,NOTE: Workaround for tables not rendering,1
v0.6.10,TODO: Check if this is needed with the new tables.,1
v0.6.10,TODO: Consider reducing complexity of this function.,1
v0.6.10,NOTE: Workaround for tables not rendering,1
v0.6.10,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.10,TODO: Revisit when we support custom tabs from users.,1
v0.6.10,# TODO Can the base vis be a util?,1
v0.6.10,TODO: can we get rid of this column of X?,1
v0.6.10,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.10,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.10,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.10,TODO: Make kwargs explicit.,1
v0.6.10,TODO: a few ways to improve this function:,1
v0.6.10,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.10,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.10,TODO: should preprocessors handle 0 samples?,1
v0.6.10,TODO: check for names/indexes in the dict that are not,1
v0.6.10,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.10,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.10,TODO: clean up this hack that uses strings of the indexes,1
v0.6.10,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.10,TODO: Add unit tests for internal EBM interfacing,1
v0.6.10,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.10,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.10,TODO: Needs test.,1
v0.6.10,BIG TODO LIST:,1
v0.6.10,FUTURE TODOS in our callers and in JSON:,1
v0.6.10,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.10,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.10,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.10,TODO : should this be np.float64 with a check for big integers,1
v0.6.10,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.10,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.10,TODO: does this work if there are spaces or bools?,1
v0.6.10,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.10,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.10,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.10,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.10,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.10,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.10,"TODO: currently we are using the CategoricalDtype order as the order,",1
v0.6.10,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.10,TODO: we could instead capture the misbehaving,1
v0.6.10,TODO: implement pd.SparseDtype,1
v0.6.10,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.10,TODO: modify our callers the EBMPreprocessor and unify_data and the ebm.fit and predict functions,1
v0.6.10,TODO: instead of returning both categories (a dictionary) and uniques (a numpy array) perhaps we can just return,1
v0.6.10,"TODO: we can probably eliminate the ""bad"" return value and maybe replace it with either nan or a bool array",1
v0.6.10,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.10,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.10,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.10,TODO: handle as a single feature model,1
v0.6.10,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.10,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.10,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.10,TODO: END SECTION TO BE REMOVED,1
v0.6.10,TODO: we should not use Pandas in a public interface like this,1
v0.6.10,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.10,TODO: remove this.. we don't seem to use it,1
v0.6.10,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.10,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.10,"TODO: Consider removing later, potentially dead code.",1
v0.6.10,TODO: we could probably handle this case,1
v0.6.10,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.10,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.10,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.10,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.10,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.10,TODO: we could probably handle this case,1
v0.6.10,Todo: check if this call,1
v0.6.10,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.10,TODO: check these,1
v0.6.10,TODO: load python parameters,1
v0.6.10,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.10,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.10,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.10,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.10,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.10,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.10,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.10,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.10,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.10,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.10,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.10,TODO: in the future we might at this point try and figure out the most,1
v0.6.10,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.10,TODO: we might be able to do these operations earlier,1
v0.6.10,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.10,TODO: consider making it illegal to duplicate features in terms,1
v0.6.10,TODO: consider making it illegal to duplicate features in terms,1
v0.6.10,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.10,TODO: check the other inputs for common mistakes here,1
v0.6.10,TODO: should we make this something higher?,1
v0.6.10,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.10,TODO: instead of making these copies we should,1
v0.6.10,"TODO: instead of going back to the original data in X, we",1
v0.6.10,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.10,TODO: this will fail if we have multiple categories in a bin,1
v0.6.10,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.10,TODO: would transposing preds_per_bag here improve speed?,1
v0.6.10,TODO: do this per-bag in addition to the final scores:,1
v0.6.10,TODO: do this per-bag in addition to the final scores:,1
v0.6.10,TODO: do this per-bag in addition to the final scores:,1
v0.6.10,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.10,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.10,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.10,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.10,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.10,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.10,TODO: Support other languages,1
v0.6.10,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.10,TODO: MLI should handle multiclass at a future date.,1
v0.6.10,TODO: Generalize this out.,1
v0.6.10,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.10,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.10,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.10,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.10,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.10,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.10,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.10,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.10,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.10,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.10,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.10,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.10,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.10,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.10,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.10,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.10,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.10,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.10,perhaps might return that for subnormal floats.,1
v0.6.10,TODO: this entire section below!,1
v0.6.10,TODO: implement this:,1
v0.6.10,TODO: implement this:,1
v0.6.10,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.10,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.10,TODO: review these comments below now that things have changed:,1
v0.6.10,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.10,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.10,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.10,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.10,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.10,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.10,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.10,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.10,TODO : ALL OF THE BELOW!,1
v0.6.10,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.10,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.10,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.10,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.10,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.10,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.10,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.10,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.10,TODO: we should calculate the default partial gain before splitting anything. Once we have that,1
v0.6.10,TODO: We can optimize away some of these calls to TensorTotalsSum because some of the,1
v0.6.10,TODO: we're doing extra computation above when we calculate the unpurified gain so eliminate that,1
v0.6.10,"TODO: the code below is duplicated in GenerateTempUpdate, so we can probably",1
v0.6.10,"TODO: for now purify to the max, but test tolerances and profile them",1
v0.6.10,TODO: in the future try randomizing the purification order.  It probably doesn't make much,1
v0.6.10,TODO: we should move this computation to the top and then calculate how much gain we need,1
v0.6.10,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.10,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.10,our caller can give us one of these bad types of inputs:,1
v0.6.10,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.10,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.10,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.10,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.10,TODO: Modify this file so that it can return a boosting update corresponding to the straight cuts,1
v0.6.10,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.10,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.10,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.10,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.10,"TODO: add this as a python/R option ""winsorized""",1
v0.6.10,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.10,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.10,TODO: implement sparse features,1
v0.6.10,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.10,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.10,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.10,TODO: sort the data by the target (if there is only one target),1
v0.6.10,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.10,TODO: handle sparse data someday,1
v0.6.10,TODO: clean this float in float32 format,1
v0.6.10,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.10,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.10,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.10,g_TODO_removeThisThreadTest = 1;,1
v0.6.10,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.10,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.10,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.10,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.10,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.10,TODO: move this to init,1
v0.6.10,TODO: move this to init,1
v0.6.10,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.10,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.10,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.10,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.10,- TODO: POST-HEALING,1
v0.6.10,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.10,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.10,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.10,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.10,TODO: evaluate max here instead as well,1
v0.6.10,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.10,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.10,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.10,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.10,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.10,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.10,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.10,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.10,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.10,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.10,There's actually two subtle issues here that we need to handle differently:,1
v0.6.10,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.10,- TODO: EXPLORING BOTH SIDES,1
v0.6.10,- TODO:,1
v0.6.10,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.10,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.10,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.10,TODO : in the future fill this priority queue with the average length within our,1
v0.6.10,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.10,TODO: mirror the bMissing option for bUnseen,1
v0.6.10,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.10,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.10,TODO: add zeroing of subnormal numbers here to match PurifyInternal. ARM does not handle subnormals reliably.,1
v0.6.10,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.10,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.10,TODO: move this to init,1
v0.6.10,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.10,TODO: move this to init,1
v0.6.10,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.10,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.10,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.10,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.10,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.10,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.10,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.10,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.10,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.10,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.10,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.10,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.10,TODO: move most of this code out of this function into a non-templated place,1
v0.6.10,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.10,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.10,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.10,TODO : add classification binary and multiclass versions of this,1
v0.6.10,TODO : add classification binary and multiclass versions of this,1
v0.6.10,TODO: restore this test,1
v0.6.10,TODO: restore this test,1
v0.6.10,"terms.push_back({0, 1, 2}); // TODO: enable when fast enough",1
v0.6.10,"terms.push_back({0, 1, 2, 3}); // TODO: enable when fast enough",1
v0.6.10,TODO: restore this test,1
v0.6.10,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.10,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.10,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.10,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.10,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.10,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.10,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.10,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.10,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.10,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.10,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.9,TODO: begin_delete can delete on server but fail,1
v0.6.9,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.9,TODO: include support for Azure passwordless credentials:,1
v0.6.9,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.9,TODO: Consider separation of concerns for each field.,1
v0.6.9,TODO: Needs further discussion at design-level.,1
v0.6.9,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.9,TODO: Harden these tests later to check content from data method.,1
v0.6.9,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.9,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.9,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.9,NOTE: We know this environment is going to use Dash.,1
v0.6.9,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.9,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.9,TODO PK add a test for Regression with interactions,1
v0.6.9,TODO PK add a test with a real regression dataset,1
v0.6.9,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.9,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.9,TODO: expand this test to use the other feature types available,1
v0.6.9,TODO: whittle these down to the minimum,1
v0.6.9,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.9,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.9,TODO: write this test,1
v0.6.9,TODO: write this test,1
v0.6.9,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.9,TODO: stop this call from writing to stdout or stderr,1
v0.6.9,NOTE: Not implemented yet,1
v0.6.9,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.9,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.9,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.9,TODO: Remove this if threshold lines are never used.,1
v0.6.9,TODO: Clean this up after validation.,1
v0.6.9,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.9,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.9,NOTE: Workaround for tables not rendering,1
v0.6.9,TODO: Check if this is needed with the new tables.,1
v0.6.9,TODO: Consider reducing complexity of this function.,1
v0.6.9,NOTE: Workaround for tables not rendering,1
v0.6.9,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.9,TODO: Revisit when we support custom tabs from users.,1
v0.6.9,# TODO Can the base vis be a util?,1
v0.6.9,TODO: can we get rid of this column of X?,1
v0.6.9,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.9,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.9,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.9,TODO: Make kwargs explicit.,1
v0.6.9,TODO: a few ways to improve this function:,1
v0.6.9,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.9,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.9,TODO: should preprocessors handle 0 samples?,1
v0.6.9,TODO: check for names/indexes in the dict that are not,1
v0.6.9,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.9,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.9,TODO: clean up this hack that uses strings of the indexes,1
v0.6.9,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.9,TODO: Add unit tests for internal EBM interfacing,1
v0.6.9,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.9,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.9,TODO: Needs test.,1
v0.6.9,BIG TODO LIST:,1
v0.6.9,FUTURE TODOS in our callers and in JSON:,1
v0.6.9,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.9,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.9,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.9,TODO : should this be np.float64 with a check for big integers,1
v0.6.9,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.9,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.9,TODO: does this work if there are spaces or bools?,1
v0.6.9,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.9,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.9,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.9,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.9,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.9,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.9,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.9,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.9,TODO: implement pd.SparseDtype,1
v0.6.9,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.9,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.9,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.9,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.9,TODO: handle as a single feature model,1
v0.6.9,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.9,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.9,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.9,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.9,TODO: END SECTION TO BE REMOVED,1
v0.6.9,TODO: we should not use Pandas in a public interface like this,1
v0.6.9,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.9,TODO: remove this.. we don't seem to use it,1
v0.6.9,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.9,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.9,"TODO: Consider removing later, potentially dead code.",1
v0.6.9,TODO: we could probably handle this case,1
v0.6.9,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.9,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.9,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.9,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.9,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.9,TODO: we could probably handle this case,1
v0.6.9,Todo: check if this call,1
v0.6.9,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.9,TODO: check these,1
v0.6.9,TODO: load python parameters,1
v0.6.9,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.9,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.9,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.9,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.9,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.9,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.9,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.9,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.9,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.9,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.9,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.9,TODO: in the future we might at this point try and figure out the most,1
v0.6.9,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.9,TODO: we might be able to do these operations earlier,1
v0.6.9,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.9,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.9,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.9,TODO: check the other inputs for common mistakes here,1
v0.6.9,TODO: should we make this something higher?,1
v0.6.9,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.9,TODO: instead of making these copies we should,1
v0.6.9,"TODO: instead of going back to the original data in X, we",1
v0.6.9,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.9,TODO: this will fail if we have multiple categories in a bin,1
v0.6.9,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.9,TODO: do this per-bag in addition to the final scores:,1
v0.6.9,TODO: do this per-bag in addition to the final scores:,1
v0.6.9,TODO: do this per-bag in addition to the final scores:,1
v0.6.9,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.9,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.9,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.9,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.9,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.9,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.9,TODO: Support other languages,1
v0.6.9,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.9,TODO: MLI should handle multiclass at a future date.,1
v0.6.9,TODO: Generalize this out.,1
v0.6.9,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.9,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.9,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.9,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.9,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.9,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.9,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.9,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.9,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.9,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.9,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.9,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.9,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.9,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.9,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.9,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.9,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.9,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.9,perhaps might return that for subnormal floats.,1
v0.6.9,TODO: this entire section below!,1
v0.6.9,TODO: implement this:,1
v0.6.9,TODO: implement this:,1
v0.6.9,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.9,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.9,TODO: review these comments below now that things have changed:,1
v0.6.9,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.9,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.9,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.9,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.9,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.9,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.9,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.9,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.9,TODO : ALL OF THE BELOW!,1
v0.6.9,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.9,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.9,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.9,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.9,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.9,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.9,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.9,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.9,TODO: we should calculate the default partial gain before splitting anything. Once we have that,1
v0.6.9,TODO: We can optimize away some of these calls to TensorTotalsSum because some of the,1
v0.6.9,TODO: we're doing extra computation above when we calculate the unpurified gain so eliminate that,1
v0.6.9,"TODO: the code below is duplicated in GenerateTempUpdate, so we can probably",1
v0.6.9,"TODO: for now purify to the max, but test tolerances and profile them",1
v0.6.9,TODO: in the future try randomizing the purification order.  It probably doesn't make much,1
v0.6.9,TODO: we should move this computation to the top and then calculate how much gain we need,1
v0.6.9,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.9,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.9,our caller can give us one of these bad types of inputs:,1
v0.6.9,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.9,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.9,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.9,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.9,TODO: Modify this file so that it can return a boosting update corresponding to the straight cuts,1
v0.6.9,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.9,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.9,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.9,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.9,"TODO: add this as a python/R option ""winsorized""",1
v0.6.9,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.9,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.9,TODO: implement sparse features,1
v0.6.9,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.9,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.9,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.9,TODO: sort the data by the target (if there is only one target),1
v0.6.9,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.9,TODO: handle sparse data someday,1
v0.6.9,TODO: clean this float in float32 format,1
v0.6.9,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.9,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.9,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.9,g_TODO_removeThisThreadTest = 1;,1
v0.6.9,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.9,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.9,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.9,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.9,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.9,TODO: move this to init,1
v0.6.9,TODO: move this to init,1
v0.6.9,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.9,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.9,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.9,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.9,- TODO: POST-HEALING,1
v0.6.9,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.9,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.9,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.9,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.9,TODO: evaluate max here instead as well,1
v0.6.9,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.9,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.9,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.9,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.9,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.9,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.9,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.9,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.9,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.9,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.9,There's actually two subtle issues here that we need to handle differently:,1
v0.6.9,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.9,- TODO: EXPLORING BOTH SIDES,1
v0.6.9,- TODO:,1
v0.6.9,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.9,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.9,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.9,TODO : in the future fill this priority queue with the average length within our,1
v0.6.9,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.9,TODO: mirror the bMissing option for bUnseen,1
v0.6.9,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.9,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.9,TODO: add zeroing of subnormal numbers here to match PurifyInternal. ARM does not handle subnormals reliably.,1
v0.6.9,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.9,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.9,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.9,TODO: move this to init,1
v0.6.9,TODO: move this to init,1
v0.6.9,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.9,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.9,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.9,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.9,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.9,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.9,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.9,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.9,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.9,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.9,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.9,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.9,TODO: move most of this code out of this function into a non-templated place,1
v0.6.9,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.9,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.9,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.9,TODO : add classification binary and multiclass versions of this,1
v0.6.9,TODO : add classification binary and multiclass versions of this,1
v0.6.9,TODO: restore this test,1
v0.6.9,TODO: restore this test,1
v0.6.9,"terms.push_back({0, 1, 2}); // TODO: enable when fast enough",1
v0.6.9,"terms.push_back({0, 1, 2, 3}); // TODO: enable when fast enough",1
v0.6.9,TODO: restore this test,1
v0.6.9,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.9,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.9,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.9,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.9,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.9,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.9,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.9,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.9,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.9,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.9,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.7,TODO: begin_delete can delete on server but fail,1
v0.6.7,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.7,TODO: include support for Azure passwordless credentials:,1
v0.6.7,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.7,TODO: Consider separation of concerns for each field.,1
v0.6.7,TODO: Needs further discussion at design-level.,1
v0.6.7,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.7,TODO: Harden these tests later to check content from data method.,1
v0.6.7,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.7,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.7,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.7,NOTE: We know this environment is going to use Dash.,1
v0.6.7,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.7,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.7,TODO PK add a test for Regression with interactions,1
v0.6.7,TODO PK add a test with a real regression dataset,1
v0.6.7,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.7,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.7,TODO: expand this test to use the other feature types available,1
v0.6.7,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.7,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.7,TODO: write this test,1
v0.6.7,TODO: write this test,1
v0.6.7,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.7,TODO: stop this call from writing to stdout or stderr,1
v0.6.7,NOTE: Not implemented yet,1
v0.6.7,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.7,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.7,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.7,TODO: Remove this if threshold lines are never used.,1
v0.6.7,TODO: Clean this up after validation.,1
v0.6.7,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.7,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.7,NOTE: Workaround for tables not rendering,1
v0.6.7,TODO: Check if this is needed with the new tables.,1
v0.6.7,TODO: Consider reducing complexity of this function.,1
v0.6.7,NOTE: Workaround for tables not rendering,1
v0.6.7,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.7,TODO: Revisit when we support custom tabs from users.,1
v0.6.7,# TODO Can the base vis be a util?,1
v0.6.7,TODO: can we get rid of this column of X?,1
v0.6.7,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.7,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.7,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.7,TODO: Make kwargs explicit.,1
v0.6.7,TODO: a few ways to improve this function:,1
v0.6.7,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.7,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.7,TODO: should preprocessors handle 0 samples?,1
v0.6.7,TODO: check for names/indexes in the dict that are not,1
v0.6.7,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.7,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.7,TODO: clean up this hack that uses strings of the indexes,1
v0.6.7,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.7,TODO: Add unit tests for internal EBM interfacing,1
v0.6.7,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.7,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.7,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.7,TODO: Needs test.,1
v0.6.7,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.7,BIG TODO LIST:,1
v0.6.7,FUTURE TODOS in our callers and in JSON:,1
v0.6.7,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.7,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.7,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.7,TODO : should this be np.float64 with a check for big integers,1
v0.6.7,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.7,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.7,TODO: does this work if there are spaces or bools?,1
v0.6.7,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.7,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.7,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.7,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.7,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.7,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.7,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.7,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.7,TODO: implement pd.SparseDtype,1
v0.6.7,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.7,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.7,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.7,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.7,TODO: handle as a single feature model,1
v0.6.7,TODO: handle as a single feature model,1
v0.6.7,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.7,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.7,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.7,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.7,TODO: END SECTION TO BE REMOVED,1
v0.6.7,TODO: we should not use Pandas in a public interface like this,1
v0.6.7,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.7,TODO: remove this.. we don't seem to use it,1
v0.6.7,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.7,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.7,"TODO: Consider removing later, potentially dead code.",1
v0.6.7,TODO: we could probably handle this case,1
v0.6.7,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.7,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.7,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.7,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.7,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.7,TODO: we could probably handle this case,1
v0.6.7,Todo: check if this call,1
v0.6.7,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.7,TODO: check these,1
v0.6.7,TODO: load python parameters,1
v0.6.7,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.7,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.7,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.7,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.7,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.7,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.7,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.7,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.7,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.7,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.7,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.7,TODO: in the future we might at this point try and figure out the most,1
v0.6.7,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.7,TODO: we might be able to do these operations earlier,1
v0.6.7,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.7,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.7,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.7,TODO: check the other inputs for common mistakes here,1
v0.6.7,TODO: should we make this something higher?,1
v0.6.7,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.7,TODO: instead of making these copies we should,1
v0.6.7,"TODO: instead of going back to the original data in X, we",1
v0.6.7,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.7,TODO: this will fail if we have multiple categories in a bin,1
v0.6.7,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.7,TODO: do this per-bag in addition to the final scores:,1
v0.6.7,TODO: do this per-bag in addition to the final scores:,1
v0.6.7,TODO: do this per-bag in addition to the final scores:,1
v0.6.7,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.7,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.7,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.7,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.7,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.7,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.7,TODO: Support other languages,1
v0.6.7,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.7,TODO: MLI should handle multiclass at a future date.,1
v0.6.7,TODO: Generalize this out.,1
v0.6.7,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.7,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.7,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.7,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.7,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.7,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.7,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.7,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.7,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.7,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.7,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.7,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.7,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.7,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.7,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.7,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.7,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.7,TODO: we should calculate the default partial gain before splitting anything. Once we have that,1
v0.6.7,TODO: We can optimize away some of these calls to TensorTotalsSum because some of the,1
v0.6.7,TODO: we're doing extra computation above when we calculate the unpurified gain so eliminate that,1
v0.6.7,"TODO: the code below is duplicated in GenerateTempUpdate, so we can probably",1
v0.6.7,TODO: in the future try randomizing the purification order.  It probably doesn't make much,1
v0.6.7,TODO: we should move this computation to the top and then calculate how much gain we need,1
v0.6.7,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.7,perhaps might return that for subnormal floats.,1
v0.6.7,TODO: this entire section below!,1
v0.6.7,TODO: implement this:,1
v0.6.7,TODO: implement this:,1
v0.6.7,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.7,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.7,TODO: review these comments below now that things have changed:,1
v0.6.7,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.7,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.7,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.7,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.7,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.7,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.7,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.7,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.7,TODO : ALL OF THE BELOW!,1
v0.6.7,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.7,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.7,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.7,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.7,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.7,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.7,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.7,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.7,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.7,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.7,our caller can give us one of these bad types of inputs:,1
v0.6.7,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.7,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.7,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.7,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.7,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.7,"TODO: add this as a python/R option ""winsorized""",1
v0.6.7,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.7,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.7,TODO: implement sparse features,1
v0.6.7,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.7,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.7,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.7,TODO: sort the data by the target (if there is only one target),1
v0.6.7,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.7,TODO: handle sparse data someday,1
v0.6.7,TODO: clean this float in float32 format,1
v0.6.7,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.7,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.7,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.7,g_TODO_removeThisThreadTest = 1;,1
v0.6.7,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.7,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.7,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.7,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.7,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.7,TODO: move this to init,1
v0.6.7,TODO: move this to init,1
v0.6.7,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.7,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.7,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.7,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.7,- TODO: POST-HEALING,1
v0.6.7,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.7,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.7,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.7,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.7,TODO: evaluate max here instead as well,1
v0.6.7,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.7,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.7,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.7,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.7,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.7,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.7,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.7,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.7,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.7,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.7,There's actually two subtle issues here that we need to handle differently:,1
v0.6.7,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.7,- TODO: EXPLORING BOTH SIDES,1
v0.6.7,- TODO:,1
v0.6.7,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.7,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.7,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.7,TODO : in the future fill this priority queue with the average length within our,1
v0.6.7,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.7,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.7,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.7,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.7,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.7,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.7,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.7,TODO: move this to init,1
v0.6.7,TODO: move this to init,1
v0.6.7,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.7,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.7,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.7,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.7,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.7,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.7,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.7,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.7,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.7,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.7,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.7,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.7,TODO: move most of this code out of this function into a non-templated place,1
v0.6.7,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.7,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.7,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.7,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.7,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.7,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.7,TODO : add classification binary and multiclass versions of this,1
v0.6.7,TODO : add classification binary and multiclass versions of this,1
v0.6.7,TODO: restore this test,1
v0.6.7,TODO: restore this test,1
v0.6.7,TODO: restore this test,1
v0.6.7,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.7,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.7,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.7,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.7,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.7,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.7,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.7,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.7,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.7,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.7,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.6,TODO: begin_delete can delete on server but fail,1
v0.6.6,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.6,TODO: include support for Azure passwordless credentials:,1
v0.6.6,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.6,TODO: Consider separation of concerns for each field.,1
v0.6.6,TODO: Needs further discussion at design-level.,1
v0.6.6,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.6,TODO: Harden these tests later to check content from data method.,1
v0.6.6,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.6,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.6,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.6,NOTE: We know this environment is going to use Dash.,1
v0.6.6,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.6,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.6,TODO PK add a test for Regression with interactions,1
v0.6.6,TODO PK add a test with a real regression dataset,1
v0.6.6,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.6,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.6,TODO: expand this test to use the other feature types available,1
v0.6.6,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.6,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.6,TODO: write this test,1
v0.6.6,TODO: write this test,1
v0.6.6,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.6,TODO: stop this call from writing to stdout or stderr,1
v0.6.6,NOTE: Not implemented yet,1
v0.6.6,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.6,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.6,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.6,TODO: Remove this if threshold lines are never used.,1
v0.6.6,TODO: Clean this up after validation.,1
v0.6.6,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.6,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.6,NOTE: Workaround for tables not rendering,1
v0.6.6,TODO: Check if this is needed with the new tables.,1
v0.6.6,TODO: Consider reducing complexity of this function.,1
v0.6.6,NOTE: Workaround for tables not rendering,1
v0.6.6,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.6,TODO: Revisit when we support custom tabs from users.,1
v0.6.6,# TODO Can the base vis be a util?,1
v0.6.6,TODO: can we get rid of this column of X?,1
v0.6.6,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.6,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.6,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.6,TODO: Make kwargs explicit.,1
v0.6.6,TODO: a few ways to improve this function:,1
v0.6.6,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.6,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.6,TODO: should preprocessors handle 0 samples?,1
v0.6.6,TODO: check for names/indexes in the dict that are not,1
v0.6.6,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.6,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.6,TODO: clean up this hack that uses strings of the indexes,1
v0.6.6,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.6,TODO: Add unit tests for internal EBM interfacing,1
v0.6.6,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.6,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.6,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.6,TODO: Needs test.,1
v0.6.6,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.6,BIG TODO LIST:,1
v0.6.6,FUTURE TODOS in our callers and in JSON:,1
v0.6.6,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.6,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.6,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.6,TODO : should this be np.float64 with a check for big integers,1
v0.6.6,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.6,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.6,TODO: does this work if there are spaces or bools?,1
v0.6.6,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.6,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.6,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.6,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.6,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.6,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.6,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.6,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.6,TODO: implement pd.SparseDtype,1
v0.6.6,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.6,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.6,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.6,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.6,TODO: handle as a single feature model,1
v0.6.6,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.6,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.6,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.6,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.6,TODO: END SECTION TO BE REMOVED,1
v0.6.6,TODO: we should not use Pandas in a public interface like this,1
v0.6.6,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.6,TODO: remove this.. we don't seem to use it,1
v0.6.6,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.6,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.6,"TODO: Consider removing later, potentially dead code.",1
v0.6.6,TODO: we could probably handle this case,1
v0.6.6,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.6,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.6,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.6,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.6,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.6,TODO: we could probably handle this case,1
v0.6.6,Todo: check if this call,1
v0.6.6,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.6,TODO: check these,1
v0.6.6,TODO: load python parameters,1
v0.6.6,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.6,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.6,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.6,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.6,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.6,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.6,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.6,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.6,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.6,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.6,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.6,TODO: in the future we might at this point try and figure out the most,1
v0.6.6,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.6,TODO: we might be able to do these operations earlier,1
v0.6.6,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.6,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.6,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.6,TODO: check the other inputs for common mistakes here,1
v0.6.6,TODO: should we make this something higher?,1
v0.6.6,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.6,TODO: instead of making these copies we should,1
v0.6.6,"TODO: instead of going back to the original data in X, we",1
v0.6.6,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.6,TODO: this will fail if we have multiple categories in a bin,1
v0.6.6,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.6,TODO: do this per-bag in addition to the final scores:,1
v0.6.6,TODO: do this per-bag in addition to the final scores:,1
v0.6.6,TODO: do this per-bag in addition to the final scores:,1
v0.6.6,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.6,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.6,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.6,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.6,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.6,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.6,TODO: Support other languages,1
v0.6.6,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.6,TODO: MLI should handle multiclass at a future date.,1
v0.6.6,TODO: Generalize this out.,1
v0.6.6,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.6,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.6,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.6,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.6,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.6,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.6,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.6,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.6,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.6,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.6,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.6,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.6,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.6,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.6,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.6,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.6,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.6,TODO: we should calculate the default partial gain before splitting anything. Once we have that,1
v0.6.6,TODO: We can optimize away some of these calls to TensorTotalsSum because some of the,1
v0.6.6,TODO: we're doing extra computation above when we calculate the unpurified gain so eliminate that,1
v0.6.6,"TODO: the code below is duplicated in GenerateTempUpdate, so we can probably",1
v0.6.6,TODO: in the future try randomizing the purification order.  It probably doesn't make much,1
v0.6.6,TODO: we should move this computation to the top and then calculate how much gain we need,1
v0.6.6,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.6,perhaps might return that for subnormal floats.,1
v0.6.6,TODO: this entire section below!,1
v0.6.6,TODO: implement this:,1
v0.6.6,TODO: implement this:,1
v0.6.6,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.6,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.6,TODO: review these comments below now that things have changed:,1
v0.6.6,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.6,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.6,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.6,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.6,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.6,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.6,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.6,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.6,TODO : ALL OF THE BELOW!,1
v0.6.6,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.6,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.6,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.6,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.6,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.6,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.6,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.6,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.6,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.6,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.6,our caller can give us one of these bad types of inputs:,1
v0.6.6,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.6,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.6,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.6,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.6,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.6,"TODO: add this as a python/R option ""winsorized""",1
v0.6.6,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.6,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.6,TODO: implement sparse features,1
v0.6.6,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.6,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.6,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.6,TODO: sort the data by the target (if there is only one target),1
v0.6.6,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.6,TODO: handle sparse data someday,1
v0.6.6,TODO: clean this float in float32 format,1
v0.6.6,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.6,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.6,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.6,g_TODO_removeThisThreadTest = 1;,1
v0.6.6,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.6,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.6,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.6,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.6,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.6,TODO: move this to init,1
v0.6.6,TODO: move this to init,1
v0.6.6,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.6,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.6,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.6,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.6,- TODO: POST-HEALING,1
v0.6.6,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.6,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.6,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.6,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.6,TODO: evaluate max here instead as well,1
v0.6.6,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.6,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.6,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.6,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.6,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.6,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.6,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.6,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.6,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.6,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.6,There's actually two subtle issues here that we need to handle differently:,1
v0.6.6,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.6,- TODO: EXPLORING BOTH SIDES,1
v0.6.6,- TODO:,1
v0.6.6,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.6,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.6,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.6,TODO : in the future fill this priority queue with the average length within our,1
v0.6.6,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.6,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.6,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.6,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.6,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.6,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.6,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.6,TODO: move this to init,1
v0.6.6,TODO: move this to init,1
v0.6.6,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.6,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.6,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.6,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.6,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.6,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.6,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.6,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.6,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.6,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.6,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.6,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.6,TODO: move most of this code out of this function into a non-templated place,1
v0.6.6,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.6,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.6,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.6,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.6,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.6,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.6,TODO : add classification binary and multiclass versions of this,1
v0.6.6,TODO : add classification binary and multiclass versions of this,1
v0.6.6,TODO: restore this test,1
v0.6.6,TODO: restore this test,1
v0.6.6,TODO: restore this test,1
v0.6.6,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.6,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.6,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.6,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.6,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.6,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.6,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.6,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.6,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.6,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.6,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.5,TODO: begin_delete can delete on server but fail,1
v0.6.5,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.5,TODO: include support for Azure passwordless credentials:,1
v0.6.5,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.5,TODO: Consider separation of concerns for each field.,1
v0.6.5,TODO: Needs further discussion at design-level.,1
v0.6.5,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.5,TODO: Harden these tests later to check content from data method.,1
v0.6.5,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.5,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.5,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.5,NOTE: We know this environment is going to use Dash.,1
v0.6.5,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.5,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.5,TODO PK add a test for Regression with interactions,1
v0.6.5,TODO PK add a test with a real regression dataset,1
v0.6.5,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.5,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.5,TODO: expand this test to use the other feature types available,1
v0.6.5,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.5,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.5,TODO: write this test,1
v0.6.5,TODO: write this test,1
v0.6.5,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.5,TODO: stop this call from writing to stdout or stderr,1
v0.6.5,NOTE: Not implemented yet,1
v0.6.5,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.5,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.5,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.5,TODO: Remove this if threshold lines are never used.,1
v0.6.5,TODO: Clean this up after validation.,1
v0.6.5,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.5,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.5,NOTE: Workaround for tables not rendering,1
v0.6.5,TODO: Check if this is needed with the new tables.,1
v0.6.5,TODO: Consider reducing complexity of this function.,1
v0.6.5,NOTE: Workaround for tables not rendering,1
v0.6.5,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.5,TODO: Revisit when we support custom tabs from users.,1
v0.6.5,# TODO Can the base vis be a util?,1
v0.6.5,TODO: can we get rid of this column of X?,1
v0.6.5,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.5,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.5,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.5,TODO: Make kwargs explicit.,1
v0.6.5,TODO: a few ways to improve this function:,1
v0.6.5,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.5,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.5,TODO: should preprocessors handle 0 samples?,1
v0.6.5,TODO: check for names/indexes in the dict that are not,1
v0.6.5,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.5,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.5,TODO: clean up this hack that uses strings of the indexes,1
v0.6.5,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.5,TODO: Add unit tests for internal EBM interfacing,1
v0.6.5,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.5,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.5,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.5,TODO: Needs test.,1
v0.6.5,BIG TODO LIST:,1
v0.6.5,FUTURE TODOS in our callers and in JSON:,1
v0.6.5,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.5,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.5,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.5,TODO : should this be np.float64 with a check for big integers,1
v0.6.5,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.5,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.5,TODO: does this work if there are spaces or bools?,1
v0.6.5,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.5,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.5,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.5,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.5,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.5,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.5,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.5,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.5,TODO: implement pd.SparseDtype,1
v0.6.5,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.5,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.5,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.5,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.5,TODO: handle as a single feature model,1
v0.6.5,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.5,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.5,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.5,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.5,TODO: END SECTION TO BE REMOVED,1
v0.6.5,TODO: we should not use Pandas in a public interface like this,1
v0.6.5,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.5,TODO: remove this.. we don't seem to use it,1
v0.6.5,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.5,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.5,"TODO: Consider removing later, potentially dead code.",1
v0.6.5,TODO: we could probably handle this case,1
v0.6.5,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.5,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.5,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.5,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.5,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.5,TODO: we could probably handle this case,1
v0.6.5,Todo: check if this call,1
v0.6.5,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.5,TODO: check these,1
v0.6.5,TODO: load python parameters,1
v0.6.5,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.5,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.5,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.5,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.5,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.5,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.5,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.5,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.5,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.5,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.5,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.5,TODO: in the future we might at this point try and figure out the most,1
v0.6.5,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.5,TODO: we might be able to do these operations earlier,1
v0.6.5,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.5,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.5,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.5,TODO: check the other inputs for common mistakes here,1
v0.6.5,TODO: should we make this something higher?,1
v0.6.5,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.5,TODO: instead of making these copies we should,1
v0.6.5,"TODO: instead of going back to the original data in X, we",1
v0.6.5,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.5,TODO: this will fail if we have multiple categories in a bin,1
v0.6.5,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.5,TODO: do this per-bag in addition to the final scores:,1
v0.6.5,TODO: do this per-bag in addition to the final scores:,1
v0.6.5,TODO: do this per-bag in addition to the final scores:,1
v0.6.5,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.5,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.5,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.5,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.5,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.5,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.5,TODO: Support other languages,1
v0.6.5,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.5,TODO: MLI should handle multiclass at a future date.,1
v0.6.5,TODO: Generalize this out.,1
v0.6.5,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.5,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.5,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.5,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.5,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.5,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.5,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.5,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.5,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.5,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.5,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.5,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.5,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.5,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.5,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.5,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.5,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.5,"TODO: At this point we have the bin sums histogram for the tensor, so we can purify the future update",1
v0.6.5,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.5,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.5,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.5,perhaps might return that for subnormal floats.,1
v0.6.5,TODO: this entire section below!,1
v0.6.5,TODO: implement this:,1
v0.6.5,TODO: implement this:,1
v0.6.5,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.5,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.5,TODO: review these comments below now that things have changed:,1
v0.6.5,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.5,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.5,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.5,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.5,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.5,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.5,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.5,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.5,TODO : ALL OF THE BELOW!,1
v0.6.5,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.5,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.5,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.5,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.5,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.5,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.5,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.5,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.5,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.5,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.5,our caller can give us one of these bad types of inputs:,1
v0.6.5,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.5,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.5,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.5,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.5,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.5,"TODO: add this as a python/R option ""winsorized""",1
v0.6.5,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.5,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.5,TODO: implement sparse features,1
v0.6.5,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.5,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.5,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.5,TODO: sort the data by the target (if there is only one target),1
v0.6.5,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.5,TODO: handle sparse data someday,1
v0.6.5,TODO: clean this float in float32 format,1
v0.6.5,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.5,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.5,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.5,g_TODO_removeThisThreadTest = 1;,1
v0.6.5,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.5,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.5,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.5,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.5,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're",1
v0.6.5,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.5,TODO: handle interaction detection for higher dimensions,1
v0.6.5,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.5,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.5,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.5,- TODO: POST-HEALING,1
v0.6.5,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.5,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.5,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.5,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.5,TODO: evaluate max here instead as well,1
v0.6.5,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.5,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.5,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.5,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.5,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.5,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.5,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.5,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.5,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.5,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.5,There's actually two subtle issues here that we need to handle differently:,1
v0.6.5,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.5,- TODO: EXPLORING BOTH SIDES,1
v0.6.5,- TODO:,1
v0.6.5,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.5,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.5,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.5,TODO : in the future fill this priority queue with the average length within our,1
v0.6.5,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.5,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.5,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.5,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.5,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.5,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.5,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.5,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.6.5,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.5,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.5,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.5,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.5,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.5,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.5,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.5,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.5,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.5,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.5,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.5,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.5,TODO: move most of this code out of this function into a non-templated place,1
v0.6.5,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.5,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.5,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.5,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.5,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.5,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.5,TODO : add classification binary and multiclass versions of this,1
v0.6.5,TODO : add classification binary and multiclass versions of this,1
v0.6.5,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.5,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.5,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.5,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.5,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.5,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.5,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.5,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.5,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.5,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.5,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.4,TODO: begin_delete can delete on server but fail,1
v0.6.4,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.4,TODO: include support for Azure passwordless credentials:,1
v0.6.4,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.4,TODO: Consider separation of concerns for each field.,1
v0.6.4,TODO: Needs further discussion at design-level.,1
v0.6.4,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.4,TODO: Harden these tests later to check content from data method.,1
v0.6.4,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.4,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.4,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.4,NOTE: We know this environment is going to use Dash.,1
v0.6.4,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.4,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.4,TODO PK add a test for Regression with interactions,1
v0.6.4,TODO PK add a test with a real regression dataset,1
v0.6.4,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.4,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.4,TODO: expand this test to use the other feature types available,1
v0.6.4,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.4,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.4,TODO: write this test,1
v0.6.4,TODO: write this test,1
v0.6.4,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.4,TODO: investigate if _randomize_feature_order actually decreases accuracy,1
v0.6.4,TODO: stop this call from writing to stdout or stderr,1
v0.6.4,NOTE: Not implemented yet,1
v0.6.4,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.4,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.4,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.4,TODO: Remove this if threshold lines are never used.,1
v0.6.4,TODO: Clean this up after validation.,1
v0.6.4,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.4,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.4,NOTE: Workaround for tables not rendering,1
v0.6.4,TODO: Check if this is needed with the new tables.,1
v0.6.4,TODO: Consider reducing complexity of this function.,1
v0.6.4,NOTE: Workaround for tables not rendering,1
v0.6.4,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.4,TODO: Revisit when we support custom tabs from users.,1
v0.6.4,# TODO Can the base vis be a util?,1
v0.6.4,TODO: can we get rid of this column of X?,1
v0.6.4,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.4,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.4,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.4,TODO: Make kwargs explicit.,1
v0.6.4,TODO: a few ways to improve this function:,1
v0.6.4,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.4,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.4,TODO: should preprocessors handle 0 samples?,1
v0.6.4,TODO: check for names/indexes in the dict that are not,1
v0.6.4,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.4,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.4,TODO: clean up this hack that uses strings of the indexes,1
v0.6.4,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.4,TODO: Add unit tests for internal EBM interfacing,1
v0.6.4,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.4,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.4,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.4,TODO: Needs test.,1
v0.6.4,BIG TODO LIST:,1
v0.6.4,FUTURE TODOS in our callers and in JSON:,1
v0.6.4,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.4,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.4,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.4,TODO : should this be np.float64 with a check for big integers,1
v0.6.4,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.4,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.4,TODO: does this work if there are spaces or bools?,1
v0.6.4,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.4,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.4,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.4,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.4,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.4,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.4,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.4,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.4,TODO: implement pd.SparseDtype,1
v0.6.4,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.4,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.4,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.4,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.4,TODO: handle as a single feature model,1
v0.6.4,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.4,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.4,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.4,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.4,TODO: END SECTION TO BE REMOVED,1
v0.6.4,TODO: we should not use Pandas in a public interface like this,1
v0.6.4,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.4,TODO: remove this.. we don't seem to use it,1
v0.6.4,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.4,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.4,"TODO: Consider removing later, potentially dead code.",1
v0.6.4,TODO: we could probably handle this case,1
v0.6.4,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.4,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.4,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.4,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.4,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.4,TODO: we could probably handle this case,1
v0.6.4,Todo: check if this call,1
v0.6.4,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.4,TODO: check these,1
v0.6.4,TODO: load python parameters,1
v0.6.4,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.4,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.4,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.4,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.4,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.4,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.4,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.4,TODO: in the future we might at this point try and figure out the most,1
v0.6.4,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.4,TODO: we might be able to do these operations earlier,1
v0.6.4,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.4,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.4,TODO: test if shuffling during pure cyclic is better,1
v0.6.4,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.4,TODO: check the other inputs for common mistakes here,1
v0.6.4,TODO: should we make this something higher?,1
v0.6.4,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.4,TODO: instead of making these copies we should,1
v0.6.4,"TODO: instead of going back to the original data in X, we",1
v0.6.4,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.4,TODO: this will fail if we have multiple categories in a bin,1
v0.6.4,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.4,TODO: do this per-bag in addition to the final scores:,1
v0.6.4,TODO: do this per-bag in addition to the final scores:,1
v0.6.4,TODO: do this per-bag in addition to the final scores:,1
v0.6.4,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.4,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.4,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.4,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.4,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.4,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.4,TODO: Support other languages,1
v0.6.4,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.4,TODO: MLI should handle multiclass at a future date.,1
v0.6.4,TODO: Generalize this out.,1
v0.6.4,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.4,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.4,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.4,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.4,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.4,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.4,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.4,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.4,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.4,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.4,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.4,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.4,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.4,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.4,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.4,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.4,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.4,"TODO: At this point we have the bin sums histogram for the tensor, so we can purify the future update",1
v0.6.4,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.4,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.4,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.4,perhaps might return that for subnormal floats.,1
v0.6.4,TODO: this entire section below!,1
v0.6.4,TODO: implement this:,1
v0.6.4,TODO: implement this:,1
v0.6.4,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.4,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.4,TODO: review these comments below now that things have changed:,1
v0.6.4,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.4,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.4,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.4,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.4,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.4,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.4,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.4,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.4,TODO : ALL OF THE BELOW!,1
v0.6.4,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.4,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.4,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.4,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.4,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.4,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.4,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.4,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.4,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.4,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.4,our caller can give us one of these bad types of inputs:,1
v0.6.4,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.4,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.4,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.4,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.4,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.4,"TODO: add this as a python/R option ""winsorized""",1
v0.6.4,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.4,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.4,TODO: implement sparse features,1
v0.6.4,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.4,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.4,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.4,TODO: sort the data by the target (if there is only one target),1
v0.6.4,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.4,TODO: handle sparse data someday,1
v0.6.4,TODO: clean this float in float32 format,1
v0.6.4,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.4,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.4,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.4,g_TODO_removeThisThreadTest = 1;,1
v0.6.4,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.4,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.4,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.4,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.4,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're",1
v0.6.4,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.4,TODO: handle interaction detection for higher dimensions,1
v0.6.4,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.4,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.4,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.4,- TODO: POST-HEALING,1
v0.6.4,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.4,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.4,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.4,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.4,TODO: evaluate max here instead as well,1
v0.6.4,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.4,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.4,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.4,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.4,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.4,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.4,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.4,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.4,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.4,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.4,There's actually two subtle issues here that we need to handle differently:,1
v0.6.4,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.4,- TODO: EXPLORING BOTH SIDES,1
v0.6.4,- TODO:,1
v0.6.4,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.4,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.4,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.4,TODO : in the future fill this priority queue with the average length within our,1
v0.6.4,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.4,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.4,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.4,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.4,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.4,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.4,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.4,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.6.4,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.4,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.4,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.4,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.4,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.4,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.4,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.4,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.4,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.6.4,"Actually, I think the real solution here is that",1
v0.6.4,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.6.4,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.6.4,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.4,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.4,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.4,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.4,TODO: move most of this code out of this function into a non-templated place,1
v0.6.4,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.4,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.4,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.4,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.4,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.4,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.4,TODO : add classification binary and multiclass versions of this,1
v0.6.4,TODO : add classification binary and multiclass versions of this,1
v0.6.4,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.4,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.4,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.4,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.4,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.4,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.4,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.4,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.4,TODO: combine this with the NaN check (we simply pass it through if it's +inf (with negation if required),1
v0.6.4,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.4,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.4,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.4,TODO: combine this with the NaN (we simply pass it through if it's +inf (with negation if required),1
v0.6.4,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.4,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.3,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.3,TODO(nopdive): Should this be in the store?,1
v0.6.3,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.3,TODO: Consider separation of concerns for each field.,1
v0.6.3,TODO: Needs further discussion at design-level.,1
v0.6.3,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.3,TODO: Harden these tests later to check content from data method.,1
v0.6.3,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.3,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.3,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.3,NOTE: We know this environment is going to use Dash.,1
v0.6.3,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.3,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.3,TODO PK add a test for Regression with interactions,1
v0.6.3,TODO PK add a test with a real regression dataset,1
v0.6.3,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.3,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.3,TODO: expand this test to use the other feature types available,1
v0.6.3,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.3,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.3,TODO: write this test,1
v0.6.3,TODO: write this test,1
v0.6.3,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.3,TODO: investigate if _randomize_feature_order actually decreases accuracy,1
v0.6.3,TODO: stop this call from writing to stdout or stderr,1
v0.6.3,NOTE: Not implemented yet,1
v0.6.3,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.3,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.3,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.3,TODO: Remove this if threshold lines are never used.,1
v0.6.3,TODO: Clean this up after validation.,1
v0.6.3,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.3,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.3,NOTE: Workaround for tables not rendering,1
v0.6.3,TODO: Check if this is needed with the new tables.,1
v0.6.3,TODO: Consider reducing complexity of this function.,1
v0.6.3,NOTE: Workaround for tables not rendering,1
v0.6.3,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.3,TODO: Revisit when we support custom tabs from users.,1
v0.6.3,# TODO Can the base vis be a util?,1
v0.6.3,TODO: can we get rid of this column of X?,1
v0.6.3,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.3,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.3,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.3,TODO: Make kwargs explicit.,1
v0.6.3,TODO: a few ways to improve this function:,1
v0.6.3,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.3,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.3,TODO: should preprocessors handle 0 samples?,1
v0.6.3,TODO: check for names/indexes in the dict that are not,1
v0.6.3,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.3,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.3,TODO: clean up this hack that uses strings of the indexes,1
v0.6.3,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.3,TODO: Add unit tests for internal EBM interfacing,1
v0.6.3,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.3,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.3,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.3,TODO: Needs test.,1
v0.6.3,BIG TODO LIST:,1
v0.6.3,FUTURE TODOS in our callers and in JSON:,1
v0.6.3,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.3,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.3,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.3,TODO : should this be np.float64 with a check for big integers,1
v0.6.3,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.3,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.3,TODO: does this work if there are spaces or bools?,1
v0.6.3,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.3,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.3,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.3,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.3,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.3,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.3,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.3,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.3,TODO: implement pd.SparseDtype,1
v0.6.3,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.3,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.3,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.3,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.3,TODO: handle as a single feature model,1
v0.6.3,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.3,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.3,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.3,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.3,TODO: END SECTION TO BE REMOVED,1
v0.6.3,TODO: we should not use Pandas in a public interface like this,1
v0.6.3,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.3,TODO: remove this.. we don't seem to use it,1
v0.6.3,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.3,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.3,"TODO: Consider removing later, potentially dead code.",1
v0.6.3,TODO: we could probably handle this case,1
v0.6.3,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.3,TODO: add feature_names and feature_types to conform to glassbox API,1
v0.6.3,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.3,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.3,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.3,TODO: we could probably handle this case,1
v0.6.3,Todo: check if this call,1
v0.6.3,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.3,TODO: check these,1
v0.6.3,TODO: load python parameters,1
v0.6.3,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.3,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.3,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.3,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.3,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.3,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.3,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.3,TODO: in the future we might at this point try and figure out the most,1
v0.6.3,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.3,TODO: we might be able to do these operations earlier,1
v0.6.3,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.3,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.3,TODO: test if shuffling during pure cyclic is better,1
v0.6.3,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.3,TODO: check the other inputs for common mistakes here,1
v0.6.3,TODO: should we make this something higher?,1
v0.6.3,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.3,TODO: instead of making these copies we should,1
v0.6.3,"TODO: instead of going back to the original data in X, we",1
v0.6.3,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.3,TODO: this will fail if we have multiple categories in a bin,1
v0.6.3,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.3,TODO: do this per-bag in addition to the final scores:,1
v0.6.3,TODO: do this per-bag in addition to the final scores:,1
v0.6.3,TODO: do this per-bag in addition to the final scores:,1
v0.6.3,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.3,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.3,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.3,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.3,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.3,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.3,TODO: Support other languages,1
v0.6.3,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.3,TODO: MLI should handle multiclass at a future date.,1
v0.6.3,TODO: Generalize this out.,1
v0.6.3,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.3,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.3,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.3,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.3,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.3,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.3,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.3,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.3,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.3,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.3,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.3,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.3,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.3,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.3,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.3,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.3,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.3,"TODO: At this point we have the bin sums histogram for the tensor, so we can purify the future update",1
v0.6.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.3,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.3,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.3,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.3,perhaps might return that for subnormal floats.,1
v0.6.3,TODO: this entire section below!,1
v0.6.3,TODO: implement this:,1
v0.6.3,TODO: implement this:,1
v0.6.3,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.3,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.3,TODO: review these comments below now that things have changed:,1
v0.6.3,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.3,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.3,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.3,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.3,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.3,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.3,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.3,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.3,TODO : ALL OF THE BELOW!,1
v0.6.3,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.3,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.3,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.3,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.3,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.3,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.3,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.3,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.3,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.3,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.3,our caller can give us one of these bad types of inputs:,1
v0.6.3,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.3,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.3,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.3,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.3,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.3,"TODO: add this as a python/R option ""winsorized""",1
v0.6.3,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.3,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.3,TODO: implement sparse features,1
v0.6.3,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.3,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.3,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.3,TODO: sort the data by the target (if there is only one target),1
v0.6.3,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.3,TODO: handle sparse data someday,1
v0.6.3,TODO: clean this float in float32 format,1
v0.6.3,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.3,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.3,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.3,g_TODO_removeThisThreadTest = 1;,1
v0.6.3,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.3,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.3,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.3,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.3,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're",1
v0.6.3,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.3,TODO: handle interaction detection for higher dimensions,1
v0.6.3,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.3,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.3,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.3,- TODO: POST-HEALING,1
v0.6.3,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.3,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.3,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.3,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.3,TODO: evaluate max here instead as well,1
v0.6.3,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.3,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.3,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.3,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.3,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.3,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.3,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.3,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.3,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.3,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.3,There's actually two subtle issues here that we need to handle differently:,1
v0.6.3,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.3,- TODO: EXPLORING BOTH SIDES,1
v0.6.3,- TODO:,1
v0.6.3,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.3,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.3,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.3,TODO : in the future fill this priority queue with the average length within our,1
v0.6.3,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.3,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.3,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.3,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.3,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.3,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.3,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.3,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.6.3,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.3,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.3,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.3,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.3,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.3,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.3,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.3,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.3,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.6.3,"Actually, I think the real solution here is that",1
v0.6.3,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.6.3,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.6.3,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.3,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.3,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.3,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.3,TODO: move most of this code out of this function into a non-templated place,1
v0.6.3,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all,1
v0.6.3,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.3,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.3,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.3,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.3,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.3,TODO : add classification binary and multiclass versions of this,1
v0.6.3,TODO : add classification binary and multiclass versions of this,1
v0.6.3,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.3,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.3,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.3,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.3,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.3,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.3,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.3,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.3,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.3,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.3,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.3,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.3,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.2,TODO(nopdive): Review how seq_num (integrity) are done with measure outcomes.,1
v0.6.2,TODO(nopdive): Should this be in the store?,1
v0.6.2,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.2,TODO: Consider separation of concerns for each field.,1
v0.6.2,TODO: Needs further discussion at design-level.,1
v0.6.2,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.2,TODO: Harden these tests later to check content from data method.,1
v0.6.2,TODO: Turn this back on after TreeSHAP works on numpy 2.0,1
v0.6.2,TODO: Turn this back on after SHAP works on numpy 2.0,1
v0.6.2,elif explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.2,NOTE: We know this environment is going to use Dash.,1
v0.6.2,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.2,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.2,TODO PK add a test for Regression with interactions,1
v0.6.2,TODO PK add a test with a real regression dataset,1
v0.6.2,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.2,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.2,TODO: expand this test to use the other feature types available,1
v0.6.2,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.2,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.2,TODO: write this test,1
v0.6.2,TODO: write this test,1
v0.6.2,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.2,TODO: stop this call from writing to stdout or stderr,1
v0.6.2,NOTE: Not implemented yet,1
v0.6.2,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.2,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.2,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.2,TODO: Remove this if threshold lines are never used.,1
v0.6.2,TODO: Clean this up after validation.,1
v0.6.2,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.2,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.2,NOTE: Workaround for tables not rendering,1
v0.6.2,TODO: Check if this is needed with the new tables.,1
v0.6.2,TODO: Consider reducing complexity of this function.,1
v0.6.2,NOTE: Workaround for tables not rendering,1
v0.6.2,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.2,TODO: Revisit when we support custom tabs from users.,1
v0.6.2,# TODO Can the base vis be a util?,1
v0.6.2,TODO: can we get rid of this column of X?,1
v0.6.2,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.2,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.2,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.2,TODO: Make kwargs explicit.,1
v0.6.2,TODO: a few ways to improve this function:,1
v0.6.2,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.2,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.2,TODO: should preprocessors handle 0 samples?,1
v0.6.2,TODO: check for names/indexes in the dict that are not,1
v0.6.2,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.2,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.2,TODO: clean up this hack that uses strings of the indexes,1
v0.6.2,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.2,TODO: Add unit tests for internal EBM interfacing,1
v0.6.2,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.2,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.2,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.2,TODO: Needs test.,1
v0.6.2,BIG TODO LIST:,1
v0.6.2,FUTURE TODOS in our callers and in JSON:,1
v0.6.2,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.2,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.2,TODO : should this be np.float64 with a check for big integers,1
v0.6.2,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.2,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.2,TODO: does this work if there are spaces or bools?,1
v0.6.2,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.2,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.2,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.2,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.2,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.2,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.2,TODO: implement pd.SparseDtype,1
v0.6.2,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.2,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.2,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.2,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.2,TODO: handle as a single feature model,1
v0.6.2,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.2,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.2,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.2,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.2,TODO: END SECTION TO BE REMOVED,1
v0.6.2,TODO: we should not use Pandas in a public interface like this,1
v0.6.2,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.2,TODO: remove this.. we don't seem to use it,1
v0.6.2,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.2,TODO: implement the above and also a method of keeping track when the same feature appears multiple,1
v0.6.2,"TODO: Consider removing later, potentially dead code.",1
v0.6.2,TODO: we could probably handle this case,1
v0.6.2,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.2,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.2,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.2,TODO: we could probably handle this case,1
v0.6.2,Todo: check if this call,1
v0.6.2,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.2,TODO: check these,1
v0.6.2,TODO: load python parameters,1
v0.6.2,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.2,"TODO: benchmark if it is better to add new_impurities to the existing model scores,",1
v0.6.2,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.2,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.2,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.2,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.2,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.2,TODO: in the future we might at this point try and figure out the most,1
v0.6.2,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.2,TODO: we might be able to do these operations earlier,1
v0.6.2,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.2,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.2,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.2,TODO: check the other inputs for common mistakes here,1
v0.6.2,TODO: should we make this something higher?,1
v0.6.2,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.2,TODO: instead of making these copies we should,1
v0.6.2,"TODO: instead of going back to the original data in X, we",1
v0.6.2,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.2,TODO: this will fail if we have multiple categories in a bin,1
v0.6.2,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.2,TODO: do this per-bag in addition to the final scores:,1
v0.6.2,TODO: do this per-bag in addition to the final scores:,1
v0.6.2,TODO: do this per-bag in addition to the final scores:,1
v0.6.2,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.2,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.2,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.2,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.2,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.2,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.2,TODO: Support other languages,1
v0.6.2,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.2,TODO: MLI should handle multiclass at a future date.,1
v0.6.2,TODO: Generalize this out.,1
v0.6.2,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.2,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.2,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.2,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.2,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.2,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.2,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.2,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.2,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.2,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.2,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.2,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.2,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.2,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.2,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.2,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.2,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.2,"TODO: At this point we have the bin sums histogram for the tensor, so we can purify the future update",1
v0.6.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.2,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.2,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.2,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.2,perhaps might return that for subnormal floats.,1
v0.6.2,TODO: this entire section below!,1
v0.6.2,TODO: implement this:,1
v0.6.2,TODO: implement this:,1
v0.6.2,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.2,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.2,TODO: review these comments below now that things have changed:,1
v0.6.2,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.2,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.2,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.2,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.2,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.2,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.2,TODO : ALL OF THE BELOW!,1
v0.6.2,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.2,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.2,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.2,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.2,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.2,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.2,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.2,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.2,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.2,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.2,our caller can give us one of these bad types of inputs:,1
v0.6.2,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.2,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.2,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.2,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.2,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.2,"TODO: add this as a python/R option ""winsorized""",1
v0.6.2,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.2,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.2,TODO: implement sparse features,1
v0.6.2,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.2,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.2,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.2,TODO: sort the data by the target (if there is only one target),1
v0.6.2,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.2,TODO: handle sparse data someday,1
v0.6.2,TODO: clean this float in float32 format,1
v0.6.2,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.2,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.2,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.2,g_TODO_removeThisThreadTest = 1;,1
v0.6.2,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.2,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.2,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.2,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.2,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're",1
v0.6.2,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.2,TODO: handle interaction detection for higher dimensions,1
v0.6.2,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.2,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.2,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.2,- TODO: POST-HEALING,1
v0.6.2,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.2,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.2,TODO: evaluate max here instead as well,1
v0.6.2,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.2,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.2,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.2,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.2,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.2,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.2,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.2,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.2,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.2,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.2,There's actually two subtle issues here that we need to handle differently:,1
v0.6.2,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.2,- TODO: EXPLORING BOTH SIDES,1
v0.6.2,- TODO:,1
v0.6.2,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.2,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.2,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.2,TODO : in the future fill this priority queue with the average length within our,1
v0.6.2,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.2,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.2,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.2,TODO: We're currently generating different randomized ordering for each class when doing,1
v0.6.2,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.2,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.2,TODO: cache this memory allocation so that we don't do it each time,1
v0.6.2,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.6.2,TODO: in the future try randomizing the purification order.  It probably doesn't make much difference,1
v0.6.2,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.2,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.2,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.2,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.2,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.2,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.2,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.6.2,"Actually, I think the real solution here is that",1
v0.6.2,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.6.2,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.6.2,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.2,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.2,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.2,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.2,TODO: move most of this code out of this function into a non-templated place,1
v0.6.2,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all,1
v0.6.2,TODO: We are purififying the simple 2x2 solution below using a simple system of equations,1
v0.6.2,"TODO: Once more efficient purification is done, we can use the same purification",1
v0.6.2,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.2,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.2,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.2,TODO : add classification binary and multiclass versions of this,1
v0.6.2,TODO : add classification binary and multiclass versions of this,1
v0.6.2,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.2,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.2,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.2,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.2,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.2,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.2,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.2,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.2,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.2,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.2,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.2,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.2,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.1,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.1,TODO: Consider separation of concerns for each field.,1
v0.6.1,TODO: Needs further discussion at design-level.,1
v0.6.1,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.1,TODO: Harden these tests later to check content from data method.,1
v0.6.1,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.1,NOTE: We know this environment is going to use Dash.,1
v0.6.1,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.1,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.1,TODO PK add a test for Regression with interactions,1
v0.6.1,TODO PK add a test with a real regression dataset,1
v0.6.1,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.1,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.1,TODO: expand this test to use the other feature types available,1
v0.6.1,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.1,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.1,TODO: write this test,1
v0.6.1,TODO: write this test,1
v0.6.1,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.1,TODO: stop this call from writing to stdout or stderr,1
v0.6.1,NOTE: Not implemented yet,1
v0.6.1,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.1,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.1,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.1,TODO: Remove this if threshold lines are never used.,1
v0.6.1,TODO: Clean this up after validation.,1
v0.6.1,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.1,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.1,NOTE: Workaround for tables not rendering,1
v0.6.1,TODO: Check if this is needed with the new tables.,1
v0.6.1,TODO: Consider reducing complexity of this function.,1
v0.6.1,NOTE: Workaround for tables not rendering,1
v0.6.1,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.1,TODO: Revisit when we support custom tabs from users.,1
v0.6.1,# TODO Can the base vis be a util?,1
v0.6.1,TODO: can we get rid of this column of X?,1
v0.6.1,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.1,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.1,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.1,TODO: Make kwargs explicit.,1
v0.6.1,TODO: a few ways to improve this function:,1
v0.6.1,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.1,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.1,TODO: should preprocessors handle 0 samples?,1
v0.6.1,TODO: check for names/indexes in the dict that are not,1
v0.6.1,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.1,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.1,TODO: clean up this hack that uses strings of the indexes,1
v0.6.1,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.1,TODO: Add unit tests for internal EBM interfacing,1
v0.6.1,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.1,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.1,TODO: re-enable AVX512 after we have sufficient evidence it works and speeds processing,1
v0.6.1,TODO: Needs test.,1
v0.6.1,BIG TODO LIST:,1
v0.6.1,FUTURE TODOS in our callers and in JSON:,1
v0.6.1,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.1,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.1,TODO : should this be np.float64 with a check for big integers,1
v0.6.1,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.1,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.1,TODO: does this work if there are spaces or bools?,1
v0.6.1,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.1,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.1,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.1,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.1,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.1,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.1,TODO: implement pd.SparseDtype,1
v0.6.1,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.1,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.1,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.1,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.1,TODO: handle as a single feature model,1
v0.6.1,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.1,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.1,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.1,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.1,TODO: END SECTION TO BE REMOVED,1
v0.6.1,TODO: we should not use Pandas in a public interface like this,1
v0.6.1,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.1,TODO: remove this.. we don't seem to use it,1
v0.6.1,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.1,"TODO: Consider removing later, potentially dead code.",1
v0.6.1,TODO: we could probably handle this case,1
v0.6.1,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.1,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.1,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.1,TODO: we could probably handle this case,1
v0.6.1,Todo: check if this call,1
v0.6.1,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.1,TODO: check these,1
v0.6.1,TODO: load python parameters,1
v0.6.1,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.1,TODO: call purify() here from the glassbox\ebm\_research\_purify.py file,1
v0.6.1,"TODO: for multiclass, call a fixed version of multiclass_postprocess_RESTORE_THIS",1
v0.6.1,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.1,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.1,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.1,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.1,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.1,TODO: in the future we might at this point try and figure out the most,1
v0.6.1,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.1,TODO: we might be able to do these operations earlier,1
v0.6.1,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.1,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.1,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.1,TODO: check the other inputs for common mistakes here,1
v0.6.1,TODO: should we make this something higher?,1
v0.6.1,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.1,TODO: instead of making these copies we should,1
v0.6.1,"TODO: instead of going back to the original data in X, we",1
v0.6.1,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.1,TODO: this will fail if we have multiple categories in a bin,1
v0.6.1,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.1,TODO: do this per-bag in addition to the final scores:,1
v0.6.1,TODO: do this per-bag in addition to the final scores:,1
v0.6.1,TODO: do this per-bag in addition to the final scores:,1
v0.6.1,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.1,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.1,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.1,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.1,TODO: Support other languages,1
v0.6.1,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.1,TODO: MLI should handle multiclass at a future date.,1
v0.6.1,TODO: Generalize this out.,1
v0.6.1,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.1,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.1,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.1,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.1,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.1,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.1,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.1,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.1,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.1,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.1,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.1,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.1,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.1,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.1,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.1,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.1,perhaps might return that for subnormal floats.,1
v0.6.1,TODO: this entire section below!,1
v0.6.1,TODO: implement this:,1
v0.6.1,TODO: implement this:,1
v0.6.1,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.1,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.1,TODO: review these comments below now that things have changed:,1
v0.6.1,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.1,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.1,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.1,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.1,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.1,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.1,TODO : ALL OF THE BELOW!,1
v0.6.1,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.1,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.1,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.1,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.1,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.1,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.1,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.1,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.1,TODO: we should move the application of aCounts and aWeights into a separate function,1
v0.6.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.1,our caller can give us one of these bad types of inputs:,1
v0.6.1,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.1,"TODO: add this as a python/R option ""winsorized""",1
v0.6.1,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.1,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.1,TODO: implement sparse features,1
v0.6.1,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.1,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.1,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.1,TODO: sort the data by the target (if there is only one target),1
v0.6.1,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.1,TODO: handle sparse data someday,1
v0.6.1,TODO: clean this float in float32 format,1
v0.6.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.1,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.1,g_TODO_removeThisThreadTest = 1;,1
v0.6.1,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.1,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.1,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.1,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.1,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're",1
v0.6.1,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.1,TODO: handle interaction detection for higher dimensions,1
v0.6.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.1,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.1,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.1,- TODO: POST-HEALING,1
v0.6.1,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.1,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.1,TODO: evaluate max here instead as well,1
v0.6.1,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.1,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.1,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.1,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.1,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.1,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.1,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.1,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.1,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.1,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.1,There's actually two subtle issues here that we need to handle differently:,1
v0.6.1,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.1,- TODO: EXPLORING BOTH SIDES,1
v0.6.1,- TODO:,1
v0.6.1,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.1,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.1,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.1,TODO : in the future fill this priority queue with the average length within our,1
v0.6.1,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.1,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.1,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.1,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.1,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.1,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.6.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.1,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.1,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.1,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.1,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.1,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.1,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.6.1,"Actually, I think the real solution here is that",1
v0.6.1,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.6.1,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.6.1,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.1,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.1,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.1,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.1,TODO: move most of this code out of this function into a non-templated place,1
v0.6.1,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all,1
v0.6.1,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.1,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.1,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.1,TODO : add classification binary and multiclass versions of this,1
v0.6.1,TODO : add classification binary and multiclass versions of this,1
v0.6.1,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.1,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.1,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.1,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.1,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.1,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.1,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.1,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.1,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.1,TODO: we might be able to move this operation to where we store the packed indexes so that,1
v0.6.1,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.1,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.1,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.6.0,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.6.0,TODO: Consider separation of concerns for each field.,1
v0.6.0,TODO: Needs further discussion at design-level.,1
v0.6.0,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.6.0,TODO: Harden these tests later to check content from data method.,1
v0.6.0,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.6.0,NOTE: We know this environment is going to use Dash.,1
v0.6.0,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.6.0,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.6.0,TODO PK add a test for Regression with interactions,1
v0.6.0,TODO PK add a test with a real regression dataset,1
v0.6.0,TODO PK add a test with more than 1 multiclass interaction,1
v0.6.0,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.6.0,TODO: expand this test to use the other feature types available,1
v0.6.0,"test fails as 1.0 != ""1.0"", maybe test should be fixed upstream?",1
v0.6.0,TODO: improve this test by checking the merged ebms for validity.,1
v0.6.0,TODO: write this test,1
v0.6.0,TODO: write this test,1
v0.6.0,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.6.0,TODO: stop this call from writing to stdout or stderr,1
v0.6.0,NOTE: Not implemented yet,1
v0.6.0,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.6.0,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.6.0,"meant to be public. We write it in this submodule, but it looks like that",1
v0.6.0,TODO: Remove this if threshold lines are never used.,1
v0.6.0,TODO: Clean this up after validation.,1
v0.6.0,TODO: Remove this completely once performance graphs are hardened.,1
v0.6.0,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.6.0,NOTE: Workaround for tables not rendering,1
v0.6.0,TODO: Check if this is needed with the new tables.,1
v0.6.0,TODO: Consider reducing complexity of this function.,1
v0.6.0,NOTE: Workaround for tables not rendering,1
v0.6.0,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.6.0,TODO: Revisit when we support custom tabs from users.,1
v0.6.0,# TODO Can the base vis be a util?,1
v0.6.0,TODO: can we get rid of this column of X?,1
v0.6.0,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.6.0,TODO: move this to a more general location where other blackbox methods can access it,1
v0.6.0,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.6.0,TODO: Make kwargs explicit.,1
v0.6.0,TODO: a few ways to improve this function:,1
v0.6.0,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.6.0,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.6.0,TODO: should preprocessors handle 0 samples?,1
v0.6.0,TODO: check for names/indexes in the dict that are not,1
v0.6.0,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.6.0,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.0,TODO: clean up this hack that uses strings of the indexes,1
v0.6.0,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.6.0,TODO: Add unit tests for internal EBM interfacing,1
v0.6.0,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.6.0,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.6.0,TODO: Needs test.,1
v0.6.0,BIG TODO LIST:,1
v0.6.0,FUTURE TODOS in our callers and in JSON:,1
v0.6.0,is probably better than the alternative of getting different categorical strings in different programming,1
v0.6.0,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.6.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.0,TODO : should this be np.float64 with a check for big integers,1
v0.6.0,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.6.0,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.6.0,TODO: does this work if there are spaces or bools?,1
v0.6.0,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.6.0,np.unicode_ array here.  There are two issues with keeping it here,1
v0.6.0,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.6.0,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.6.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.0,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.6.0,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.6.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.6.0,TODO: implement pd.SparseDtype,1
v0.6.0,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.6.0,TODO: in the future special case this to make single samples faster at predict time,1
v0.6.0,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.6.0,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.6.0,TODO: handle as a single feature model,1
v0.6.0,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.6.0,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.6.0,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.6.0,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.6.0,TODO: END SECTION TO BE REMOVED,1
v0.6.0,TODO: we should not use Pandas in a public interface like this,1
v0.6.0,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.6.0,TODO: remove this.. we don't seem to use it,1
v0.6.0,TODO: at some point we should also handle column position remapping when the column names match,1
v0.6.0,"TODO: Consider removing later, potentially dead code.",1
v0.6.0,TODO: we could probably handle this case,1
v0.6.0,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.6.0,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.6.0,TODO: move this call into the explain_global function and extract the information needed,1
v0.6.0,TODO: we could probably handle this case,1
v0.6.0,Todo: check if this call,1
v0.6.0,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.6.0,TODO: check these,1
v0.6.0,TODO: load python parameters,1
v0.6.0,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.6.0,TODO: call purify() here from the glassbox\ebm\_research\_purify.py file,1
v0.6.0,"TODO: for multiclass, call a fixed version of multiclass_postprocess_RESTORE_THIS",1
v0.6.0,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.6.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.6.0,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.6.0,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.6.0,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.6.0,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.6.0,TODO: in the future we might at this point try and figure out the most,1
v0.6.0,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.6.0,TODO: we might be able to do these operations earlier,1
v0.6.0,TODO: we could pass out a bool array instead of objects for this function only,1
v0.6.0,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.6.0,"sometimes there will be 1 or 0 samples in some bags, so it isn't as good as",1
v0.6.0,TODO: check the other inputs for common mistakes here,1
v0.6.0,TODO: should we make this something higher?,1
v0.6.0,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.6.0,TODO: instead of making these copies we should,1
v0.6.0,"TODO: instead of going back to the original data in X, we",1
v0.6.0,TODO: the combinations below should be selected from the non-excluded features,1
v0.6.0,TODO: this will fail if we have multiple categories in a bin,1
v0.6.0,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.6.0,TODO: do this per-bag in addition to the final scores:,1
v0.6.0,TODO: do this per-bag in addition to the final scores:,1
v0.6.0,TODO: do this per-bag in addition to the final scores:,1
v0.6.0,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.6.0,TODO: use Literal for the string types once everything is python 3.8,1
v0.6.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.6.0,TODO this is consistent to what Interpret is doing but might be changed,1
v0.6.0,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.0,TODO: Support other languages,1
v0.6.0,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.6.0,TODO: MLI should handle multiclass at a future date.,1
v0.6.0,TODO: Generalize this out.,1
v0.6.0,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.6.0,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.6.0,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.0,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.0,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.6.0,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.0,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.0,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.6.0,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.6.0,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.6.0,TODO: do we handle 0?  We would write out all zeros..,1
v0.6.0,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.6.0,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.6.0,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.6.0,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.6.0,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.6.0,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.6.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.6.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.6.0,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.6.0,perhaps might return that for subnormal floats.,1
v0.6.0,TODO: this entire section below!,1
v0.6.0,TODO: implement this:,1
v0.6.0,TODO: implement this:,1
v0.6.0,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.6.0,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.6.0,TODO: review these comments below now that things have changed:,1
v0.6.0,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.6.0,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.6.0,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.6.0,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.6.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.6.0,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.6.0,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.6.0,TODO : ALL OF THE BELOW!,1
v0.6.0,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.6.0,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.6.0,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.6.0,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.6.0,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.6.0,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.6.0,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.6.0,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.6.0,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.0,our caller can give us one of these bad types of inputs:,1
v0.6.0,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.6.0,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.0,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.0,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.0,"TODO: add this as a python/R option ""winsorized""",1
v0.6.0,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.6.0,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.6.0,TODO: implement sparse features,1
v0.6.0,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.6.0,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.6.0,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.6.0,TODO: sort the data by the target (if there is only one target),1
v0.6.0,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.6.0,TODO: handle sparse data someday,1
v0.6.0,TODO: clean this float in float32 format,1
v0.6.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.6.0,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.6.0,g_TODO_removeThisThreadTest = 1;,1
v0.6.0,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.6.0,if(0 == g_TODO_removeThisThreadTest) {,1
v0.6.0,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.6.0,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.6.0,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're",1
v0.6.0,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.6.0,TODO: handle interaction detection for higher dimensions,1
v0.6.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.6.0,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.6.0,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.6.0,- TODO: POST-HEALING,1
v0.6.0,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.6.0,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.6.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.6.0,TODO: evaluate max here instead as well,1
v0.6.0,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.6.0,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.6.0,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.6.0,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.6.0,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.6.0,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.6.0,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.6.0,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.6.0,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.6.0,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.6.0,There's actually two subtle issues here that we need to handle differently:,1
v0.6.0,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.6.0,- TODO: EXPLORING BOTH SIDES,1
v0.6.0,- TODO:,1
v0.6.0,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.6.0,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.6.0,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.6.0,TODO : in the future fill this priority queue with the average length within our,1
v0.6.0,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.6.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.0,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.6.0,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.6.0,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.6.0,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.6.0,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.6.0,"then we'll output this log message more times than desired, but we can live with that",1
v0.6.0,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.6.0,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.6.0,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.0,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.6.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.6.0,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.6.0,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.6.0,"Actually, I think the real solution here is that",1
v0.6.0,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.6.0,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.6.0,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.6.0,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.6.0,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.6.0,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.6.0,TODO: move most of this code out of this function into a non-templated place,1
v0.6.0,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.6.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all,1
v0.6.0,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.6.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.6.0,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.6.0,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.6.0,TODO : add classification binary and multiclass versions of this,1
v0.6.0,TODO : add classification binary and multiclass versions of this,1
v0.6.0,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.6.0,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.6.0,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.6.0,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.6.0,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.6.0,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.6.0,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.0,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.6.0,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.6.0,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.6.0,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.5.1,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.5.1,TODO: Consider separation of concerns for each field.,1
v0.5.1,TODO: Needs further discussion at design-level.,1
v0.5.1,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.5.1,TODO: Harden these tests later to check content from data method.,1
v0.5.1,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.5.1,NOTE: We know this environment is going to use Dash.,1
v0.5.1,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.5.1,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.5.1,TODO PK add a test for Regression with interactions,1
v0.5.1,TODO PK add a test with a real regression dataset,1
v0.5.1,TODO PK add a test with more than 1 multiclass interaction,1
v0.5.1,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.5.1,TODO: expand this test to use the other feature types available,1
v0.5.1,TODO: improve this test by checking the merged ebms for validity.,1
v0.5.1,TODO: write this test,1
v0.5.1,TODO: write this test,1
v0.5.1,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.5.1,TODO: stop this call from writing to stdout or stderr,1
v0.5.1,NOTE: Not implemented yet,1
v0.5.1,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.5.1,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.5.1,"meant to be public. We write it in this submodule, but it looks like that",1
v0.5.1,TODO: Remove this if threshold lines are never used.,1
v0.5.1,TODO: Clean this up after validation.,1
v0.5.1,TODO: Remove this completely once performance graphs are hardened.,1
v0.5.1,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.5.1,NOTE: Workaround for tables not rendering,1
v0.5.1,TODO: Check if this is needed with the new tables.,1
v0.5.1,TODO: Consider reducing complexity of this function.,1
v0.5.1,NOTE: Workaround for tables not rendering,1
v0.5.1,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.5.1,TODO: Revisit when we support custom tabs from users.,1
v0.5.1,# TODO Can the base vis be a util?,1
v0.5.1,TODO: can we get rid of this column of X?,1
v0.5.1,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.5.1,TODO: move this to a more general location where other blackbox methods can access it,1
v0.5.1,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.5.1,TODO: Make kwargs explicit.,1
v0.5.1,TODO: a few ways to improve this function:,1
v0.5.1,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.5.1,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.5.1,TODO: should preprocessors handle 0 samples?,1
v0.5.1,TODO: check for names/indexes in the dict that are not,1
v0.5.1,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.5.1,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.5.1,TODO: clean up this hack that uses strings of the indexes,1
v0.5.1,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.5.1,TODO: Add unit tests for internal EBM interfacing,1
v0.5.1,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.5.1,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.5.1,TODO: Needs test.,1
v0.5.1,BIG TODO LIST:,1
v0.5.1,FUTURE TODOS in our callers and in JSON:,1
v0.5.1,is probably better than the alternative of getting different categorical strings in different programming,1
v0.5.1,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.5.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.5.1,TODO : should this be np.float64 with a check for big integers,1
v0.5.1,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.5.1,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.5.1,TODO: does this work if there are spaces or bools?,1
v0.5.1,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.5.1,np.unicode_ array here.  There are two issues with keeping it here,1
v0.5.1,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.5.1,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.5.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.5.1,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.5.1,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.5.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.5.1,TODO: implement pd.SparseDtype,1
v0.5.1,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.5.1,TODO: in the future special case this to make single samples faster at predict time,1
v0.5.1,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.5.1,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.5.1,TODO: handle as a single feature model,1
v0.5.1,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.5.1,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.5.1,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.5.1,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.5.1,TODO: END SECTION TO BE REMOVED,1
v0.5.1,TODO: we should not use Pandas in a public interface like this,1
v0.5.1,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.5.1,TODO: remove this.. we don't seem to use it,1
v0.5.1,TODO: at some point we should also handle column position remapping when the column names match,1
v0.5.1,"TODO: Consider removing later, potentially dead code.",1
v0.5.1,TODO: we could probably handle this case,1
v0.5.1,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.5.1,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.5.1,TODO: move this call into the explain_global function and extract the information needed,1
v0.5.1,TODO: we could probably handle this case,1
v0.5.1,Todo: check if this call,1
v0.5.1,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.5.1,TODO: check these,1
v0.5.1,TODO: load python parameters,1
v0.5.1,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.5.1,TODO: call purify() here from the glassbox\ebm\_research\_purify.py file,1
v0.5.1,"TODO: for multiclass, call a fixed version of multiclass_postprocess_RESTORE_THIS",1
v0.5.1,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.5.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.1,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.5.1,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.5.1,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.5.1,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.5.1,TODO: in the future we might at this point try and figure out the most,1
v0.5.1,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.5.1,TODO: we might be able to do these operations earlier,1
v0.5.1,TODO: we could pass out a bool array instead of objects for this function only,1
v0.5.1,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.5.1,TODO: check the other inputs for common mistakes here,1
v0.5.1,TODO: should we make this something higher?,1
v0.5.1,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.5.1,TODO: instead of making these copies we should,1
v0.5.1,"TODO: instead of going back to the original data in X, we",1
v0.5.1,TODO: the combinations below should be selected from the non-excluded features,1
v0.5.1,TODO: this will fail if we have multiple categories in a bin,1
v0.5.1,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.5.1,TODO: do this per-bag in addition to the final scores:,1
v0.5.1,TODO: do this per-bag in addition to the final scores:,1
v0.5.1,TODO: do this per-bag in addition to the final scores:,1
v0.5.1,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.5.1,TODO: use Literal for the string types once everything is python 3.8,1
v0.5.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.5.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.5.1,TODO this is consistent to what Interpret is doing but might be changed,1
v0.5.1,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.5.1,TODO: Support other languages,1
v0.5.1,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.5.1,TODO: MLI should handle multiclass at a future date.,1
v0.5.1,TODO: Generalize this out.,1
v0.5.1,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.5.1,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.5.1,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.5.1,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.5.1,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.5.1,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.5.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.5.1,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which",1
v0.5.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our",1
v0.5.1,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.5.1,TODO: do we handle 0?  We would write out all zeros..,1
v0.5.1,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions",1
v0.5.1,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions,",1
v0.5.1,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.5.1,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.5.1,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.5.1,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.5.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.5.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.5.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.5.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the,1
v0.5.1,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.5.1,perhaps might return that for subnormal floats.,1
v0.5.1,TODO: this entire section below!,1
v0.5.1,TODO: implement this:,1
v0.5.1,TODO: implement this:,1
v0.5.1,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.5.1,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.5.1,TODO: review these comments below now that things have changed:,1
v0.5.1,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.5.1,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.5.1,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this",1
v0.5.1,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.5.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.5.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.5.1,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as,1
v0.5.1,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.5.1,TODO : ALL OF THE BELOW!,1
v0.5.1,TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just,1
v0.5.1,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler",1
v0.5.1,TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more,1
v0.5.1,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we,1
v0.5.1,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.5.1,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.5.1,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.5.1,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.5.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.5.1,our caller can give us one of these bad types of inputs:,1
v0.5.1,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.5.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.5.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.5.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.5.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.5.1,"TODO: add this as a python/R option ""winsorized""",1
v0.5.1,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.5.1,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.5.1,TODO: implement sparse features,1
v0.5.1,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.5.1,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.5.1,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.5.1,TODO: sort the data by the target (if there is only one target),1
v0.5.1,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.5.1,TODO: handle sparse data someday,1
v0.5.1,TODO: clean this float in float32 format,1
v0.5.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.5.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.5.1,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.5.1,g_TODO_removeThisThreadTest = 1;,1
v0.5.1,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.5.1,if(0 == g_TODO_removeThisThreadTest) {,1
v0.5.1,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.5.1,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should,1
v0.5.1,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're",1
v0.5.1,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.5.1,TODO: handle interaction detection for higher dimensions,1
v0.5.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.5.1,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.5.1,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.5.1,- TODO: POST-HEALING,1
v0.5.1,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.5.1,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.5.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.5.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.5.1,TODO: evaluate max here instead as well,1
v0.5.1,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.5.1,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.5.1,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.5.1,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.5.1,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.5.1,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.5.1,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.5.1,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.5.1,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points",1
v0.5.1,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.5.1,There's actually two subtle issues here that we need to handle differently:,1
v0.5.1,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse,1
v0.5.1,- TODO: EXPLORING BOTH SIDES,1
v0.5.1,- TODO:,1
v0.5.1,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.5.1,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.5.1,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.5.1,TODO : in the future fill this priority queue with the average length within our,1
v0.5.1,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split,",1
v0.5.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.1,"TODO : implement the randomized splitting described for interaction effect, which can be done the same",1
v0.5.1,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.5.1,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.5.1,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required",1
v0.5.1,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.5.1,"then we'll output this log message more times than desired, but we can live with that",1
v0.5.1,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from,1
v0.5.1,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then,1
v0.5.1,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.5.1,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.5.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.5.1,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.",1
v0.5.1,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.5.1,"Actually, I think the real solution here is that",1
v0.5.1,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.5.1,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.5.1,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.5.1,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the,1
v0.5.1,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.5.1,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor,1
v0.5.1,TODO: move most of this code out of this function into a non-templated place,1
v0.5.1,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.5.1,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.5.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all,1
v0.5.1,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.5.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.1,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.5.1,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.5.1,TODO : add classification binary and multiclass versions of this,1
v0.5.1,TODO : add classification binary and multiclass versions of this,1
v0.5.1,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.5.1,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using,1
v0.5.1,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or,1
v0.5.1,TODO : add test for the condition where we overflow the validation regression or classification scores without,1
v0.5.1,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function,",1
v0.5.1,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.5.1,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.5.1,TODO: we might want different constants for binary classification and multiclass. See notes in,1
v0.5.1,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.5.1,someone might change this to a unicode function someday and that new function might be in characters instead of,1
v0.5.1,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.5.0,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.5.0,TODO: Consider separation of concerns for each field.,1
v0.5.0,TODO: Needs further discussion at design-level.,1
v0.5.0,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.5.0,TODO: Harden these tests later to check content from data method.,1
v0.5.0,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.5.0,NOTE: We know this environment is going to use Dash.,1
v0.5.0,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.5.0,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.5.0,TODO PK add a test for Regression with interactions,1
v0.5.0,TODO PK add a test with a real regression dataset,1
v0.5.0,TODO PK add a test with more than 1 multiclass interaction,1
v0.5.0,"hack the EBM into being a 2-class OVR, which is not legal, but will work",1
v0.5.0,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.5.0,TODO: stop this call from writing to stdout or stderr,1
v0.5.0,NOTE: Not implemented yet,1
v0.5.0,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.5.0,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.5.0,"meant to be public. We write it in this submodule, but it looks like that",1
v0.5.0,TODO: Remove this if threshold lines are never used.,1
v0.5.0,TODO: Clean this up after validation.,1
v0.5.0,TODO: Remove this completely once performance graphs are hardened.,1
v0.5.0,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.5.0,NOTE: Workaround for tables not rendering,1
v0.5.0,TODO: Check if this is needed with the new tables.,1
v0.5.0,TODO: Consider reducing complexity of this function.,1
v0.5.0,NOTE: Workaround for tables not rendering,1
v0.5.0,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.5.0,TODO: Revisit when we support custom tabs from users.,1
v0.5.0,# TODO Can the base vis be a util?,1
v0.5.0,TODO: can we get rid of this column of X?,1
v0.5.0,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.5.0,TODO: move this to a more general location where other blackbox methods can access it,1
v0.5.0,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.5.0,TODO: Make kwargs explicit.,1
v0.5.0,TODO: a few ways to improve this function:,1
v0.5.0,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.5.0,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.5.0,TODO: should preprocessors handle 0 samples?,1
v0.5.0,TODO: check for names/indexes in the dict that are not,1
v0.5.0,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.5.0,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.5.0,TODO: clean up this hack that uses strings of the indexes,1
v0.5.0,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.5.0,TODO: Add unit tests for internal EBM interfacing,1
v0.5.0,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.5.0,"TODO: if the library does not exists, build it using build.sh or build.bat",1
v0.5.0,TODO: Needs test.,1
v0.5.0,BIG TODO LIST:,1
v0.5.0,FUTURE TODOS in our callers and in JSON:,1
v0.5.0,is probably better than the alternative of getting different categorical strings in different programming,1
v0.5.0,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.5.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.5.0,TODO : should this be np.float64 with a check for big integers,1
v0.5.0,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.5.0,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.5.0,TODO: does this work if there are spaces or bools?,1
v0.5.0,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.5.0,np.unicode_ array here.  There are two issues with keeping it here,1
v0.5.0,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.5.0,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.5.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.5.0,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.5.0,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.5.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.5.0,TODO: implement pd.SparseDtype,1
v0.5.0,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.5.0,TODO: in the future special case this to make single samples faster at predict time,1
v0.5.0,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.5.0,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.5.0,TODO: handle as a single feature model,1
v0.5.0,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.5.0,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.5.0,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.5.0,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.5.0,TODO: END SECTION TO BE REMOVED,1
v0.5.0,TODO: we should not use Pandas in a public interface like this,1
v0.5.0,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.5.0,TODO: remove this.. we don't seem to use it,1
v0.5.0,TODO: at some point we should also handle column position remapping when the column names match,1
v0.5.0,"TODO: Consider removing later, potentially dead code.",1
v0.5.0,TODO: we could probably handle this case,1
v0.5.0,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.5.0,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.5.0,TODO: move this call into the explain_global function and extract the information needed,1
v0.5.0,TODO: we could probably handle this case,1
v0.5.0,Todo: check if this call,1
v0.5.0,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.5.0,TODO: check these,1
v0.5.0,TODO: load python parameters,1
v0.5.0,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.5.0,TODO: call purify() here from the glassbox\ebm\_research\_purify.py file,1
v0.5.0,"TODO: for multiclass, call a fixed version of multiclass_postprocess_RESTORE_THIS",1
v0.5.0,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.5.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.5.0,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.5.0,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.5.0,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.5.0,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.5.0,TODO: in the future we might at this point try and figure out the most,1
v0.5.0,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.5.0,TODO: we might be able to do these operations earlier,1
v0.5.0,TODO: we could pass out a bool array instead of objects for this function only,1
v0.5.0,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.5.0,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.5.0,"TODO: PK, I think this is a bug and the first iteration no_change_run_length",1
v0.5.0,TODO: check the other inputs for common mistakes here,1
v0.5.0,TODO: should we make this something higher?,1
v0.5.0,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.5.0,TODO: instead of making these copies we should,1
v0.5.0,"TODO: instead of going back to the original data in X, we",1
v0.5.0,TODO: the combinations below should be selected from the non-excluded features,1
v0.5.0,TODO: this will fail if we have multiple categories in a bin,1
v0.5.0,TODO: handle mono-classification,1
v0.5.0,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.5.0,TODO: do this per-bag in addition to the final scores:,1
v0.5.0,TODO: do this per-bag in addition to the final scores:,1
v0.5.0,TODO: do this per-bag in addition to the final scores:,1
v0.5.0,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.5.0,TODO: use Literal for the string types once everything is python 3.8,1
v0.5.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.5.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.5.0,TODO this is consistent to what Interpret is doing but might be changed,1
v0.5.0,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.5.0,TODO: Support other languages,1
v0.5.0,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.5.0,TODO: MLI should handle multiclass at a future date.,1
v0.5.0,TODO: Generalize this out.,1
v0.5.0,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.5.0,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.5.0,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.5.0,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.5.0,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.5.0,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.5.0,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.5.0,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.5.0,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.5.0,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.5.0,TODO: do we handle 0?  We would write out all zeros..,1
v0.5.0,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.5.0,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.5.0,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.5.0,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.5.0,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.5.0,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.5.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.5.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.5.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.0,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.5.0,perhaps might return that for subnormal floats.,1
v0.5.0,TODO: this entire section below!,1
v0.5.0,TODO: implement this:,1
v0.5.0,TODO: implement this:,1
v0.5.0,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.5.0,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.5.0,TODO: review these comments below now that things have changed:,1
v0.5.0,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.5.0,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.5.0,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.5.0,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.5.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.5.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.5.0,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.5.0,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.5.0,TODO : ALL OF THE BELOW!,1
v0.5.0,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.5.0,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.5.0,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.5.0,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.5.0,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.5.0,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.5.0,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.5.0,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.5.0,"times than desired, but we can live with that",1
v0.5.0,our caller can give us one of these bad types of inputs:,1
v0.5.0,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.5.0,"times than desired, but we can live with that",1
v0.5.0,"times than desired, but we can live with that",1
v0.5.0,"times than desired, but we can live with that",1
v0.5.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.5.0,"TODO: add this as a python/R option ""winsorized""",1
v0.5.0,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.5.0,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.5.0,TODO: implement sparse features,1
v0.5.0,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.5.0,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.5.0,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.5.0,TODO: sort the data by the target (if there is only one target),1
v0.5.0,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.5.0,TODO: handle sparse data someday,1
v0.5.0,TODO: clean this float in float32 format,1
v0.5.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.5.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.5.0,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.5.0,g_TODO_removeThisThreadTest = 1;,1
v0.5.0,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.5.0,if(0 == g_TODO_removeThisThreadTest) {,1
v0.5.0,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.5.0,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.5.0,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.5.0,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.5.0,TODO: handle interaction detection for higher dimensions,1
v0.5.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.5.0,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.5.0,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.5.0,- TODO: POST-HEALING,1
v0.5.0,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.5.0,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.5.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.5.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.5.0,TODO: evaluate max here instead as well,1
v0.5.0,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.5.0,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.5.0,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.5.0,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.5.0,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.5.0,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.5.0,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.5.0,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.5.0,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.5.0,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.5.0,There's actually two subtle issues here that we need to handle differently:,1
v0.5.0,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.5.0,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.5.0,- TODO: EXPLORING BOTH SIDES,1
v0.5.0,- TODO:,1
v0.5.0,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.5.0,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.5.0,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.5.0,TODO : in the future fill this priority queue with the average length within our,1
v0.5.0,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.5.0,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.5.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.0,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.5.0,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.5.0,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.5.0,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.5.0,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.5.0,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.5.0,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.5.0,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.5.0,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.5.0,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.5.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.5.0,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.5.0,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.5.0,"Actually, I think the real solution here is that",1
v0.5.0,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.5.0,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.5.0,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.5.0,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.5.0,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.5.0,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.5.0,TODO: move most of this code out of this function into a non-templated place,1
v0.5.0,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.5.0,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.5.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.0,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.5.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.5.0,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.5.0,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.5.0,TODO : add classification binary and multiclass versions of this,1
v0.5.0,TODO : add classification binary and multiclass versions of this,1
v0.5.0,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.5.0,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.5.0,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.5.0,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.5.0,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.5.0,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.5.0,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.5.0,TODO: we might want different constants for binary classification and multiclass. See notes in approximate_math.hpp,1
v0.5.0,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.5.0,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.5.0,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.4.4,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.4.4,TODO: Consider separation of concerns for each field.,1
v0.4.4,TODO: Needs further discussion at design-level.,1
v0.4.4,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.4.4,TODO: Harden these tests later to check content from data method.,1
v0.4.4,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.4.4,NOTE: We know this environment is going to use Dash.,1
v0.4.4,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.4.4,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.4.4,TODO PK add a test for Regression with interactions,1
v0.4.4,TODO PK add a test with a real regression dataset,1
v0.4.4,TODO PK add a test with more than 1 multiclass interaction,1
v0.4.4,TODO: Make a better test to ensure explanations are correct,1
v0.4.4,TODO: Make a better test to ensure explanations are correct,1
v0.4.4,TODO: Make a better test to ensure explanations are correct,1
v0.4.4,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.4.4,NOTE: Not implemented yet,1
v0.4.4,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.4.4,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.4.4,"meant to be public. We write it in this submodule, but it looks like that",1
v0.4.4,TODO: Remove this if threshold lines are never used.,1
v0.4.4,TODO: Clean this up after validation.,1
v0.4.4,TODO: Remove this completely once performance graphs are hardened.,1
v0.4.4,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.4.4,NOTE: Workaround for tables not rendering,1
v0.4.4,TODO: Check if this is needed with the new tables.,1
v0.4.4,TODO: Consider reducing complexity of this function.,1
v0.4.4,NOTE: Workaround for tables not rendering,1
v0.4.4,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.4.4,TODO: Revisit when we support custom tabs from users.,1
v0.4.4,# TODO Can the base vis be a util?,1
v0.4.4,TODO: can we get rid of this column of X?,1
v0.4.4,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.4.4,TODO: move this to a more general location where other blackbox methods can access it,1
v0.4.4,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.4.4,TODO: Make kwargs explicit.,1
v0.4.4,TODO: a few ways to improve this function:,1
v0.4.4,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.4.4,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.4.4,TODO: should preprocessors handle 0 samples?,1
v0.4.4,TODO: check for names/indexes in the dict that are not,1
v0.4.4,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.4.4,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.4.4,TODO: clean up this hack that uses strings of the indexes,1
v0.4.4,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.4.4,TODO: Add unit tests for internal EBM interfacing,1
v0.4.4,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.4.4,TODO: Needs test.,1
v0.4.4,BIG TODO LIST:,1
v0.4.4,FUTURE TODOS in our callers and in JSON:,1
v0.4.4,is probably better than the alternative of getting different categorical strings in different programming,1
v0.4.4,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.4.4,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.4,TODO : should this be np.float64 with a check for big integers,1
v0.4.4,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.4.4,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.4.4,TODO: does this work if there are spaces or bools?,1
v0.4.4,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.4.4,np.unicode_ array here.  There are two issues with keeping it here,1
v0.4.4,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.4.4,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.4.4,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.4,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.4.4,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.4.4,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.4,TODO: implement pd.SparseDtype,1
v0.4.4,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.4.4,TODO: in the future special case this to make single samples faster at predict time,1
v0.4.4,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.4.4,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.4.4,TODO: handle as a single feature model,1
v0.4.4,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.4.4,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.4.4,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.4.4,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.4.4,TODO: END SECTION TO BE REMOVED,1
v0.4.4,TODO: we should not use Pandas in a public interface like this,1
v0.4.4,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.4.4,TODO: remove this.. we don't seem to use it,1
v0.4.4,TODO: at some point we should also handle column position remapping when the column names match,1
v0.4.4,"TODO: Consider removing later, potentially dead code.",1
v0.4.4,TODO: we could probably handle this case,1
v0.4.4,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.4.4,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.4.4,TODO: move this call into the explain_global function and extract the information needed,1
v0.4.4,TODO: we could probably handle this case,1
v0.4.4,Todo: check if this call,1
v0.4.4,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.4.4,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.4.4,TODO PK: Generally if a bin for missing/unknown has zero weight then it means that the score should be,1
v0.4.4,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.4.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.4,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.4,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.4.4,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.4.4,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.4.4,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.4.4,TODO: in the future we might at this point try and figure out the most,1
v0.4.4,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.4.4,TODO: we might be able to do these operations earlier,1
v0.4.4,TODO: we could pass out a bool array instead of objects for this function only,1
v0.4.4,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.4.4,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.4.4,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.4.4,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.4.4,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.4.4,TODO: the original intended algorithm from the paper is in the function multiclass_postprocess_RESTORE_THIS,1
v0.4.4,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.4.4,"TODO: PK, I think this is a bug and the first iteration no_change_run_length",1
v0.4.4,TODO: check the other inputs for common mistakes here,1
v0.4.4,TODO: should we make this something higher?,1
v0.4.4,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.4.4,TODO: instead of making these copies we should,1
v0.4.4,"TODO: instead of going back to the original data in X, we",1
v0.4.4,TODO: the combinations below should be selected from the non-excluded features,1
v0.4.4,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.4.4,TODO: handle the 1 class case here,1
v0.4.4,TODO: this will fail if we have multiple categories in a bin,1
v0.4.4,TODO: handle the 1 class case here,1
v0.4.4,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.4.4,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.4.4,TODO: use Literal for the string types once everything is python 3.8,1
v0.4.4,TODO: handle the 1 class case here,1
v0.4.4,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.4,TODO: handle the 1 class case here,1
v0.4.4,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.4,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.4,TODO: handle the 1 class case here,1
v0.4.4,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.4,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.4,TODO this is consistent to what Interpret is doing but might be changed,1
v0.4.4,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.4,TODO: Support other languages,1
v0.4.4,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.4,TODO: MLI should handle multiclass at a future date.,1
v0.4.4,TODO: Generalize this out.,1
v0.4.4,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.4.4,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.4.4,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.4.4,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.4.4,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.4.4,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.4.4,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.4,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.4.4,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.4,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.4.4,TODO: do we handle 0?  We would write out all zeros..,1
v0.4.4,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.4.4,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.4.4,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.4.4,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.4.4,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.4.4,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.4.4,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.4,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.4,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.4,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.4,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.4.4,perhaps might return that for subnormal floats.,1
v0.4.4,TODO: this entire section below!,1
v0.4.4,TODO: implement this:,1
v0.4.4,TODO: implement this:,1
v0.4.4,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.4.4,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.4.4,TODO: review these comments below now that things have changed:,1
v0.4.4,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.4.4,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.4.4,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.4.4,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.4.4,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.4,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.4,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.4.4,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.4.4,TODO : ALL OF THE BELOW!,1
v0.4.4,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.4.4,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.4.4,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.4.4,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.4.4,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.4.4,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.4.4,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.4.4,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.4.4,"times than desired, but we can live with that",1
v0.4.4,our caller can give us one of these bad types of inputs:,1
v0.4.4,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.4.4,"times than desired, but we can live with that",1
v0.4.4,"times than desired, but we can live with that",1
v0.4.4,"times than desired, but we can live with that",1
v0.4.4,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.4,"TODO: add this as a python/R option ""winsorized""",1
v0.4.4,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.4.4,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.4.4,TODO: implement sparse features,1
v0.4.4,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.4.4,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.4.4,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.4.4,TODO: sort the data by the target (if there is only one target),1
v0.4.4,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.4.4,TODO: handle sparse data someday,1
v0.4.4,TODO: clean this float in float32 format,1
v0.4.4,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.4,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.4,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.4.4,g_TODO_removeThisThreadTest = 1;,1
v0.4.4,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.4.4,if(0 == g_TODO_removeThisThreadTest) {,1
v0.4.4,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.4.4,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.4.4,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.4.4,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.4.4,TODO: handle interaction detection for higher dimensions,1
v0.4.4,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.4,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.4.4,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.4.4,- TODO: POST-HEALING,1
v0.4.4,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.4.4,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.4.4,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.4,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.4,TODO: evaluate max here instead as well,1
v0.4.4,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.4.4,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.4.4,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.4.4,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.4.4,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.4.4,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.4.4,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.4.4,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.4.4,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.4.4,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.4.4,There's actually two subtle issues here that we need to handle differently:,1
v0.4.4,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.4.4,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.4.4,- TODO: EXPLORING BOTH SIDES,1
v0.4.4,- TODO:,1
v0.4.4,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.4.4,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.4.4,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.4.4,TODO : in the future fill this priority queue with the average length within our,1
v0.4.4,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.4.4,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.4.4,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.4,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.4,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.4.4,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.4.4,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.4.4,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.4.4,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.4.4,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.4.4,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.4.4,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.4.4,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.4.4,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.4.4,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.4,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.4.4,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.4.4,"Actually, I think the real solution here is that",1
v0.4.4,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.4.4,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.4.4,TODO: add a flag in the pCpuObjectiveWrapperOut struct that indicates if the objective can be SIMDed,1
v0.4.4,"TODO: enabled AVX512f, but only after we've had some time verifying AVX2 works",1
v0.4.4,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.4.4,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.4.4,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.4.4,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.4.4,TODO: move most of this code out of this function into a non-templated place,1
v0.4.4,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.4.4,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.4.4,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.4,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.4.4,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.4,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.4.4,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.4.4,TODO : add classification binary and multiclass versions of this,1
v0.4.4,TODO : add classification binary and multiclass versions of this,1
v0.4.4,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.4.4,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.4.4,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.4.4,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.4.4,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.4.4,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.4.4,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.4.4,TODO: we might want different constants for binary classification and multiclass. See notes in approximate_math.hpp,1
v0.4.4,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.4.4,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.4.4,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.4.3,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.4.3,TODO: Consider separation of concerns for each field.,1
v0.4.3,TODO: Needs further discussion at design-level.,1
v0.4.3,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.4.3,TODO: Harden these tests later to check content from data method.,1
v0.4.3,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.4.3,NOTE: We know this environment is going to use Dash.,1
v0.4.3,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.4.3,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.4.3,TODO PK add a test for Regression with interactions,1
v0.4.3,TODO PK add a test with a real regression dataset,1
v0.4.3,TODO PK add a test with more than 1 multiclass interaction,1
v0.4.3,TODO: Make a better test to ensure explanations are correct,1
v0.4.3,TODO: Make a better test to ensure explanations are correct,1
v0.4.3,TODO: Make a better test to ensure explanations are correct,1
v0.4.3,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.4.3,NOTE: Not implemented yet,1
v0.4.3,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.4.3,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.4.3,"meant to be public. We write it in this submodule, but it looks like that",1
v0.4.3,TODO: Remove this if threshold lines are never used.,1
v0.4.3,TODO: Clean this up after validation.,1
v0.4.3,TODO: Remove this completely once performance graphs are hardened.,1
v0.4.3,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.4.3,NOTE: Workaround for tables not rendering,1
v0.4.3,TODO: Check if this is needed with the new tables.,1
v0.4.3,TODO: Consider reducing complexity of this function.,1
v0.4.3,NOTE: Workaround for tables not rendering,1
v0.4.3,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.4.3,TODO: Revisit when we support custom tabs from users.,1
v0.4.3,# TODO Can the base vis be a util?,1
v0.4.3,TODO: can we get rid of this column of X?,1
v0.4.3,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.4.3,TODO: move this to a more general location where other blackbox methods can access it,1
v0.4.3,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.4.3,TODO: Make kwargs explicit.,1
v0.4.3,TODO: a few ways to improve this function:,1
v0.4.3,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.4.3,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.4.3,TODO: should preprocessors handle 0 samples?,1
v0.4.3,TODO: check for names/indexes in the dict that are not,1
v0.4.3,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.4.3,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.4.3,TODO: clean up this hack that uses strings of the indexes,1
v0.4.3,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.4.3,TODO: Add unit tests for internal EBM interfacing,1
v0.4.3,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.4.3,TODO: Needs test.,1
v0.4.3,BIG TODO LIST:,1
v0.4.3,FUTURE TODOS in our callers and in JSON:,1
v0.4.3,is probably better than the alternative of getting different categorical strings in different programming,1
v0.4.3,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.4.3,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.3,TODO : should this be np.float64 with a check for big integers,1
v0.4.3,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.4.3,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.4.3,TODO: does this work if there are spaces or bools?,1
v0.4.3,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.4.3,np.unicode_ array here.  There are two issues with keeping it here,1
v0.4.3,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.4.3,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.4.3,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.3,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.4.3,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.4.3,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.3,TODO: implement pd.SparseDtype,1
v0.4.3,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.4.3,TODO: in the future special case this to make single samples faster at predict time,1
v0.4.3,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.4.3,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.4.3,TODO: handle as a single feature model,1
v0.4.3,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.4.3,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.4.3,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.4.3,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.4.3,TODO: END SECTION TO BE REMOVED,1
v0.4.3,TODO: we should not use Pandas in a public interface like this,1
v0.4.3,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.4.3,TODO: remove this.. we don't seem to use it,1
v0.4.3,TODO: at some point we should also handle column position remapping when the column names match,1
v0.4.3,"TODO: Consider removing later, potentially dead code.",1
v0.4.3,TODO: we could probably handle this case,1
v0.4.3,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.4.3,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.4.3,TODO: move this call into the explain_global function and extract the information needed,1
v0.4.3,TODO: we could probably handle this case,1
v0.4.3,Todo: check if this call,1
v0.4.3,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.4.3,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.4.3,TODO PK: Generally if a bin for missing/unknown has zero weight then it means that the score should be,1
v0.4.3,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.4.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.3,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.3,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.4.3,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.4.3,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.4.3,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.4.3,TODO: in the future we might at this point try and figure out the most,1
v0.4.3,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.4.3,TODO: we might be able to do these operations earlier,1
v0.4.3,TODO: we could pass out a bool array instead of objects for this function only,1
v0.4.3,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.4.3,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.4.3,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.4.3,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.4.3,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.4.3,TODO: the original intended algorithm from the paper is in the function multiclass_postprocess_RESTORE_THIS,1
v0.4.3,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.4.3,"TODO: PK, I think this is a bug and the first iteration no_change_run_length",1
v0.4.3,TODO: check the other inputs for common mistakes here,1
v0.4.3,TODO: should we make this something higher?,1
v0.4.3,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.4.3,TODO: instead of making these copies we should,1
v0.4.3,"TODO: instead of going back to the original data in X, we",1
v0.4.3,TODO: the combinations below should be selected from the non-excluded features,1
v0.4.3,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.4.3,TODO: handle the 1 class case here,1
v0.4.3,TODO: this will fail if we have multiple categories in a bin,1
v0.4.3,TODO: handle the 1 class case here,1
v0.4.3,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.4.3,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.4.3,TODO: use Literal for the string types once everything is python 3.8,1
v0.4.3,TODO: handle the 1 class case here,1
v0.4.3,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.3,TODO: handle the 1 class case here,1
v0.4.3,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.3,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.3,TODO: handle the 1 class case here,1
v0.4.3,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.3,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.3,TODO this is consistent to what Interpret is doing but might be changed,1
v0.4.3,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.3,TODO: Support other languages,1
v0.4.3,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.3,TODO: MLI should handle multiclass at a future date.,1
v0.4.3,TODO: Generalize this out.,1
v0.4.3,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.4.3,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.4.3,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.4.3,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.4.3,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.4.3,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.4.3,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.3,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.4.3,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.3,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.4.3,TODO: do we handle 0?  We would write out all zeros..,1
v0.4.3,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.4.3,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.4.3,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.4.3,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.4.3,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.4.3,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.4.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.3,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.3,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.3,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.4.3,perhaps might return that for subnormal floats.,1
v0.4.3,TODO: this entire section below!,1
v0.4.3,TODO: implement this:,1
v0.4.3,TODO: implement this:,1
v0.4.3,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.4.3,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.4.3,TODO: review these comments below now that things have changed:,1
v0.4.3,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.4.3,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.4.3,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.4.3,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.4.3,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.3,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.3,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.4.3,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.4.3,TODO : ALL OF THE BELOW!,1
v0.4.3,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.4.3,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.4.3,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.4.3,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.4.3,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.4.3,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.4.3,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.4.3,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.4.3,"times than desired, but we can live with that",1
v0.4.3,our caller can give us one of these bad types of inputs:,1
v0.4.3,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.4.3,"times than desired, but we can live with that",1
v0.4.3,"times than desired, but we can live with that",1
v0.4.3,"times than desired, but we can live with that",1
v0.4.3,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.3,"TODO: add this as a python/R option ""winsorized""",1
v0.4.3,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.4.3,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.4.3,TODO: implement sparse features,1
v0.4.3,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.4.3,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.4.3,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.4.3,TODO: sort the data by the target (if there is only one target),1
v0.4.3,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.4.3,TODO: handle sparse data someday,1
v0.4.3,TODO: clean this float in float32 format,1
v0.4.3,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.3,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.3,"TODO: we currently index into the gradient array using the target, but the gradient array is also",1
v0.4.3,g_TODO_removeThisThreadTest = 1;,1
v0.4.3,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.4.3,if(0 == g_TODO_removeThisThreadTest) {,1
v0.4.3,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.4.3,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.4.3,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.4.3,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.4.3,TODO: handle interaction detection for higher dimensions,1
v0.4.3,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.3,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.4.3,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.4.3,- TODO: POST-HEALING,1
v0.4.3,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.4.3,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.4.3,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.3,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.3,TODO: evaluate max here instead as well,1
v0.4.3,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.4.3,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.4.3,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.4.3,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.4.3,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.4.3,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.4.3,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.4.3,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.4.3,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.4.3,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.4.3,There's actually two subtle issues here that we need to handle differently:,1
v0.4.3,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.4.3,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.4.3,- TODO: EXPLORING BOTH SIDES,1
v0.4.3,- TODO:,1
v0.4.3,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.4.3,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.4.3,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.4.3,TODO : in the future fill this priority queue with the average length within our,1
v0.4.3,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.4.3,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.4.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.3,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.4.3,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.4.3,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.4.3,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.4.3,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.4.3,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.4.3,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.4.3,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.4.3,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.4.3,this is kind of hacky where if any one of a number of things occurs (like we have only 1 leaf),1
v0.4.3,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.3,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.4.3,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.4.3,"Actually, I think the real solution here is that",1
v0.4.3,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.4.3,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.4.3,TODO: add a flag in the pCpuObjectiveWrapperOut struct that indicates if the objective can be SIMDed,1
v0.4.3,"TODO: enabled AVX512f, but only after we've had some time verifying AVX2 works",1
v0.4.3,"TODO: for now let's return after we find the first metric, but in the future we'll want to return",1
v0.4.3,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.4.3,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.4.3,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.4.3,TODO: move most of this code out of this function into a non-templated place,1
v0.4.3,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.4.3,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.4.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.3,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.4.3,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.3,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.4.3,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.4.3,TODO : add classification binary and multiclass versions of this,1
v0.4.3,TODO : add classification binary and multiclass versions of this,1
v0.4.3,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.4.3,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.4.3,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.4.3,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.4.3,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.4.3,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.4.3,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.4.3,TODO: we might want different constants for binary classification and multiclass. See notes in approximate_math.hpp,1
v0.4.3,"TODO: _mm256_cmp_ps has a latency of 4 and a throughput of 0.5.  It might be faster to convert to integers,",1
v0.4.3,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.4.3,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.4.2,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.4.2,TODO: Consider separation of concerns for each field.,1
v0.4.2,TODO: Needs further discussion at design-level.,1
v0.4.2,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.4.2,TODO: Harden these tests later to check content from data method.,1
v0.4.2,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.4.2,NOTE: We know this environment is going to use Dash.,1
v0.4.2,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.4.2,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.4.2,TODO PK add a test for Regression with interactions,1
v0.4.2,TODO PK add a test with a real regression dataset,1
v0.4.2,TODO PK add a test with more than 1 multiclass interaction,1
v0.4.2,TODO: Make a better test to ensure explanations are correct,1
v0.4.2,TODO: Make a better test to ensure explanations are correct,1
v0.4.2,TODO: Make a better test to ensure explanations are correct,1
v0.4.2,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.4.2,NOTE: Not implemented yet,1
v0.4.2,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.4.2,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.4.2,"meant to be public. We write it in this submodule, but it looks like that",1
v0.4.2,TODO: Remove this if threshold lines are never used.,1
v0.4.2,TODO: Clean this up after validation.,1
v0.4.2,TODO: Remove this completely once performance graphs are hardened.,1
v0.4.2,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.4.2,NOTE: Workaround for tables not rendering,1
v0.4.2,TODO: Check if this is needed with the new tables.,1
v0.4.2,TODO: Consider reducing complexity of this function.,1
v0.4.2,NOTE: Workaround for tables not rendering,1
v0.4.2,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.4.2,TODO: Revisit when we support custom tabs from users.,1
v0.4.2,# TODO Can the base vis be a util?,1
v0.4.2,TODO: can we get rid of this column of X?,1
v0.4.2,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.4.2,TODO: move this to a more general location where other blackbox methods can access it,1
v0.4.2,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.4.2,TODO: Make kwargs explicit.,1
v0.4.2,TODO: a few ways to improve this function:,1
v0.4.2,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.4.2,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.4.2,TODO: should preprocessors handle 0 samples?,1
v0.4.2,TODO: check for names/indexes in the dict that are not,1
v0.4.2,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.4.2,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.4.2,TODO: clean up this hack that uses strings of the indexes,1
v0.4.2,"TODO: instead of passing in ""max_bins - 1"" should we be passing in ""max_bins - 2""?",1
v0.4.2,TODO: Add unit tests for internal EBM interfacing,1
v0.4.2,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.4.2,TODO: Needs test.,1
v0.4.2,BIG TODO LIST:,1
v0.4.2,FUTURE TODOS in our callers and in JSON:,1
v0.4.2,is probably better than the alternative of getting different categorical strings in different programming,1
v0.4.2,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.4.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.2,TODO : should this be np.float64 with a check for big integers,1
v0.4.2,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.4.2,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.4.2,TODO: does this work if there are spaces or bools?,1
v0.4.2,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.4.2,np.unicode_ array here.  There are two issues with keeping it here,1
v0.4.2,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.4.2,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.4.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.2,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.4.2,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.4.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.2,TODO: implement pd.SparseDtype,1
v0.4.2,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.4.2,TODO: in the future special case this to make single samples faster at predict time,1
v0.4.2,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.4.2,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.4.2,TODO: handle as a single feature model,1
v0.4.2,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.4.2,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.4.2,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.4.2,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.4.2,TODO: END SECTION TO BE REMOVED,1
v0.4.2,TODO: we should not use Pandas in a public interface like this,1
v0.4.2,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.4.2,TODO: remove this.. we don't seem to use it,1
v0.4.2,TODO: at some point we should also handle column position remapping when the column names match,1
v0.4.2,"TODO: Consider removing later, potentially dead code.",1
v0.4.2,TODO: we could probably handle this case,1
v0.4.2,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.4.2,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.4.2,TODO: move this call into the explain_global function and extract the information needed,1
v0.4.2,TODO: we could probably handle this case,1
v0.4.2,Todo: check if this call,1
v0.4.2,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.4.2,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.4.2,TODO PK: Generally if a bin for missing/unknown has zero weight then it means that the score should be,1
v0.4.2,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.4.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.2,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.2,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.4.2,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.4.2,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.4.2,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.4.2,TODO: in the future we might at this point try and figure out the most,1
v0.4.2,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.4.2,TODO: we might be able to do these operations earlier,1
v0.4.2,TODO: we could pass out a bool array instead of objects for this function only,1
v0.4.2,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.4.2,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.4.2,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.4.2,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.4.2,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.4.2,TODO: the original intended algorithm from the paper is in the function multiclass_postprocess_RESTORE_THIS,1
v0.4.2,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.4.2,"TODO: PK, I think this is a bug and the first iteration no_change_run_length",1
v0.4.2,TODO: check the other inputs for common mistakes here,1
v0.4.2,TODO: should we make this something higher?,1
v0.4.2,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.4.2,TODO: instead of making these copies we should,1
v0.4.2,"TODO: instead of going back to the original data in X, we",1
v0.4.2,TODO: the combinations below should be selected from the non-excluded features,1
v0.4.2,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.4.2,TODO: handle the 1 class case here,1
v0.4.2,TODO: this will fail if we have multiple categories in a bin,1
v0.4.2,TODO: handle the 1 class case here,1
v0.4.2,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.4.2,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.4.2,TODO: use Literal for the string types once everything is python 3.8,1
v0.4.2,TODO: handle the 1 class case here,1
v0.4.2,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.2,TODO: handle the 1 class case here,1
v0.4.2,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.2,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.2,TODO: handle the 1 class case here,1
v0.4.2,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.2,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.2,TODO this is consistent to what Interpret is doing but might be changed,1
v0.4.2,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.2,TODO: Support other languages,1
v0.4.2,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.2,TODO: MLI should handle multiclass at a future date.,1
v0.4.2,TODO: Generalize this out.,1
v0.4.2,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.4.2,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.4.2,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.4.2,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.4.2,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.2,"TODO : our caller should handle NaN *pTargetFrom values, which means that the target is missing, which means we should delete that sample",1
v0.4.2,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.2,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.4.2,TODO: do we handle 0?  We would write out all zeros..,1
v0.4.2,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.4.2,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.4.2,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.4.2,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.4.2,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.4.2,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.4.2,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.4.2,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.4.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.2,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.2,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.2,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.4.2,perhaps might return that for subnormal floats.,1
v0.4.2,TODO: this entire section below!,1
v0.4.2,TODO: implement this:,1
v0.4.2,TODO: implement this:,1
v0.4.2,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.4.2,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.4.2,TODO: review these comments below now that things have changed:,1
v0.4.2,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.4.2,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.4.2,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.4.2,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.4.2,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.4.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.2,TODO: Notes on SIMD-ifying,1
v0.4.2,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.4.2,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.4.2,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.4.2,TODO : ALL OF THE BELOW!,1
v0.4.2,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.4.2,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.4.2,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.4.2,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.4.2,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.4.2,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.4.2,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.4.2,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.4.2,"times than desired, but we can live with that",1
v0.4.2,our caller can give us one of these bad types of inputs:,1
v0.4.2,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.4.2,"times than desired, but we can live with that",1
v0.4.2,"times than desired, but we can live with that",1
v0.4.2,"times than desired, but we can live with that",1
v0.4.2,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.2,"TODO: add this as a python/R option ""winsorized""",1
v0.4.2,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.4.2,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.4.2,TODO: implement sparse features,1
v0.4.2,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.4.2,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.4.2,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.4.2,TODO: sort the data by the target (if there is only one target),1
v0.4.2,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.4.2,TODO: handle sparse data someday,1
v0.4.2,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.2,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.2,g_TODO_removeThisThreadTest = 1;,1
v0.4.2,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.4.2,if(0 == g_TODO_removeThisThreadTest) {,1
v0.4.2,TODO: Ideally we would flip our input dimensions so that we're aligned with the output ordering,1
v0.4.2,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.4.2,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.4.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.2,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.4.2,TODO: handle interaction detection for higher dimensions,1
v0.4.2,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.2,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.4.2,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.4.2,- TODO: POST-HEALING,1
v0.4.2,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.4.2,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.4.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.2,TODO: evaluate max here instead as well,1
v0.4.2,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.4.2,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.4.2,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.4.2,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.4.2,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.4.2,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.4.2,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.4.2,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.4.2,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.4.2,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.4.2,There's actually two subtle issues here that we need to handle differently:,1
v0.4.2,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.4.2,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.4.2,- TODO: EXPLORING BOTH SIDES,1
v0.4.2,- TODO:,1
v0.4.2,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.4.2,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.4.2,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.4.2,TODO : in the future fill this priority queue with the average length within our,1
v0.4.2,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.4.2,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.4.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.2,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.4.2,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.4.2,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.4.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.2,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.4.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.2,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.4.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.2,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.4.2,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.4.2,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.4.2,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.4.2,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.4.2,"Actually, I think the real solution here is that",1
v0.4.2,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.4.2,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.4.2,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.4.2,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.4.2,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.4.2,TODO: move most of this code out of this function into a non-templated place,1
v0.4.2,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.4.2,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.4.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.2,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.4.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.2,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.4.2,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.4.2,TODO : add classification binary and multiclass versions of this,1
v0.4.2,TODO : add classification binary and multiclass versions of this,1
v0.4.2,TODO: reinstate this AFTER we have moved missing value handling into C++,1
v0.4.2,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.4.2,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.4.2,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.4.2,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.4.2,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.4.2,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.4.2,TODO: make a fast approximation of this,1
v0.4.2,TODO: make a fast approximation of this,1
v0.4.2,TODO: make a fast approximation of this,1
v0.4.2,TODO: this could be written to be more efficient,1
v0.4.2,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.4.2,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.4.1,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.4.1,TODO: Consider separation of concerns for each field.,1
v0.4.1,TODO: Needs further discussion at design-level.,1
v0.4.1,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.4.1,TODO: Harden these tests later to check content from data method.,1
v0.4.1,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.4.1,NOTE: We know this environment is going to use Dash.,1
v0.4.1,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.4.1,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.4.1,TODO PK add a test for Regression with interactions,1
v0.4.1,TODO PK add a test with a real regression dataset,1
v0.4.1,TODO PK add a test with more than 1 multiclass interaction,1
v0.4.1,TODO: Make a better test to ensure explanations are correct,1
v0.4.1,TODO: Make a better test to ensure explanations are correct,1
v0.4.1,TODO: Make a better test to ensure explanations are correct,1
v0.4.1,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.4.1,NOTE: Not implemented yet,1
v0.4.1,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.4.1,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.4.1,"meant to be public. We write it in this submodule, but it looks like that",1
v0.4.1,TODO: Remove this if threshold lines are never used.,1
v0.4.1,TODO: Clean this up after validation.,1
v0.4.1,TODO: Remove this completely once performance graphs are hardened.,1
v0.4.1,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.4.1,NOTE: Workaround for tables not rendering,1
v0.4.1,TODO: Check if this is needed with the new tables.,1
v0.4.1,TODO: Consider reducing complexity of this function.,1
v0.4.1,NOTE: Workaround for tables not rendering,1
v0.4.1,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.4.1,TODO: Revisit when we support custom tabs from users.,1
v0.4.1,# TODO Can the base vis be a util?,1
v0.4.1,TODO: can we get rid of this column of X?,1
v0.4.1,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.4.1,TODO: move this to a more general location where other blackbox methods can access it,1
v0.4.1,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.4.1,TODO: Make kwargs explicit.,1
v0.4.1,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.4.1,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.4.1,TODO: should preprocessors handle 0 samples?,1
v0.4.1,TODO: check for names/indexes in the dict that are not,1
v0.4.1,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.4.1,TODO: clean up this hack that uses strings of the indexes,1
v0.4.1,TODO: Add unit tests for internal EBM interfacing,1
v0.4.1,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.4.1,TODO: Needs test.,1
v0.4.1,BIG TODO LIST:,1
v0.4.1,FUTURE TODOS in our callers and in JSON:,1
v0.4.1,is probably better than the alternative of getting different categorical strings in different programming,1
v0.4.1,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.4.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.1,TODO : should this be np.float64 with a check for big integers,1
v0.4.1,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.4.1,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.4.1,TODO: does this work if there are spaces or bools?,1
v0.4.1,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.4.1,np.unicode_ array here.  There are two issues with keeping it here,1
v0.4.1,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.4.1,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.4.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.1,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.4.1,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.4.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.1,TODO: implement pd.SparseDtype,1
v0.4.1,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.4.1,TODO: in the future special case this to make single samples faster at predict time,1
v0.4.1,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.4.1,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.4.1,TODO: handle as a single feature model,1
v0.4.1,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.4.1,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.4.1,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.4.1,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.4.1,TODO: END SECTION TO BE REMOVED,1
v0.4.1,TODO: we should not use Pandas in a public interface like this,1
v0.4.1,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.4.1,TODO: remove this.. we don't seem to use it,1
v0.4.1,TODO: at some point we should also handle column position remapping when the column names match,1
v0.4.1,"TODO: Consider removing later, potentially dead code.",1
v0.4.1,TODO: we could probably handle this case,1
v0.4.1,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.4.1,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.4.1,TODO: move this call into the explain_global function and extract the information needed,1
v0.4.1,TODO: we could probably handle this case,1
v0.4.1,Todo: check if this call,1
v0.4.1,TODO: replace this function with a bool array that we generate in bin_native.. this function will crash,1
v0.4.1,TODO: this isn't a problem today since any unnamed categories in the mains and the pairs are the same,1
v0.4.1,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.4.1,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.4.1,TODO PK: Generally if a bin for missing/unknown has zero weight then it means that the score should be,1
v0.4.1,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.4.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.1,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.1,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.4.1,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.4.1,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.4.1,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.4.1,TODO: in the future we might at this point try and figure out the most,1
v0.4.1,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.4.1,TODO: we might be able to do these operations earlier,1
v0.4.1,TODO: we could pass out a bool array instead of objects for this function only,1
v0.4.1,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.4.1,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.4.1,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.4.1,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.4.1,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.4.1,TODO: the original intended algorithm from the paper is in the function multiclass_postprocess_RESTORE_THIS,1
v0.4.1,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.4.1,"TODO: PK, I think this is a bug and the first iteration no_change_run_length",1
v0.4.1,TODO: check the other inputs for common mistakes here,1
v0.4.1,TODO: should we make this something higher?,1
v0.4.1,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.4.1,"TODO: instead of going back to the original data in X, we",1
v0.4.1,TODO: the combinations below should be selected from the non-excluded features,1
v0.4.1,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.4.1,TODO: handle the 1 class case here,1
v0.4.1,TODO: this will fail if we have multiple categories in a bin,1
v0.4.1,TODO: handle the 1 class case here,1
v0.4.1,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.4.1,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.4.1,TODO: use Literal for the string types once everything is python 3.8,1
v0.4.1,TODO: handle the 1 class case here,1
v0.4.1,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.1,TODO: handle the 1 class case here,1
v0.4.1,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.1,TODO: handle the 1 class case here,1
v0.4.1,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.1,TODO this is consistent to what Interpret is doing but might be changed,1
v0.4.1,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.1,TODO: Support other languages,1
v0.4.1,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.1,TODO: MLI should handle multiclass at a future date.,1
v0.4.1,TODO: Generalize this out.,1
v0.4.1,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.4.1,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.4.1,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.4.1,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.4.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.1,"TODO : our caller should handle NaN *pTargetFrom values, which means that the target is missing, which means we should delete that sample",1
v0.4.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.1,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.4.1,TODO: do we handle 0?  We would write out all zeros..,1
v0.4.1,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.4.1,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.4.1,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.4.1,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.4.1,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.4.1,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.4.1,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.4.1,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.4.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.1,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.4.1,perhaps might return that for subnormal floats.,1
v0.4.1,TODO: this entire section below!,1
v0.4.1,TODO: implement this:,1
v0.4.1,TODO: implement this:,1
v0.4.1,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.4.1,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.4.1,TODO: review these comments below now that things have changed:,1
v0.4.1,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.4.1,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.4.1,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.4.1,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.4.1,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.4.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.1,TODO: Notes on SIMD-ifying,1
v0.4.1,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.4.1,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.4.1,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.4.1,TODO : ALL OF THE BELOW!,1
v0.4.1,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.4.1,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.4.1,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.4.1,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.4.1,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.4.1,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.4.1,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.4.1,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.4.1,"times than desired, but we can live with that",1
v0.4.1,our caller can give us one of these bad types of inputs:,1
v0.4.1,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.4.1,"times than desired, but we can live with that",1
v0.4.1,"times than desired, but we can live with that",1
v0.4.1,"times than desired, but we can live with that",1
v0.4.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.1,"TODO: add this as a python/R option ""winsorized""",1
v0.4.1,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.4.1,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.4.1,TODO: implement sparse features,1
v0.4.1,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.4.1,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.4.1,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.4.1,TODO: sort the data by the target (if there is only one target),1
v0.4.1,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.4.1,TODO: handle sparse data someday,1
v0.4.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.1,g_TODO_removeThisThreadTest = 1;,1
v0.4.1,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.4.1,if(0 == g_TODO_removeThisThreadTest) {,1
v0.4.1,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.4.1,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.4.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.1,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.4.1,TODO: handle interaction detection for higher dimensions,1
v0.4.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.1,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.4.1,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.4.1,- TODO: POST-HEALING,1
v0.4.1,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.4.1,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.4.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.1,TODO: evaluate max here instead as well,1
v0.4.1,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.4.1,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.4.1,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.4.1,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.4.1,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.4.1,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.4.1,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.4.1,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.4.1,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.4.1,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.4.1,There's actually two subtle issues here that we need to handle differently:,1
v0.4.1,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.4.1,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.4.1,- TODO: EXPLORING BOTH SIDES,1
v0.4.1,- TODO:,1
v0.4.1,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.4.1,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.4.1,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.4.1,TODO : in the future fill this priority queue with the average length within our,1
v0.4.1,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.4.1,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.4.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.1,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.4.1,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.4.1,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.4.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.1,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.4.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.1,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.4.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.1,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.4.1,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.4.1,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.4.1,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.4.1,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.4.1,"Actually, I think the real solution here is that",1
v0.4.1,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.4.1,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.4.1,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.4.1,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.4.1,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.4.1,TODO: move most of this code out of this function into a non-templated place,1
v0.4.1,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.4.1,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.4.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.1,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.4.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.1,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.4.1,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.4.1,TODO : add classification binary and multiclass versions of this,1
v0.4.1,TODO : add classification binary and multiclass versions of this,1
v0.4.1,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.4.1,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.4.1,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.4.1,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.4.1,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.4.1,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.4.1,TODO: make a fast approximation of this,1
v0.4.1,TODO: make a fast approximation of this,1
v0.4.1,TODO: make a fast approximation of this,1
v0.4.1,TODO: this could be written to be more efficient,1
v0.4.1,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.4.1,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.4.0,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.4.0,TODO: Consider separation of concerns for each field.,1
v0.4.0,TODO: Needs further discussion at design-level.,1
v0.4.0,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.4.0,TODO: Harden these tests later to check content from data method.,1
v0.4.0,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.4.0,NOTE: We know this environment is going to use Dash.,1
v0.4.0,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.4.0,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.4.0,TODO PK add a test for Regression with interactions,1
v0.4.0,TODO PK add a test with a real regression dataset,1
v0.4.0,TODO PK add a test with more than 1 multiclass interaction,1
v0.4.0,TODO: Make a better test to ensure explanations are correct,1
v0.4.0,TODO: Make a better test to ensure explanations are correct,1
v0.4.0,TODO: Make a better test to ensure explanations are correct,1
v0.4.0,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.4.0,NOTE: Not implemented yet,1
v0.4.0,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.4.0,"TODO: app is a global variable, but doesn't seem to be read anywhere. It",1
v0.4.0,"meant to be public. We write it in this submodule, but it looks like that",1
v0.4.0,TODO: Remove this if threshold lines are never used.,1
v0.4.0,TODO: Clean this up after validation.,1
v0.4.0,TODO: Remove this completely once performance graphs are hardened.,1
v0.4.0,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.4.0,NOTE: Workaround for tables not rendering,1
v0.4.0,TODO: Check if this is needed with the new tables.,1
v0.4.0,TODO: Consider reducing complexity of this function.,1
v0.4.0,NOTE: Workaround for tables not rendering,1
v0.4.0,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.4.0,TODO: Revisit when we support custom tabs from users.,1
v0.4.0,# TODO Can the base vis be a util?,1
v0.4.0,TODO: can we get rid of this column of X?,1
v0.4.0,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.4.0,TODO: move this to a more general location where other blackbox methods can access it,1
v0.4.0,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.4.0,TODO: Make kwargs explicit.,1
v0.4.0,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.4.0,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.4.0,TODO: should preprocessors handle 0 samples?,1
v0.4.0,TODO: check for names/indexes in the dict that are not,1
v0.4.0,TODO: do some sanity checking on the shape of privacy_bounds,1
v0.4.0,TODO: clean up this hack that uses strings of the indexes,1
v0.4.0,TODO: Add unit tests for internal EBM interfacing,1
v0.4.0,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.4.0,TODO: Needs test.,1
v0.4.0,BIG TODO LIST:,1
v0.4.0,FUTURE TODOS in our callers and in JSON:,1
v0.4.0,is probably better than the alternative of getting different categorical strings in different programming,1
v0.4.0,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.4.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.0,TODO : should this be np.float64 with a check for big integers,1
v0.4.0,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.4.0,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.4.0,TODO: does this work if there are spaces or bools?,1
v0.4.0,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.4.0,np.unicode_ array here.  There are two issues with keeping it here,1
v0.4.0,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.4.0,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.4.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.0,TODO: we could instead handle this by re-ordering the pandas pd_categories.,1
v0.4.0,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.4.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.4.0,TODO: implement pd.SparseDtype,1
v0.4.0,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.4.0,TODO: in the future special case this to make single samples faster at predict time,1
v0.4.0,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.4.0,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.4.0,TODO: handle as a single feature model,1
v0.4.0,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.4.0,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.4.0,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.4.0,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.4.0,TODO: END SECTION TO BE REMOVED,1
v0.4.0,TODO: we should not use Pandas in a public interface like this,1
v0.4.0,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.4.0,TODO: remove this.. we don't seem to use it,1
v0.4.0,TODO: at some point we should also handle column position remapping when the column names match,1
v0.4.0,"TODO: Consider removing later, potentially dead code.",1
v0.4.0,TODO: we could probably handle this case,1
v0.4.0,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.4.0,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.4.0,TODO: move this call into the explain_global function and extract the information needed,1
v0.4.0,TODO: we could probably handle this case,1
v0.4.0,Todo: check if this call,1
v0.4.0,TODO: replace this function with a bool array that we generate in bin_native.. this function will crash,1
v0.4.0,TODO: this isn't a problem today since any unnamed categories in the mains and the pairs are the same,1
v0.4.0,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.4.0,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.4.0,TODO PK: Generally if a bin for missing/unknown has zero weight then it means that the score should be,1
v0.4.0,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.4.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.0,"TODO: if nan OR out of bounds from the cuts, estimate it.",1
v0.4.0,"TODO: create the ExplainableBoostingClassifier etc, type directly",1
v0.4.0,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.4.0,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.4.0,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.4.0,TODO: in the future we might at this point try and figure out the most,1
v0.4.0,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.4.0,TODO: we might be able to do these operations earlier,1
v0.4.0,TODO: we could pass out a bool array instead of objects for this function only,1
v0.4.0,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.4.0,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.4.0,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.4.0,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.4.0,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.4.0,TODO: the original intended algorithm from the paper is in the function multiclass_postprocess_RESTORE_THIS,1
v0.4.0,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.4.0,"TODO: PK, I think this is a bug and the first iteration no_change_run_length",1
v0.4.0,TODO: check the other inputs for common mistakes here,1
v0.4.0,TODO: should we make this something higher?,1
v0.4.0,"TODO: bump this up to something like 10 again, but ONLY after we've standardized",1
v0.4.0,"TODO: instead of going back to the original data in X, we",1
v0.4.0,TODO: the combinations below should be selected from the non-excluded features,1
v0.4.0,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.4.0,TODO: handle the 1 class case here,1
v0.4.0,TODO: this will fail if we have multiple categories in a bin,1
v0.4.0,TODO: handle the 1 class case here,1
v0.4.0,TODO: in the future we can apply monotonize to the individual outer bags in bagged_scores_,1
v0.4.0,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.4.0,TODO: use Literal for the string types once everything is python 3.8,1
v0.4.0,TODO: handle the 1 class case here,1
v0.4.0,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.0,TODO: handle the 1 class case here,1
v0.4.0,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.0,TODO: handle the 1 class case here,1
v0.4.0,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.4.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.4.0,TODO this is consistent to what Interpret is doing but might be changed,1
v0.4.0,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.0,TODO: Support other languages,1
v0.4.0,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.4.0,TODO: MLI should handle multiclass at a future date.,1
v0.4.0,TODO: Generalize this out.,1
v0.4.0,"TODO: instead of having interpret.api.base, it would probably be easier to just have a single base.py file",1
v0.4.0,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.4.0,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.4.0,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.4.0,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.0,"TODO : our caller should handle NaN *pTargetFrom values, which means that the target is missing, which means we should delete that sample",1
v0.4.0,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.4.0,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.4.0,TODO: do we handle 0?  We would write out all zeros..,1
v0.4.0,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.4.0,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.4.0,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.4.0,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.4.0,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.4.0,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.4.0,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.4.0,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.4.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.4.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.0,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.4.0,perhaps might return that for subnormal floats.,1
v0.4.0,TODO: this entire section below!,1
v0.4.0,TODO: implement this:,1
v0.4.0,TODO: implement this:,1
v0.4.0,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.4.0,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.4.0,TODO: review these comments below now that things have changed:,1
v0.4.0,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.4.0,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.4.0,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.4.0,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.4.0,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.4.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.4.0,TODO: Notes on SIMD-ifying,1
v0.4.0,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.4.0,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.4.0,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.4.0,TODO : ALL OF THE BELOW!,1
v0.4.0,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.4.0,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.4.0,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.4.0,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.4.0,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.4.0,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.4.0,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.4.0,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.4.0,"times than desired, but we can live with that",1
v0.4.0,our caller can give us one of these bad types of inputs:,1
v0.4.0,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.4.0,"times than desired, but we can live with that",1
v0.4.0,"times than desired, but we can live with that",1
v0.4.0,"times than desired, but we can live with that",1
v0.4.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.0,"TODO: add this as a python/R option ""winsorized""",1
v0.4.0,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.4.0,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.4.0,TODO: implement sparse features,1
v0.4.0,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.4.0,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.4.0,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.4.0,TODO: sort the data by the target (if there is only one target),1
v0.4.0,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.4.0,TODO: handle sparse data someday,1
v0.4.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.4.0,g_TODO_removeThisThreadTest = 1;,1
v0.4.0,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.4.0,if(0 == g_TODO_removeThisThreadTest) {,1
v0.4.0,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.4.0,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.4.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.0,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.4.0,TODO: handle interaction detection for higher dimensions,1
v0.4.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.4.0,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.4.0,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.4.0,- TODO: POST-HEALING,1
v0.4.0,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.4.0,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.4.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.4.0,TODO: evaluate max here instead as well,1
v0.4.0,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.4.0,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.4.0,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.4.0,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.4.0,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.4.0,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.4.0,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.4.0,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.4.0,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.4.0,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.4.0,There's actually two subtle issues here that we need to handle differently:,1
v0.4.0,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.4.0,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.4.0,- TODO: EXPLORING BOTH SIDES,1
v0.4.0,- TODO:,1
v0.4.0,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.4.0,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.4.0,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.4.0,TODO : in the future fill this priority queue with the average length within our,1
v0.4.0,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.4.0,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.4.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.0,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.4.0,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.4.0,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.4.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.0,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.4.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.0,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.4.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.4.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.4.0,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.4.0,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.4.0,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.4.0,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.4.0,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.4.0,"Actually, I think the real solution here is that",1
v0.4.0,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.4.0,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.4.0,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.4.0,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.4.0,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.4.0,TODO: move most of this code out of this function into a non-templated place,1
v0.4.0,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.4.0,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.4.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.0,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.4.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.4.0,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.4.0,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.4.0,TODO : add classification binary and multiclass versions of this,1
v0.4.0,TODO : add classification binary and multiclass versions of this,1
v0.4.0,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.4.0,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.4.0,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.4.0,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.4.0,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.4.0,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.4.0,TODO: make a fast approximation of this,1
v0.4.0,TODO: make a fast approximation of this,1
v0.4.0,TODO: make a fast approximation of this,1
v0.4.0,TODO: this could be written to be more efficient,1
v0.4.0,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.4.0,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.3.2,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.3.2,TODO: Consider separation of concerns for each field.,1
v0.3.2,TODO: Needs further discussion at design-level.,1
v0.3.2,NOTE: Not implemented yet,1
v0.3.2,NOTE: We know this environment is going to use Dash.,1
v0.3.2,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.3.2,TODO: Remove this if threshold lines are never used.,1
v0.3.2,TODO: Clean this up after validation.,1
v0.3.2,TODO: Remove this completely once performance graphs are hardened.,1
v0.3.2,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.3.2,NOTE: Workaround for tables not rendering,1
v0.3.2,TODO: Check if this is needed with the new tables.,1
v0.3.2,TODO: Consider reducing complexity of this function.,1
v0.3.2,NOTE: Workaround for tables not rendering,1
v0.3.2,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.3.2,TODO: Revisit when we support custom tabs from users.,1
v0.3.2,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.3.2,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.3.2,TODO: Harden these tests later to check content from data method.,1
v0.3.2,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.3.2,# TODO Can the base vis be a util?,1
v0.3.2,TODO: move this to a more general location where other blackbox methods can access it,1
v0.3.2,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.3.2,TODO: Make kwargs explicit.,1
v0.3.2,TODO: can we get rid of this column of X?,1
v0.3.2,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.3.2,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.3.2,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.3.2,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.3.2,TODO: END SECTION TO BE REMOVED,1
v0.3.2,TODO: we should not use Pandas in a public interface like this,1
v0.3.2,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.3.2,BIG TODO LIST:,1
v0.3.2,FUTURE TODOS in our callers and in JSON:,1
v0.3.2,is probably better than the alternative of getting different categorical strings in different programming,1
v0.3.2,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.3.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.2,TODO : should this be np.float64 with a check for big integers,1
v0.3.2,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.3.2,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.3.2,TODO: does this work if there are spaces or bools?,1
v0.3.2,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.3.2,np.unicode_ array here.  There are two issues with keeping it here,1
v0.3.2,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.3.2,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.3.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.2,TODO: we could instead handle this by re-ordering the pandas pd_categories.  Someone might want to construct it quickly but then override the pd_categories,1
v0.3.2,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.3.2,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.2,TODO: implement pd.SparseDtype,1
v0.3.2,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.3.2,TODO: in the future special case this to make single samples faster at predict time,1
v0.3.2,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.3.2,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.3.2,TODO: handle as a single feature model,1
v0.3.2,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.3.2,TODO Add link function to operate on predict's output when needed,1
v0.3.2,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.3.2,TODO: should preprocessors handle 0 samples?,1
v0.3.2,TODO: clean up this hack that uses strings of the indexes,1
v0.3.2,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.3.2,TODO: at some point we should also handle column position remapping when the column names match,1
v0.3.2,TODO: Add unit tests for internal EBM interfacing,1
v0.3.2,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.3.2,TODO: Needs test.,1
v0.3.2,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.3.2,TODO: we could probably handle this case,1
v0.3.2,Todo: check if this call,1
v0.3.2,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.3.2,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.3.2,TODO: move this call into the explain_global function and extract the information needed,1
v0.3.2,"TODO: Consider removing later, potentially dead code.",1
v0.3.2,TODO: we could probably handle this case,1
v0.3.2,TODO: we could pass out a bool array instead of objects for this function only,1
v0.3.2,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.3.2,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.3.2,TODO: replace this function with a bool array that we generate in bin_native.. this function will crash,1
v0.3.2,TODO: this isn't a problem today since any unnamed categories in the mains and the pairs are the same,1
v0.3.2,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.3.2,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.3.2,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.3.2,TODO: the original intended algorithm from the paper is in the function multiclass_postprocess_RESTORE_THIS,1
v0.3.2,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.3.2,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.3.2,TODO PK: Generally if a bin for missing/unknown has zero weight then it means that the score should be,1
v0.3.2,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.3.2,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.2,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.2,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.2,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.2,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.3.2,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.3.2,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.3.2,TODO: in the future we might at this point try and figure out the most,1
v0.3.2,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.3.2,TODO: we might be able to do these operations earlier,1
v0.3.2,TODO: Clean up,1
v0.3.2,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.3.2,TODO: Add more ways to call alternative get_current_model,1
v0.3.2,TODO: order these parameters the same as our public parameter list,1
v0.3.2,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.3.2,"TODO: instead of going back to the original data in X, we",1
v0.3.2,TODO: the combinations below should be selected from the non-excluded features,1
v0.3.2,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.3.2,TODO: this will fail if we have multiple categories in a bin,1
v0.3.2,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.3.2,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.2,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.2,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.3.2,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.2,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.3.2,TODO this is consistent to what Interpret is doing but might be changed,1
v0.3.2,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.3.2,TODO PK add a test for Regression with interactions,1
v0.3.2,TODO PK add a test with a real regression dataset,1
v0.3.2,TODO PK add a test with more than 1 multiclass interaction,1
v0.3.2,TODO: Make a better test to ensure explanations are correct,1
v0.3.2,TODO: Make a better test to ensure explanations are correct,1
v0.3.2,TODO: Make a better test to ensure explanations are correct,1
v0.3.2,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.3.2,TODO: Support other languages,1
v0.3.2,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.3.2,TODO: MLI should handle multiclass at a future date.,1
v0.3.2,TODO: Generalize this out.,1
v0.3.2,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.3.2,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.3.2,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.3.2,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.3.2,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.3.2,TODO: do we handle 0?  We would write out all zeros..,1
v0.3.2,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.3.2,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.3.2,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.3.2,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.3.2,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.3.2,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.3.2,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.3.2,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.3.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.2,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.3.2,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.3.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.2,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.3.2,perhaps might return that for subnormal floats.,1
v0.3.2,TODO: this entire section below!,1
v0.3.2,TODO: implement this:,1
v0.3.2,TODO: implement this:,1
v0.3.2,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.3.2,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.3.2,TODO: review these comments below now that things have changed:,1
v0.3.2,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.3.2,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.3.2,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.3.2,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.3.2,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.3.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.3.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.3.2,TODO: Notes on SIMD-ifying,1
v0.3.2,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.3.2,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.3.2,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.3.2,TODO : ALL OF THE BELOW!,1
v0.3.2,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.3.2,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.3.2,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.3.2,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.3.2,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.3.2,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.3.2,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.3.2,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.3.2,"times than desired, but we can live with that",1
v0.3.2,our caller can give us one of these bad types of inputs:,1
v0.3.2,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.3.2,"times than desired, but we can live with that",1
v0.3.2,"times than desired, but we can live with that",1
v0.3.2,"times than desired, but we can live with that",1
v0.3.2,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.3.2,"TODO: add this as a python/R option ""winsorized""",1
v0.3.2,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.3.2,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.3.2,TODO: implement sparse features,1
v0.3.2,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.3.2,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.3.2,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.3.2,TODO: sort the data by the target (if there is only one target),1
v0.3.2,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.3.2,TODO: handle sparse data someday,1
v0.3.2,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.3.2,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.3.2,g_TODO_removeThisThreadTest = 1;,1
v0.3.2,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.3.2,if(0 == g_TODO_removeThisThreadTest) {,1
v0.3.2,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.3.2,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.3.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.2,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.3.2,TODO: handle interaction detection for higher dimensions,1
v0.3.2,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.3.2,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.3.2,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.3.2,- TODO: POST-HEALING,1
v0.3.2,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.3.2,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.3.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.3.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.3.2,TODO: evaluate max here instead as well,1
v0.3.2,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.3.2,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.3.2,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.3.2,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.3.2,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.3.2,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.3.2,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.3.2,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.3.2,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.3.2,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.3.2,There's actually two subtle issues here that we need to handle differently:,1
v0.3.2,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.3.2,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.3.2,- TODO: EXPLORING BOTH SIDES,1
v0.3.2,- TODO:,1
v0.3.2,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.3.2,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.3.2,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.3.2,TODO : in the future fill this priority queue with the average length within our,1
v0.3.2,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.3.2,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.3.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.2,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.3.2,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.3.2,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.3.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.2,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.3.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.2,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.3.2,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.2,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.2,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.3.2,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.3.2,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.3.2,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.3.2,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.3.2,"Actually, I think the real solution here is that",1
v0.3.2,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.3.2,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.3.2,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.3.2,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.3.2,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.3.2,TODO: move most of this code out of this function into a non-templated place,1
v0.3.2,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.3.2,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.3.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.2,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.3.2,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.2,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.3.2,TODO: move this into the BoosterShell::Create function,1
v0.3.2,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.3.2,TODO: consider making a fast approximation of this,1
v0.3.2,TODO : add classification binary and multiclass versions of this,1
v0.3.2,TODO : add classification binary and multiclass versions of this,1
v0.3.2,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.3.2,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.3.2,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.3.2,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.3.2,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.3.2,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.3.2,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.3.2,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.3.1,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.3.1,TODO: Consider separation of concerns for each field.,1
v0.3.1,TODO: Needs further discussion at design-level.,1
v0.3.1,NOTE: Not implemented yet,1
v0.3.1,NOTE: We know this environment is going to use Dash.,1
v0.3.1,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.3.1,TODO: Remove this if threshold lines are never used.,1
v0.3.1,TODO: Clean this up after validation.,1
v0.3.1,TODO: Remove this completely once performance graphs are hardened.,1
v0.3.1,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.3.1,NOTE: Workaround for tables not rendering,1
v0.3.1,TODO: Check if this is needed with the new tables.,1
v0.3.1,TODO: Consider reducing complexity of this function.,1
v0.3.1,NOTE: Workaround for tables not rendering,1
v0.3.1,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.3.1,TODO: Revisit when we support custom tabs from users.,1
v0.3.1,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.3.1,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.3.1,TODO: Harden these tests later to check content from data method.,1
v0.3.1,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.3.1,# TODO Can the base vis be a util?,1
v0.3.1,TODO: move this to a more general location where other blackbox methods can access it,1
v0.3.1,TODO: see if we can clean up these datatypes to simpler and easier to understand,1
v0.3.1,TODO: Make kwargs explicit.,1
v0.3.1,TODO: can we get rid of this column of X?,1
v0.3.1,TODO: we can probably extract the data in pdps_ to be less opaque,1
v0.3.1,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.3.1,TODO: rename from scores to something else: predicted & make predicted best_predicted,1
v0.3.1,"TODO: The UI currently expects an index in di[""predicted""] and di[""actual""]",1
v0.3.1,TODO: END SECTION TO BE REMOVED,1
v0.3.1,TODO: we should not use Pandas in a public interface like this,1
v0.3.1,"TODO: update the javascript to accept ""nominal"" or ""ordinal"" instead of ""categorical""",1
v0.3.1,BIG TODO LIST:,1
v0.3.1,FUTURE TODOS in our callers and in JSON:,1
v0.3.1,is probably better than the alternative of getting different categorical strings in different programming,1
v0.3.1,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.3.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.1,TODO : should this be np.float64 with a check for big integers,1
v0.3.1,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.3.1,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.3.1,TODO: does this work if there are spaces or bools?,1
v0.3.1,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.3.1,np.unicode_ array here.  There are two issues with keeping it here,1
v0.3.1,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.3.1,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.3.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.1,TODO: we could instead handle this by re-ordering the pandas pd_categories.  Someone might want to construct it quickly but then override the pd_categories,1
v0.3.1,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.3.1,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.1,TODO: implement pd.SparseDtype,1
v0.3.1,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.3.1,TODO: in the future special case this to make single samples faster at predict time,1
v0.3.1,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.3.1,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.3.1,TODO: handle as a single feature model,1
v0.3.1,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.3.1,TODO Add link function to operate on predict's output when needed,1
v0.3.1,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.3.1,TODO: should preprocessors handle 0 samples?,1
v0.3.1,TODO: clean up this hack that uses strings of the indexes,1
v0.3.1,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.3.1,TODO: at some point we should also handle column position remapping when the column names match,1
v0.3.1,TODO: Add unit tests for internal EBM interfacing,1
v0.3.1,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.3.1,TODO: Needs test.,1
v0.3.1,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.3.1,TODO: we could probably handle this case,1
v0.3.1,Todo: check if this call,1
v0.3.1,"TODO: it might be cleaner to pass is no feature names, then use mapping property.  That way if they change their names we'll use their new names",1
v0.3.1,TODO: this mean approach is going to fail to be useful for multiclass,1
v0.3.1,TODO: move this call into the explain_global function and extract the information needed,1
v0.3.1,"TODO: Consider removing later, potentially dead code.",1
v0.3.1,TODO: we could probably handle this case,1
v0.3.1,TODO: we could pass out a bool array instead of objects for this function only,1
v0.3.1,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.3.1,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.3.1,TODO: replace this function with a bool array that we generate in bin_native.. this function will crash,1
v0.3.1,TODO: this isn't a problem today since any unnamed categories in the mains and the pairs are the same,1
v0.3.1,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.3.1,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.3.1,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.3.1,TODO: the original intended algorithm from the paper is in the function multiclass_postprocess_RESTORE_THIS,1
v0.3.1,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.3.1,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.3.1,TODO PK: Generally if a bin for missing/unknown has zero weight then it means that the score should be,1
v0.3.1,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.3.1,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.1,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.1,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.1,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.1,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.3.1,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.3.1,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.3.1,TODO: in the future we might at this point try and figure out the most,1
v0.3.1,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.3.1,TODO: we might be able to do these operations earlier,1
v0.3.1,TODO: Clean up,1
v0.3.1,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.3.1,TODO: Add more ways to call alternative get_current_model,1
v0.3.1,TODO: order these parameters the same as our public parameter list,1
v0.3.1,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.3.1,"TODO: instead of going back to the original data in X, we",1
v0.3.1,TODO: the combinations below should be selected from the non-excluded features,1
v0.3.1,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.3.1,TODO: this will fail if we have multiple categories in a bin,1
v0.3.1,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.3.1,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.1,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.3.1,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.1,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.3.1,TODO this is consistent to what Interpret is doing but might be changed,1
v0.3.1,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.3.1,TODO PK add a test for Regression with interactions,1
v0.3.1,TODO PK add a test with a real regression dataset,1
v0.3.1,TODO PK add a test with more than 1 multiclass interaction,1
v0.3.1,TODO: Make a better test to ensure explanations are correct,1
v0.3.1,TODO: Make a better test to ensure explanations are correct,1
v0.3.1,TODO: Make a better test to ensure explanations are correct,1
v0.3.1,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.3.1,TODO: Support other languages,1
v0.3.1,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.3.1,TODO: MLI should handle multiclass at a future date.,1
v0.3.1,TODO: Generalize this out.,1
v0.3.1,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.3.1,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.3.1,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.3.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.3.1,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.3.1,TODO: do we handle 0?  We would write out all zeros..,1
v0.3.1,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.3.1,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.3.1,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.3.1,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.3.1,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.3.1,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.3.1,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.3.1,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.3.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.3.1,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.3.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.1,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.3.1,perhaps might return that for subnormal floats.,1
v0.3.1,TODO: this entire section below!,1
v0.3.1,TODO: implement this:,1
v0.3.1,TODO: implement this:,1
v0.3.1,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.3.1,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.3.1,TODO: review these comments below now that things have changed:,1
v0.3.1,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.3.1,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.3.1,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.3.1,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.3.1,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.3.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.3.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.3.1,TODO: Notes on SIMD-ifying,1
v0.3.1,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.3.1,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.3.1,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.3.1,TODO : ALL OF THE BELOW!,1
v0.3.1,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.3.1,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.3.1,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.3.1,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.3.1,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.3.1,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.3.1,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.3.1,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.3.1,"times than desired, but we can live with that",1
v0.3.1,our caller can give us one of these bad types of inputs:,1
v0.3.1,TODO: We're doing a lot more work here than necessary.  Typically in the early phases we improve,1
v0.3.1,"times than desired, but we can live with that",1
v0.3.1,"times than desired, but we can live with that",1
v0.3.1,"times than desired, but we can live with that",1
v0.3.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.3.1,"TODO: add this as a python/R option ""winsorized""",1
v0.3.1,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.3.1,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.3.1,TODO: implement sparse features,1
v0.3.1,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.3.1,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.3.1,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.3.1,TODO: sort the data by the target (if there is only one target),1
v0.3.1,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.3.1,TODO: handle sparse data someday,1
v0.3.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.3.1,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.3.1,g_TODO_removeThisThreadTest = 1;,1
v0.3.1,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.3.1,if(0 == g_TODO_removeThisThreadTest) {,1
v0.3.1,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.3.1,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.3.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.1,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.3.1,TODO: handle interaction detection for higher dimensions,1
v0.3.1,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.3.1,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.3.1,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.3.1,- TODO: POST-HEALING,1
v0.3.1,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.3.1,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.3.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.3.1,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.3.1,TODO: evaluate max here instead as well,1
v0.3.1,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.3.1,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.3.1,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.3.1,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.3.1,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.3.1,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.3.1,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.3.1,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.3.1,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.3.1,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.3.1,There's actually two subtle issues here that we need to handle differently:,1
v0.3.1,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.3.1,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.3.1,- TODO: EXPLORING BOTH SIDES,1
v0.3.1,- TODO:,1
v0.3.1,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.3.1,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.3.1,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.3.1,TODO : in the future fill this priority queue with the average length within our,1
v0.3.1,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.3.1,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.3.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.1,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.3.1,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.3.1,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.3.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.1,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.3.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.1,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.3.1,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.1,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.1,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.3.1,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.3.1,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.3.1,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.3.1,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.3.1,"Actually, I think the real solution here is that",1
v0.3.1,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.3.1,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.3.1,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.3.1,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.3.1,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.3.1,TODO: move most of this code out of this function into a non-templated place,1
v0.3.1,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.3.1,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.3.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.1,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.3.1,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.1,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.3.1,TODO: move this into the BoosterShell::Create function,1
v0.3.1,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.3.1,TODO: consider making a fast approximation of this,1
v0.3.1,TODO : add classification binary and multiclass versions of this,1
v0.3.1,TODO : add classification binary and multiclass versions of this,1
v0.3.1,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.3.1,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.3.1,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.3.1,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.3.1,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.3.1,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.3.1,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.3.1,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.3.0,"If true, `todo` and `todoList` produce output, else they produce nothing.",1
v0.3.0,TODO: Consider separation of concerns for each field.,1
v0.3.0,TODO: Needs further discussion at design-level.,1
v0.3.0,NOTE: Not implemented yet,1
v0.3.0,NOTE: We know this environment is going to use Dash.,1
v0.3.0,TODO: Remove pragma when tree interpreter updates.,1
v0.3.0,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.3.0,TODO: Stop ignoring when treeinterpreter updates upstream.,1
v0.3.0,TODO: Remove this if threshold lines are never used.,1
v0.3.0,TODO: Clean this up after validation.,1
v0.3.0,TODO: Remove this completely once performance graphs are hardened.,1
v0.3.0,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.3.0,NOTE: Workaround for tables not rendering,1
v0.3.0,TODO: Check if this is needed with the new tables.,1
v0.3.0,TODO: Consider reducing complexity of this function.,1
v0.3.0,NOTE: Workaround for tables not rendering,1
v0.3.0,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.3.0,TODO: Revisit when we support custom tabs from users.,1
v0.3.0,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.3.0,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.3.0,TODO: Harden these tests later to check content from data method.,1
v0.3.0,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.3.0,# TODO Can the base vis be a util?,1
v0.3.0,TODO: Make kwargs explicit.,1
v0.3.0,"TODO PK: check with Harsha, but we can probably alternate the taking of nibbles from both ends",1
v0.3.0,Todo: check if this call,1
v0.3.0,TODO: Docs for unify_data.,1
v0.3.0,TODO: Clean up code to have less duplication.,1
v0.3.0,NOTE: Workaround for older versions of pandas.,1
v0.3.0,BIG TODO LIST:,1
v0.3.0,FUTURE TODOS in our callers and in JSON:,1
v0.3.0,is probably better than the alternative of getting different categorical strings in different programming,1
v0.3.0,"a bar for 0 and annother bar for 1, which implies nominal, but this has a problem if the",1
v0.3.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.0,TODO : should this be np.float64 with a check for big integers,1
v0.3.0,TODO: handle ints here too which need to be checked if they are larger than the safe int max value,1
v0.3.0,TODO: converting object types first to pd.CatigoricalDType is somewhat faster than our code here which converts,1
v0.3.0,TODO: does this work if there are spaces or bools?,1
v0.3.0,TODO: we need to move this re-ordering functionality to EBMPreprocessor.fit(...) and return a,1
v0.3.0,np.unicode_ array here.  There are two issues with keeping it here,1
v0.3.0,"but it's a bit more complicated.  Also, we need to think through how we handle categoricals from",1
v0.3.0,"TODO: add a callback function option here that allows the caller to sort, remove, combine",1
v0.3.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.0,TODO: we could instead handle this by re-ordering the pandas pd_categories.  Someone might want to construct it quickly but then override the pd_categories,1
v0.3.0,"TODO: instead of throwing, we could match the ordinal values with the pandas pd_categories and",1
v0.3.0,TODO: add special case handling if there is only 1 sample to make that faster,1
v0.3.0,TODO: implement pd.SparseDtype,1
v0.3.0,TODO: implement pd.StringDtype both the numpy and arrow versions,1
v0.3.0,TODO: in the future special case this to make single samples faster at predict time,1
v0.3.0,TODO: I'm not sure that simply checking X.flags.c_contiguous handles all the situations that we'd want,1
v0.3.0,"TODO: create a C++ transposer that takes the stride length between items, so we can pass in 1 for bytes",1
v0.3.0,TODO: handle as a single feature model,1
v0.3.0,"TODO: if we checked item for various types like numpy, and those types were not of type np.object_",1
v0.3.0,TODO Add link function to operate on predict's output when needed,1
v0.3.0,"TODO: for now weights of zero are illegal, but in the future accept them",1
v0.3.0,TODO: should preprocessors handle 0 samples?,1
v0.3.0,TODO: clean up this hack that uses strings of the indexes,1
v0.3.0,TODO: this could be made more efficient by storing continuous and categorical values in separate numpy arrays,1
v0.3.0,TODO: Add unit tests for internal EBM interfacing,1
v0.3.0,"TODO: for speed and efficiency, we should instead accept in the bin_indexes array",1
v0.3.0,TODO: Needs test.,1
v0.3.0,Caution: can fail with extremely low probability. TODO: Harsha calculate this failure prob.,1
v0.3.0,"TODO: Consider removing later, potentially dead code.",1
v0.3.0,TODO: we could pass out a bool array instead of objects for this function only,1
v0.3.0,TODO: we could pass out a single bool (not an array) if these aren't continuous convertible,1
v0.3.0,TODO: add a test for multiclass calls to ebm_decision_function_and_explain,1
v0.3.0,TODO: replace this function with a bool array that we generate in bin_native.. this function will crash,1
v0.3.0,TODO: this isn't a problem today since any unnamed categories in the mains and the pairs are the same,1
v0.3.0,"TODO: shouldn't this be ""continuous"" instead of ""numeric""?",1
v0.3.0,TODO: our existing implementation has a bug where it always uses the simpler method of taking,1
v0.3.0,"TODO: we can probably do all the classes together, and that would make it generalize to interactions as well",1
v0.3.0,"TODO: this code, if we continue to do multiclass this way, can be merged with binary and regression handling",1
v0.3.0,TODO: move everything below here into C++ to ensure cross language compatibility,1
v0.3.0,TODO PK: shouldn't we be zero centering each score tensor first before taking the standard deviation,1
v0.3.0,TODO: don't pass in new_bound and old_bounds.  We use the bounds to proportion,1
v0.3.0,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.0,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.0,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.0,"TODO: if nan OR out of bounds from the cuts, estimate it.  If -inf or +inf, change it to min/max for float",1
v0.3.0,TODO: every time we merge models we fragment the bins more and more and this is undesirable,1
v0.3.0,"TODO: for now we just support alphabetical ordering in merged models, but",1
v0.3.0,TODO: estimate the histogram bin counts by taking the min of the mins and the max of the maxes,1
v0.3.0,TODO: in the future we might at this point try and figure out the most,1
v0.3.0,TODO: this algorithm has some problems.  The estimated tensor that we get by taking the,1
v0.3.0,TODO: we might be able to do these operations earlier,1
v0.3.0,TODO: Clean up,1
v0.3.0,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.3.0,TODO: Add more ways to call alternative get_current_model,1
v0.3.0,TODO: order these parameters the same as our public parameter list,1
v0.3.0,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.3.0,"TODO: instead of going back to the original data in X, we",1
v0.3.0,TODO: the combinations below should be selected from the non-excluded features,1
v0.3.0,TODO: we need to clean up and validate our input parameters before putting them into JSON,1
v0.3.0,TODO: this will fail if we have multiple categories in a bin,1
v0.3.0,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.3.0,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.0,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.3.0,TODO: for binary classification we could just look for values greater than zero instead of expanding,1
v0.3.0,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.3.0,TODO this is consistent to what Interpret is doing but might be changed,1
v0.3.0,"TODO For multiclass this is currently consistent with interpret, but might be changed",1
v0.3.0,TODO PK add a test for Regression with interactions,1
v0.3.0,TODO PK add a test with a real regression dataset,1
v0.3.0,TODO PK add a test with more than 1 multiclass interaction,1
v0.3.0,TODO: Make a better test to ensure explanations are correct,1
v0.3.0,TODO: Make a better test to ensure explanations are correct,1
v0.3.0,TODO: Make a better test to ensure explanations are correct,1
v0.3.0,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.3.0,TODO: Support other languages,1
v0.3.0,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.3.0,TODO: MLI should handle multiclass at a future date.,1
v0.3.0,TODO: Generalize this out.,1
v0.3.0,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.3.0,NOTE: Workaround for Azure DevOps.,1
v0.3.0,this is a kind of hack (a good one) where we are sending in an update of all zeros in order to,1
v0.3.0,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.3.0,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.3.0,NOTE: it might be better to generate a seed that has all 128 bits of,1
v0.3.0,TODO: do we handle 0?  We would write out all zeros..,1
v0.3.0,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.3.0,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.3.0,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.3.0,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.3.0,TODO: check this file for how we handle subnormal numbers!  It's tricky if we get them,1
v0.3.0,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.3.0,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.3.0,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.3.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.3.0,TODO: we can probably copy all 4 of these with a single memcpy,1
v0.3.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.0,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.3.0,perhaps might return that for subnormal floats.,1
v0.3.0,TODO: this entire section below!,1
v0.3.0,TODO: implement this:,1
v0.3.0,TODO: implement this:,1
v0.3.0,TODO: this is misguided... python shortens floating point numbers to the shorted string when printing numbers,1
v0.3.0,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.3.0,TODO: review these comments below now that things have changed:,1
v0.3.0,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.3.0,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.3.0,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.3.0,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.3.0,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.3.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.3.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.3.0,TODO: Notes on SIMD-ifying,1
v0.3.0,TODO: In the future we'd like to eliminate this but we need the ability to change the Bin class,1
v0.3.0,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.3.0,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.3.0,TODO : ALL OF THE BELOW!,1
v0.3.0,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.3.0,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.3.0,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.3.0,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.3.0,"TODO: on the 0th dimension, we could preserve the prev bin sum and avoid at least one read by",1
v0.3.0,"TODO: if we have 3 dimensions (as an example), we don't have to keep storing the results of the Add",1
v0.3.0,TODO: Is there any benefit in making a pair/tripple specific version of this function,1
v0.3.0,the up bin. Perhaps we could optimize all dimensions to preserve these things though.,1
v0.3.0,"times than desired, but we can live with that",1
v0.3.0,our caller can give us one of these bad types of inputs:,1
v0.3.0,"TODO : in the future don't copy over all Tensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.3.0,"times than desired, but we can live with that",1
v0.3.0,"times than desired, but we can live with that",1
v0.3.0,"times than desired, but we can live with that",1
v0.3.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.3.0,"TODO: add this as a python/R option ""winsorized""",1
v0.3.0,TODO PK Implement the following to speed boosting and generating the gradients/hessians in interaction detection:,1
v0.3.0,IMPORTANT: m_offsets must be in the last position for the struct hack and this must be standard layout,1
v0.3.0,TODO: implement sparse features,1
v0.3.0,IMPORTANT: m_nonDefaults must be in the last position for the struct hack and this must be standard layout,1
v0.3.0,TODO: should I be checking for these bad weight values here or somewhere else?,1
v0.3.0,TODO: should I be checking for these bad regression targets here or somewhere else?,1
v0.3.0,TODO: sort the data by the target (if there is only one target),1
v0.3.0,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.3.0,TODO: handle sparse data someday,1
v0.3.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.3.0,TODO: make an inline wrapper that forces this to the correct type and have 2 differently named functions,1
v0.3.0,g_TODO_removeThisThreadTest = 1;,1
v0.3.0,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.3.0,if(0 == g_TODO_removeThisThreadTest) {,1
v0.3.0,TODO : someday add equal gain multidimensional randomized picking.  I think for that we should generate,1
v0.3.0,"TODO : we NEVER use the hessian term (currently) in GradientPair when calculating interaction scores, but we're spending time calculating",1
v0.3.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.0,TODO: we can exit here back to python to allow caller modification to our bins,1
v0.3.0,TODO: handle interaction detection for higher dimensions,1
v0.3.0,TODO: check this file for how we handle subnormal numbers.  NEVER RETURN SUBNORMALS!,1
v0.3.0,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.3.0,TODO: m_cUncuttableHighVals is redundant in that the next higher cutting range has the same value.,1
v0.3.0,- TODO: POST-HEALING,1
v0.3.0,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.3.0,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.3.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.3.0,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.3.0,TODO: evaluate max here instead as well,1
v0.3.0,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.3.0,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.3.0,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.3.0,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.3.0,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.3.0,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.3.0,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.3.0,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.3.0,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.3.0,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.3.0,There's actually two subtle issues here that we need to handle differently:,1
v0.3.0,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.3.0,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.3.0,- TODO: EXPLORING BOTH SIDES,1
v0.3.0,- TODO:,1
v0.3.0,TODO : eliminate this function after we've eliminated m_cUncuttableHighVals and wrap this functionality,1
v0.3.0,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.3.0,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.3.0,TODO : in the future fill this priority queue with the average length within our,1
v0.3.0,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.3.0,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.3.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.0,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.3.0,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.3.0,"cannot have true uniform cuts. We could make this algorithm a little better, but IMHO it isn't worth the added",1
v0.3.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.0,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.3.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.0,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.3.0,TODO: put this into it's own function that converts our fast floats to big floats,1
v0.3.0,TODO: we can exit here back to python to allow caller modification to our histograms,1
v0.3.0,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.3.0,TODO: we can probably eliminate lastDimensionLeavesMax and cSignificantBinCount and just fetch them from iDimensionImportant afterwards,1
v0.3.0,TODO: move this code down into our called functions since we can happily pass down nullptr into there and then use the rng CPU register trick at the lowest function level,1
v0.3.0,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.3.0,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.3.0,"Actually, I think the real solution here is that",1
v0.3.0,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.3.0,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.3.0,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.3.0,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.3.0,TODO: accept 0 == minSamplesLeaf as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.3.0,TODO: move most of this code out of this function into a non-templated place,1
v0.3.0,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.3.0,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.3.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.0,"TODO: instead of checking the denominators for zero above, can we do it earlier?",1
v0.3.0,TODO : we can make this faster by doing the division in CalcPartialGain after we add all the numerators,1
v0.3.0,"TODO: since BoosterCore is a non-POD C++ class, we should probably move the call to new from inside",1
v0.3.0,TODO: move this into the BoosterShell::Create function,1
v0.3.0,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.3.0,TODO: consider making a fast approximation of this,1
v0.3.0,TODO : add classification binary and multiclass versions of this,1
v0.3.0,TODO : add classification binary and multiclass versions of this,1
v0.3.0,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.3.0,TODO : add test for the condition where we overflow the term update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.3.0,TODO : add test for the condition where we overflow the result of adding the term update to the existing term NaN or +-infinity for regression,1
v0.3.0,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the term update or the,1
v0.3.0,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.3.0,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.3.0,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.3.0,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.7,TODO: Consider separation of concerns for each field.,1
v0.2.7,TODO: Needs further discussion at design-level.,1
v0.2.7,NOTE: Not implemented yet,1
v0.2.7,NOTE: We know this environment is going to use Dash.,1
v0.2.7,TODO: Remove pragma when tree interpreter updates.,1
v0.2.7,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.7,TODO: Stop ignoring when treeinterpreter updates upstream.,1
v0.2.7,TODO: Remove this if threshold lines are never used.,1
v0.2.7,TODO: Clean this up after validation.,1
v0.2.7,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.7,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.2.7,NOTE: Workaround for tables not rendering,1
v0.2.7,TODO: Check if this is needed with the new tables.,1
v0.2.7,TODO: Consider reducing complexity of this function.,1
v0.2.7,NOTE: Workaround for tables not rendering,1
v0.2.7,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.7,TODO: Revisit when we support custom tabs from users.,1
v0.2.7,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.7,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.7,TODO: Harden these tests later to check content from data method.,1
v0.2.7,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.7,# TODO Can the base vis be a util?,1
v0.2.7,TODO: Make kwargs explicit.,1
v0.2.7,Todo: check if this call,1
v0.2.7,TODO: Docs for unify_data.,1
v0.2.7,TODO: Clean up code to have less duplication.,1
v0.2.7,NOTE: Workaround for older versions of pandas.,1
v0.2.7,"TODO: Consider removing later, potentially dead code.",1
v0.2.7,TODO: Clean up,1
v0.2.7,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.7,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.7,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.7,TODO: Add more ways to call alternative get_current_model,1
v0.2.7,TODO: Add unit tests for internal EBM interfacing,1
v0.2.7,TODO: Needs test.,1
v0.2.7,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.7,TODO: More documentation in binning process to be explicit.,1
v0.2.7,TODO: Consider stripping this down to the bare minimum.,1
v0.2.7,"TODO PK v.3 replace mains in favor of a ""boosting stage plan""",1
v0.2.7,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.7,"TODO PK sanity check all our inputs from the __init__ function, and this fit fuction",1
v0.2.7,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.7,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.7,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.7,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.7,"TODO: PK don't overwrite self.feature_names here (scikit-learn rules), and it's also confusing to",1
v0.2.7,TODO PK v.3 don't overwrite feature_names and feature_types.  Create new fields called feature_names_out and,1
v0.2.7,TODO PK v.3 shouldn't this be self._global_selector_ ??,1
v0.2.7,hack. remove the 0th index which is for missing values,1
v0.2.7,hack. remove the 0th index which is for missing values,1
v0.2.7,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.7,hack. remove the 0th index which is for missing values,1
v0.2.7,hack. remove the 0th index which is for missing values,1
v0.2.7,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.7,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.7,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.7,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.7,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.7,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.7,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.7,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.7,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.7,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.7,TODO PK add a test for Regression with interactions,1
v0.2.7,TODO PK add a test with a real regression dataset,1
v0.2.7,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.7,TODO: Make a better test to ensure explanations are correct,1
v0.2.7,TODO: Make a better test to ensure explanations are correct,1
v0.2.7,TODO: Make a better test to ensure explanations are correct,1
v0.2.7,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.7,TODO: Support other languages,1
v0.2.7,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.7,TODO: MLI should handle multiclass at a future date.,1
v0.2.7,TODO: Generalize this out.,1
v0.2.7,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.2.7,NOTE: Workaround for Azure DevOps.,1
v0.2.7,"TODO: we can replace this (I think) with an ""ApplyModelUpdate"" which has all zeros.  That might be useful",1
v0.2.7,"TODO : review this function to see if iZeroLogit was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.7,TODO : !!! re-examine the idea of zeroing one of the logits with iZeroLogit after we have the ability to test large numbers of datasets,1
v0.2.7,"TODO : review this function to see if iZeroLogit was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.7,TODO : !!! re-examine the idea of zeroing one of the logits with iZeroLogit after we have the ability to test large numbers of datasets,1
v0.2.7,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.2.7,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.2.7,"this is a bit inefficient in that we go through a complete regeneration of the internal state,",1
v0.2.7,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.7,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.2.7,// TODO: handle multiclass,1
v0.2.7,UNUSED(countTargetClasses); // TODO: use this,1
v0.2.7,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.2.7,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.2.7,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.2.7,"TODO: are we going to use this..  If not, then we can remove the additional -inf and +inf bin requirements",1
v0.2.7,TODO : optimize this function,1
v0.2.7,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.7,TODO : we can make this faster by doing the division in ComputeSinglePartitionGainParent after we add all the numerators,1
v0.2.7,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.7,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.7,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.7,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.7,"TODO : try replacing cItemsRemaining with a pGradientAndHessiansExit which eliminates one subtact operation, but might make it harder for",1
v0.2.7,TODO : enable SIMD(AVX-512) to work,1
v0.2.7,"clang's static checker seems to dislike this comparison and says it's not an integral comparison, but it is!",1
v0.2.7,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.2.7,perhaps might return that for subnormal floats.,1
v0.2.7,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.2.7,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.2.7,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.2.7,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.7,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.7,TODO : ALL OF THE BELOW!,1
v0.2.7,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.7,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.7,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.2.7,TODO: we can get rid of the cCompilerDimensions aspect here by making the 1 or 2 inner loops register/pointer,1
v0.2.7,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.7,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.7,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.7,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.7,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.7,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.7,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.7,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.7,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.7,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.7,our caller can give us one of these bad types of inputs:,1
v0.2.7,"TODO : in the future don't copy over all CompressibleTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.7,"times than desired, but we can live with that",1
v0.2.7,"times than desired, but we can live with that",1
v0.2.7,TODO: handle this better where we handle mismatches in index types,1
v0.2.7,"times than desired, but we can live with that",1
v0.2.7,"times than desired, but we can live with that",1
v0.2.7,TODO PK Implement the following for memory efficiency and speed of initialization :,1
v0.2.7,"One example bad situation is having 3 features: one of which is sparse, one of which has 3 items per 64 - bit number, and the",1
v0.2.7,work for us someday (currently they only allow only just typenames or the same datatypes per parameter pack),1
v0.2.7,m_offsets needs to be at the bottom of this struct.  We use the struct hack to size this array,1
v0.2.7,TODO: implement sparse features,1
v0.2.7,TODO: sort the data by the target (if there is only one target),1
v0.2.7,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.2.7,TODO: handle sparse data someday,1
v0.2.7,TODO: bit compact this,1
v0.2.7,TODO: sort by the target and then convert the target to a count of each index,1
v0.2.7,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.7,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.7,"TODO: add this as a python/R option ""winsorized""",1
v0.2.7,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.2.7,if(0 == g_TODO_removeThisThreadTest) {,1
v0.2.7,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.7,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.2.7,TODO: m_cUncuttableHighValues is redundant in that the next higher cutting range has the same value.,1
v0.2.7,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.7,- TODO: POST-HEALING,1
v0.2.7,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.2.7,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.2.7,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.7,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.7,TODO: evaluate max here instead as well,1
v0.2.7,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.2.7,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.2.7,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.2.7,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.2.7,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.2.7,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.2.7,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.7,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.7,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.2.7,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.2.7,There's actually two subtle issues here that we need to handle differently:,1
v0.2.7,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.2.7,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.2.7,- TODO: EXPLORING BOTH SIDES,1
v0.2.7,- TODO:,1
v0.2.7,TODO : eliminate this function after we've eliminated m_cUncuttableHighValues and wrap this functionality,1
v0.2.7,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.2.7,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.2.7,TODO : in the future fill this priority queue with the average length within our,1
v0.2.7,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.7,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.7,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.2.7,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.2.7,TODO : memcpy this instead,1
v0.2.7,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.7,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.7,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.7,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.7,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.7,"TODO : VERY IMPORTANT, review if this is sorting in the correct direction!!!",1
v0.2.7,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.7,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.7,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.7,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.7,TODO : enable SIMD(AVX-512) to work,1
v0.2.7,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.7,TODO: template this check away,1
v0.2.7,TODO: template this check away,1
v0.2.7,TODO: template this check away,1
v0.2.7,TODO: template this check away,1
v0.2.7,TODO: template this check away,1
v0.2.7,TODO: template this check away,1
v0.2.7,TODO : enable SIMD(AVX-512) to work,1
v0.2.7,"TODO : we NEVER use the hessian term (currently) in HistogramTargetEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.7,TODO: handle this better,1
v0.2.7,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.7,"TODO: instead of putting the FeatureGroup into a character buffer, consider putting k_cDimensionsMax",1
v0.2.7,TODO: move this into the loop above,1
v0.2.7,TODO: remove the pInteractionCore object here.  pInteractionShell contains pInteractionCore,1
v0.2.7,TODO: use memset,1
v0.2.7,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.7,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.2.7,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.2.7,TODO: accept 0 == countSamplesRequiredForChildSplitMin as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.2.7,TODO: move most of this code out of this function into a non-templated place,1
v0.2.7,TODO: move this into a helper function on the histogram bucket object that zeros N bytes (if we know the bytes).  Mostly as a warning to understand where we're using memset,1
v0.2.7,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.2.7,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.2.7,TODO : move this to initialization where we execute it only once,1
v0.2.7,TODO : move this to initialization where we execute it only once,1
v0.2.7,TODO : move this to initialization where we execute it only once,1
v0.2.7,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.2.7,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.2.7,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.7,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.2.7,"Actually, I think the real solution here is that",1
v0.2.7,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.7,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.2.7,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.7,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.7,TODO : test if our GenerateUpdateOptionsType options flags only include flags that we use,1
v0.2.7,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.7,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.7,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.2.7,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.7,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.2.7,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.2.7,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.7,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.7,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.7,TODO: consider making a fast approximation of this,1
v0.2.7,TODO : add classification binary and multiclass versions of this,1
v0.2.7,TODO : add classification binary and multiclass versions of this,1
v0.2.7,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.2.7,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.7,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.7,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the model update or the,1
v0.2.7,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.7,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.7,TODO: combine SetLogMessageFunction and SetTraceLevel and verify logMessageFunction hasn't changed.  if set to something new turn off logging!,1
v0.2.7,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.7,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.7,TODO : change this so that it doesn't execute anything if EbmFloat is a double,1
v0.2.6,TODO: Consider separation of concerns for each field.,1
v0.2.6,TODO: Needs further discussion at design-level.,1
v0.2.6,NOTE: Not implemented yet,1
v0.2.6,NOTE: We know this environment is going to use Dash.,1
v0.2.6,TODO: Remove pragma when tree interpreter updates.,1
v0.2.6,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.6,TODO: Stop ignoring when treeinterpreter updates upstream.,1
v0.2.6,TODO: Remove this if threshold lines are never used.,1
v0.2.6,TODO: Clean this up after validation.,1
v0.2.6,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.6,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.2.6,NOTE: Workaround for tables not rendering,1
v0.2.6,TODO: Check if this is needed with the new tables.,1
v0.2.6,TODO: Consider reducing complexity of this function.,1
v0.2.6,NOTE: Workaround for tables not rendering,1
v0.2.6,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.6,TODO: Revisit when we support custom tabs from users.,1
v0.2.6,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.6,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.6,TODO: Harden these tests later to check content from data method.,1
v0.2.6,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.6,# TODO Can the base vis be a util?,1
v0.2.6,TODO: Make kwargs explicit.,1
v0.2.6,Todo: check if this call,1
v0.2.6,TODO: Docs for unify_data.,1
v0.2.6,TODO: Clean up code to have less duplication.,1
v0.2.6,NOTE: Workaround for older versions of pandas.,1
v0.2.6,"TODO: Consider removing later, potentially dead code.",1
v0.2.6,TODO: Clean up,1
v0.2.6,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.6,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.6,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.6,TODO: Add more ways to call alternative get_current_model,1
v0.2.6,TODO: Add unit tests for internal EBM interfacing,1
v0.2.6,TODO: Needs test.,1
v0.2.6,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.6,TODO: More documentation in binning process to be explicit.,1
v0.2.6,TODO: Consider stripping this down to the bare minimum.,1
v0.2.6,"TODO PK v.3 replace mains in favor of a ""boosting stage plan""",1
v0.2.6,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.6,"TODO PK sanity check all our inputs from the __init__ function, and this fit fuction",1
v0.2.6,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.6,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.6,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.6,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.6,"TODO: PK don't overwrite self.feature_names here (scikit-learn rules), and it's also confusing to",1
v0.2.6,TODO PK v.3 don't overwrite feature_names and feature_types.  Create new fields called feature_names_out and,1
v0.2.6,TODO PK v.3 shouldn't this be self._global_selector_ ??,1
v0.2.6,hack. remove the 0th index which is for missing values,1
v0.2.6,hack. remove the 0th index which is for missing values,1
v0.2.6,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.6,hack. remove the 0th index which is for missing values,1
v0.2.6,hack. remove the 0th index which is for missing values,1
v0.2.6,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.6,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.6,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.6,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.6,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.6,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.6,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.6,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.6,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.6,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.6,TODO PK add a test for Regression with interactions,1
v0.2.6,TODO PK add a test with a real regression dataset,1
v0.2.6,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.6,TODO: Make a better test to ensure explanations are correct,1
v0.2.6,TODO: Make a better test to ensure explanations are correct,1
v0.2.6,TODO: Make a better test to ensure explanations are correct,1
v0.2.6,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.6,TODO: Support other languages,1
v0.2.6,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.6,TODO: MLI should handle multiclass at a future date.,1
v0.2.6,TODO: Generalize this out.,1
v0.2.6,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.2.6,NOTE: Workaround for Azure DevOps.,1
v0.2.6,"TODO: we can replace this (I think) with an ""ApplyModelUpdate"" which has all zeros.  That might be useful",1
v0.2.6,"TODO : review this function to see if iZeroLogit was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.6,TODO : !!! re-examine the idea of zeroing one of the logits with iZeroLogit after we have the ability to test large numbers of datasets,1
v0.2.6,"TODO : review this function to see if iZeroLogit was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.6,TODO : !!! re-examine the idea of zeroing one of the logits with iZeroLogit after we have the ability to test large numbers of datasets,1
v0.2.6,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.2.6,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.2.6,"this is a bit inefficient in that we go through a complete regeneration of the internal state,",1
v0.2.6,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.6,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.2.6,// TODO: handle multiclass,1
v0.2.6,UNUSED(countTargetClasses); // TODO: use this,1
v0.2.6,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.2.6,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.2.6,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.2.6,"TODO: are we going to use this..  If not, then we can remove the additional -inf and +inf bin requirements",1
v0.2.6,TODO : optimize this function,1
v0.2.6,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.6,TODO : we can make this faster by doing the division in ComputeSinglePartitionGainParent after we add all the numerators,1
v0.2.6,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.6,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.6,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.6,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.6,"TODO : try replacing cItemsRemaining with a pGradientAndHessiansExit which eliminates one subtact operation, but might make it harder for",1
v0.2.6,TODO : enable SIMD(AVX-512) to work,1
v0.2.6,"clang's static checker seems to dislike this comparison and says it's not an integral comparison, but it is!",1
v0.2.6,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.2.6,perhaps might return that for subnormal floats.,1
v0.2.6,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.2.6,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.2.6,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.2.6,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.6,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.6,TODO : ALL OF THE BELOW!,1
v0.2.6,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.6,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.6,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the splits, we can undo the re-ordering for splitting the tensor, which has just a few cells, so will be efficient",1
v0.2.6,TODO: we can get rid of the cCompilerDimensions aspect here by making the 1 or 2 inner loops register/pointer,1
v0.2.6,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.6,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.6,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.6,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.6,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.6,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.6,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.6,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.6,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.6,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.6,our caller can give us one of these bad types of inputs:,1
v0.2.6,"TODO : in the future don't copy over all CompressibleTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.6,"times than desired, but we can live with that",1
v0.2.6,"times than desired, but we can live with that",1
v0.2.6,TODO: handle this better where we handle mismatches in index types,1
v0.2.6,"times than desired, but we can live with that",1
v0.2.6,"times than desired, but we can live with that",1
v0.2.6,TODO PK Implement the following for memory efficiency and speed of initialization :,1
v0.2.6,"One example bad situation is having 3 features: one of which is sparse, one of which has 3 items per 64 - bit number, and the",1
v0.2.6,work for us someday (currently they only allow only just typenames or the same datatypes per parameter pack),1
v0.2.6,m_offsets needs to be at the bottom of this struct.  We use the struct hack to size this array,1
v0.2.6,TODO: implement sparse features,1
v0.2.6,TODO: sort the data by the target (if there is only one target),1
v0.2.6,TODO: evalute the data to decide if the feature should be sparse or not,1
v0.2.6,TODO: handle sparse data someday,1
v0.2.6,TODO: bit compact this,1
v0.2.6,TODO: sort by the target and then convert the target to a count of each index,1
v0.2.6,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.6,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.6,"TODO: add this as a python/R option ""winsorized""",1
v0.2.6,// TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.2.6,if(0 == g_TODO_removeThisThreadTest) {,1
v0.2.6,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.6,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.2.6,TODO: m_cUncuttableHighValues is redundant in that the next higher cutting range has the same value.,1
v0.2.6,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.6,- TODO: POST-HEALING,1
v0.2.6,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.2.6,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.2.6,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.6,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.6,TODO: evaluate max here instead as well,1
v0.2.6,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.2.6,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.2.6,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.2.6,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.2.6,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.2.6,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.2.6,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.6,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.6,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.2.6,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.2.6,There's actually two subtle issues here that we need to handle differently:,1
v0.2.6,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.2.6,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.2.6,- TODO: EXPLORING BOTH SIDES,1
v0.2.6,- TODO:,1
v0.2.6,TODO : eliminate this function after we've eliminated m_cUncuttableHighValues and wrap this functionality,1
v0.2.6,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.2.6,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.2.6,TODO : in the future fill this priority queue with the average length within our,1
v0.2.6,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.6,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.6,"TODO: it would be easy for us to implement a -1 lookback where we make the first split, find the second split, elimnate the first split and try",1
v0.2.6,Probably 1 split isn't very good since with 2 splits we can localize a region of high gain in the center somewhere,1
v0.2.6,TODO : memcpy this instead,1
v0.2.6,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.6,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.6,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.6,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.6,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.6,"TODO : VERY IMPORTANT, review if this is sorting in the correct direction!!!",1
v0.2.6,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.6,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.6,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.6,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.6,TODO : enable SIMD(AVX-512) to work,1
v0.2.6,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.6,TODO: template this check away,1
v0.2.6,TODO: template this check away,1
v0.2.6,TODO: template this check away,1
v0.2.6,TODO: template this check away,1
v0.2.6,TODO: template this check away,1
v0.2.6,TODO: template this check away,1
v0.2.6,TODO : enable SIMD(AVX-512) to work,1
v0.2.6,"TODO : we NEVER use the hessian term (currently) in HistogramTargetEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.6,TODO: handle this better,1
v0.2.6,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.6,"TODO: instead of putting the FeatureGroup into a character buffer, consider putting k_cDimensionsMax",1
v0.2.6,TODO: move this into the loop above,1
v0.2.6,TODO: remove the pInteractionCore object here.  pInteractionShell contains pInteractionCore,1
v0.2.6,TODO: use memset,1
v0.2.6,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.6,TODO: add a new random_rety option that will retry random splitting for N times and select the one with the best gain,1
v0.2.6,"TODO: accept the minimum number of items in a split and then refuse to allow the split if we violate it, or",1
v0.2.6,TODO: accept 0 == countSamplesRequiredForChildSplitMin as a minimum number of items so that we can always choose to allow a tensor split (for DP),1
v0.2.6,TODO: move most of this code out of this function into a non-templated place,1
v0.2.6,TODO: move this into a helper function on the histogram bucket object that zeros N bytes (if we know the bytes).  Mostly as a warning to understand where we're using memset,1
v0.2.6,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.2.6,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.2.6,TODO : move this to initialization where we execute it only once,1
v0.2.6,TODO : move this to initialization where we execute it only once,1
v0.2.6,TODO : move this to initialization where we execute it only once,1
v0.2.6,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.2.6,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.2.6,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.6,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.2.6,"Actually, I think the real solution here is that",1
v0.2.6,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.6,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.2.6,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.6,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.6,TODO : test if our GenerateUpdateOptionsType options flags only include flags that we use,1
v0.2.6,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.6,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.6,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.2.6,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.6,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.2.6,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.2.6,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.6,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.6,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.6,TODO: consider making a fast approximation of this,1
v0.2.6,TODO : add classification binary and multiclass versions of this,1
v0.2.6,TODO : add classification binary and multiclass versions of this,1
v0.2.6,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.2.6,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.6,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.6,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the model update or the,1
v0.2.6,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.6,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.6,TODO: combine SetLogMessageFunction and SetTraceLevel and verify logMessageFunction hasn't changed.  if set to something new turn off logging!,1
v0.2.6,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.6,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.6,TODO : change this so that it doesn't execute anything if EbmFloat is a double,1
v0.2.5,TODO: Consider separation of concerns for each field.,1
v0.2.5,TODO: Needs further discussion at design-level.,1
v0.2.5,NOTE: Not implemented yet,1
v0.2.5,NOTE: We know this environment is going to use Dash.,1
v0.2.5,TODO: Remove pragma when tree interpreter updates.,1
v0.2.5,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.5,TODO: Stop ignoring when treeinterpreter updates upstream.,1
v0.2.5,TODO: Remove this if threshold lines are never used.,1
v0.2.5,TODO: Clean this up after validation.,1
v0.2.5,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.5,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.2.5,NOTE: Workaround for tables not rendering,1
v0.2.5,TODO: Check if this is needed with the new tables.,1
v0.2.5,TODO: Consider reducing complexity of this function.,1
v0.2.5,NOTE: Workaround for tables not rendering,1
v0.2.5,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.5,TODO: Revisit when we support custom tabs from users.,1
v0.2.5,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.5,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.5,TODO: Harden these tests later to check content from data method.,1
v0.2.5,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.5,# TODO Can the base vis be a util?,1
v0.2.5,TODO: Make kwargs explicit.,1
v0.2.5,Todo: check if this call,1
v0.2.5,TODO: Docs for unify_data.,1
v0.2.5,TODO: Clean up code to have less duplication.,1
v0.2.5,NOTE: Workaround for older versions of pandas.,1
v0.2.5,"TODO: Consider removing later, potentially dead code.",1
v0.2.5,TODO: Clean up,1
v0.2.5,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.5,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.5,TODO: Add unit tests for internal EBM interfacing,1
v0.2.5,TODO: Needs test.,1
v0.2.5,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.5,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.5,TODO: Add more ways to call alternative get_current_model,1
v0.2.5,TODO: More documentation in binning process to be explicit.,1
v0.2.5,TODO: Consider stripping this down to the bare minimum.,1
v0.2.5,"TODO PK v.3 replace mains in favor of a ""boosting stage plan""",1
v0.2.5,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.5,"TODO PK sanity check all our inputs from the __init__ function, and this fit fuction",1
v0.2.5,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.5,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.5,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.5,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.5,"TODO: PK don't overwrite self.feature_names here (scikit-learn rules), and it's also confusing to",1
v0.2.5,TODO PK v.3 don't overwrite feature_names and feature_types.  Create new fields called feature_names_out and,1
v0.2.5,TODO PK v.3 shouldn't this be self._global_selector_ ??,1
v0.2.5,hack. remove the 0th index which is for missing values,1
v0.2.5,hack. remove the 0th index which is for missing values,1
v0.2.5,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.5,hack. remove the 0th index which is for missing values,1
v0.2.5,hack. remove the 0th index which is for missing values,1
v0.2.5,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.5,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.5,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.5,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.5,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.5,TODO PK add a test for Regression with interactions,1
v0.2.5,TODO PK add a test with a real regression dataset,1
v0.2.5,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.5,TODO: Make a better test to ensure explanations are correct,1
v0.2.5,TODO: Make a better test to ensure explanations are correct,1
v0.2.5,TODO: Make a better test to ensure explanations are correct,1
v0.2.5,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.5,TODO: Support other languages,1
v0.2.5,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.5,TODO: MLI should handle multiclass at a future date.,1
v0.2.5,TODO: Generalize this out.,1
v0.2.5,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.2.5,NOTE: Workaround for Azure DevOps.,1
v0.2.5,"TODO : review this function to see if iZeroLogit was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.5,TODO : !!! re-examine the idea of zeroing one of the logits with iZeroLogit after we have the ability to test large numbers of datasets,1
v0.2.5,"TODO : review this function to see if iZeroLogit was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.5,TODO : !!! re-examine the idea of zeroing one of the logits with iZeroLogit after we have the ability to test large numbers of datasets,1
v0.2.5,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.2.5,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.2.5,"this is a bit inefficient in that we go through a complete regeneration of the internal state,",1
v0.2.5,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.5,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.2.5,// TODO: handle multiclass,1
v0.2.5,UNUSED(countTargetClasses); // TODO: use this,1
v0.2.5,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.2.5,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.2.5,TODO: we want this function super-fast to handle the case where someone calls Discretize repeatedly,1
v0.2.5,TODO : optimize this function,1
v0.2.5,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.5,TODO : we can make this faster by doing the division in ComputeSinglePartitionGainParent after we add all the numerators,1
v0.2.5,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.5,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.5,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.5,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.5,"TODO : try replacing cItemsRemaining with a pGradientAndHessiansExit which eliminates one subtact operation, but might make it harder for",1
v0.2.5,TODO : enable SIMD(AVX-512) to work,1
v0.2.5,"clang's static checker seems to dislike this comparison and says it's not an integral comparison, but it is!",1
v0.2.5,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.2.5,perhaps might return that for subnormal floats.,1
v0.2.5,TODO: switch over to using our better ConvertStringToFloat function now!,1
v0.2.5,"- In theory, +inf cut points might have a use to separate max and +inf feature values, but it's kind of weird",1
v0.2.5,"- obviously the cut should be below +10, but what should the max be?  We can't really show a range",1
v0.2.5,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.5,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.5,TODO : ALL OF THE BELOW!,1
v0.2.5,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.5,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler cCompilerDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.5,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the cuts, we can undo the re-ordering for cutting the tensor, which has just a few cells, so will be efficient",1
v0.2.5,TODO: we can get rid of the cCompilerDimensions aspect here by making the 1 or 2 inner loops register/pointer,1
v0.2.5,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.5,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.5,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.5,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.5,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.5,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.5,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.5,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.5,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.5,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.5,our caller can give us one of these bad types of inputs:,1
v0.2.5,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.5,"times than desired, but we can live with that",1
v0.2.5,"times than desired, but we can live with that",1
v0.2.5,TODO: handle this better where we handle mismatches in index types,1
v0.2.5,"times than desired, but we can live with that",1
v0.2.5,"times than desired, but we can live with that",1
v0.2.5,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.5,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.2.5,"checking the max isn't really the best here, but doing this right seems pretty complicated",1
v0.2.5,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.5,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.5,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.5,TODO: bit compact this,1
v0.2.5,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.5,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.5,"TODO: add this as a python/R option ""winsorized""",1
v0.2.5,TODO: eliminate this code I added to test that threads are available on the majority of our systems,1
v0.2.5,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.5,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.2.5,TODO: m_cUncuttableHighValues is redundant in that the next higher cutting range has the same value.,1
v0.2.5,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.5,- TODO: POST-HEALING,1
v0.2.5,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.2.5,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.2.5,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.5,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.5,TODO: evaluate max here instead as well,1
v0.2.5,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.2.5,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.2.5,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.2.5,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.2.5,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.2.5,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.2.5,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.5,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.5,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.2.5,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.2.5,There's actually two subtle issues here that we need to handle differently:,1
v0.2.5,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.2.5,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.2.5,- TODO: EXPLORING BOTH SIDES,1
v0.2.5,- TODO:,1
v0.2.5,TODO : eliminate this function after we've eliminated m_cUncuttableHighValues and wrap this functionality,1
v0.2.5,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.2.5,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.2.5,TODO : in the future fill this priority queue with the average length within our,1
v0.2.5,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.5,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.5,"TODO: it would be easy for us to implement a -1 lookback where we make the first cut, find the second cut, elimnate the first cut and try",1
v0.2.5,Probably 1 cut isn't very good since with 2 cuts we can localize a region of high gain in the center somewhere,1
v0.2.5,TODO : memcpy this instead,1
v0.2.5,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.5,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.5,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.5,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.5,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.5,"TODO : VERY IMPORTANT, review if this is sorting in the correct direction!!!",1
v0.2.5,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.5,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.5,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.5,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.5,TODO : enable SIMD(AVX-512) to work,1
v0.2.5,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.5,TODO: template this check away,1
v0.2.5,TODO: template this check away,1
v0.2.5,TODO: template this check away,1
v0.2.5,TODO: template this check away,1
v0.2.5,TODO: template this check away,1
v0.2.5,TODO: template this check away,1
v0.2.5,TODO : enable SIMD(AVX-512) to work,1
v0.2.5,"TODO : we NEVER use the hessian term (currently) in HistogramTargetEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.5,TODO: handle this better,1
v0.2.5,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.5,"TODO: instead of putting the FeatureGroup into a character buffer, consider putting k_cDimensionsMax",1
v0.2.5,TODO: move this into the loop above,1
v0.2.5,TODO: remove the pInteractionCore object here.  pInteractionShell contains pInteractionCore,1
v0.2.5,TODO: use memset,1
v0.2.5,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.5,TODO: add a new random_rety option that will retry random cutting for N times and select the one with the best gain,1
v0.2.5,"TODO: accept the minimum number of items in a cut and then refuse to allow the cut if we violate it, or",1
v0.2.5,TODO: accept 0 == countSamplesRequiredForChildSplitMin as a minimum number of items so that we can always choose to allow a tensor cut (for DP),1
v0.2.5,TODO: move most of this code out of this function into a non-templated place,1
v0.2.5,TODO: move this into a helper function on the histogram bucket object that zeros N bytes (if we know the bytes).  Mostly as a warning to understand where we're using memset,1
v0.2.5,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.2.5,TODO: this section can probably be eliminated since ComputeSinglePartitionUpdate now checks,1
v0.2.5,TODO : move this to initialization where we execute it only once,1
v0.2.5,TODO : move this to initialization where we execute it only once,1
v0.2.5,TODO : move this to initialization where we execute it only once,1
v0.2.5,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the hessian isn't required (yet) in order to make decisions about",1
v0.2.5,TODO: eventually handle this in our caller and this function can specialize in handling just 2 dimensional,1
v0.2.5,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.5,"// TODO : for classification with logit zeroing, is our learning rate essentially being inflated as",1
v0.2.5,"Actually, I think the real solution here is that",1
v0.2.5,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.5,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.2.5,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.5,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.5,TODO : test if our GenerateUpdateOptionsType options flags only include flags that we use,1
v0.2.5,TODO : we can make this faster by doing the division in ComputeSinglePartitionGain after we add all the numerators,1
v0.2.5,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.5,TODO: we might move the call to FillAllocations to be more lazy incase the caller doesn't use it all,1
v0.2.5,TODO: consider making a fast approximation of this,1
v0.2.5,TODO : add classification binary and multiclass versions of this,1
v0.2.5,TODO : add classification binary and multiclass versions of this,1
v0.2.5,TODO : re-formulate these tests after we reach agreement on how the graph bounds are suposed to work,1
v0.2.5,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.5,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.5,TODO : add test for the condition where we overflow the validation regression or classification scores without overflowing the model update or the,1
v0.2.5,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.5,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.5,TODO: combine SetLogMessageFunction and SetTraceLevel and verify logMessageFunction hasn't changed.  if set to something new turn off logging!,1
v0.2.5,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.5,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.5,TODO : change this so that it doesn't execute anything if EbmFloat is a double,1
v0.2.4,NOTE: Not implemented yet,1
v0.2.4,NOTE: We know this environment is going to use Dash.,1
v0.2.4,TODO: Remove pragma when tree interpreter updates.,1
v0.2.4,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.4,TODO: Stop ignoring when treeinterpreter updates upstream.,1
v0.2.4,TODO: Remove this if threshold lines are never used.,1
v0.2.4,TODO: Clean this up after validation.,1
v0.2.4,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.4,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.2.4,NOTE: Workaround for tables not rendering,1
v0.2.4,TODO: Check if this is needed with the new tables.,1
v0.2.4,TODO: Consider reducing complexity of this function.,1
v0.2.4,NOTE: Workaround for tables not rendering,1
v0.2.4,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.4,TODO: Revisit when we support custom tabs from users.,1
v0.2.4,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.4,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.4,TODO: Harden these tests later to check content from data method.,1
v0.2.4,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.4,# TODO Can the base vis be a util?,1
v0.2.4,TODO: Make kwargs explicit.,1
v0.2.4,Todo: check if this call,1
v0.2.4,TODO: Docs for unify_data.,1
v0.2.4,TODO: Clean up code to have less duplication.,1
v0.2.4,NOTE: Workaround for older versions of pandas.,1
v0.2.4,"TODO: Consider removing later, potentially dead code.",1
v0.2.4,TODO: Clean up,1
v0.2.4,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.4,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.4,TODO: Add unit tests for internal EBM interfacing,1
v0.2.4,TODO : !WARNING! currently we can only accept a single number for max_leaves because in C++ we eliminate,1
v0.2.4,TODO: Needs test.,1
v0.2.4,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.4,TODO PK make sure the None value here is handled by our caller,1
v0.2.4,TODO PK make sure the None value here is handled by our caller,1
v0.2.4,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.4,TODO: Add alternative | get_current_model,1
v0.2.4,TODO: More documentation in binning process to be explicit.,1
v0.2.4,TODO: Consider stripping this down to the bare minimum.,1
v0.2.4,"TODO PK v.3 replace mains in favor of a ""boosting stage plan""",1
v0.2.4,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.4,"TODO PK sanity check all our inputs from the __init__ function, and this fit fuction",1
v0.2.4,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.4,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.4,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.4,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.4,"TODO: PK don't overwrite self.feature_names here (scikit-learn rules), and it's also confusing to",1
v0.2.4,TODO PK v.3 don't overwrite feature_names and feature_types.  Create new fields called feature_names_out and,1
v0.2.4,TODO PK v.3 shouldn't this be self._global_selector_ ??,1
v0.2.4,hack. remove the 0th index which is for missing values,1
v0.2.4,hack. remove the 0th index which is for missing values,1
v0.2.4,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.4,hack. remove the 0th index which is for missing values,1
v0.2.4,hack. remove the 0th index which is for missing values,1
v0.2.4,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.4,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.4,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.4,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.4,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.4,TODO PK add a test for Regression with interactions,1
v0.2.4,TODO PK add a test with a real regression dataset,1
v0.2.4,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.4,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.4,TODO: Support other languages,1
v0.2.4,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.4,TODO: MLI should handle multiclass at a future date.,1
v0.2.4,TODO: Generalize this out.,1
v0.2.4,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.2.4,NOTE: Workaround for Azure DevOps.,1
v0.2.4,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.2.4,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.2.4,TODO: m_cUncuttableHighValues is redundant in that the next higher cutting range has the same value.,1
v0.2.4,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.4,- TODO: POST-HEALING,1
v0.2.4,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.2.4,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.2.4,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.4,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.4,TODO: evaluate max here instead as well,1
v0.2.4,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.2.4,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.2.4,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.2.4,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.2.4,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.2.4,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.2.4,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.4,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.4,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.2.4,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.2.4,There's actually two subtle issues here that we need to handle differently:,1
v0.2.4,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.2.4,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.2.4,- TODO: EXPLORING BOTH SIDES,1
v0.2.4,- TODO:,1
v0.2.4,TODO : eliminate this function after we've eliminated m_cUncuttableHighValues and wrap this functionality,1
v0.2.4,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.2.4,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.2.4,TODO : in the future fill this priority queue with the average length within our,1
v0.2.4,TODO optimize the next few lines,1
v0.2.4,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.2.4,TODO: implement weights,1
v0.2.4,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.4,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.4,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.4,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.4,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.4,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for",1
v0.2.4,TODO : enable SIMD(AVX-512) to work,1
v0.2.4,TODO : move this to initialization where we execute it only once,1
v0.2.4,TODO : move this to initialization where we execute it only once,1
v0.2.4,TODO : move this to initialization where we execute it only once,1
v0.2.4,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the denominator isn't required in order to make decisions about",1
v0.2.4,TODO: handle this better,1
v0.2.4,TODO: add a log warning here that we're boosting zero dimensionally for whatever reason,1
v0.2.4,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.4,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as",1
v0.2.4,"Actually, I think the real solution here is that",1
v0.2.4,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.4,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.2.4,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.4,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.4,"TODO: BIG ISSUE: if we reduced the number of dimensions because one of the dimensions had only 1 state,",1
v0.2.4,TODO : test if our GenerateUpdateOptionsType options flags only include flags that we use,1
v0.2.4,"this is a bit inefficient in that we go through a complete regeneration of the internal state,",1
v0.2.4,TODO : optimize this function,1
v0.2.4,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.4,TODO : we can make this faster by doing the division in ComputeNodeSplittingScoreParent after we add all the numerators,1
v0.2.4,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.4,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.4,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.4,TODO : ALL OF THE BELOW!,1
v0.2.4,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.4,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler compilerCountDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.4,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the cuts, we can undo the re-ordering for cutting the tensor, which has just a few cells, so will be efficient",1
v0.2.4,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.4,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.4,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.4,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.4,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.4,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.4,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.4,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.4,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.4,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.4,our caller can give us one of these bad types of inputs:,1
v0.2.4,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.4,"times than desired, but we can live with that",1
v0.2.4,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.4,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.4,TODO : eventually eliminate this subtract variable once we've decided how to handle removing one logit,1
v0.2.4,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.4,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.4,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.4,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.4,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.4,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.2.4,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.2.4,"TODO: add this as a python/R option ""winsorized""",1
v0.2.4,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.4,"TODO: it would be easy for us to implement a -1 lookback where we make the first cut, find the second cut, elimnate the first cut and try",1
v0.2.4,Probably 1 cut isn't very good since with 2 cuts we can localize a region of high gain in the center somewhere,1
v0.2.4,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.4,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.4,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.4,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.4,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.4,"TODO : VERY IMPORTANT, review if this is sorting in the correct direction!!!",1
v0.2.4,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.4,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.4,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.4,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.4,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.2.4,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.4,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.4,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.4,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.4,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.4,TODO: add a new random_rety option that will retry random cutting for N times and select the one with the best gain,1
v0.2.4,"TODO: accept the minimum number of items in a cut and then refuse to allow the cut if we violate it, or",1
v0.2.4,TODO: accept 0 == countSamplesRequiredForChildSplitMin as a minimum number of items so that we can always choose to allow a tensor cut (for DP),1
v0.2.4,TODO: move most of this code out of this function into a non-templated place,1
v0.2.4,TODO: move this into a helper function on the histogram bucket object that zeros N bytes (if we know the bytes).  Mostly as a warning to understand where we're using memset,1
v0.2.4,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.2.4,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.4,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.4,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.4,TODO : enable SIMD(AVX-512) to work,1
v0.2.4,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.4,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.4,TODO : enable SIMD(AVX-512) to work,1
v0.2.4,"TODO : we NEVER use the denominator term in HistogramBucketVectorEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.4,TODO: handle this better,1
v0.2.4,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.4,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.2.4,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.4,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.2.4,perhaps might return that for subnormal floats.,1
v0.2.4,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.4,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.2.4,TODO: handle multiclass,1
v0.2.4,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.2.4,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.2.4,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.4,TODO : implement weights,1
v0.2.4,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.4,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.4,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.4,TODO : add test for the condition where we overflow the validation regression or classification residuals without overflowing the model update or the,1
v0.2.4,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.4,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.4,TODO : add classification binary and multiclass versions of this,1
v0.2.4,TODO : add classification binary and multiclass versions of this,1
v0.2.4,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.3,NOTE: Not implemented yet,1
v0.2.3,NOTE: We know this environment is going to use Dash.,1
v0.2.3,TODO: Remove pragma when tree interpreter updates.,1
v0.2.3,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.3,TODO: Stop ignoring when treeinterpreter updates upstream.,1
v0.2.3,TODO: Remove this if threshold lines are never used.,1
v0.2.3,TODO: Clean this up after validation.,1
v0.2.3,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.3,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.2.3,NOTE: Workaround for tables not rendering,1
v0.2.3,TODO: Check if this is needed with the new tables.,1
v0.2.3,TODO: Consider reducing complexity of this function.,1
v0.2.3,NOTE: Workaround for tables not rendering,1
v0.2.3,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.3,TODO: Revisit when we support custom tabs from users.,1
v0.2.3,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.3,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.3,TODO: Harden these tests later to check content from data method.,1
v0.2.3,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.3,# TODO Can the base vis be a util?,1
v0.2.3,TODO: Make kwargs explicit.,1
v0.2.3,Todo: check if this call,1
v0.2.3,TODO: Docs for unify_data.,1
v0.2.3,TODO: Clean up code to have less duplication.,1
v0.2.3,NOTE: Workaround for older versions of pandas.,1
v0.2.3,"TODO: Consider removing later, potentially dead code.",1
v0.2.3,TODO: Clean up,1
v0.2.3,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.3,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.3,TODO: Add unit tests for internal EBM interfacing,1
v0.2.3,TODO : !WARNING! currently we can only accept a single number for max_leaves because in C++ we eliminate,1
v0.2.3,TODO: Needs test.,1
v0.2.3,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.3,TODO PK make sure the None value here is handled by our caller,1
v0.2.3,TODO PK make sure the None value here is handled by our caller,1
v0.2.3,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.3,TODO: Add alternative | get_current_model,1
v0.2.3,TODO: More documentation in binning process to be explicit.,1
v0.2.3,TODO: Consider stripping this down to the bare minimum.,1
v0.2.3,"TODO PK v.3 replace mains in favor of a ""boosting stage plan""",1
v0.2.3,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.3,"TODO PK sanity check all our inputs from the __init__ function, and this fit fuction",1
v0.2.3,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.3,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.3,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.3,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.3,"TODO: PK don't overwrite self.feature_names here (scikit-learn rules), and it's also confusing to",1
v0.2.3,TODO PK v.3 don't overwrite feature_names and feature_types.  Create new fields called feature_names_out and,1
v0.2.3,TODO PK v.3 shouldn't this be self._global_selector_ ??,1
v0.2.3,hack. remove the 0th index which is for missing values,1
v0.2.3,hack. remove the 0th index which is for missing values,1
v0.2.3,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.3,hack. remove the 0th index which is for missing values,1
v0.2.3,hack. remove the 0th index which is for missing values,1
v0.2.3,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.3,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.3,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.3,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.3,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.3,TODO PK add a test for Regression with interactions,1
v0.2.3,TODO PK add a test with a real regression dataset,1
v0.2.3,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.3,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.3,TODO: Support other languages,1
v0.2.3,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.3,TODO: MLI should handle multiclass at a future date.,1
v0.2.3,TODO: Generalize this out.,1
v0.2.3,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.2.3,NOTE: Workaround for Azure DevOps.,1
v0.2.3,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.2.3,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.2.3,TODO: m_cUncuttableHighValues is redundant in that the next higher cutting range has the same value.,1
v0.2.3,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.3,- TODO: POST-HEALING,1
v0.2.3,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.2.3,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.2.3,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.3,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.3,TODO: evaluate max here instead as well,1
v0.2.3,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.2.3,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.2.3,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.2.3,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.2.3,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.2.3,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.2.3,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.3,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.3,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.2.3,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.2.3,There's actually two subtle issues here that we need to handle differently:,1
v0.2.3,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.2.3,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.2.3,- TODO: EXPLORING BOTH SIDES,1
v0.2.3,- TODO:,1
v0.2.3,TODO : eliminate this function after we've eliminated m_cUncuttableHighValues and wrap this functionality,1
v0.2.3,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.2.3,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.2.3,TODO : in the future fill this priority queue with the average length within our,1
v0.2.3,TODO optimize the next few lines,1
v0.2.3,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.2.3,TODO: implement weights,1
v0.2.3,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.3,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.3,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.3,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.3,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.3,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for",1
v0.2.3,TODO : enable SIMD(AVX-512) to work,1
v0.2.3,TODO : move this to initialization where we execute it only once,1
v0.2.3,TODO : move this to initialization where we execute it only once,1
v0.2.3,TODO : move this to initialization where we execute it only once,1
v0.2.3,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the denominator isn't required in order to make decisions about",1
v0.2.3,TODO: handle this better,1
v0.2.3,TODO: add a log warning here that we're boosting zero dimensionally for whatever reason,1
v0.2.3,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.3,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as",1
v0.2.3,"Actually, I think the real solution here is that",1
v0.2.3,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.3,"TODO: When NewtonBoosting is enabled, we need to multiply our rate by (K - 1)/K (see above), per:",1
v0.2.3,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.3,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.3,"TODO: BIG ISSUE: if we reduced the number of dimensions because one of the dimensions had only 1 state,",1
v0.2.3,TODO : test if our GenerateUpdateOptionsType options flags only include flags that we use,1
v0.2.3,"this is a bit inefficient in that we go through a complete regeneration of the internal state,",1
v0.2.3,TODO : optimize this function,1
v0.2.3,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.3,TODO : we can make this faster by doing the division in ComputeNodeSplittingScoreParent after we add all the numerators,1
v0.2.3,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.3,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.3,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.3,TODO : ALL OF THE BELOW!,1
v0.2.3,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.3,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler compilerCountDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.3,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the cuts, we can undo the re-ordering for cutting the tensor, which has just a few cells, so will be efficient",1
v0.2.3,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.3,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.3,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.3,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.3,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.3,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.3,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.3,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.3,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.3,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.3,our caller can give us one of these bad types of inputs:,1
v0.2.3,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.3,"times than desired, but we can live with that",1
v0.2.3,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.3,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.3,TODO : eventually eliminate this subtract variable once we've decided how to handle removing one logit,1
v0.2.3,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.3,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.3,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.3,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.3,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.3,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.2.3,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.2.3,"TODO: add this as a python/R option ""winsorized""",1
v0.2.3,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.3,"TODO: it would be easy for us to implement a -1 lookback where we make the first cut, find the second cut, elimnate the first cut and try",1
v0.2.3,Probably 1 cut isn't very good since with 2 cuts we can localize a region of high gain in the center somewhere,1
v0.2.3,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.3,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.3,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.3,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.3,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.3,"TODO : VERY IMPORTANT, review if this is sorting in the correct direction!!!",1
v0.2.3,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.3,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.3,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.3,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.3,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.2.3,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.3,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.3,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.3,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.3,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.3,TODO: add a new random_rety option that will retry random cutting for N times and select the one with the best gain,1
v0.2.3,"TODO: accept the minimum number of items in a cut and then refuse to allow the cut if we violate it, or",1
v0.2.3,TODO: accept 0 == countSamplesRequiredForChildSplitMin as a minimum number of items so that we can always choose to allow a tensor cut (for DP),1
v0.2.3,TODO: move most of this code out of this function into a non-templated place,1
v0.2.3,TODO: move this into a helper function on the histogram bucket object that zeros N bytes (if we know the bytes).  Mostly as a warning to understand where we're using memset,1
v0.2.3,"1st slice.  Yeah, it's pretty confusing, but it allows for some pretty compact code in this",1
v0.2.3,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.3,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.3,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.3,TODO : enable SIMD(AVX-512) to work,1
v0.2.3,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.3,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.3,TODO : enable SIMD(AVX-512) to work,1
v0.2.3,"TODO : we NEVER use the denominator term in HistogramBucketVectorEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.3,TODO: handle this better,1
v0.2.3,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.3,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.2.3,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.3,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.2.3,perhaps might return that for subnormal floats.,1
v0.2.3,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.3,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.2.3,TODO: handle multiclass,1
v0.2.3,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.2.3,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.2.3,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.3,TODO : implement weights,1
v0.2.3,TODO: in the future maybe accept null aFeaturesCategorical and assume there are no missing values,1
v0.2.3,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.3,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.3,TODO : add test for the condition where we overflow the validation regression or classification residuals without overflowing the model update or the,1
v0.2.3,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.3,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.3,TODO : add classification binary and multiclass versions of this,1
v0.2.3,TODO : add classification binary and multiclass versions of this,1
v0.2.3,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.2,NOTE: Not implemented yet,1
v0.2.2,NOTE: We know this environment is going to use Dash.,1
v0.2.2,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.2,TODO: Remove this if threshold lines are never used.,1
v0.2.2,TODO: Clean this up after validation.,1
v0.2.2,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.2,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.2.2,NOTE: Workaround for tables not rendering,1
v0.2.2,TODO: Check if this is needed with the new tables.,1
v0.2.2,TODO: Consider reducing complexity of this function.,1
v0.2.2,NOTE: Workaround for tables not rendering,1
v0.2.2,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.2,TODO: Revisit when we support custom tabs from users.,1
v0.2.2,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.2,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.2,TODO: Harden these tests later to check content from data method.,1
v0.2.2,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.2,# TODO Can the base vis be a util?,1
v0.2.2,TODO: Make kwargs explicit.,1
v0.2.2,Todo: check if this call,1
v0.2.2,TODO: Docs for unify_data.,1
v0.2.2,TODO: Clean up code to have less duplication.,1
v0.2.2,NOTE: Workaround for older versions of pandas.,1
v0.2.2,TODO: Fix this once we know it works.,1
v0.2.2,TODO: Work with ordinal later.,1
v0.2.2,"TODO: Consider removing later, potentially dead code.",1
v0.2.2,TODO: Clean up,1
v0.2.2,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.2,"NOTE: Missing not implemented at native, always set to false.",1
v0.2.2,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.2,TODO: Add unit tests for internal EBM interfacing,1
v0.2.2,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.2,TODO PK make sure the None value here is handled by our caller,1
v0.2.2,TODO PK make sure the None value here is handled by our caller,1
v0.2.2,TODO: Needs test.,1
v0.2.2,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.2,TODO: Add alternative | get_current_model,1
v0.2.2,"TODO PK we only need to store the top n_interactions items, so use a heap",1
v0.2.2,TODO: More documentation in binning process to be explicit.,1
v0.2.2,TODO: Consider stripping this down to the bare minimum.,1
v0.2.2,TODO: Review NA as we don't support it yet.,1
v0.2.2,"TODO PK v.3 replace mains in favor of a ""boosting stage plan""",1
v0.2.2,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.2,"TODO PK sanity check all our inputs from the __init__ function, and this fit fuction",1
v0.2.2,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.2,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.2,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.2,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.2,TODO PK v.3 don't overwrite feature_names and feature_types.  Create new fields called feature_names_out and,1
v0.2.2,TODO PK v.3 shouldn't this be self._global_selector_ ??,1
v0.2.2,TODO PK we really need to use purification before here because it's not really legal to elminate,1
v0.2.2,"TODO PK rename the ""pair"" variables in this function to ""interaction"" since that's more generalized",1
v0.2.2,"TODO PK sort the interaction tuples so that they have a unique ordering, otherwise",1
v0.2.2,TODO PK move the work done inside this loop to the original parallel threads so that this part can be done in parallel,1
v0.2.2,TODO PK this algorithm in O(N^2) by the number of interactions.  Alternatively,1
v0.2.2,TODO PK we can remove the is_train input to ebm_train_test_split once we've moved the pair scoring stuff,1
v0.2.2,TODO PK this copy isn't required,1
v0.2.2,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.2,TODO PK v.3 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.2,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.2,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.2,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.2,TODO PK v.3 use underscores here like RegressorMixin._estimator_type?,1
v0.2.2,TODO PK add a test for Regression with interactions,1
v0.2.2,TODO PK add a test with a real regression dataset,1
v0.2.2,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.2,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.2,TODO: Support other languages,1
v0.2.2,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.2,TODO: MLI should handle multiclass at a future date.,1
v0.2.2,TODO: Generalize this out.,1
v0.2.2,"TODO v.3 PK Possibly rename explainer types to (blackbox, glassbox, greybox)",1
v0.2.2,NOTE: Workaround for Azure DevOps.,1
v0.2.2,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.2.2,"TODO: increase the k_cutExploreDistance, and also increase our testing length to compensate",1
v0.2.2,TODO: m_cUncuttableHighValues is redundant in that the next higher cutting range has the same value.,1
v0.2.2,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.2,- TODO: POST-HEALING,1
v0.2.2,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.2.2,TODO: This calculation doesn't take into account that we can trade our cut points with neighbours,1
v0.2.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.2,TODO : these are not guaranteed due to floating point inexactness.  We should detect this scenario,1
v0.2.2,TODO: evaluate max here instead as well,1
v0.2.2,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.2.2,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.2.2,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.2.2,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.2.2,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.2.2,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.2.2,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.2,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.2,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized cutting points such",1
v0.2.2,TODO: We've just finished materializing the cut based on the plan we developed earlier.  We'll,1
v0.2.2,There's actually two subtle issues here that we need to handle differently:,1
v0.2.2,TODO: For each cut point we've examined our neighbourhood and selected a right/left decison that we can live with,1
v0.2.2,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.2.2,- TODO: EXPLORING BOTH SIDES,1
v0.2.2,- TODO:,1
v0.2.2,TODO : eliminate this function after we've eliminated m_cUncuttableHighValues and wrap this functionality,1
v0.2.2,"the data is perfectly symmetric centered arround zero.  Something like ""-2 -1 0 1 2"" would do this.  There is",1
v0.2.2,it's probably better to just place a lot of asiprational cuts at the minimum separation and trim them,1
v0.2.2,TODO : in the future fill this priority queue with the average length within our,1
v0.2.2,TODO optimize the next few lines,1
v0.2.2,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.2.2,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.2,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.2,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.2,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.2,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for",1
v0.2.2,TODO : enable SIMD(AVX-512) to work,1
v0.2.2,TODO : move this to initialization where we execute it only once,1
v0.2.2,TODO : move this to initialization where we execute it only once,1
v0.2.2,TODO : move this to initialization where we execute it only once,1
v0.2.2,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the denominator isn't required in order to make decisions about",1
v0.2.2,TODO: handle this better,1
v0.2.2,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureGroupUpdatePerTargetClasses function,1
v0.2.2,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.2,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as",1
v0.2.2,"Actually, I think the real solution here is that",1
v0.2.2,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.2,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.2,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.2,"this is a bit inefficient in that we go through a complete regeneration of the internal state,",1
v0.2.2,"this is a stupid input.  Fix it, but give the caller a warning so they can correct their code",1
v0.2.2,"this is a stupid input.  Fix it, but give the caller a warning so they can correct their code",1
v0.2.2,TODO : optimize this function,1
v0.2.2,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.2,TODO : we can make this faster by doing the division in ComputeNodeSplittingScoreParent after we add all the numerators,1
v0.2.2,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.2,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.2,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.2,TODO : ALL OF THE BELOW!,1
v0.2.2,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.2,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler compilerCountDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.2,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the cuts, we can undo the re-ordering for cutting the tensor, which has just a few cells, so will be efficient",1
v0.2.2,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.2,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.2,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.2,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.2,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.2,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.2,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.2,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.2,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.2,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.2,our caller can give us one of these bad types of inputs:,1
v0.2.2,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.2,"times than desired, but we can live with that",1
v0.2.2,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.2,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.2,TODO : eventually eliminate this subtract variable once we've decided how to handle removing one logit,1
v0.2.2,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.2,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.2,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.2,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.2,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.2,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.2.2,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.2.2,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.2,"TODO: it would be easy for us to implement a -1 lookback where we make the first cut, find the second cut, elimnate the first cut and try",1
v0.2.2,Probably 1 cut isn't very good since with 2 cuts we can localize a region of high gain in the center somewhere,1
v0.2.2,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.2,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.2,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.2,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.2,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.2,"TODO : VERY IMPORTANT, review if this is sorting in the correct direction!!!",1
v0.2.2,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.2,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.2,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.2,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.2,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.2.2,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.2,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.2,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.2,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.2,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.2,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.2,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.2,TODO : enable SIMD(AVX-512) to work,1
v0.2.2,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.2,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.2,TODO : enable SIMD(AVX-512) to work,1
v0.2.2,"TODO : we NEVER use the denominator term in HistogramBucketVectorEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.2,TODO: handle this better,1
v0.2.2,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.2,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.2.2,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.2,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.2.2,perhaps might return that for subnormal floats.,1
v0.2.2,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.2,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.2.2,TODO: handle multiclass,1
v0.2.2,"data.  It wouldn't do us much good though if we striped just two features at a time, so we'd want to",1
v0.2.2,and I think it would be better to pay the streaming to memory cost than to fetch somewhat unpredictably,1
v0.2.2,"TODO: since we can't fit everything into registers, perhaps we'd get better performance doing a full",1
v0.2.2,"TODO: for 8 specifically, we could probably do a special case of binary search with everything in",1
v0.2.2,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.2,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.2,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.2,TODO : add test for the condition where we overflow the validation regression or classification residuals without overflowing the model update or the,1
v0.2.2,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.2,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.2,TODO : add classification binary and multiclass versions of this,1
v0.2.2,TODO : add classification binary and multiclass versions of this,1
v0.2.2,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.1,NOTE: Not implemented yet,1
v0.2.1,NOTE: We know this environment is going to use Dash.,1
v0.2.1,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.1,TODO: Remove this if threshold lines are never used.,1
v0.2.1,TODO: Clean this up after validation.,1
v0.2.1,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.1,TODO: Remove from code coverage until skope rules is updated upstream to work with latest scikit-learn.,1
v0.2.1,NOTE: Workaround for tables not rendering,1
v0.2.1,TODO: Check if this is needed with the new tables.,1
v0.2.1,TODO: Consider reducing complexity of this function.,1
v0.2.1,NOTE: Workaround for tables not rendering,1
v0.2.1,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.1,TODO: Revisit when we support custom tabs from users.,1
v0.2.1,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.1,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.1,TODO: Harden these tests later to check content from data method.,1
v0.2.1,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.1,# TODO Can the base vis be a util?,1
v0.2.1,TODO: Make kwargs explicit.,1
v0.2.1,Todo: check if this call,1
v0.2.1,TODO: Docs for unify_data.,1
v0.2.1,TODO: Clean up code to have less duplication.,1
v0.2.1,NOTE: Workaround for older versions of pandas.,1
v0.2.1,TODO: Fix this once we know it works.,1
v0.2.1,TODO: Work with ordinal later.,1
v0.2.1,"TODO: Consider removing later, potentially dead code.",1
v0.2.1,TODO: Clean up,1
v0.2.1,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.1,"NOTE: Missing not implemented at native, always set to false.",1
v0.2.1,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.1,TODO: Add unit tests for internal EBM interfacing,1
v0.2.1,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.1,TODO PK make sure the None value here is handled by our caller,1
v0.2.1,TODO PK v.2 currently we return only a single logit for binary classification,1
v0.2.1,TODO PK make sure the None value here is handled by our caller,1
v0.2.1,TODO: Needs test.,1
v0.2.1,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.1,TODO: Add alternative | get_current_model,1
v0.2.1,"TODO PK we only need to store the top n_interactions items, so use a heap",1
v0.2.1,TODO: More documentation in binning process to be explicit.,1
v0.2.1,TODO: Consider stripping this down to the bare minimum.,1
v0.2.1,TODO: Review NA as we don't support it yet.,1
v0.2.1,TODO: Clean up,1
v0.2.1,TODO PK decide if we should follow any kind of sklearn convention here with,1
v0.2.1,TODO PK do we really need all of these parameters??,1
v0.2.1,"TODO PK v.3 mains will be deprecated in the future in favor of ""boosting_stage_plan""",1
v0.2.1,TODO PK v.2 we should probably have two types of interaction terms.,1
v0.2.1,TODO PK v.2 change interactions to n_interactions which can either be a number for pairs,1
v0.2.1,TODO PK v.2 add specific_interactions list of interactions to include (n_interactions will not re-pick these).,1
v0.2.1,"TODO PK v.2 exclude -> exclude feature_groups, either mains, or pairs or whatever.  This will take precedence over specific_interactions so anything there will be excluded",1
v0.2.1,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.1,TODO PK sanity check all our inputs,1
v0.2.1,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.1,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.1,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.1,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.1,TODO PK we really need to use purification before here because it's not really legal to elminate,1
v0.2.1,"TODO PK rename the ""pair"" variables in this function to ""interaction"" since that's more generalized",1
v0.2.1,"TODO PK sort the interaction tuples so that they have a unique ordering, otherwise",1
v0.2.1,TODO PK move the work done inside this loop to the original parallel threads so that this part can be done in parallel,1
v0.2.1,TODO PK this algorithm in O(N^2) by the number of interactions.  Alternatively,1
v0.2.1,TODO PK we can remove the is_train input to ebm_train_test_split once we've moved the pair scoring stuff,1
v0.2.1,TODO PK this copy isn't required,1
v0.2.1,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.1,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.1,TODO PK v.2 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.1,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.1,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.1,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.1,TODO PK v.2 use underscores here like RegressorMixin._estimator_type?,1
v0.2.1,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.1,TODO PK add a test for Regression with interactions,1
v0.2.1,TODO PK add a test with a real regression dataset,1
v0.2.1,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.1,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.1,TODO: Support other languages,1
v0.2.1,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.1,TODO: MLI should handle multiclass at a future date.,1
v0.2.1,TODO: Generalize this out.,1
v0.2.1,NOTE: Workaround for Azure DevOps.,1
v0.2.1,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.2.1,TODO optimize the next few lines,1
v0.2.1,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.2.1,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.1,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.1,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.1,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.1,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for",1
v0.2.1,TODO : enable SIMD(AVX-512) to work,1
v0.2.1,TODO : move this to initialization where we execute it only once,1
v0.2.1,TODO : move this to initialization where we execute it only once,1
v0.2.1,TODO : move this to initialization where we execute it only once,1
v0.2.1,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the denominator isn't required in order to make decisions about",1
v0.2.1,TODO: handle this better,1
v0.2.1,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureGroupUpdatePerTargetClasses function,1
v0.2.1,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.1,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as",1
v0.2.1,"Actually, I think the real solution here is that",1
v0.2.1,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.1,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.1,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.1,TODO : optimize this function,1
v0.2.1,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.1,TODO : we can make this faster by doing the division in ComputeNodeSplittingScoreParent after we add all the numerators,1
v0.2.1,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.1,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.1,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.1,TODO : ALL OF THE BELOW!,1
v0.2.1,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.1,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler compilerCountDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.1,"TODO: sort our N-dimensional groups at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the cuts, we can undo the re-ordering for cutting the tensor, which has just a few cells, so will be efficient",1
v0.2.1,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.1,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.1,DO: I THINK THIS HAS ALREADY BEEN HANDLED IN OUR OPERATIONAL VERSION of BuildFastTotals -> sort our N-dimensional groups at program startup so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!,1
v0.2.1,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.1,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.1,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.1,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.1,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.1,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.1,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.1,our caller can give us one of these bad types of inputs:,1
v0.2.1,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.1,"times than desired, but we can live with that",1
v0.2.1,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.1,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.1,TODO : eventually eliminate this subtract variable once we've decided how to handle removing one logit,1
v0.2.1,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.1,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.1,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.1,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.1,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.1,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that sample",1
v0.2.1,"TODO: NaN target values essentially mean missing, so we should be filtering those samples out, but our caller should do that so",1
v0.2.1,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.1,"TODO: it would be easy for us to implement a -1 lookback where we make the first cut, find the second cut, elimnate the first cut and try",1
v0.2.1,Probably 1 cut isn't very good since with 2 cuts we can localize a region of high gain in the center somewhere,1
v0.2.1,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.1,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.1,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.1,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.1,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.1,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.1,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.1,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.1,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.1,TODO: another issue is that isnan and isinf don't work on some compilers with some compiler settings,1
v0.2.1,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.1,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.1,"TODO : try using a sampling method with non-repeating samples, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.1,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.1,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.1,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.1,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.1,TODO : enable SIMD(AVX-512) to work,1
v0.2.1,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.1,"TODO : because there is only one bin for a zero feature feature group, we could move these values to the stack where the",1
v0.2.1,TODO : enable SIMD(AVX-512) to work,1
v0.2.1,"TODO : we NEVER use the denominator term in HistogramBucketVectorEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.1,TODO: handle this better,1
v0.2.1,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.1,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.2.1,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.1,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.1,"TODO: review all the C++ library calls, including things like std::abs and verify that none of them throw exceptions, otherwise use the C versions that provide this guarantee",1
v0.2.1,"TODO: after we've found our splits, generate the best interpretable cut points, then move 1% backwards and forwards",1
v0.2.1,TODO: Next steps:,1
v0.2.1,7) Come back later and improve on this algorithm per the TODOs in this file,1
v0.2.1,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.1,"but who knows what's happening inside log, which would get NaN for zero and in a bad implementation",1
v0.2.1,perhaps might return that for subnormal floats.,1
v0.2.1,TODO: add some static checks either here or our caller that ensures we have enough room in the str buffer to,1
v0.2.1,"TODO: also, is the val we usually write actually a long, since we use strtol above??",1
v0.2.1,"TODO : add logs here when we find a condition we didn't think was possible, but that occurs",1
v0.2.1,"TODO : handle low == 0.  We probalby want to invert these divisions, or change them to multiplications",1
v0.2.1,- TODO: POST-HEALING,1
v0.2.1,"TODO: It's tempting to want to materialize cuts if both of it's neighbours are materialized, since our",1
v0.2.1,TODO: We're currently NOT examining our near neighbourhood for where we'd put our neighbouring cuts.  We need,1
v0.2.1,"cuttable points.  This doesn't build an exact plan, but it's probably easier (I think we should probably",1
v0.2.1,TODO: we also want to try tweaking the number of cuts on either side.  Perhaps we determined at first that,1
v0.2.1,TODO: our priority queue priority should probably somewhat incorporate how good or bad our neighbourhood options,1
v0.2.1,"TODO: IF there are no hard decisions to make near the tail ends of the windows, we might want to switch tracts",1
v0.2.1,"really bad that we'd like to avoid, and comparatively good cut points that we wnat to aim for.  This is",1
v0.2.1,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.1,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.1,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized splitting points such",1
v0.2.1,"TODO: since the movement of pSplitHighHighWindow is dependent on hitting a maximum, we should",1
v0.2.1,"TODO: since the movement of pSplitLowLowWindow is dependent on hitting a maximum, we should",1
v0.2.1,"TODO: after we set m_iVal, do we really still need to keep m_iValAspirationalFloat??",1
v0.2.1,"TODO: ok, we've just finished materializing the cut based on the plan we developed earlier.  We'll",1
v0.2.1,"size we should get the same minimum if we start from the left or right, but I might be wrong about that,",1
v0.2.1,TODO : improve this if our boundary is a size_t,1
v0.2.1,TODO : improve this if our boundary is a size_t,1
v0.2.1,"TODO: Ok, so each cut point we've examined our neighbours and selected a right/left decison that we can live with",1
v0.2.1,TODO: CONSIDER (very tentatively) incorporating how bad it would be if we were forced to choose the worse side to cut on,1
v0.2.1,TODO : HANDLE THIS,1
v0.2.1,- TODO: EXPLORING BOTH SIDES,1
v0.2.1,TODO: handle this!,1
v0.2.1,"TODO : before executing this, we can determine what the maximum numbers of splits based on the cSamplesPerBinMin",1
v0.2.1,"TODO : we construct this early on in our process, so we might want to use it when building SplittingRanges",1
v0.2.1,TODO test this,1
v0.2.1,TODO:,1
v0.2.1,TODO: limit cBinsMax to a reasonable number based on the number of samples.,1
v0.2.1,"sometimes cut points will move between SplittingRanges, so we won't know an accurate",1
v0.2.1,TODO : in the future fill this priority queue with the average length within our,1
v0.2.1,TODO : don't ignore the return value of TradeSplitSegment,1
v0.2.1,"TODO: for now be lazy and just use the low one, but eventually try and get symetry from order",1
v0.2.1,TODO: IMPLEMENT,1
v0.2.1,TODO: IMPLEMENT,1
v0.2.1,"TODO: if we pad the cutPointsLowerBoundInclusive array up to a power of 2 by putting min or max values,",1
v0.2.1,"TODO: if we want to go crazy, we could also parallelize this, which would probably use hypterthreading",1
v0.2.1,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.1,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.1,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.1,TODO : add test for the condition where we overflow the validation regression or classification residuals without overflowing the model update or the,1
v0.2.1,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.1,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.1,TODO : add classification binary and multiclass versions of this,1
v0.2.1,TODO : add classification binary and multiclass versions of this,1
v0.2.1,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.2.0,NOTE: Not implemented yet,1
v0.2.0,NOTE: We know this environment is going to use Dash.,1
v0.2.0,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.2.0,TODO: Remove this if threshold lines are never used.,1
v0.2.0,TODO: Clean this up after validation.,1
v0.2.0,TODO: Remove this completely once performance graphs are hardened.,1
v0.2.0,NOTE: Workaround for tables not rendering,1
v0.2.0,TODO: Check if this is needed with the new tables.,1
v0.2.0,TODO: Consider reducing complexity of this function.,1
v0.2.0,NOTE: Workaround for tables not rendering,1
v0.2.0,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.2.0,TODO: Revisit when we support custom tabs from users.,1
v0.2.0,TODO: Re-enable on skoperules working with latest scikit learn.,1
v0.2.0,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.2.0,TODO: Harden these tests later to check content from data method.,1
v0.2.0,TODO: Generalize specific models (currently only testing trees),1
v0.2.0,if explainer_class == PermutationImportance:  # TODO should true labels be passed in the constructor here?,1
v0.2.0,# TODO Can the base vis be a util?,1
v0.2.0,TODO: Make kwargs explicit.,1
v0.2.0,Todo: check if this call,1
v0.2.0,TODO: Docs for unify_data.,1
v0.2.0,TODO: Clean up code to have less duplication.,1
v0.2.0,NOTE: Workaround for older versions of pandas.,1
v0.2.0,TODO: Fix this once we know it works.,1
v0.2.0,TODO: Work with ordinal later.,1
v0.2.0,"TODO: Consider removing later, potentially dead code.",1
v0.2.0,TODO: Clean up,1
v0.2.0,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.2.0,"NOTE: Missing not implemented at native, always set to false.",1
v0.2.0,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.2.0,TODO: Add unit tests for internal EBM interfacing,1
v0.2.0,TODO PK do this once during construction so that we don't have to do it again,1
v0.2.0,TODO PK make sure the None value here is handled by our caller,1
v0.2.0,TODO PK v.2 currently we return only a single logit for binary classification,1
v0.2.0,TODO PK make sure the None value here is handled by our caller,1
v0.2.0,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.2.0,"TODO PK we only need to store the top n_interactions items, so use a heap",1
v0.2.0,TODO: More documentation in binning process to be explicit.,1
v0.2.0,TODO: Consider stripping this down to the bare minimum.,1
v0.2.0,TODO: Review NA as we don't support it yet.,1
v0.2.0,TODO: Clean up,1
v0.2.0,TODO PK decide if we should follow any kind of sklearn convention here with,1
v0.2.0,TODO PK do we really need all of these parameters??,1
v0.2.0,"TODO PK v.3 mains will be deprecated in the future in favor of ""boosting_stage_plan""",1
v0.2.0,TODO PK v.2 we should probably have two types of interaction terms.,1
v0.2.0,TODO PK v.2 change interactions to n_interactions which can either be a number for pairs,1
v0.2.0,TODO PK v.2 add specific_interactions list of interactions to include (n_interactions will not re-pick these).,1
v0.2.0,"TODO PK v.2 exclude -> exclude feature_combinations, either mains, or pairs or whatever.  This will take precedence over specific_interactions so anything there will be excluded",1
v0.2.0,"TODO PK try setting this (not here, but in our caller) to 6 and run tests to verify the best value.",1
v0.2.0,TODO PK sanity check all our inputs,1
v0.2.0,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.2.0,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.2.0,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.2.0,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.2.0,TODO PK we really need to use purification before here because it's not really legal to elminate,1
v0.2.0,"TODO PK rename the ""pair"" variables in this function to ""interaction"" since that's more generalized",1
v0.2.0,"TODO PK sort the interaction tuples so that they have a unique ordering, otherwise",1
v0.2.0,TODO PK move the work done inside this loop to the original parallel threads so that this part can be done in parallel,1
v0.2.0,TODO PK this algorithm in O(N^2) by the number of interactions.  Alternatively,1
v0.2.0,TODO PK we can remove the is_train input to ebm_train_test_split once we've moved the pair scoring stuff,1
v0.2.0,TODO PK this copy isn't required,1
v0.2.0,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.0,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.0,TODO PK v.2 use underscores here like ClassifierMixin._estimator_type?,1
v0.2.0,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.2.0,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.0,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.0,TODO PK v.2 use underscores here like RegressorMixin._estimator_type?,1
v0.2.0,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.2.0,TODO PK add a test for Regression with interactions,1
v0.2.0,TODO PK add a test with a real regression dataset,1
v0.2.0,TODO PK add a test with more than 1 multiclass interaction,1
v0.2.0,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.0,TODO: Support other languages,1
v0.2.0,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.2.0,TODO: MLI should handle multiclass at a future date.,1
v0.2.0,TODO: Generalize this out.,1
v0.2.0,NOTE: Workaround for Azure DevOps.,1
v0.2.0,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.2.0,TODO optimize the next few lines,1
v0.2.0,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.2.0,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.2.0,"TODO : try using a sampling method with non-repeating instances, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.0,"TODO : try using a sampling method with non-repeating instances, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.0,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.2.0,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for",1
v0.2.0,TODO : enable SIMD(AVX-512) to work,1
v0.2.0,TODO : move this to initialization where we execute it only once,1
v0.2.0,TODO : move this to initialization where we execute it only once,1
v0.2.0,TODO : move this to initialization where we execute it only once,1
v0.2.0,"TODO: for higher dimensional spaces, we need to add/subtract individual cells alot and the denominator isn't required in order to make decisions about",1
v0.2.0,TODO: handle this better,1
v0.2.0,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.2.0,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.2.0,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as",1
v0.2.0,"Actually, I think the real solution here is that",1
v0.2.0,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.2.0,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.0,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.2.0,TODO : optimize this function,1
v0.2.0,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.0,TODO : we can make this faster by doing the division in ComputeNodeSplittingScoreParent after we add all the numerators,1
v0.2.0,TODO: this gain value is untested.  We should build a new test that compares the single feature gains to the multi-dimensional gains by,1
v0.2.0,TODO: Implement a far more efficient boosting algorithm for higher dimensional interactions.  The algorithm works as follows:,1
v0.2.0,"calculation anyways, so it's more memory efficient than either of the other two algorithms",1
v0.2.0,TODO : ALL OF THE BELOW!,1
v0.2.0,"TODO: build a pair and triple specific version of this function.  For pairs we can get ride of the pPrevious and just use the actual cell at (-1,-1) from our current cell, and we can use two loops with everything in memory [look at code above from before we incoporated the previous totals].  Triples would also benefit from pulling things out since we have low iterations of the inner loop and we can access indicies directly without additional add/subtract/bit operations.  Beyond triples, the combinatorial choices start to explode, so we should probably use this general N-dimensional code.",1
v0.2.0,"TODO: after we build pair and triple specific versions of this function, we don't need to have a compiler compilerCountDimensions, since the compiler won't really be able to simpify the loops that are exploding in dimensionality",1
v0.2.0,"TODO: sort our N-dimensional combinations at initialization so that the longest dimension is first!  That way we can more efficiently walk through contiguous memory better in this function!  After we determine the cuts, we can undo the re-ordering for cutting the tensor, which has just a few cells, so will be efficient",1
v0.2.0,TODO : we don't need either the first or the wrap values since they are the next ones in the list.. we may need to populate one item past,1
v0.2.0,"// TODO: If we have a compiler cVectorLength, we could put the pPrevious object into our stack since it would have a defined size.  We could then eliminate having to access it through a pointer and we'd just access through the stack pointer",1
v0.2.0,// TODO: can we put HistogramBucket object onto the stack in other places too?,1
v0.2.0,"// TODO: We're currently reducing the work by a factor of 2 by keeping the pPrevious values.  I think I could reduce the work by annohter factor of 2 if I maintained a 1 dimensional array of previous values for the 2nd dimension.  I think I could reduce by annohter factor of 2 by maintaininng a two dimensional space of previous values, etc..  At the end I think I can remove the combinatorial treatment by adding about the same order of memory as our existing totals space, which is a great tradeoff because then we can figure out a cell by looping N times for N dimensions instead of 2^N!",1
v0.2.0,"//       I think instead of storing the totals in the N^D space, I'll end up storing the previous values for the 1st dimension, or maybe I need to keep both.  Or maybe I can eliminate a huge amount of memory in the last dimension by doing a tiny bit of extra work.  I don't know yet.",1
v0.2.0,"// TODO: before doing the above, I think I want to take what I have and extract a 2-dimensional and 3-dimensional specializations since these don't need the extra complexity.  Especially for 2-D where I don't even need to keep the previous value",1
v0.2.0,"// be a bad choice because we can exit this loop early when the permutation number is low, and on average that eliminates more than half of the loop iterations",1
v0.2.0,// TODO: we are putting storage that would exist in our array from the innermost loop into registers (multipliedIndexCur0 & multipleTotal0).  We can probably do this in many other places as well that use this pattern of indexing via an array,1
v0.2.0,our caller can give us one of these bad types of inputs:,1
v0.2.0,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.2.0,"times than desired, but we can live with that",1
v0.2.0,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.0,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.0,TODO : eventually eliminate this subtract variable once we've decided how to handle removing one logit,1
v0.2.0,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.0,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.0,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.0,"TODO : review this function to see if iZeroResidual was set to a valid index, does that affect the number of items in pPredictorScores (I assume so),",1
v0.2.0,TODO : !!! re-examine the idea of zeroing one of the residuals with iZeroResidual after we have the ability to test large numbers of datasets,1
v0.2.0,"TODO : our caller should handle NaN *pTargetData values, which means that the target is missing, which means we should delete that instance",1
v0.2.0,"TODO: NaN target values essentially mean missing, so we should be filtering those instances out, but our caller should do that so",1
v0.2.0,"TODO: in theory, a malicious caller could overflow our stack if they pass us data that will grow a sufficiently deep tree.  Consider changing this",1
v0.2.0,"TODO: it would be easy for us to implement a -1 lookback where we make the first cut, find the second cut, elimnate the first cut and try",1
v0.2.0,Probably 1 cut isn't very good since with 2 cuts we can localize a region of high gain in the center somewhere,1
v0.2.0,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.0,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.0,"TODO : implement the randomized splitting described for interaction effect, which can be done the same although we might want to",1
v0.2.0,TODO: usually we've done this calculation for the parent already.  Why not keep the result arround to avoid extra work?,1
v0.2.0,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.0,TODO : we can eliminate this check as long as we ensure that the ThreadByteBuffer2 is always initialized to be equal to the size of three,1
v0.2.0,TODO : we don't need to get the right and left pointer from the root.. we know where they will be,1
v0.2.0,TODO: someday see if we can replace this with an in-class priority queue that stores it's info inside,1
v0.2.0,"TODO: these can be done with bitwise operators, which would be good for SIMD.  Check to see what assembly this turns into.",1
v0.2.0,TODO : consider adding templated cVectorLength and cDimensions to this function.  At worst someone can pass in 0 and use the loops,1
v0.2.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.0,"TODO: the existing code below works, but handle this differently (we can do it more efficiently)",1
v0.2.0,"TODO : try using a sampling method with non-repeating instances, and put the count into a bit.  Then unwind that loop either at the byte level",1
v0.2.0,"TODO : we can elminate the inner vector loop for regression at least, and also if we add a templated bool for binary class.  Propegate this change",1
v0.2.0,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the",1
v0.2.0,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.0,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.2.0,TODO : enable SIMD(AVX-512) to work,1
v0.2.0,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.2.0,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the",1
v0.2.0,TODO : enable SIMD(AVX-512) to work,1
v0.2.0,"TODO : we NEVER use the denominator term in HistogramBucketVectorEntry when calculating interaction scores, but we're spending time calculating",1
v0.2.0,TODO: handle this better,1
v0.2.0,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.2.0,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.2.0,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.2.0,"TODO: use noexcept throughout our codebase (exception extern ""C"" functions) !  The compiler can optimize functions better if it knows there are no exceptions",1
v0.2.0,"TODO: using our doubly linked list, we can move them from one place to",1
v0.2.0,TODO : check how efficient this is.  Is there a faster way to to this,1
v0.2.0,- TODO: POST-HEALING,1
v0.2.0,TODO: here we should try to even out our final result in case there are large scale differences in size,1
v0.2.0,TODO: one option would be to try pushing inwards from the outer regions.  Take a window size that we think,1
v0.2.0,TODO: we might try making a sliding window of 5 cuts.  Delete the 5 cuts in between two boundaries and try,1
v0.2.0,TODO TODO TODO:,1
v0.2.0,TODO TODO TODO TODO TODO TODO TODO TODO,1
v0.2.0,"but we set the priority in a later function, so we need to somehow signal that we have no cuts, and then set the priority afterwards ? ?",1
v0.2.0,"change.  In the future though we might someday move counts of ranges arround, and perhaps a split point will",1
v0.2.0,TODO: we could take an alternate approach here and look at N lower and N higher points based on our ideal,1
v0.2.0,TODO: another idea would be to slide a window through all potential cut points and measure how well we can,1
v0.2.0,"TODO: no matter what, I think we'll need to have a way to re-balance the cut points from one open region to",1
v0.2.0,TODO: this simple metric just determins which side leads to a better average length.  There are other,1
v0.2.0,"TODO: for now this simple metric to choose which direction we go should suffice, but in the future",1
v0.2.0,TODO: we should also examine how splits work on both sides if we add or subtract some ranges.  We can,1
v0.2.0,"TODO: for now this simple metric to choose which direction we go should suffice, but in the future",1
v0.2.0,"TODO: someday, for performance, it might make sense to use a non-allocating tree, like:",1
v0.2.0,"TODO: try to use integer math for indexes instead of floating point numbers which introduce inexactness, and they break down above 2^52 where",1
v0.2.0,"254, but that is clearly bad computationally, since then our algorithm would be O(N^2 * log(N)).  For low",1
v0.2.0,"percentage, we shouldn't get too far out of whack.  Also, we'll quickly put down actualized splitting points such",1
v0.2.0,TODO:,1
v0.2.0,"TODO: since the movement of pSplitHighHighWindow is dependent on hitting a maximum, we should",1
v0.2.0,"TODO: since the movement of pSplitLowLowWindow is dependent on hitting a maximum, we should",1
v0.2.0,"TODO: after we set m_iVal, do we really still need to keep m_iValAspirationalFloat??",1
v0.2.0,TODO : improve this if our boundary is a size_t,1
v0.2.0,TODO : improve this if our boundary is a size_t,1
v0.2.0,TODO : HANDLE THIS,1
v0.2.0,TODO : we have an optional phase here were we try and reduce the tension between neighbours and improve,1
v0.2.0,- TODO: EXPLORING BOTH SIDES,1
v0.2.0,TODO: handle this!,1
v0.2.0,TODO test this,1
v0.2.0,TODO:,1
v0.2.0,TODO: limit cMaximumBins to a reasonable number based on the number of instances.,1
v0.2.0,"sometimes cut points will move between SplittingRanges, so we won't know an accurate",1
v0.2.0,TODO: review if we still require these extra split point endpoints or not,1
v0.2.0,TODO : don't ignore the return value of TradeSplitSegment,1
v0.2.0,TODO: IMPLEMENT,1
v0.2.0,TODO: IMPLEMENT,1
v0.2.0,TODO : we can make this faster by doing the division in ComputeNodeSplittingScore after we add all the numerators,1
v0.2.0,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.2.0,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.2.0,TODO : add test for the condition where we overflow the validation regression or classification residuals without overflowing the model update or the,1
v0.2.0,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.2.0,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.2.0,TODO : add classification binary and multiclass versions of this,1
v0.2.0,TODO : add classification binary and multiclass versions of this,1
v0.2.0,TODO: decide what to do with this test,1
v0.2.0,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.1.22,NOTE: Not implemented yet,1
v0.1.22,NOTE: We know this environment is going to use Dash.,1
v0.1.22,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.1.22,TODO: Remove this if threshold lines are never used.,1
v0.1.22,TODO: Clean this up after validation.,1
v0.1.22,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.22,NOTE: Workaround for tables not rendering,1
v0.1.22,TODO: Check if this is needed with the new tables.,1
v0.1.22,TODO: Consider reducing complexity of this function.,1
v0.1.22,NOTE: Workaround for tables not rendering,1
v0.1.22,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.22,TODO: Revisit when we support custom tabs from users.,1
v0.1.22,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.22,TODO: Harden these tests later to check content from data method.,1
v0.1.22,TODO: Generalize specific models (currently only testing trees),1
v0.1.22,TODO: Make kwargs explicit.,1
v0.1.22,Todo: check if this call,1
v0.1.22,TODO: Docs for unify_data.,1
v0.1.22,TODO: Clean up code to have less duplication.,1
v0.1.22,NOTE: Workaround for older versions of pandas.,1
v0.1.22,TODO: Fix this once we know it works.,1
v0.1.22,TODO: Work with ordinal later.,1
v0.1.22,"TODO: Consider removing later, potentially dead code.",1
v0.1.22,TODO: Clean up,1
v0.1.22,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.1.22,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.22,"TODO PK v.2 remove n_attributes (this is the only place it is used, but it's public)",1
v0.1.22,"TODO PK v.2 rename all instances of ""attributes"" -> ""features""",1
v0.1.22,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.1.22,TODO: Add unit tests for internal EBM interfacing,1
v0.1.22,TODO PK do this once during construction so that we don't have to do it again,1
v0.1.22,TODO PK make sure the None value here is handled by our caller,1
v0.1.22,TODO PK v.2 currently we return only a single logit for binary classification,1
v0.1.22,TODO PK make sure the None value here is handled by our caller,1
v0.1.22,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.1.22,"TODO PK we only need to store the top n_interactions items, so use a heap",1
v0.1.22,TODO: More documentation in binning process to be explicit.,1
v0.1.22,TODO: Consider stripping this down to the bare minimum.,1
v0.1.22,TODO: Review NA as we don't support it yet.,1
v0.1.22,TODO: Clean up,1
v0.1.22,TODO PK decide if we should follow any kind of sklearn convention here with,1
v0.1.22,TODO PK do we really need all of these parameters??,1
v0.1.22,"TODO PK v.2 Should we be exposing data in this class, or use helper functions to return the values?",1
v0.1.22,"TODO PK v.2 per above, we've decided to pass information related to the dataset in via __init__, but",1
v0.1.22,TODO PK v.2 feature_names is currently by feature_combination.  Perahps we need to make one per,1
v0.1.22,TODO PK v.2 look at how sklearn has thought about feature types -> https://github.com/scikit-learn/scikit-learn/pull/3346,1
v0.1.22,TODO PK v.2 feature_types is currently by feature_combination.  Perahps we need to make one per,1
v0.1.22,"TODO PK v.2 either add a bin_cuts parameter here, or add a preprocessor/transformer class input parameter here so that the user",1
v0.1.22,TODO PK v.2 can we eliminate the schema parameter given that we also take feature_names and feature_types definitions in this interface?,1
v0.1.22,TODO PK v.2 holdout_size doesn't seem to do anything.  Eliminate.  holdout_split is used,1
v0.1.22,TODO PK v.2 change main_attr -> main_features (also look for anything with attr in it),1
v0.1.22,TODO PK v.2 we should probably have two types of interaction terms.,1
v0.1.22,TODO PK v.2 change interactions to n_interactions which can either be a number for pairs,1
v0.1.22,TODO PK v.2 add specific_interactions list of interactions to include (n_interactions will not re-pick these).,1
v0.1.22,"TODO PK v.2 exclude -> exclude feature_combinations, either mains, or pairs or whatever.  This will take precedence over specific_interactions so anything there will be excluded",1
v0.1.22,"TODO PK v.2 use validation_size instead of holdout_split, since sklearn uses ""test_size""",1
v0.1.22,TODO PK v.2 eliminate early_stopping_tolerance (use zero for this!),1
v0.1.22,TODO PK v.2 feature_step_n_inner_bags -> n_inner_bags,1
v0.1.22,"TODO PK v.2 eliminate training_step_episodes (if not, rename to boosting_step_episodes)",1
v0.1.22,TODO PK sanity check all our inputs,1
v0.1.22,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.1.22,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.1.22,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.1.22,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.1.22,TODO PK v.2 get rid of self.schema_ here since that's already included in self.preprocessor_.schema_,1
v0.1.22,TODO PK v.2 eliminate self.n_classes_ for our public interface BaseEBM,1
v0.1.22,TODO PK v.2 consider exposing our models as pandas.NDFrame,1
v0.1.22,TODO PK v.2 attribute_set_models_ -> model_,1
v0.1.22,TODO PK v.2 if we end up choosing to expand/contract by removing,1
v0.1.22,TODO PK v.2 _attrib_set_model_means_ -> _model_means_,1
v0.1.22,TODO PK we really need to use purification before here because it's not really legal to elminate,1
v0.1.22,"TODO PK rename the ""pair"" variables in this function to ""interaction"" since that's more generalized",1
v0.1.22,"TODO PK sort the interaction tuples so that they have a unique ordering, otherwise",1
v0.1.22,TODO PK move the work done inside this loop to the original parallel threads so that this part can be done in parallel,1
v0.1.22,TODO PK this algorithm in O(N^2) by the number of interactions.  Alternatively,1
v0.1.22,TODO PK we can remove the is_train input to ebm_train_test_split once we've moved the pair scoring stuff,1
v0.1.22,TODO PK this copy isn't required,1
v0.1.22,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.22,TODO PK v.2 these decision_scores are unexpanded.  We need to expand them,1
v0.1.22,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.22,TODO PK v.2 use underscores here like ClassifierMixin._estimator_type?,1
v0.1.22,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.22,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.22,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.22,TODO PK v.2 use underscores here like RegressorMixin._estimator_type?,1
v0.1.22,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.22,TODO PK add a test for Regression with interactions,1
v0.1.22,TODO PK add a test with a real regression dataset,1
v0.1.22,TODO PK add a test with more than 1 multiclass interaction,1
v0.1.22,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.22,TODO: Support other languages,1
v0.1.22,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.22,TODO: Generalize this out.,1
v0.1.22,NOTE: Workaround for Azure DevOps.,1
v0.1.22,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.1.22,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.1.22,TODO : add test for the condition where we overflow the validation regression or classification residuals without overflowing the model update or the,1
v0.1.22,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.1.22,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.1.22,TODO : add classification binary and multiclass versions of this,1
v0.1.22,TODO : add classification binary and multiclass versions of this,1
v0.1.22,TODO: decide what to do with this test,1
v0.1.22,TODO : check if it's surprising that our interaction score doubles when we change a binary classification with 1 logit to a binary,1
v0.1.22,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.22,TODO optimize the next few lines,1
v0.1.22,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.22,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.1.22,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.22,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.22,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.1.22,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as",1
v0.1.22,"Actually, I think the real solution here is that",1
v0.1.22,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.1.22,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.22,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.1.22,our caller can give us one of these bad types of inputs:,1
v0.1.22,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.1.22,"times than desired, but we can live with that",1
v0.1.22,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.22,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.22,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.22,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.1.22,TODO: Is this being used?,1
v0.1.22,TODO:,1
v0.1.22,TODO: IMPLEMENT,1
v0.1.22,TODO: IMPLEMENT,1
v0.1.22,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.1.21,NOTE: Not implemented yet,1
v0.1.21,NOTE: We know this environment is going to use Dash.,1
v0.1.21,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.1.21,TODO: Remove this if threshold lines are never used.,1
v0.1.21,TODO: Clean this up after validation.,1
v0.1.21,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.21,NOTE: Workaround for tables not rendering,1
v0.1.21,TODO: Check if this is needed with the new tables.,1
v0.1.21,TODO: Consider reducing complexity of this function.,1
v0.1.21,NOTE: Workaround for tables not rendering,1
v0.1.21,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.21,TODO: Revisit when we support custom tabs from users.,1
v0.1.21,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.21,TODO: Harden these tests later to check content from data method.,1
v0.1.21,TODO: Generalize specific models (currently only testing trees),1
v0.1.21,TODO: Make kwargs explicit.,1
v0.1.21,TODO: State criteria in docs.,1
v0.1.21,Todo: check if this call,1
v0.1.21,TODO: Docs for unify_data.,1
v0.1.21,TODO: Clean up code to have less duplication.,1
v0.1.21,NOTE: Workaround for older versions of pandas.,1
v0.1.21,TODO: Fix this once we know it works.,1
v0.1.21,TODO: Work with ordinal later.,1
v0.1.21,"TODO: Consider removing later, potentially dead code.",1
v0.1.21,TODO: Clean up,1
v0.1.21,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.1.21,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.21,"TODO PK v.2 remove n_attributes (this is the only place it is used, but it's public)",1
v0.1.21,"TODO PK v.2 rename all instances of ""attributes"" -> ""features""",1
v0.1.21,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.1.21,TODO: Add unit tests for internal EBM interfacing,1
v0.1.21,TODO PK do this once during construction so that we don't have to do it again,1
v0.1.21,TODO PK make sure the None value here is handled by our caller,1
v0.1.21,TODO PK v.2 currently we return only a single logit for binary classification,1
v0.1.21,TODO PK make sure the None value here is handled by our caller,1
v0.1.21,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.1.21,"TODO PK we only need to store the top n_interactions items, so use a heap",1
v0.1.21,TODO: Fix for multiclass classification,1
v0.1.21,TODO: More documentation in binning process to be explicit.,1
v0.1.21,TODO: Consider stripping this down to the bare minimum.,1
v0.1.21,TODO: Review NA as we don't support it yet.,1
v0.1.21,TODO: Clean up,1
v0.1.21,TODO PK decide if we should follow any kind of sklearn convention here with,1
v0.1.21,TODO PK do we really need all of these parameters??,1
v0.1.21,"TODO PK v.2 Should we be exposing data in this class, or use helper functions to return the values?",1
v0.1.21,"TODO PK v.2 per above, we've decided to pass information related to the dataset in via __init__, but",1
v0.1.21,TODO PK v.2 feature_names is currently by feature_combination.  Perahps we need to make one per,1
v0.1.21,TODO PK v.2 look at how sklearn has thought about feature types -> https://github.com/scikit-learn/scikit-learn/pull/3346,1
v0.1.21,TODO PK v.2 feature_types is currently by feature_combination.  Perahps we need to make one per,1
v0.1.21,"TODO PK v.2 either add a bin_cuts parameter here, or add a preprocessor/transformer class input parameter here so that the user",1
v0.1.21,TODO PK v.2 can we eliminate the schema parameter given that we also take feature_names and feature_types definitions in this interface?,1
v0.1.21,TODO PK v.2 holdout_size doesn't seem to do anything.  Eliminate.  holdout_split is used,1
v0.1.21,TODO PK v.2 change main_attr -> main_features (also look for anything with attr in it),1
v0.1.21,TODO PK v.2 we should probably have two types of interaction terms.,1
v0.1.21,TODO PK v.2 change interactions to n_interactions which can either be a number for pairs,1
v0.1.21,TODO PK v.2 add specific_interactions list of interactions to include (n_interactions will not re-pick these).,1
v0.1.21,"TODO PK v.2 exclude -> exclude feature_combinations, either mains, or pairs or whatever.  This will take precedence over specific_interactions so anything there will be excluded",1
v0.1.21,"TODO PK v.2 use validation_size instead of holdout_split, since sklearn uses ""test_size""",1
v0.1.21,TODO PK v.2 eliminate early_stopping_tolerance (use zero for this!),1
v0.1.21,TODO PK v.2 feature_step_n_inner_bags -> n_inner_bags,1
v0.1.21,"TODO PK v.2 eliminate training_step_episodes (if not, rename to boosting_step_episodes)",1
v0.1.21,TODO PK sanity check all our inputs,1
v0.1.21,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.1.21,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.1.21,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.1.21,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.1.21,TODO PK v.2 get rid of self.schema_ here since that's already included in self.preprocessor_.schema_,1
v0.1.21,TODO PK v.2 eliminate self.n_classes_ for our public interface BaseEBM,1
v0.1.21,TODO PK v.2 consider exposing our models as pandas.NDFrame,1
v0.1.21,TODO PK v.2 attribute_set_models_ -> model_,1
v0.1.21,TODO PK v.2 if we end up choosing to expand/contract by removing,1
v0.1.21,TODO PK v.2 _attrib_set_model_means_ -> _model_means_,1
v0.1.21,TODO: Clean this up before release.,1
v0.1.21,TODO PK we really need to use purification before here because it's not really legal to elminate,1
v0.1.21,"TODO PK rename the ""pair"" variables in this function to ""interaction"" since that's more generalized",1
v0.1.21,"TODO PK sort the interaction tuples so that they have a unique ordering, otherwise",1
v0.1.21,TODO PK move the work done inside this loop to the original parallel threads so that this part can be done in parallel,1
v0.1.21,TODO PK this algorithm in O(N^2) by the number of interactions.  Alternatively,1
v0.1.21,TODO PK we can remove the is_train input to ebm_train_test_split once we've moved the pair scoring stuff,1
v0.1.21,TODO PK this copy isn't required,1
v0.1.21,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.21,TODO PK v.2 these decision_scores are unexpanded.  We need to expand them,1
v0.1.21,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.21,TODO PK v.2 use underscores here like ClassifierMixin._estimator_type?,1
v0.1.21,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.21,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.21,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.21,TODO PK v.2 use underscores here like RegressorMixin._estimator_type?,1
v0.1.21,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.21,TODO PK add a test for Regression with interactions,1
v0.1.21,TODO PK add a test with a real regression dataset,1
v0.1.21,TODO PK add a test with more than 1 multiclass interaction,1
v0.1.21,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.21,TODO: Support other languages,1
v0.1.21,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.21,TODO: Generalize this out.,1
v0.1.21,NOTE: Workaround for Azure DevOps.,1
v0.1.21,TODO : add test for the condition where we overflow the small model update to NaN or +-infinity for regression by using exteme regression values and in,1
v0.1.21,TODO : add test for the condition where we overflow the result of adding the small model update to the existing model NaN or +-infinity for regression,1
v0.1.21,TODO : add test for the condition where we overflow the validation regression or classification residuals without overflowing the model update or the,1
v0.1.21,"TODO: write a test to compare gain from single vs multi-dimensional splitting (they use the same underlying function, so if we make a pair where one",1
v0.1.21,TODO: write some NaN and +infinity tests to check propagation at various points,1
v0.1.21,TODO : add classification binary and multiclass versions of this,1
v0.1.21,TODO : add classification binary and multiclass versions of this,1
v0.1.21,TODO: decide what to do with this test,1
v0.1.21,TODO : check if it's surprising that our interaction score doubles when we change a binary classification with 1 logit to a binary,1
v0.1.21,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.21,TODO optimize the next few lines,1
v0.1.21,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.21,TODO : someday add equal gain multidimensional randomized picking.  It's rather hard though with the existing sweep functions for,1
v0.1.21,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.21,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.21,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the",1
v0.1.21,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as",1
v0.1.21,"Actually, I think the real solution here is that",1
v0.1.21,"// TODO : for classification, is our learning rate essentially being inflated as",1
v0.1.21,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.21,"TODO : change this so that our caller allocates the memory that contains the update, but this is complicated in various ways",1
v0.1.21,our caller can give us one of these bad types of inputs:,1
v0.1.21,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we",1
v0.1.21,"times than desired, but we can live with that",1
v0.1.21,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.21,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.21,"count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.21,unicode function someday and that new function might be in characters instead of bytes.  For us #bytes == #chars.  If a unicode specific version,1
v0.1.21,TODO: Is this being used?,1
v0.1.21,TODO:,1
v0.1.21,TODO: IMPLEMENT,1
v0.1.21,TODO: IMPLEMENT,1
v0.1.21,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which",1
v0.1.20,NOTE: Not implemented yet,1
v0.1.20,NOTE: We know this environment is going to use Dash.,1
v0.1.20,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.1.20,TODO: Remove this if threshold lines are never used.,1
v0.1.20,TODO: Clean this up after validation.,1
v0.1.20,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.20,NOTE: Workaround for tables not rendering,1
v0.1.20,TODO: Check if this is needed with the new tables.,1
v0.1.20,TODO: Consider reducing complexity of this function.,1
v0.1.20,NOTE: Workaround for tables not rendering,1
v0.1.20,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.20,TODO: Revisit when we support custom tabs from users.,1
v0.1.20,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.20,TODO: Harden these tests later to check content from data method.,1
v0.1.20,TODO: Generalize specific models (currently only testing trees),1
v0.1.20,TODO: Make kwargs explicit.,1
v0.1.20,TODO: State criteria in docs.,1
v0.1.20,Todo: check if this call,1
v0.1.20,TODO: Docs for unify_data.,1
v0.1.20,TODO: Clean up code to have less duplication.,1
v0.1.20,NOTE: Workaround for older versions of pandas.,1
v0.1.20,TODO: Fix this once we know it works.,1
v0.1.20,TODO: Work with ordinal later.,1
v0.1.20,"TODO: Consider removing later, potentially dead code.",1
v0.1.20,TODO: Clean up,1
v0.1.20,TODO PK Implement the following for memory efficiency and speed of initialization:,1
v0.1.20,TODO PK doing a fortran re-ordering here (and an extra copy) isn't the most efficient way,1
v0.1.20,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.20,"TODO PK v.2 remove n_attributes (this is the only place it is used, but it's public)",1
v0.1.20,"TODO PK v.2 rename all instances of ""attributes"" -> ""features""",1
v0.1.20,"TODO PK we should consider changing the feature type to the same "" x "" separator",1
v0.1.20,TODO: Add unit tests for internal EBM interfacing,1
v0.1.20,TODO PK do this once during construction so that we don't have to do it again,1
v0.1.20,TODO PK make sure the None value here is handled by our caller,1
v0.1.20,TODO PK v.2 currently we return only a single logit for binary classification,1
v0.1.20,TODO PK make sure the None value here is handled by our caller,1
v0.1.20,TODO PK this early_stopping_tolerance is a little inconsistent,1
v0.1.20,"TODO PK we only need to store the top n_interactions items, so use a heap",1
v0.1.20,TODO: Fix for multiclass classification,1
v0.1.20,TODO: More documentation in binning process to be explicit.,1
v0.1.20,TODO: Consider stripping this down to the bare minimum.,1
v0.1.20,TODO: Review NA as we don't support it yet.,1
v0.1.20,TODO: Clean up,1
v0.1.20,TODO PK decide if we should follow any kind of sklearn convention here with,1
v0.1.20,TODO PK do we really need all of these parameters??,1
v0.1.20,"TODO PK v.2 Should we be exposing data in this class, or use helper functions to return the values?",1
v0.1.20,"TODO PK v.2 per above, we've decided to pass information related to the dataset in via __init__, but",1
v0.1.20,TODO PK v.2 feature_names is currently by feature_combination.  Perahps we need to make one per,1
v0.1.20,TODO PK v.2 look at how sklearn has thought about feature types -> https://github.com/scikit-learn/scikit-learn/pull/3346,1
v0.1.20,TODO PK v.2 feature_types is currently by feature_combination.  Perahps we need to make one per,1
v0.1.20,"TODO PK v.2 either add a bin_cuts parameter here, or add a preprocessor/transformer class input parameter here so that the user",1
v0.1.20,TODO PK v.2 can we eliminate the schema parameter given that we also take feature_names and feature_types definitions in this interface?,1
v0.1.20,TODO PK v.2 holdout_size doesn't seem to do anything.  Eliminate.  holdout_split is used,1
v0.1.20,TODO PK v.2 change main_attr -> main_features (also look for anything with attr in it),1
v0.1.20,TODO PK v.2 we should probably have two types of interaction terms.,1
v0.1.20,"both at the same time, and there isn't a good way to separate the two concepts",1
v0.1.20,TODO PK v.2 change interactions to n_interactions which can either be a number for pairs,1
v0.1.20,TODO PK v.2 add specific_interactions list of interactions to include (n_interactions will not re-pick these).,1
v0.1.20,"TODO PK v.2 exclude -> exclude feature_combinations, either mains, or pairs or whatever.  This will take precedence over specific_interactions so anything there will be excluded",1
v0.1.20,"TODO PK v.2 use test_size instead of holdout_split, since sklearn does",1
v0.1.20,TODO PK v.2 eliminate early_stopping_tolerance (use zero for this!),1
v0.1.20,TODO PK v.2 feature_step_n_inner_bags -> n_inner_bags,1
v0.1.20,"TODO PK v.2 eliminate training_step_episodes (if not, rename to boosting_step_episodes)",1
v0.1.20,TODO PK sanity check all our inputs,1
v0.1.20,TODO PK we shouldn't expose our internal state until we are 100% sure that we succeeded,1
v0.1.20,TODO PK we should do some basic checks here that X and y have the same dimensions and that,1
v0.1.20,"TODO PK handle calls where X.dim == 1.  This could occur if there was only 1 feature, or if",1
v0.1.20,TODO PK write an efficient striping converter for X that replaces unify_data for EBMs,1
v0.1.20,TODO PK v.2 get rid of self.schema_ here since that's already included in self.preprocessor_.schema_,1
v0.1.20,TODO PK v.2 eliminate self.n_classes_ for our public interface BaseEBM,1
v0.1.20,TODO PK v.2 consider exposing our models as pandas.NDFrame,1
v0.1.20,TODO PK v.2 attribute_set_models_ -> model_,1
v0.1.20,TODO PK v.2 if we end up choosing to expand/contract by removing,1
v0.1.20,TODO PK v.2 _attrib_set_model_means_ -> _model_means_,1
v0.1.20,TODO: Clean this up before release.,1
v0.1.20,TODO PK we really need to use purification before here because it's not really legal to elminate,1
v0.1.20,"TODO PK rename the ""pair"" variables in this function to ""interaction"" since that's more generalized",1
v0.1.20,"TODO PK sort the interaction tuples so that they have a unique ordering, otherwise",1
v0.1.20,TODO PK move the work done inside this loop to the original parallel threads so that this part can be done in parallel,1
v0.1.20,TODO PK this algorithm in O(N^2) by the number of interactions.  Alternatively,1
v0.1.20,TODO PK we can remove the is_train input to ebm_train_test_split once we've moved the pair scoring stuff,1
v0.1.20,TODO PK this copy isn't required,1
v0.1.20,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.20,TODO PK v.2 these decision_scores are unexpanded.  We need to expand them,1
v0.1.20,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.20,TODO PK v.2 use underscores here like ClassifierMixin._estimator_type?,1
v0.1.20,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.20,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.20,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.20,TODO PK v.2 use underscores here like RegressorMixin._estimator_type?,1
v0.1.20,TODO PK add a test to see if we handle X.ndim == 1 (or should we throw ValueError),1
v0.1.20,TODO PK add a test for Regression with interactions,1
v0.1.20,TODO PK add a test with a real regression dataset,1
v0.1.20,TODO PK add a test with more than 1 multiclass interaction,1
v0.1.20,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.20,TODO: Support other languages,1
v0.1.20,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.20,TODO: Generalize this out.,1
v0.1.20,NOTE: Workaround for Azure DevOps.,1
v0.1.20,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.20,TODO optimize the next few lines,1
v0.1.20,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.20,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.20,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.20,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.20,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.20,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.20,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.20,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.20,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.20,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.20,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.20,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.20,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.20,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.20,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.20,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.20,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.20,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.20,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.20,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.20,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.20,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmBoostingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmBoostingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.20,"// TODO : for classification, is our learning rate essentially being inflated as pEbmBoostingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmBoostingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates equivalent as possible",1
v0.1.20,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.20,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmBoostingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.20,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.20,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.20,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.20,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.20,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.20,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.20,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.20,TODO : add classification binary and multiclass versions of this,1
v0.1.20,TODO : add classification binary and multiclass versions of this,1
v0.1.20,TODO: decide what to do with this test,1
v0.1.20,TODO : check if it's surprising that our interaction score doubles when we change a binary classification with 1 logit to a binary classification with 2 logits,1
v0.1.20,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which bypass the regular return mechanisms.  We need to use R_tryCatch (which is older than R_UnwindProtect) to not leak memory that we allocate before calling the R error or warning functions",1
v0.1.19,NOTE: Not implemented yet,1
v0.1.19,NOTE: We know this environment is going to use Dash.,1
v0.1.19,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.1.19,TODO: Remove this if threshold lines are never used.,1
v0.1.19,TODO: Clean this up after validation.,1
v0.1.19,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.19,NOTE: Workaround for tables not rendering,1
v0.1.19,TODO: Check if this is needed with the new tables.,1
v0.1.19,TODO: Consider reducing complexity of this function.,1
v0.1.19,NOTE: Workaround for tables not rendering,1
v0.1.19,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.19,TODO: Revisit when we support custom tabs from users.,1
v0.1.19,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.19,TODO: Harden these tests later to check content from data method.,1
v0.1.19,TODO: Generalize specific models (currently only testing trees),1
v0.1.19,TODO: Make kwargs explicit.,1
v0.1.19,TODO: State criteria in docs.,1
v0.1.19,Todo: check if this call,1
v0.1.19,TODO: Docs for unify_data.,1
v0.1.19,TODO: Clean up code to have less duplication.,1
v0.1.19,NOTE: Workaround for older versions of pandas.,1
v0.1.19,TODO: Fix this once we know it works.,1
v0.1.19,TODO: Work with ordinal later.,1
v0.1.19,"TODO: Consider removing later, potentially dead code.",1
v0.1.19,TODO: Clean up,1
v0.1.19,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.19,TODO: Double check that this works,1
v0.1.19,Old method -- TODO: remove once tested,1
v0.1.19,Old method -- TODO: remove once tested,1
v0.1.19,TODO: Add unit tests for internal EBM interfacing,1
v0.1.19,TODO: Update documentation for training/val scores args.,1
v0.1.19,TODO: Remove once we check that this works,1
v0.1.19,TODO: Fix for multiclass classification,1
v0.1.19,TODO: More documentation in binning process to be explicit.,1
v0.1.19,TODO: Consider stripping this down to the bare minimum.,1
v0.1.19,TODO: Review NA as we don't support it yet.,1
v0.1.19,TODO: Clean up,1
v0.1.19,TODO: Clean this up before release.,1
v0.1.19,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.19,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.19,TODO: Support other languages,1
v0.1.19,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.19,TODO: Generalize this out.,1
v0.1.19,NOTE: Workaround for Azure DevOps.,1
v0.1.19,TODO optimize the next few lines,1
v0.1.19,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.19,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.19,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.19,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.19,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.19,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.19,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.19,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.19,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.19,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.19,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.19,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.19,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.19,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.19,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.19,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.19,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.19,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.19,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.19,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.19,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.19,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.19,"// TODO : for classification, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates equivalent as possible",1
v0.1.19,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.19,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmTrainingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.19,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.19,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.19,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.19,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.19,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.19,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.19,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.19,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.19,"TODO : call test.Train many more times in a loop, and verify the output remains the same as previous runs",1
v0.1.19,TODO : add classification binary and multiclass versions of this,1
v0.1.19,"TODO : call test.Train many more times in a loop, and verify the output remains the same as previous runs",1
v0.1.19,TODO : add classification binary and multiclass versions of this,1
v0.1.19,TODO: decide what to do with this test,1
v0.1.19,TODO : check if it's surprising that our interaction score doubles when we change a binary classification with 1 logit to a binary classification with 2 logits,1
v0.1.19,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which bypass the regular return mechanisms.  We need to use R_tryCatch (which is older than R_UnwindProtect) to not leak memory that we allocate before calling the R error or warning functions",1
v0.1.18,NOTE: Not implemented yet,1
v0.1.18,NOTE: We know this environment is going to use Dash.,1
v0.1.18,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.1.18,TODO: Remove this if threshold lines are never used.,1
v0.1.18,TODO: Clean this up after validation.,1
v0.1.18,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.18,NOTE: Workaround for tables not rendering,1
v0.1.18,TODO: Check if this is needed with the new tables.,1
v0.1.18,TODO: Consider reducing complexity of this function.,1
v0.1.18,NOTE: Workaround for tables not rendering,1
v0.1.18,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.18,TODO: Revisit when we support custom tabs from users.,1
v0.1.18,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.18,TODO: Harden these tests later to check content from data method.,1
v0.1.18,TODO: Generalize specific models (currently only testing trees),1
v0.1.18,TODO: Make kwargs explicit.,1
v0.1.18,TODO: State criteria in docs.,1
v0.1.18,Todo: check if this call,1
v0.1.18,TODO: Docs for unify_data.,1
v0.1.18,TODO: Clean up code to have less duplication.,1
v0.1.18,NOTE: Workaround for older versions of pandas.,1
v0.1.18,TODO: Fix this once we know it works.,1
v0.1.18,TODO: Work with ordinal later.,1
v0.1.18,"TODO: Consider removing later, potentially dead code.",1
v0.1.18,TODO: Clean up,1
v0.1.18,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.18,TODO: Double check that this works,1
v0.1.18,Old method -- TODO: remove once tested,1
v0.1.18,Old method -- TODO: remove once tested,1
v0.1.18,TODO: Add unit tests for internal EBM interfacing,1
v0.1.18,TODO: Update documentation for training/val scores args.,1
v0.1.18,TODO: Remove once we check that this works,1
v0.1.18,TODO: Fix for multiclass classification,1
v0.1.18,TODO: More documentation in binning process to be explicit.,1
v0.1.18,TODO: Consider stripping this down to the bare minimum.,1
v0.1.18,TODO: Review NA as we don't support it yet.,1
v0.1.18,TODO: Clean up,1
v0.1.18,TODO: Clean this up before release.,1
v0.1.18,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.18,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.18,TODO: Support other languages,1
v0.1.18,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.18,TODO: Generalize this out.,1
v0.1.18,NOTE: Workaround for Azure DevOps.,1
v0.1.18,TODO optimize the next few lines,1
v0.1.18,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.18,"TODO : because there is only one bin for a zero feature feature combination, we can move the fetch of smallChangeToPredictorScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.18,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.18,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.18,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.18,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.18,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.18,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.18,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.18,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.18,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.18,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.18,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.18,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.18,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.18,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.18,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.18,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.18,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.18,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.18,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.18,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.18,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.18,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.18,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.18,"// TODO : for classification, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates equivalent as possible",1
v0.1.18,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.18,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmTrainingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.18,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.18,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.18,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.18,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.18,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.18,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.18,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.18,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.18,"TODO : change this so that we first call GetCurrentModelExpanded OR GetBestModelExpanded, which will return a tensor expanded as needed THEN  we call an indexing function if desired",1
v0.1.18,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.18,TODO : add classification binary and multiclass versions of this,1
v0.1.18,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.18,TODO : add classification binary and multiclass versions of this,1
v0.1.18,TODO: remove visibility to internal functions that don't need visibiliy -> https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Controlling-visibility,1
v0.1.18,TODO: Improve calling speed (see section 5.4.1 Speed considerations) https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Registering-native-routines,1
v0.1.18,"TODO: switch logging to use the R logging infrastructure when invoked from R, BUT calling error or warning will generate longjumps, which bypass the regular return mechanisms.  We need to use R_tryCatch (which is older than R_UnwindProtect) to not leak memory that we allocate before calling the R error or warning functions",1
v0.1.17,NOTE: Not implemented yet,1
v0.1.17,NOTE: We know this environment is going to use Dash.,1
v0.1.17,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.1.17,TODO: Remove this if threshold lines are never used.,1
v0.1.17,TODO: Clean this up after validation.,1
v0.1.17,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.17,NOTE: Workaround for tables not rendering,1
v0.1.17,TODO: Check if this is needed with the new tables.,1
v0.1.17,TODO: Consider reducing complexity of this function.,1
v0.1.17,NOTE: Workaround for tables not rendering,1
v0.1.17,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.17,TODO: Revisit when we support custom tabs from users.,1
v0.1.17,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.17,TODO: Harden these tests later to check content from data method.,1
v0.1.17,TODO: Generalize specific models (currently only testing trees),1
v0.1.17,TODO: Make kwargs explicit.,1
v0.1.17,TODO: State criteria in docs.,1
v0.1.17,Todo: check if this call,1
v0.1.17,TODO: Docs for unify_data.,1
v0.1.17,TODO: Clean up code to have less duplication.,1
v0.1.17,NOTE: Workaround for older versions of pandas.,1
v0.1.17,TODO: Fix this once we know it works.,1
v0.1.17,TODO: Work with ordinal later.,1
v0.1.17,"TODO: Consider removing later, potentially dead code.",1
v0.1.17,TODO: Clean up,1
v0.1.17,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.17,TODO: Double check that this works,1
v0.1.17,Old method -- TODO: remove once tested,1
v0.1.17,Old method -- TODO: remove once tested,1
v0.1.17,TODO: Add unit tests for internal EBM interfacing,1
v0.1.17,TODO: Update documentation for training/val scores args.,1
v0.1.17,TODO: Remove once we check that this works,1
v0.1.17,TODO: Fix for multiclass classification,1
v0.1.17,TODO: More documentation in binning process to be explicit.,1
v0.1.17,TODO: Consider stripping this down to the bare minimum.,1
v0.1.17,TODO: Review NA as we don't support it yet.,1
v0.1.17,TODO: Clean up,1
v0.1.17,TODO: Clean this up before release.,1
v0.1.17,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.17,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.17,TODO: Support other languages,1
v0.1.17,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.17,TODO: Generalize this out.,1
v0.1.17,NOTE: Workaround for Azure DevOps.,1
v0.1.17,TODO optimize the next few lines,1
v0.1.17,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.17,"TODO : because there is only one bin for a zero feature feature combination, we can move the fetch of smallChangeToPredictorScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.17,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.17,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.17,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.17,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.17,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.17,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.17,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.17,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.17,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.17,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.17,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.17,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.17,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.17,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.17,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.17,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.17,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.17,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.17,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.17,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.17,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.17,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.17,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.17,"// TODO : for classification, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates equivalent as possible",1
v0.1.17,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.17,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmTrainingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.17,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.17,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.17,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.17,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.17,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.17,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.17,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.17,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.17,"TODO : change this so that we first call GetCurrentModelExpanded OR GetBestModelExpanded, which will return a tensor expanded as needed THEN  we call an indexing function if desired",1
v0.1.17,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.17,TODO : add classification binary and multiclass versions of this,1
v0.1.17,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.17,TODO : add classification binary and multiclass versions of this,1
v0.1.16,NOTE: Not implemented yet,1
v0.1.16,NOTE: We know this environment is going to use Dash.,1
v0.1.16,"TODO: Value 1 doesn't make sense for this bias, consider refactoring values to take None.",1
v0.1.16,TODO: Remove this if threshold lines are never used.,1
v0.1.16,TODO: Clean this up after validation.,1
v0.1.16,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.16,NOTE: Workaround for tables not rendering,1
v0.1.16,TODO: Check if this is needed with the new tables.,1
v0.1.16,TODO: Consider reducing complexity of this function.,1
v0.1.16,NOTE: Workaround for tables not rendering,1
v0.1.16,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.16,TODO: Revisit when we support custom tabs from users.,1
v0.1.16,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.16,TODO: Harden these tests later to check content from data method.,1
v0.1.16,TODO: Generalize specific models (currently only testing trees),1
v0.1.16,TODO: Make kwargs explicit.,1
v0.1.16,TODO: State criteria in docs.,1
v0.1.16,Todo: check if this call,1
v0.1.16,TODO: Docs for unify_data.,1
v0.1.16,TODO: Clean up code to have less duplication.,1
v0.1.16,TODO: Fix this once we know it works.,1
v0.1.16,TODO: Work with ordinal later.,1
v0.1.16,"TODO: Consider removing later, potentially dead code.",1
v0.1.16,TODO: Clean up,1
v0.1.16,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.16,TODO: Double check that this works,1
v0.1.16,Old method -- TODO: remove once tested,1
v0.1.16,Old method -- TODO: remove once tested,1
v0.1.16,TODO: Add unit tests for internal EBM interfacing,1
v0.1.16,TODO: Update documentation for training/val scores args.,1
v0.1.16,TODO: Remove once we check that this works,1
v0.1.16,TODO: Fix for multiclass classification,1
v0.1.16,TODO: More documentation in binning process to be explicit.,1
v0.1.16,TODO: Consider stripping this down to the bare minimum.,1
v0.1.16,TODO: Review NA as we don't support it yet.,1
v0.1.16,TODO: Clean up,1
v0.1.16,TODO: Clean this up before release.,1
v0.1.16,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.16,"TODO: More checks for explainer validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.16,TODO: Support other languages,1
v0.1.16,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.16,TODO: Generalize this out.,1
v0.1.16,TODO optimize the next few lines,1
v0.1.16,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.16,"TODO : because there is only one bin for a zero feature feature combination, we can move the fetch of smallChangeToPredictorScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.16,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.16,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.16,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.16,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.16,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.16,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.16,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.16,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.16,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.16,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.16,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.16,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.16,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.16,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.16,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.16,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.16,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.16,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.16,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.16,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.16,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.16,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.16,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.16,"// TODO : for classification, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates equivalent as possible",1
v0.1.16,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.16,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmTrainingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.16,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.16,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.16,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.16,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.16,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.16,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.16,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.16,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.16,"TODO : change this so that we first call GetCurrentModelExpanded OR GetBestModelExpanded, which will return a tensor expanded as needed THEN  we call an indexing function if desired",1
v0.1.16,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.16,TODO : add classification binary and multiclass versions of this,1
v0.1.16,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.16,TODO : add classification binary and multiclass versions of this,1
v0.1.15,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.15,TODO: Remove this if threshold lines are never used.,1
v0.1.15,TODO: Clean this up after validation.,1
v0.1.15,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.15,NOTE: Workaround for tables not rendering,1
v0.1.15,TODO: Check if this is needed with the new tables.,1
v0.1.15,TODO: Consider reducing complexity of this function.,1
v0.1.15,NOTE: Workaround for tables not rendering,1
v0.1.15,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.15,TODO: Revisit when we support custom tabs from users.,1
v0.1.15,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.15,TODO: Harden these tests later to check content from data method.,1
v0.1.15,TODO: Make kwargs explicit.,1
v0.1.15,TODO: State criteria in docs.,1
v0.1.15,Todo: check if this call,1
v0.1.15,TODO: Docs for unify_data.,1
v0.1.15,TODO: Clean up code to have less duplication.,1
v0.1.15,TODO: Fix this once we know it works.,1
v0.1.15,TODO: Work with ordinal later.,1
v0.1.15,"TODO: Consider removing later, potentially dead code.",1
v0.1.15,TODO: Clean up,1
v0.1.15,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.15,TODO: Double check that this works,1
v0.1.15,Old method -- TODO: remove once tested,1
v0.1.15,Old method -- TODO: remove once tested,1
v0.1.15,TODO: Add unit tests for internal EBM interfacing,1
v0.1.15,TODO: Update documentation for training/val scores args.,1
v0.1.15,TODO: Remove once we check that this works,1
v0.1.15,TODO: Fix for multiclass classification,1
v0.1.15,TODO: More documentation in binning process to be explicit.,1
v0.1.15,TODO: Consider stripping this down to the bare minimum.,1
v0.1.15,TODO: Review NA as we don't support it yet.,1
v0.1.15,TODO: Clean up,1
v0.1.15,TODO: Clean this up before release.,1
v0.1.15,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.15,TODO: Support other languages,1
v0.1.15,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.15,TODO: Generalize this out.,1
v0.1.15,TODO optimize the next few lines,1
v0.1.15,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.15,"TODO : because there is only one bin for a zero feature feature combination, we can move the fetch of smallChangeToPredictorScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.15,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.15,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.15,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.15,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.15,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.15,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.15,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.15,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.15,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.15,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.15,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.15,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.15,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.15,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.15,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.15,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.15,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.15,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.15,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.15,"TODO: figure out why this is being called, and if that is bad!",1
v0.1.15,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.15,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.15,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.15,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.15,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.15,"// TODO : for classification, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates equivalent as possible",1
v0.1.15,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.15,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmTrainingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.15,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.15,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.15,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.15,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.15,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.15,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.15,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.15,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.15,"TODO : change this so that we first call GetCurrentModelExpanded OR GetBestModelExpanded, which will return a tensor expanded as needed THEN  we call an indexing function if desired",1
v0.1.15,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.15,TODO : add classification binary and multiclass versions of this,1
v0.1.15,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.15,TODO : add classification binary and multiclass versions of this,1
v0.1.14,TODO: Dashboard needs to be tested.,1
v0.1.14,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.14,TODO: Remove this if threshold lines are never used.,1
v0.1.14,TODO: Clean this up after validation.,1
v0.1.14,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.14,NOTE: Workaround for tables not rendering,1
v0.1.14,TODO: Check if this is needed with the new tables.,1
v0.1.14,TODO: Consider reducing complexity of this function.,1
v0.1.14,NOTE: Workaround for tables not rendering,1
v0.1.14,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.14,TODO: Revisit when we support custom tabs from users.,1
v0.1.14,TODO: Investigate why this doesn't work in DevOps environment.,1
v0.1.14,TODO: Harden these tests later to check content from data method.,1
v0.1.14,TODO: Make kwargs explicit.,1
v0.1.14,TODO: State criteria in docs.,1
v0.1.14,Todo: check if this call,1
v0.1.14,TODO: Docs for unify_data.,1
v0.1.14,TODO: Clean up code to have less duplication.,1
v0.1.14,TODO: Fix this once we know it works.,1
v0.1.14,TODO: Work with ordinal later.,1
v0.1.14,"TODO: Consider removing later, potentially dead code.",1
v0.1.14,TODO: Clean up,1
v0.1.14,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.14,TODO: Double check that this works,1
v0.1.14,Old method -- TODO: remove once tested,1
v0.1.14,Old method -- TODO: remove once tested,1
v0.1.14,TODO: Add unit tests for internal EBM interfacing,1
v0.1.14,TODO: Update documentation for training/val scores args.,1
v0.1.14,TODO: Remove once we check that this works,1
v0.1.14,TODO: More documentation in binning process to be explicit.,1
v0.1.14,TODO: Consider stripping this down to the bare minimum.,1
v0.1.14,TODO: Review NA as we don't support it yet.,1
v0.1.14,TODO: Clean up,1
v0.1.14,TODO: Clean this up before release.,1
v0.1.14,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.14,TODO: Support other languages,1
v0.1.14,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.14,TODO: Generalize this out.,1
v0.1.14,TODO optimize the next few lines,1
v0.1.14,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.14,"TODO : because there is only one bin for a zero feature feature combination, we can move the fetch of smallChangeToPredictorScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.14,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.14,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.14,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.14,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.14,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.14,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.14,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.14,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.14,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.14,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.14,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.14,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.14,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.14,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.14,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.14,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.14,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.14,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.14,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.14,"TODO: figure out why this is being called, and if that is bad!",1
v0.1.14,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.14,"TODO: turn these EBM_ASSERTS into log errors!!  Small checks like this of our wrapper's inputs hardly cost anything, and catch issues faster",1
v0.1.14,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.14,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.14,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.14,"// TODO : for classification, is our learning rate essentially being inflated as pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_runtimeLearningTypeOrCountTargetClasses here to keep learning rates equivalent as possible",1
v0.1.14,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.14,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmTrainingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.14,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.14,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.14,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.14,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.14,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.14,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.14,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.14,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.14,"TODO : change this so that we first call GetCurrentModelExpanded OR GetBestModelExpanded, which will return a tensor expanded as needed THEN  we call an indexing function if desired",1
v0.1.14,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.14,TODO : add classification binary and multiclass versions of this,1
v0.1.14,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.14,TODO : add classification binary and multiclass versions of this,1
v0.1.13,TODO: Dashboard needs to be tested.,1
v0.1.13,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.13,TODO: Remove this if threshold lines are never used.,1
v0.1.13,TODO: Remove this completely once performance graphs are hardened.,1
v0.1.13,NOTE: Workaround for tables not rendering,1
v0.1.13,TODO: Consider reducing complexity of this function.,1
v0.1.13,NOTE: Workaround for tables not rendering,1
v0.1.13,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.13,TODO: Revisit when we support custom tabs from users.,1
v0.1.13,TODO: Harden these tests later to check content from data method.,1
v0.1.13,TODO: Make kwargs explicit.,1
v0.1.13,TODO: State criteria in docs.,1
v0.1.13,Todo: check if this call,1
v0.1.13,TODO: Docs for unify_data.,1
v0.1.13,TODO: Clean up code to have less duplication.,1
v0.1.13,TODO: Fix this once we know it works.,1
v0.1.13,TODO: Work with ordinal later.,1
v0.1.13,TODO: Clean up,1
v0.1.13,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.13,Old method -- TODO: remove once tested,1
v0.1.13,Old method -- TODO: remove once tested,1
v0.1.13,TODO: Add unit tests for internal EBM interfacing,1
v0.1.13,TODO: Update documentation for training/val scores args.,1
v0.1.13,TODO: More documentation in binning process to be explicit.,1
v0.1.13,TODO: Consider stripping this down to the bare minimum.,1
v0.1.13,TODO: Review NA as we don't support it yet.,1
v0.1.13,TODO: Clean up,1
v0.1.13,TODO: Clean this up before release.,1
v0.1.13,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.13,TODO: Support other languages,1
v0.1.13,"TODO: More checks for blackbox validation, specifically on spec for explainer/explanation when instantiated.",1
v0.1.13,TODO: Generalize this out.,1
v0.1.13,TODO optimize the next few lines,1
v0.1.13,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.13,"TODO : because there is only one bin for a zero feature feature combination, we can move the fetch of smallChangeToPredictorScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.13,"TODO : because there is only one bin for a zero feature feature combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.13,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.13,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.13,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.13,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.13,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.13,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.13,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.13,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.13,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.13,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.13,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.13,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.13,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.13,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.13,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.13,TODO : consider replacing iVector with pValidationPredictorScoresInnerEnd,1
v0.1.13,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.13,TODO : perhaps we should change m_cBins into m_iBinMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.13,"TODO: figure out why this is being called, and if that is bad!",1
v0.1.13,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.13,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelFeatureCombinationUpdatePerTargetClasses function,1
v0.1.13,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.13,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pEbmTrainingState->m_cTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_cTargetClasses here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.13,"// TODO : for classification, is our learning rate essentially being inflated as pEbmTrainingState->m_cTargetClasses goes up?  If so, maybe we should divide by pEbmTrainingState->m_cTargetClasses here to keep learning rates equivalent as possible",1
v0.1.13,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.13,"TODO : we can make GenerateModelFeatureCombinationUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pEbmTrainingState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.13,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.13,TODO : move the target bits branch inside TrainingSetInputFeatureLoop to here outside instead of the feature combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do feature combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.13,"TODO : in the future don't copy over all SegmentedTensors.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.13,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.13,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.13,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.13,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.13,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.13,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.13,TODO : add classification binary and multiclass versions of this,1
v0.1.13,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.13,TODO : add classification binary and multiclass versions of this,1
v0.1.12,TODO: Dashboard needs to be tested.,1
v0.1.12,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.12,NOTE: Workaround for tables not rendering,1
v0.1.12,TODO: Consider reducing complexity of this function.,1
v0.1.12,NOTE: Workaround for tables not rendering,1
v0.1.12,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.12,TODO: Revisit when we support custom tabs from users.,1
v0.1.12,"TODO: Code duplication, refactor.",1
v0.1.12,TODO: Make kwargs explicit.,1
v0.1.12,TODO: State criteria in docs.,1
v0.1.12,Todo: check if this call,1
v0.1.12,TODO: Docs for unify_data.,1
v0.1.12,TODO: Clean up code to have less duplication.,1
v0.1.12,TODO: Fix this once we know it works.,1
v0.1.12,TODO: Work with ordinal later.,1
v0.1.12,TODO: Clean up,1
v0.1.12,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.12,Old method -- TODO: remove once tested,1
v0.1.12,Old method -- TODO: remove once tested,1
v0.1.12,TODO: Add unit tests for internal EBM interfacing,1
v0.1.12,TODO: Update documentation for training/val scores args.,1
v0.1.12,TODO: More documentation in binning process to be explicit.,1
v0.1.12,TODO: Consider stripping this down to the bare minimum.,1
v0.1.12,TODO: Review NA as we don't support it yet.,1
v0.1.12,TODO: Clean up,1
v0.1.12,TODO: Clean this up before release.,1
v0.1.12,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.12,TODO: Support other languages,1
v0.1.12,TODO: Generalize this out.,1
v0.1.12,TODO optimize the next few lines,1
v0.1.12,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.12,"TODO : because there is only one bin for a zero attribute attribute combination, we can move the fetch of smallChangeToPredictionScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.12,"TODO : because there is only one bin for a zero attribute attribute combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.12,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.12,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.12,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.12,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.12,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.12,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.12,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.12,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.12,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.12,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.12,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.12,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.12,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.12,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.12,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.12,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.12,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.12,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.12,"TODO: figure out why this is being called, and if that is bad!",1
v0.1.12,TODO: rename this EbmTrainingState,1
v0.1.12,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.12,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelUpdatePerTargetStates function,1
v0.1.12,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.12,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pTmlState->m_cTargetStates goes up?  If so, maybe we should divide by pTmlState->m_cTargetStates here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.12,"// TODO : for classification, is our learning rate essentially being inflated as pTmlState->m_cTargetStates goes up?  If so, maybe we should divide by pTmlState->m_cTargetStates here to keep learning rates equivalent as possible",1
v0.1.12,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.12,"TODO : we can make GenerateModelUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pTmlState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.12,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.12,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.12,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.12,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.12,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.12,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.12,TODO : rename this to EbmInteractionState,1
v0.1.12,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.12,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.12,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.12,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.12,TODO : add classification binary and multiclass versions of this,1
v0.1.12,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.12,TODO : add classification binary and multiclass versions of this,1
v0.1.11,TODO: Dashboard needs to be tested.,1
v0.1.11,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.11,NOTE: Workaround for tables not rendering,1
v0.1.11,TODO: Consider reducing complexity of this function.,1
v0.1.11,NOTE: Workaround for tables not rendering,1
v0.1.11,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.11,TODO: Revisit when we support custom tabs from users.,1
v0.1.11,"TODO: Code duplication, refactor.",1
v0.1.11,TODO: Make kwargs explicit.,1
v0.1.11,TODO: State criteria in docs.,1
v0.1.11,Todo: check if this call,1
v0.1.11,TODO: Docs for unify_data.,1
v0.1.11,TODO: Clean up code to have less duplication.,1
v0.1.11,TODO: Fix this once we know it works.,1
v0.1.11,TODO: Work with ordinal later.,1
v0.1.11,TODO: Clean up,1
v0.1.11,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.11,Old method -- TODO: remove once tested,1
v0.1.11,Old method -- TODO: remove once tested,1
v0.1.11,TODO: Add unit tests for internal EBM interfacing,1
v0.1.11,TODO: Update documentation for training/val scores args.,1
v0.1.11,TODO: More documentation in binning process to be explicit.,1
v0.1.11,TODO: Consider stripping this down to the bare minimum.,1
v0.1.11,TODO: Review NA as we don't support it yet.,1
v0.1.11,TODO: Clean up,1
v0.1.11,TODO: Clean this up before release.,1
v0.1.11,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.11,TODO: Support other languages,1
v0.1.11,TODO: Generalize this out.,1
v0.1.11,TODO optimize the next few lines,1
v0.1.11,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.11,"TODO : because there is only one bin for a zero attribute attribute combination, we can move the fetch of smallChangeToPredictionScores outside of our loop so that the code doesn't have this dereference each loop",1
v0.1.11,"TODO : because there is only one bin for a zero attribute attribute combination, we could move these values to the stack where the copmiler could reason about their visibility and optimize small arrays into registers",1
v0.1.11,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.11,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.11,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.11,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.11,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.11,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.11,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.11,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.11,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.11,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.11,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.11,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.11,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.11,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.11,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.11,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.11,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.11,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.11,"TODO: figure out why this is being called, and if that is bad!",1
v0.1.11,TODO: rename this EbmTrainingState,1
v0.1.11,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.11,TODO remove this after we use aTrainingWeights and aValidationWeights into the GenerateModelUpdatePerTargetStates function,1
v0.1.11,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.11,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as pTmlState->m_cTargetStates goes up?  If so, maybe we should divide by pTmlState->m_cTargetStates here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.11,"// TODO : for classification, is our learning rate essentially being inflated as pTmlState->m_cTargetStates goes up?  If so, maybe we should divide by pTmlState->m_cTargetStates here to keep learning rates equivalent as possible",1
v0.1.11,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.11,"TODO : we can make GenerateModelUpdate callable by multiple threads so that this step could be parallelized before making a decision and applying one of the updates.  Right now we're accessing scratch space in the pTmlState object, but we can move that to a thread resident object.  Do do this, we would need to have our caller allocate our tensor, but that is a manageable operation",1
v0.1.11,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.11,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.11,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.11,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.11,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.11,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.11,TODO : rename this to EbmInteractionState,1
v0.1.11,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.11,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.11,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.11,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.11,TODO : add classification binary and multiclass versions of this,1
v0.1.11,TODO : move this into our tests that iterate many loops and compare output for no splitting.  AND also loop this,1
v0.1.11,TODO : add classification binary and multiclass versions of this,1
v0.1.10,TODO: Dashboard needs to be tested.,1
v0.1.10,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.10,NOTE: Workaround for tables not rendering,1
v0.1.10,TODO: Consider reducing complexity of this function.,1
v0.1.10,NOTE: Workaround for tables not rendering,1
v0.1.10,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.10,TODO: Revisit when we support custom tabs from users.,1
v0.1.10,TODO: Make kwargs explicit.,1
v0.1.10,TODO: State criteria in docs.,1
v0.1.10,Todo: check if this call,1
v0.1.10,TODO: Docs for unify_data.,1
v0.1.10,TODO: Clean up code to have less duplication.,1
v0.1.10,TODO: Fix this once we know it works.,1
v0.1.10,TODO: Work with ordinal later.,1
v0.1.10,TODO: Clean up,1
v0.1.10,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.10,TODO: Add unit tests for internal EBM interfacing,1
v0.1.10,TODO: Update documentation for training/val scores args.,1
v0.1.10,TODO: More documentation in binning process to be explicit.,1
v0.1.10,TODO: Consider stripping this down to the bare minimum.,1
v0.1.10,TODO: Review NA as we don't support it yet.,1
v0.1.10,TODO: Clean up,1
v0.1.10,TODO: Clean this up before release.,1
v0.1.10,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.10,TODO: Generalize this out.,1
v0.1.10,TODO optimize the next few lines,1
v0.1.10,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.10,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.10,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.10,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.10,"TODO : we're calculating exp(predictionScore) above, and then again in ComputeClassificationResidualErrorMulticlass.  exp(..) is expensive so we should just do it once instead and store the result in a small memory array here",1
v0.1.10,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.10,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.10,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.10,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.10,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.10,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.10,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.10,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.10,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.10,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.10,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.10,"// TODO : for classification with residual zeroing, is our learning rate essentially being inflated as cTargetStates goes up?  If so, maybe we should divide by cTargetStates here to keep learning rates as equivalent as possible..  Actually, I think the real solution here is that",1
v0.1.10,"// TODO : for classification, is our learning rate essentially being inflated as cTargetStates goes up?  If so, maybe we should divide by cTargetStates here to keep learning rates equivalent as possible",1
v0.1.10,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.10,"TODO: figure out why this is being called, and if that is bad!",1
v0.1.10,TODO: rename this EbmTrainingState,1
v0.1.10,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.10,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.10,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.10,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.10,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.10,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.10,TODO : rename this to EbmInteractionState,1
v0.1.10,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.10,"we only decrease the count if the count is non-zero, so at worst if there is a race condition then we'll output this log message more times than desired, but we can live with that",1
v0.1.10,TODO : !! change our code so that we don't need to allocate an AttributeCombinationCore each time we do an interaction score calculation,1
v0.1.10,TODO : eliminate the counts here and use pointers,1
v0.1.10,"TODO: eliminate this extra internal index lookup (very bad!).  Since the attributes will be in-order, we can probably just use a single pointer to the input data and just keep incrementing it over all the attributes",1
v0.1.10,TODO : integrate this subtraction into the copy instead of doing it afterwards,1
v0.1.9,TODO: Dashboard needs to be tested.,1
v0.1.9,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.9,NOTE: Workaround for tables not rendering,1
v0.1.9,TODO: Consider reducing complexity of this function.,1
v0.1.9,NOTE: Workaround for tables not rendering,1
v0.1.9,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.9,TODO: Revisit when we support custom tabs from users.,1
v0.1.9,TODO: Make kwargs explicit.,1
v0.1.9,TODO: State criteria in docs.,1
v0.1.9,Todo: check if this call,1
v0.1.9,TODO: Clean up code to have less duplication.,1
v0.1.9,TODO: Fix this once we know it works.,1
v0.1.9,TODO: Work with ordinal later.,1
v0.1.9,TODO: Clean up,1
v0.1.9,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.9,TODO: Add unit tests for internal EBM interfacing,1
v0.1.9,TODO: Update documentation for training/val scores args.,1
v0.1.9,TODO: More documentation in binning process to be explicit.,1
v0.1.9,TODO: Consider stripping this down to the bare minimum.,1
v0.1.9,TODO: Remove this.,1
v0.1.9,TODO: Review NA as we don't support it yet.,1
v0.1.9,TODO: Clean up,1
v0.1.9,TODO: Clean this up before release.,1
v0.1.9,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.9,TODO optimize the next few lines,1
v0.1.9,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.9,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.9,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.9,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.9,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.9,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.9,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.9,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.9,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.9,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.9,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.9,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.9,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.9,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.9,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.9,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.9,"TODO: figure out why this is being called, and if that is bad!",1
v0.1.9,TODO: rename this EbmTrainingState,1
v0.1.9,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.9,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.9,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.9,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.9,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.9,TODO : rename this to EbmInteractionState,1
v0.1.9,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.9,TODO : !! change our code so that we don't need to allocate an AttributeCombinationCore each time we do an interaction score calculation,1
v0.1.9,TODO : eliminate the counts here and use pointers,1
v0.1.9,"TODO: eliminate this extra internal index lookup (very bad!).  Since the attributes will be in-order, we can probably just use a single pointer to the input data and just keep incrementing it over all the attributes",1
v0.1.8,TODO: Fill this out once specs are provided.,1
v0.1.8,TODO: Dashboard needs to be tested.,1
v0.1.8,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.8,NOTE: Workaround for tables not rendering,1
v0.1.8,TODO: Consider reducing complexity of this function.,1
v0.1.8,NOTE: Workaround for tables not rendering,1
v0.1.8,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.8,TODO: Revisit when we support custom tabs from users.,1
v0.1.8,TODO: Make kwargs explicit.,1
v0.1.8,TODO: State criteria in docs.,1
v0.1.8,Todo: check if this call,1
v0.1.8,TODO: Clean up code to have less duplication.,1
v0.1.8,TODO: Fix this once we know it works.,1
v0.1.8,TODO: Work with ordinal later.,1
v0.1.8,TODO: Clean up,1
v0.1.8,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.8,TODO: Add unit tests for internal EBM interfacing,1
v0.1.8,TODO: Update documentation for training/val scores args.,1
v0.1.8,TODO: More documentation in binning process to be explicit.,1
v0.1.8,TODO: Consider stripping this down to the bare minimum.,1
v0.1.8,TODO: Remove this.,1
v0.1.8,TODO: Review NA as we don't support it yet.,1
v0.1.8,TODO: Clean up,1
v0.1.8,TODO: Clean this up before release.,1
v0.1.8,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.8,TODO optimize the next few lines,1
v0.1.8,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.8,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.8,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.8,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.8,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.8,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.8,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.8,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.8,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.8,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.8,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.8,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.8,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.8,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.8,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.8,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.8,TODO: rename this TmlTrainingState,1
v0.1.8,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.8,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.8,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.8,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.8,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.8,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.8,TODO : !! change our code so that we don't need to allocate an AttributeCombinationCore each time we do an interaction score calculation,1
v0.1.8,TODO : eliminate the counts here and use pointers,1
v0.1.8,"TODO: eliminate this extra internal index lookup (very bad!).  Since the attributes will be in-order, we can probably just use a single pointer to the input data and just keep incrementing it over all the attributes",1
v0.1.7,TODO: Fill this out once specs are provided.,1
v0.1.7,TODO: Dashboard needs to be tested.,1
v0.1.7,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.7,NOTE: Workaround for tables not rendering,1
v0.1.7,TODO: Consider reducing complexity of this function.,1
v0.1.7,NOTE: Workaround for tables not rendering,1
v0.1.7,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.7,TODO: Revisit when we support custom tabs from users.,1
v0.1.7,TODO: Add test for log registration.,1
v0.1.7,TODO: Add regression problem to spec.,1
v0.1.7,TODO: Make kwargs explicit.,1
v0.1.7,TODO: State criteria in docs.,1
v0.1.7,Todo: check if this call,1
v0.1.7,TODO: Clean up code to have less duplication.,1
v0.1.7,TODO: Fix this once we know it works.,1
v0.1.7,TODO: Work with ordinal later.,1
v0.1.7,TODO: Clean up,1
v0.1.7,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.7,TODO: Add unit tests for internal EBM interfacing,1
v0.1.7,TODO: Update documentation for training/val scores args.,1
v0.1.7,TODO: More documentation in binning process to be explicit.,1
v0.1.7,TODO: Consider stripping this down to the bare minimum.,1
v0.1.7,TODO: Remove this.,1
v0.1.7,TODO: Review NA as we don't support it yet.,1
v0.1.7,TODO: Clean up,1
v0.1.7,TODO: Clean this up before release.,1
v0.1.7,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.7,TODO optimize the next few lines,1
v0.1.7,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.7,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.7,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.7,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.7,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.7,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.7,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.7,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.7,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.7,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.7,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.7,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.7,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.7,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.7,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.7,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.7,TODO: rename this TmlTrainingState,1
v0.1.7,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.7,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.7,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.7,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.7,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.7,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.7,TODO : !! change our code so that we don't need to allocate an AttributeCombinationCore each time we do an interaction score calculation,1
v0.1.7,TODO : eliminate the counts here and use pointers,1
v0.1.7,"TODO: eliminate this extra internal index lookup (very bad!).  Since the attributes will be in-order, we can probably just use a single pointer to the input data and just keep incrementing it over all the attributes",1
v0.1.6,TODO: Fill this out once specs are provided.,1
v0.1.6,TODO: Dashboard needs to be tested.,1
v0.1.6,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.6,NOTE: Workaround for tables not rendering,1
v0.1.6,TODO: Consider reducing complexity of this function.,1
v0.1.6,NOTE: Workaround for tables not rendering,1
v0.1.6,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.6,TODO: Revisit when we support custom tabs from users.,1
v0.1.6,TODO: Testing for show/snap functions.,1
v0.1.6,TODO: Add test for log registration.,1
v0.1.6,TODO: Make kwargs explicit.,1
v0.1.6,TODO: State criteria in docs.,1
v0.1.6,Todo: check if this call,1
v0.1.6,TODO: Clean up code to have less duplication.,1
v0.1.6,TODO: Fix this once we know it works.,1
v0.1.6,TODO: Work with ordinal later.,1
v0.1.6,TODO: Clean up,1
v0.1.6,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.6,TODO: Add unit tests for internal EBM interfacing,1
v0.1.6,TODO: Update documentation for training/val scores args.,1
v0.1.6,TODO: More documentation in binning process to be explicit.,1
v0.1.6,TODO: Consider stripping this down to the bare minimum.,1
v0.1.6,TODO: Remove this.,1
v0.1.6,TODO: Review NA as we don't support it yet.,1
v0.1.6,TODO: Clean up,1
v0.1.6,TODO: Clean this up before release.,1
v0.1.6,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.6,TODO optimize the next few lines,1
v0.1.6,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.6,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.6,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.6,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.6,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.6,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.6,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.6,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.6,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.6,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.6,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.6,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.6,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.6,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.6,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.6,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.6,TODO: rename this TmlTrainingState,1
v0.1.6,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.6,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.6,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.6,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.6,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.6,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.6,TODO : !! change our code so that we don't need to allocate an AttributeCombinationCore each time we do an interaction score calculation,1
v0.1.6,TODO : eliminate the counts here and use pointers,1
v0.1.6,"TODO: eliminate this extra internal index lookup (very bad!).  Since the attributes will be in-order, we can probably just use a single pointer to the input data and just keep incrementing it over all the attributes",1
v0.1.5,TODO: Fill this out once specs are provided.,1
v0.1.5,TODO: Dashboard needs to be tested.,1
v0.1.5,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.5,NOTE: Workaround for tables not rendering,1
v0.1.5,TODO: Consider reducing complexity of this function.,1
v0.1.5,NOTE: Workaround for tables not rendering,1
v0.1.5,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.5,TODO: Revisit when we support custom tabs from users.,1
v0.1.5,TODO: Testing for show/snap functions.,1
v0.1.5,TODO: Add test for log registration.,1
v0.1.5,TODO: Make kwargs explicit.,1
v0.1.5,TODO: State criteria in docs.,1
v0.1.5,Todo: check if this call,1
v0.1.5,TODO: Clean up code to have less duplication.,1
v0.1.5,TODO: Fix this once we know it works.,1
v0.1.5,TODO: Work with ordinal later.,1
v0.1.5,TODO: Clean up,1
v0.1.5,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.5,TODO: Add unit tests for internal EBM interfacing,1
v0.1.5,TODO: Update documentation for training/val scores args.,1
v0.1.5,TODO: More documentation in binning process to be explicit.,1
v0.1.5,TODO: Consider stripping this down to the bare minimum.,1
v0.1.5,TODO: Remove this.,1
v0.1.5,TODO: Review NA as we don't support it yet.,1
v0.1.5,TODO: Clean up,1
v0.1.5,TODO: Clean this up before release.,1
v0.1.5,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.5,TODO optimize the next few lines,1
v0.1.5,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.5,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.5,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.5,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.5,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.5,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.5,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.5,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.5,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.5,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.5,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.5,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.5,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.5,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.5,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.5,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.5,TODO: rename this TmlTrainingState,1
v0.1.5,TODO : can we internalize these so that they are not pointers and are therefore subsumed into our class,1
v0.1.5,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.5,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.5,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.5,TODO: someday eliminate the need for generating this flat set by specially handling the case of no internal bagging,1
v0.1.5,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.5,TODO : !! change our code so that we don't need to allocate an AttributeCombinationCore each time we do an interaction score calculation,1
v0.1.5,TODO : eliminate the counts here and use pointers,1
v0.1.5,"TODO: eliminate this extra internal index lookup (very bad!).  Since the attributes will be in-order, we can probably just use a single pointer to the input data and just keep incrementing it over all the attributes",1
v0.1.4,TODO: Dashboard needs to be tested.,1
v0.1.4,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.4,"TODO: Remove this, we don't use this anymore nor expose it.",1
v0.1.4,NOTE: Workaround for tables not rendering,1
v0.1.4,TODO: Consider reducing complexity of this function.,1
v0.1.4,NOTE: Workaround for tables not rendering,1
v0.1.4,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.4,TODO: Revisit when we support custom tabs from users.,1
v0.1.4,TODO: Make kwargs explicit.,1
v0.1.4,TODO: State criteria in docs.,1
v0.1.4,Todo: check if this call,1
v0.1.4,TODO: Clean up code to have less duplication.,1
v0.1.4,TODO: Fix this once we know it works.,1
v0.1.4,TODO: Work with ordinal later.,1
v0.1.4,TODO: Clean up,1
v0.1.4,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.4,TODO: Add unit tests for internal EBM interfacing,1
v0.1.4,TODO: Update documentation for training/val scores args.,1
v0.1.4,TODO: More documentation in binning process to be explicit.,1
v0.1.4,TODO: Consider stripping this down to the bare minimum.,1
v0.1.4,TODO: Remove this.,1
v0.1.4,TODO: Review NA as we don't support it yet.,1
v0.1.4,TODO: Clean up,1
v0.1.4,TODO: Clean this up before release.,1
v0.1.4,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.4,TODO optimize the next few lines,1
v0.1.4,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.4,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.4,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.4,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.4,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.4,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.4,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.4,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.4,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.4,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.4,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.4,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.4,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.4,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.4,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.4,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.4,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.4,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.4,TODO: can I put the SamplingWithoutReplacement bit into the data if I separate my data out by sample?,1
v0.1.4,TODO: rename this TmlTrainingState,1
v0.1.4,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.4,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.4,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.4,TODO: can this be merged with the InitializeInteractionErrorCore function in the TransparentMLCoreTraining.cpp file,1
v0.1.4,TODO: handle null in pPredictionScores like we did for training,1
v0.1.4,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.4,"TODO : can we eliminate the target values and just keep the residuals for interactions (we have a loop that stores the data below, but maybe we can just copy our input data to the residuals)",1
v0.1.4,TODO : eliminate the counts here and use pointers,1
v0.1.4,TODO : eliminate the counts here and use pointers,1
v0.1.4,TODO : do loop here,1
v0.1.4,TODO : do loop here,1
v0.1.4,"this is here to catch exceptions from (TODO is this required?), but it could also catch errors if we put any other C++ types in here later",1
v0.1.4,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.3,NOTE: Numpy here is a workaround to skope-rules' dependencies.,1
v0.1.3,TODO: Dashboard needs to be tested.,1
v0.1.3,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.3,"TODO: Remove this, we don't use this anymore nor expose it.",1
v0.1.3,NOTE: Workaround for tables not rendering,1
v0.1.3,TODO: Consider reducing complexity of this function.,1
v0.1.3,NOTE: Workaround for tables not rendering,1
v0.1.3,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.3,TODO: Revisit when we support custom tabs from users.,1
v0.1.3,TODO: Make kwargs explicit.,1
v0.1.3,TODO: State criteria in docs.,1
v0.1.3,Todo: check if this call,1
v0.1.3,TODO: Clean up code to have less duplication.,1
v0.1.3,TODO: Fix this once we know it works.,1
v0.1.3,TODO: Work with ordinal later.,1
v0.1.3,TODO: Clean up,1
v0.1.3,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.3,TODO: Add unit tests for internal EBM interfacing,1
v0.1.3,TODO: Update documentation for training/val scores args.,1
v0.1.3,TODO: More documentation in binning process to be explicit.,1
v0.1.3,TODO: Consider stripping this down to the bare minimum.,1
v0.1.3,TODO: Remove this.,1
v0.1.3,TODO: Review NA as we don't support it yet.,1
v0.1.3,TODO: Clean up,1
v0.1.3,TODO: Clean this up before release.,1
v0.1.3,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.3,TODO optimize the next few lines,1
v0.1.3,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.3,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.3,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.3,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.3,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.3,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.3,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.3,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.3,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.3,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.3,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.3,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.3,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.3,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.3,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.3,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.3,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.3,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.3,TODO: can I put the SamplingWithoutReplacement bit into the data if I separate my data out by sample?,1
v0.1.3,TODO: rename this TmlTrainingState,1
v0.1.3,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.3,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.3,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.3,TODO: can this be merged with the InitializeInteractionErrorCore function in the TransparentMLCoreTraining.cpp file,1
v0.1.3,TODO: handle null in pPredictionScores like we did for training,1
v0.1.3,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.3,"TODO : can we eliminate the target values and just keep the residuals for interactions (we have a loop that stores the data below, but maybe we can just copy our input data to the residuals)",1
v0.1.3,TODO : eliminate the counts here and use pointers,1
v0.1.3,TODO : eliminate the counts here and use pointers,1
v0.1.3,TODO : do loop here,1
v0.1.3,TODO : do loop here,1
v0.1.3,"this is here to catch exceptions from (TODO is this required?), but it could also catch errors if we put any other C++ types in here later",1
v0.1.3,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.2,NOTE: Numpy here is a workaround to skope-rules' dependencies.,1
v0.1.2,TODO: Dashboard needs to be tested.,1
v0.1.2,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.2,"TODO: Remove this, we don't use this anymore nor expose it.",1
v0.1.2,NOTE: Workaround for tables not rendering,1
v0.1.2,TODO: Consider reducing complexity of this function.,1
v0.1.2,NOTE: Workaround for tables not rendering,1
v0.1.2,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.2,TODO: Revisit when we support custom tabs from users.,1
v0.1.2,TODO: Make kwargs explicit.,1
v0.1.2,TODO: State criteria in docs.,1
v0.1.2,Todo: check if this call,1
v0.1.2,TODO: Fix this once we know it works.,1
v0.1.2,TODO: Work with ordinal later.,1
v0.1.2,TODO: Clean up,1
v0.1.2,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.2,TODO: Add unit tests for internal EBM interfacing,1
v0.1.2,TODO: Update documentation for training/val scores args.,1
v0.1.2,TODO: More documentation in binning process to be explicit.,1
v0.1.2,TODO: Consider stripping this down to the bare minimum.,1
v0.1.2,TODO: Remove this.,1
v0.1.2,TODO: Review NA as we don't support it yet.,1
v0.1.2,TODO: Clean up,1
v0.1.2,TODO: Clean this up before release.,1
v0.1.2,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.2,TODO optimize the next few lines,1
v0.1.2,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.2,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.2,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.2,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.2,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.2,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.2,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.2,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.2,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.2,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.2,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.2,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.2,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.2,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.2,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.2,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.2,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.2,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.2,TODO: can I put the SamplingWithoutReplacement bit into the data if I separate my data out by sample?,1
v0.1.2,"TODO : right now we need to keep these arround and separate but we can eliminate them in the future... and we already know the number of attributes at startup since that's done outside our core module, so we can just allocate the correct number of them.  And combine them for both training and validation since they both use the same parameters.  For now we need to keep these arround so that our Attributes aren't deleted",1
v0.1.2,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.2,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.2,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.2,TODO: can this be merged with the InitializeInteractionErrorCore function in the TransparentMLCoreTraining.cpp file,1
v0.1.2,TODO: handle null in pPredictionScores like we did for training,1
v0.1.2,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.2,"TODO : can we eliminate the target values and just keep the residuals for interactions (we have a loop that stores the data below, but maybe we can just copy our input data to the residuals)",1
v0.1.2,TODO : eliminate the counts here and use pointers,1
v0.1.2,TODO : eliminate the counts here and use pointers,1
v0.1.2,TODO : do loop here,1
v0.1.2,TODO : do loop here,1
v0.1.2,"this is here to catch exceptions from (TODO is this required?), but it could also catch errors if we put any other C++ types in here later",1
v0.1.2,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.1,NOTE: Numpy here is a workaround to skope-rules' dependencies.,1
v0.1.1,TODO: Dashboard needs to be tested.,1
v0.1.1,TODO: Provide example in docstrings of share_tables usage.,1
v0.1.1,"TODO: Remove this, we don't use this anymore nor expose it.",1
v0.1.1,NOTE: Workaround for tables not rendering,1
v0.1.1,TODO: Consider reducing complexity of this function.,1
v0.1.1,NOTE: Workaround for tables not rendering,1
v0.1.1,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.1,TODO: Revisit when we support custom tabs from users.,1
v0.1.1,TODO: Make kwargs explicit.,1
v0.1.1,TODO: State criteria in docs.,1
v0.1.1,Todo: check if this call,1
v0.1.1,TODO: Fix this once we know it works.,1
v0.1.1,TODO: Work with ordinal later.,1
v0.1.1,TODO: Clean up,1
v0.1.1,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.1,TODO: Add unit tests for internal EBM interfacing,1
v0.1.1,TODO: Update documentation for training/val scores args.,1
v0.1.1,TODO: More documentation in binning process to be explicit.,1
v0.1.1,TODO: Consider stripping this down to the bare minimum.,1
v0.1.1,TODO: Remove this.,1
v0.1.1,TODO: Review NA as we don't support it yet.,1
v0.1.1,TODO: Clean up,1
v0.1.1,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.1,TODO optimize the next few lines,1
v0.1.1,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.1,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.1,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.1,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.1,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.1,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.1,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.1,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.1,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.1,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.1,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.1,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.1,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.1,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.1,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.1,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.1,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.1,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.1,TODO: can I put the SamplingWithoutReplacement bit into the data if I separate my data out by sample?,1
v0.1.1,"TODO : right now we need to keep these arround and separate but we can eliminate them in the future... and we already know the number of attributes at startup since that's done outside our core module, so we can just allocate the correct number of them.  And combine them for both training and validation since they both use the same parameters.  For now we need to keep these arround so that our Attributes aren't deleted",1
v0.1.1,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.1,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.1,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.1,TODO: can this be merged with the InitializeInteractionErrorCore function in the TransparentMLCoreTraining.cpp file,1
v0.1.1,TODO: handle null in pPredictionScores like we did for training,1
v0.1.1,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.1,"TODO : can we eliminate the target values and just keep the residuals for interactions (we have a loop that stores the data below, but maybe we can just copy our input data to the residuals)",1
v0.1.1,TODO : eliminate the counts here and use pointers,1
v0.1.1,TODO : eliminate the counts here and use pointers,1
v0.1.1,TODO : do loop here,1
v0.1.1,TODO : do loop here,1
v0.1.1,"this is here to catch exceptions from (TODO is this required?), but it could also catch errors if we put any other C++ types in here later",1
v0.1.1,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
v0.1.0,NOTE: Numpy here is a workaround to skope-rules' dependencies.,1
v0.1.0,TODO: Dashboard needs to be tested.,1
v0.1.0,NOTE: Workaround for tables not rendering,1
v0.1.0,TODO: Consider reducing complexity of this function.,1
v0.1.0,NOTE: Workaround for tables not rendering,1
v0.1.0,NOTE: Fixes concurrency bug for panes. Find better solution.,1
v0.1.0,TODO: Revisit when we support custom tabs from users.,1
v0.1.0,TODO: Make kwargs explicit.,1
v0.1.0,TODO: State criteria in docs.,1
v0.1.0,Todo: check if this call,1
v0.1.0,TODO: Fix this once we know it works.,1
v0.1.0,TODO: Work with ordinal later.,1
v0.1.0,TODO: Clean up,1
v0.1.0,"NOTE: Missing not implemented at native, always set to false.",1
v0.1.0,TODO: Add unit tests for internal EBM interfacing,1
v0.1.0,TODO: Update documentation for training/val scores args.,1
v0.1.0,TODO: More documentation in binning process to be explicit.,1
v0.1.0,TODO: Consider stripping this down to the bare minimum.,1
v0.1.0,TODO: Remove this.,1
v0.1.0,TODO: Review NA as we don't support it yet.,1
v0.1.0,TODO: Clean up,1
v0.1.0,TODO: Throw ValueError like scikit for 1d instead of 2d arrays,1
v0.1.0,TODO optimize the next few lines,1
v0.1.0,TODO there might be a nicer way to expand this at allocation time (fill with zeros is easier),1
v0.1.0,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.0,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.0,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.0,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.0,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.0,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.0,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.0,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.0,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.0,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.0,TODO : jumping back into this loop and changing cItemsRemaining to a dynamic value that isn't compile time determinable,1
v0.1.0,TODO : this is no longer a prediction for multiclass.  It is a weight.  Change all instances of this naming. -> validationLogWeight,1
v0.1.0,TODO : consider replacing iVector with pValidationPredictionScoresInnerEnd,1
v0.1.0,"TODO : try replacing cItemsRemaining with a pResidualErrorInnerLoopEnd which eliminates one subtact operation, but might make it harder for the compiler to optimize the loop away",1
v0.1.0,TODO : perhaps we should change m_cStates into m_iStateMax so that we don't need to do the above promotion to 64 bits.. we can make it <= 0xFFFFFFFF.  Write a function to fill the lowest bits with ones for any number of bits,1
v0.1.0,"TODO : when we thread this code, let's have each thread take a lock and update the combined line segment.  They'll each do it while the others are working, so there should be no blocking and our final result won't require adding by the main thread",1
v0.1.0,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.0,TODO: can I put the SamplingWithoutReplacement bit into the data if I separate my data out by sample?,1
v0.1.0,"TODO : right now we need to keep these arround and separate but we can eliminate them in the future... and we already know the number of attributes at startup since that's done outside our core module, so we can just allocate the correct number of them.  And combine them for both training and validation since they both use the same parameters.  For now we need to keep these arround so that our Attributes aren't deleted",1
v0.1.0,TODO : can I extract the stuff below into a function that can be templated?,1
v0.1.0,"TODO : in the future don't copy over all SegmentedRegions.  We only need to copy the ones that changed, which we can detect if we use a linked list and array lookup for the same data structure",1
v0.1.0,TODO : move the target bits branch inside TrainingSetInputAttributeLoop to here outside instead of the attribute combination.  The target # of bits is extremely predictable and so we get to only process one sub branch of code below that.  If we do attribute combinations here then we have to keep in instruction cache a whole bunch of options,1
v0.1.0,TODO: can this be merged with the InitializeInteractionErrorCore function in the TransparentMLCoreTraining.cpp file,1
v0.1.0,TODO: handle null in pPredictionScores like we did for training,1
v0.1.0,"TODO: this works as a way to remove one parameter, but it obviously insn't as efficient as omitting the parameter",1
v0.1.0,"TODO : can we eliminate the target values and just keep the residuals for interactions (we have a loop that stores the data below, but maybe we can just copy our input data to the residuals)",1
v0.1.0,TODO : eliminate the counts here and use pointers,1
v0.1.0,TODO : eliminate the counts here and use pointers,1
v0.1.0,TODO : do loop here,1
v0.1.0,TODO : do loop here,1
v0.1.0,"this is here to catch exceptions from (TODO is this required?), but it could also catch errors if we put any other C++ types in here later",1
v0.1.0,"TODO : be smarter about our CachedInteractionThreadResources, otherwise why have it?",1
